[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e558908a-3c8f-4bdf-bb0e-af743dad883c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92141a5f-556f-422c-ad87-1da9bd7f11f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b4fea43-ae62-415d-b049-efbc1a0fe3bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6766eb70-585a-4b86-bf59-3e5d4b80e0ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d34cc90-01ec-4de9-8814-0875089e4abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c76af36f-6f9f-4512-a464-3cc70000c7a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 323702af-267a-49ca-ae67-d32c964e2301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3832595-8a2c-4d39-9989-794c91698eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eddf92f-ede6-4d41-b66c-a35407d5c6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f07c2b6d-6e56-4aad-8d57-dd3526727591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1537d146-2602-45a1-840d-db5b140dd258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7ddef56-8bf0-4b0b-b29f-db1a8f3e6e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84a767a4-d44f-462d-898d-d661ccd4bad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c75e879f-396b-4ad2-8b97-2bafdbbce29d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22129160-4eb0-420e-9348-025087427a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dabeb799-7980-49b9-b8e2-45828e505154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4152ab43-6594-4f01-ab44-5ced7b73a576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f93b68-4196-4210-824e-36216f24fa49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a07f251-bd42-4a67-9c02-462e7cc9447c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91322a3b-7f27-4ce5-84e7-f2789a42a870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73bc059d-610b-477d-ae02-ac5aa054ef95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b7612e2-6f56-49ff-9ed5-e35b1570f54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a98f7b-b8d1-4564-b972-66ee1e61b017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec5b2518-a18f-4e2d-8e79-d3bfa97ba12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5500fbb-b75a-4c93-93b1-e2632e7f7212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f7e0a6-684c-4705-8e73-7220fe8a6fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2329b64-65f2-4a49-b170-6dcef764e06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 328ef480-8c07-4857-8067-1bde97d34021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b601c05d-04e7-4129-8c5a-273dfba59c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33b3d887-2acd-4d18-a2ee-9b6b4591c8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c5c762d-ad97-4d01-8436-d00f23c0564b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a2ebe7-a7ca-42b9-b0cf-37f1bbae986e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2dfaea4-174f-44fd-bb31-913a3b3e492c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d291534-d500-4b05-b6a4-619d7e4aad78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5055a5ac-a5b2-44e1-bb56-a657d860159d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcfe2f71-451e-4776-bd8f-03788c8b5b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d6d2a40-a1ff-4b6d-86aa-e8bc1fd32ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a201c25d-dc4d-46c2-ac36-4b8c12f7a2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c2adf9e-808c-4cf6-994e-f88d7d0fa943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56f76e22-1a40-49b4-b45a-7ad340a18960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0349a59-8fee-4470-acae-0aac02c3bfd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17f56a54-9f71-4997-88b6-fa343bd74fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09adc7f9-21c0-497e-92a8-3663a5ac2bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50380b03-b49e-47bd-83ef-4b537dfba3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e29aa80-3227-4263-a90f-3353294ad3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 410e35f5-c32b-4b4d-a9e6-8855d4198e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22cb42ec-39e3-49a3-bb4b-cdb3255e42da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 260443a8-975e-4b18-acb3-e021b9a1e755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a2f6de3-8a3b-4780-9aa0-1f009f4f6dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47f02a61-6be9-4d2c-8790-aa843d20b1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc0cc1c-9f0e-4ff6-b21f-20f437f7cae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd8c3ac2-e4e6-4455-a7c8-9bed154ec686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13bda478-f316-4a74-9c42-e567aaee2eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86f87aa2-ffcc-4b30-a84b-9ea168382a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2dbf701-5895-4fda-99d0-e507a8d9bc88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2716ebf4-bbd3-4820-bba3-66b04bef1ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51ce0f10-523b-472f-80fb-e62660ca90e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bb50d49-be02-49fc-a073-10b9392fe429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d8439d6-e5f2-4ba7-b7fd-6e28fc3fc458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 890c0b7d-2c09-494b-91ff-8ede349a9f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d686dbd0-24e3-46fe-8de3-31818e17777f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca80b9e2-e73c-4691-8526-52a364b3d364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e5f394-fce9-47de-bb9e-8ef811911bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5bd82c6-6cdc-457b-9dd4-0c8ebeb072a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d03bbd8-c7a1-4486-a83f-8efa5c387505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec8eba68-4f98-471d-bea1-668c2904650d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b49137f6-6f0e-4d9e-b641-1ba946ac3034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c9f2860-ffbb-4c8a-9cb0-98bc1d08cca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2eaa779-76d7-4ae3-93a6-0721ad6a4d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0478168b-7561-49c2-a6c4-afcd74073d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65699b39-df80-4c96-a98e-1fda269bdf94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 361d737c-b32b-4555-aa4d-575d3ff93918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70d70434-6a06-4537-ad0c-11425dd20c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beae2e23-32da-4540-9d10-c8fb060c11a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dda3b2c-b90a-4fd6-8fb8-249052b77f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bcea0fa-0072-4a11-ad42-6cf67d2328be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ca594e5-a23c-4ffa-9cf5-7c71626bd17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7404730-bd75-40e7-bedc-4558ea24b0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c6c4708-d12b-46eb-bc5f-0cb76a74af67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18069e3-9b7a-457a-81de-b84c576d51d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb95a0e-aae4-4e4e-9c9a-148b4993dc69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f0210c8-0824-4a16-bfd1-d29ab4deac51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61e96805-056e-484e-bc49-8e6f5bfc0424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c80218f4-5d98-4ed2-a9ef-a8abd7efd85f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39935440-1830-4928-aef1-fcc56745e98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 936e9f7a-0368-4a37-b559-7ed1fb57ff7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19d78ebd-b374-4581-bedf-8e3b55d9edce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ed449c-592a-40d2-b607-075430959454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c20932b-6b94-49e2-bc30-484eeeeb5390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bc37341-3b3e-4bb2-946c-ab284f726da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdd10a71-9373-4f78-b82c-c7e127654a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 766ad758-223e-4c51-824b-3dc3aceaec62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 255117e3-ac81-4365-ae45-9af0bc3ed63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70484a29-782d-446c-8b1f-c7f73d48d8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbb1793a-69d6-4d9e-81ae-e932bcc5e46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29879c15-dff5-4a83-8832-d5d251b25134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee94340-2a50-434d-a843-1658c6aa7fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb138614-5db0-482d-b20f-7a4a434515a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aa9fb4c-6334-4067-90a7-f8fe1ea0d311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ddcb1bf-72d2-4c51-8fbc-b28d27c05087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27f852dc-0304-45e0-bc1a-e646d60303af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddccc2e5-cb90-44f2-93c6-c8477fdfd84b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed1b27a9-b5ce-44a2-8d53-095bdd606800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14a1c71-1516-468f-b264-e63932c38850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 288b4185-d899-4d6e-8a58-5fafd1f167c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c7b2d20-a89c-4166-820d-91e5339ba9e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa4ad853-c84f-44bb-92bc-c211e4d42797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57205fd9-c4f2-4f6d-bd26-1431c7325e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bebf806-2b46-4b15-a1a5-1296bc75c549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 048aedf2-8e8f-46e5-ab65-546bb7e3ac3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad12fa88-4367-4dcc-9746-25546b29fec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f226af23-098f-4172-9433-9942c7bf4dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83dd5f1c-fc21-4d53-87f2-75c0a3750567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef659ef-1168-4d19-b7be-78d134b7f830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 805f9e21-2f99-4027-870d-7592f7a2d7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb97a69-2439-4dd1-a07c-ef0690d59dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59100888-4cf8-4931-93d0-95a4c0446b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fccb4bb9-9b4f-4a48-a737-e8c162d6bc8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f9f7cdf-50da-4836-bbe5-c8f6ea6a7f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c27411f-8f0a-48ee-9f82-59e55b72c6de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b06de095-0dfa-4e04-8763-69bc85af876a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2afe6aa-a120-430b-bb6e-aecbd8ab26d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 614831fc-721b-44c1-b107-921fc191983f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df46e7ce-21d0-42f6-9ecf-a8796e2083c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00a1093d-a976-4899-b238-9d90d642c761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac595f6e-1e9c-4c36-8adb-f49a53ecc1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e9edb3-16f9-40c1-b6a2-3c31b44f5cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b192b731-821c-4a91-a0a3-0e2d233bb7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86a528b8-78b5-48a7-b108-86c96d696c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf958f38-d9c9-4259-bde0-311395eff682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0916cd9-a828-49f8-b6b6-af13bbb8c109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5820cd96-271f-4f47-a8c2-b2f8df1a9fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03788ac1-5033-4758-b736-b91237fb1aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0147630-5b38-4657-bb56-9f853bb7e4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 455da867-8f67-467d-8ad0-bd36c3f495e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 640cbb77-1df5-488d-b0d7-4fee9be524f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0ccc79f-4455-48b5-9a5a-96d393802339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cd60ab3-bcea-4c64-9ee7-929d4c2a174f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3154fb3-26ef-49fe-9914-fb9f291b62f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72c18531-6c2d-4b50-9e27-55ef4478cbe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bfd898b-395b-4e7b-88f7-f3f1de9aa611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fd35e6b-4438-4fbf-90a9-04bca015b21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fedaf27-f837-4734-a3a1-15978bf14461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a61d007f-2587-4a17-9fa3-cdaa5fec8a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03af84ae-73c0-4bd9-9084-71b574777acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594632ae-1c5b-4133-beae-8214adae18da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09509bfe-54de-4db6-b048-5cff0b6c6996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb92eab6-d901-4e02-9c2d-b45072ab0e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a88f5f15-399d-4b47-8fd9-30b65e1a43f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2fcf47f-c649-46a3-aeb1-d7c805546662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 695c620d-f232-4d60-9e9c-9ec14840675e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72acbe0-caf9-491c-8517-c2bd756b34a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c624732-8124-41e7-864d-ce2f58711ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 483e870d-4ff1-48d6-ab35-a2e707b8c59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 620d6da4-acf5-4615-b0eb-5db45f0bf880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d259566-09ff-4ded-b67c-195444f0e1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94014c86-8928-4c79-8b5f-6191ea67a507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2858e40-91ca-4510-a55f-a62364032cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d61eaf-30ac-49b6-83c7-6112e6d66e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2510787-b883-4b90-9653-46c970a2d066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cd0f75c-83ec-49be-a9e4-b59051c272c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0efd787c-df6e-4e72-bafe-90b33c0f01e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a31e5a2-c66b-416e-b2c7-3da11ceddc1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6120fc9-88e1-4331-97c6-4d02e2872fc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8cc1677-327a-46f9-ac43-e00e5248c95c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_57
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/test_labels.txt

📊 Raw data loaded:
   Train: X=(1626, 24), y=(1626,)
   Test:  X=(407, 24), y=(407,)

⚠️  Limiting training data: 1626 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  398 samples, 5 features
✅ Client client_57 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1754, RMSE: 0.4188, MAE: 0.3380, R²: -1.1399

============================================================
🔄 Round 8 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1101, val=0.0785 (↓), lr=0.001000
   • Epoch   2/100: train=0.0851, val=0.0786, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0848, val=0.0778 (↓), lr=0.001000
   • Epoch   4/100: train=0.0845, val=0.0780, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0843, val=0.0783, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0832, val=0.0790, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 8 Summary - Client client_57
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0095
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0084
============================================================


============================================================
🔄 Round 9 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1369, val=0.1214 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0883, val=0.0943 (↓), lr=0.000250
   • Epoch   3/100: train=0.0819, val=0.0948, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0806, val=0.0952, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0805, val=0.0954, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0801, val=0.0957, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 9 Summary - Client client_57
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0066
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0016
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1631, RMSE: 0.4039, MAE: 0.3256, R²: -0.9899

============================================================
🔄 Round 13 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1349, val=0.1471 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1161, val=0.1240 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1001, val=0.1055 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0893, val=0.0931 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0843, val=0.0873 (↓), lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0828, val=0.0857, patience=5/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0826, val=0.0859, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 13 Summary - Client client_57
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0019
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0306
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1481, RMSE: 0.3848, MAE: 0.3107, R²: -0.8066

📊 Round 13 Test Metrics:
   Loss: 0.1380, RMSE: 0.3715, MAE: 0.3009, R²: -0.6842

============================================================
🔄 Round 15 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.1294, val=0.1308 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1258, val=0.1279 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1232, val=0.1251 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1207, val=0.1225 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1184, val=0.1200 (↓), lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1079, val=0.1092 (↓), lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1015, val=0.1023 (↓), lr=0.000002
   📉 Epoch 25: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.0991, val=0.0997 (↓), lr=0.000001
   • Epoch  41/100: train=0.0975, val=0.0980, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0961, val=0.0964, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0948, val=0.0949, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0936, val=0.0935, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0925, val=0.0922, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0914, val=0.0909, patience=2/15, lr=0.000001

============================================================
📊 Round 15 Summary - Client client_57
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=-0.0759
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.1185
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1332, RMSE: 0.3649, MAE: 0.2962, R²: -0.6249

============================================================
🔄 Round 16 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1267, val=0.1289 (↓), lr=0.000001
   • Epoch   2/100: train=0.1264, val=0.1287, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1261, val=0.1284 (↓), lr=0.000001
   • Epoch   4/100: train=0.1259, val=0.1281, patience=1/15, lr=0.000001
   • Epoch   5/100: train=0.1256, val=0.1279, patience=2/15, lr=0.000001
   • Epoch  11/100: train=0.1241, val=0.1265, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1218, val=0.1244 (↓), lr=0.000001
   • Epoch  31/100: train=0.1196, val=0.1224, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1176, val=0.1206, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1156, val=0.1187 (↓), lr=0.000001
   • Epoch  61/100: train=0.1137, val=0.1170, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1118, val=0.1153, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.1100, val=0.1136, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1082, val=0.1120 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_57
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1065, RMSE=0.3264, R²=-0.2900
   Val:   Loss=0.1106, RMSE=0.3326, R²=-0.2614
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1146, RMSE: 0.3385, MAE: 0.2793, R²: -0.3976

============================================================
🔄 Round 18 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1075, val=0.1187 (↓), lr=0.000001
   • Epoch   2/100: train=0.1074, val=0.1185, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1072, val=0.1183, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1070, val=0.1181 (↓), lr=0.000001
   • Epoch   5/100: train=0.1069, val=0.1180, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1059, val=0.1168, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1043, val=0.1149, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1028, val=0.1131 (↓), lr=0.000001
   • Epoch  41/100: train=0.1013, val=0.1113, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0998, val=0.1096, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0984, val=0.1079 (↓), lr=0.000001
   • Epoch  71/100: train=0.0970, val=0.1062, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0957, val=0.1046, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0945, val=0.1031, patience=3/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_57
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0935, RMSE=0.3057, R²=-0.1243
   Val:   Loss=0.1017, RMSE=0.3190, R²=-0.1978
============================================================


============================================================
🔄 Round 19 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0962, val=0.1077 (↓), lr=0.000001
   • Epoch   2/100: train=0.0960, val=0.1076, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0959, val=0.1074, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0958, val=0.1072, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0956, val=0.1071 (↓), lr=0.000001
   • Epoch  11/100: train=0.0949, val=0.1061, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0936, val=0.1045 (↓), lr=0.000001
   • Epoch  31/100: train=0.0924, val=0.1030, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0912, val=0.1016 (↓), lr=0.000001
   • Epoch  51/100: train=0.0902, val=0.1002, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0892, val=0.0989 (↓), lr=0.000001
   • Epoch  71/100: train=0.0882, val=0.0976, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0874, val=0.0965, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0866, val=0.0954, patience=1/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_57
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0439
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0879
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0921, RMSE: 0.3034, MAE: 0.2581, R²: -0.1231

📊 Round 19 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2522, R²: -0.0489

============================================================
🔄 Round 22 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 22 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0172
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0059
============================================================


============================================================
🔄 Round 24 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 24 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0054
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0041
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2500, R²: -0.0189

============================================================
🔄 Round 26 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 26 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0018
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0102
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2498, R²: -0.0162

📊 Round 26 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2498, R²: -0.0160

============================================================
🔄 Round 31 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 31 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0025
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0019
============================================================


============================================================
🔄 Round 32 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 32 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0025
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0013
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2495, R²: -0.0134

📊 Round 32 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2495, R²: -0.0127

============================================================
🔄 Round 39 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 39 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0049
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0088
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2495, R²: -0.0122

============================================================
🔄 Round 43 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 43 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0029
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0030
============================================================


============================================================
🔄 Round 44 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 44 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0016
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0032
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2494, R²: -0.0117

============================================================
🔄 Round 51 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 51 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0005
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0066
============================================================


============================================================
🔄 Round 52 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 52 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0008
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0137
============================================================


============================================================
🔄 Round 53 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 53 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0032
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0051
============================================================


============================================================
🔄 Round 54 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 54 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0006
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0068
============================================================


============================================================
🔄 Round 57 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 57 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0037
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0065
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2494, R²: -0.0109

📊 Round 57 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2494, R²: -0.0109

📊 Round 57 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2494, R²: -0.0108

============================================================
🔄 Round 63 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 63 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0001
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0077
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2494, R²: -0.0107

📊 Round 63 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2494, R²: -0.0107

📊 Round 63 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2494, R²: -0.0106

📊 Round 63 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2493, R²: -0.0106

============================================================
🔄 Round 68 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 68 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0025
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0107
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2493, R²: -0.0106

============================================================
🔄 Round 69 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 69 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0010
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0079
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2493, R²: -0.0105

📊 Round 69 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2493, R²: -0.0103

============================================================
🔄 Round 72 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 72 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0002
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0079
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2493, R²: -0.0102

============================================================
🔄 Round 74 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 74 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0039
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0062
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2493, R²: -0.0101

============================================================
🔄 Round 75 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 75 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0015
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0453
============================================================


============================================================
🔄 Round 78 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 78 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0040
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0017
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2493, R²: -0.0099

============================================================
🔄 Round 80 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 80 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0026
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0004
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2493, R²: -0.0098

============================================================
🔄 Round 82 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 82 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0001
   Val:   Loss=0.0790, RMSE=0.2812, R²=-0.0074
============================================================


============================================================
🔄 Round 83 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 83 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0008
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0159
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2493, R²: -0.0097

📊 Round 83 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2493, R²: -0.0097

📊 Round 83 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2493, R²: -0.0097

============================================================
🔄 Round 86 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 86 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0012
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0101
============================================================


============================================================
🔄 Round 87 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 87 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0024
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0409
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2493, R²: -0.0097

============================================================
🔄 Round 91 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 91 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0028
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0043
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2492, R²: -0.0093

📊 Round 91 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2492, R²: -0.0092

============================================================
🔄 Round 96 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 96 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0015
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0254
============================================================


============================================================
🔄 Round 97 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 97 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0003
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0209
============================================================


============================================================
🔄 Round 98 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 98 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0009
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0032
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2492, R²: -0.0092

============================================================
🔄 Round 100 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 100 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0024
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0014
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2492, R²: -0.0090

============================================================
🔄 Round 104 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 104 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0044
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0049
============================================================


============================================================
🔄 Round 105 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 105 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0033
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0043
============================================================


============================================================
🔄 Round 106 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 106 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0015
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0037
============================================================


============================================================
🔄 Round 107 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 107 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0028
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0018
============================================================


============================================================
🔄 Round 109 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 109 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0032
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0039
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2492, R²: -0.0088

============================================================
🔄 Round 110 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 110 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0036
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0064
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2492, R²: -0.0087

============================================================
🔄 Round 116 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 116 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0025
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0084
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2492, R²: -0.0087

============================================================
🔄 Round 118 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 118 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0009
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0191
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2492, R²: -0.0087

============================================================
🔄 Round 124 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 124 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0015
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0078
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2492, R²: -0.0085

============================================================
🔄 Round 126 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 126 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0022
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0068
============================================================


============================================================
🔄 Round 127 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 127 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0002
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0064
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2492, R²: -0.0084

📊 Round 127 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2492, R²: -0.0084

============================================================
🔄 Round 131 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 131 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0001
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0112
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2492, R²: -0.0084

============================================================
🔄 Round 132 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 132 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0003
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0056
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2492, R²: -0.0083

============================================================
🔄 Round 133 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 133 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0021
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0003
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2492, R²: -0.0083

📊 Round 133 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2492, R²: -0.0083

============================================================
🔄 Round 136 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 136 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0022
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0149
============================================================


============================================================
🔄 Round 138 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 138 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0013
   Val:   Loss=0.0728, RMSE=0.2697, R²=-0.0026
============================================================


============================================================
🔄 Round 139 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 139 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0014
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0125
============================================================


============================================================
🔄 Round 141 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 141 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0003
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0081
============================================================


============================================================
🔄 Round 142 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 142 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0003
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0060
============================================================


============================================================
🔄 Round 143 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 143 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0005
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0059
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2492, R²: -0.0082

============================================================
🔄 Round 144 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 144 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0003
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0056
============================================================


============================================================
🔄 Round 145 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 145 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0026
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0478
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2492, R²: -0.0083

============================================================
🔄 Round 147 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 147 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0003
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0063
============================================================


============================================================
🔄 Round 148 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 148 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0024
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0141
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2492, R²: -0.0083

📊 Round 148 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2492, R²: -0.0083

============================================================
🔄 Round 152 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 152 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0004
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0084
============================================================


============================================================
🔄 Round 154 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 154 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0031
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0202
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2492, R²: -0.0082

📊 Round 154 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2492, R²: -0.0081

============================================================
🔄 Round 158 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 158 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0020
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0064
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2492, R²: -0.0081

============================================================
🔄 Round 160 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 160 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0013
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0015
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2492, R²: -0.0081

============================================================
🔄 Round 162 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 162 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0021
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0026
============================================================


============================================================
🔄 Round 163 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 163 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0018
   Val:   Loss=0.0953, RMSE=0.3086, R²=0.0001
============================================================


============================================================
🔄 Round 164 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 164 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0006
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0116
============================================================


============================================================
🔄 Round 166 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 166 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0026
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0044
============================================================


============================================================
🔄 Round 167 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 167 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0001
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0063
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0079

============================================================
🔄 Round 168 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 168 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0016
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0128
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0078

============================================================
🔄 Round 171 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 171 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0012
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0019
============================================================


============================================================
🔄 Round 172 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 172 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0015
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0069
============================================================


============================================================
🔄 Round 173 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 173 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0014
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0074
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0077

============================================================
🔄 Round 174 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 174 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0024
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0052
============================================================


============================================================
🔄 Round 177 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 177 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0011
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0138
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0077

============================================================
🔄 Round 178 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 178 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0016
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0015
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0077

============================================================
🔄 Round 179 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 179 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0000
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0265
============================================================


============================================================
🔄 Round 182 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 182 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0008
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0061
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0077

============================================================
🔄 Round 184 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 184 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0009
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0026
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0076

============================================================
🔄 Round 186 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 186 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0017
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0062
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0077

============================================================
🔄 Round 190 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 190 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0010
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0021
============================================================


============================================================
🔄 Round 191 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 191 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0012
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0016
============================================================


============================================================
🔄 Round 193 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 193 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0015
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0100
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0075

============================================================
🔄 Round 195 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 195 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0023
   Val:   Loss=0.0947, RMSE=0.3078, R²=0.0008
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0075

============================================================
🔄 Round 198 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 198 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0024
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0007
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0076

📊 Round 198 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0075

============================================================
🔄 Round 201 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 201 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0011
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0013
============================================================


============================================================
🔄 Round 202 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 202 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0018
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0016
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0074

============================================================
🔄 Round 204 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 204 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0029
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0051
============================================================


============================================================
🔄 Round 205 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 205 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0029
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0010
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0075

============================================================
🔄 Round 206 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 206 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0017
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0009
============================================================


============================================================
🔄 Round 207 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 207 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0024
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0033
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0074

📊 Round 207 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0075

============================================================
🔄 Round 211 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 211 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0018
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0014
============================================================


❌ Client client_57 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
