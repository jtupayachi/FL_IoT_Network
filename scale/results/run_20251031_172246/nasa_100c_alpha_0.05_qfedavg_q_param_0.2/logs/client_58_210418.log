[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36e2f039-b7a5-454d-94cb-9cfaf4d65a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ab743f6-1b24-40af-851e-0d15205cd1f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f762d17-3efc-4419-93db-78fbbfdbd5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57500106-f822-4b1e-8ff3-5f97c19d05a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20441092-9d44-4c77-8595-db3e34f537fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e912377-c539-4610-93b0-ae414217eed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d26696a8-011d-4e65-9d52-26f8d922b09d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6755abcb-62c9-4868-9263-8ef4050f0855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30e32aaf-c4df-4a05-bd2b-08581bcf0318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f69fe9b5-fde7-4128-bf0b-b250a05456f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff0ade65-6c08-4e84-95b0-62240c44cd4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e20a3ead-077f-4c0e-a2ea-f0e3a5edcd69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deb5de3d-6879-4a09-91ae-1687b2afc6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2637c94f-42f8-43ab-bc9b-0b0cc76768e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8651ce36-e8ba-48f8-9e11-3a039d1c39f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8959ba30-54d4-4d98-a452-704946abe9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10efa2cf-ea12-44f6-a31a-b20f062fb93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda67222-022b-4a98-8959-73510a89323a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f392e6a-5ddf-47c5-ae5b-c6d90bf201fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 155cf538-c2b2-471f-8371-8d52b6428644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1fee344-dc18-4a8f-a9da-d4a364c23ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 400981b6-9006-4f77-8b41-e9a44020eadd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3ae2d5-6a7c-4c08-b9ca-d7f094ba98b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c683aad6-e40c-4c8d-89f5-607a553778bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09806561-96f9-4f81-bf40-c127ce1e50b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb6fc836-6aed-4493-bf3b-9e1ba9645a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c05b055-9287-4df2-bc5c-142617711111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49dc4ad2-d29c-47d6-9739-38663fe63dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b51eec01-aaec-4d92-9147-e4cd9fca40df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4423c03-6551-4c9f-8454-7b6d7bbe2fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90be84b7-315f-4e34-b7c9-ea4ab92a1b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c3d2caa-ea0f-4745-a60b-b9077abfad69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2ea8311-1d4e-40b8-ab04-2f6c1966daf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de26f71c-0138-437b-857f-f17d4a396128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 831ecbbc-2412-4e07-a1b6-7dae039b44c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a9648ec-71d5-4227-aa3f-3df82de80d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c202073-ffbe-4cff-995f-d6c8273e1f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e271a94e-8575-410d-99dd-05e46f6683f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a93291a-85b6-493e-8fee-f458592c78cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f7c995a-d032-4de1-a361-672f0239e1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02e47e74-8ebd-4c08-9b51-24b7af6283dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ec81e00-108e-4197-958c-b78406e12bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77089a8e-dc6a-4558-a17f-a9c3fa28a0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d4e3115-722a-4f8a-853b-0ea34418545a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a43d43-3681-44c5-9aa8-7794e4964369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccc855da-8f9b-450b-9827-fe0a3aeb426a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab9d1b06-e978-473f-a6f6-f89e320a3dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c83dbcc2-5558-4c47-85ce-94a7290e5ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e28823b6-cf75-4224-88d0-64f73a3393ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97728dd-dfbe-47e6-89c4-e40448893cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f2071a5-d0ac-4b36-83bc-3a8bd728f80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb5e7fb-8b8a-47c9-b85e-5d968b95cc23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f78915b-caaf-49c9-a4ef-f27a5a3e792d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cb58846-7152-4013-84bd-8b9b0b08b4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0599fcad-6889-41b8-9aad-db2adb8d053e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c6665bd-0c35-409d-bd9a-3e5e60fb6469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bde786d8-8b7e-479e-81fc-2d520d4f7938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d339252c-e481-4c50-8ad9-647094cfff33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1bf57a2-3d3a-439a-9ad2-ba40295a2fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b085d347-b1f0-498a-aec8-79ba6ed7fc72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39b93efd-2b0d-4e70-b227-db47b5bc52be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69302aeb-fdde-43f6-9174-2e5f446108d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4489c59b-d455-4318-8f98-e2112c170a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97a6ebdc-8d42-4750-bcc6-c3329d1e01fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 234db80a-fdfb-42a3-9d6c-6c9fdfd19ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1fdc2b0-4e46-4b9f-8a96-a651d4c58094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e406822-81d2-4314-9486-364134e78743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7801394e-b7a2-4ef7-a6b8-f9010ef78e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c97e58a5-89be-4f66-a368-497c7e8a2b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb26dcb0-6d19-4e6e-a8b2-5af7c7daf768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52797251-2fbb-4a5c-976b-6de0ec23f8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7c86f05-4fbe-45be-9449-40ffffcdc680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b63482-4a42-4ad0-a19d-4a61ee704e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 646ac98f-5626-48cf-935c-dcb9540039cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc6ca706-0297-4c26-ab5d-1167471619cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351c2d0b-a921-47fb-a761-1fe6036b4b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58ca3bc2-0974-45cc-af81-82e916ee4016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ad578e3-d01e-4fd0-a0d6-adbcff4ff566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5de4a6c7-8c3d-4bfc-b478-984e48355d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f66a6845-8be5-4918-b998-cad93d1fd1e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d511bd4-0208-4eb2-a132-dbed9badcacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81772190-8369-43e7-b25e-22a9b6c68747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79a0ff2a-056e-4a93-bf04-87fbd34bc3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61bd7508-4490-4fcb-845a-6b8dba550a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61b15896-92df-412b-a596-c7cb18a56a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aa3bcb1-ec1e-41cb-a414-c47e72782340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c544d2f8-01f6-4342-b361-605939639236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f49e2c8-08e1-4a18-8090-5feadaea585a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a58b75bf-312b-49fe-b891-2f30d0cd89bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e1b47df-0c3b-45ae-b9c4-d673094d082e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c91c7cdc-8444-443d-89d1-92f299ad9082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 924f9171-757b-49f2-839a-9b44901a436f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4491bed-1640-4caa-b771-afedf265db34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a8c1208-016f-45a6-96ea-d8dd300dc498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a614f9-5b3c-4a9c-98c2-88b341960068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a1f2eec-5899-4a04-8fd3-15269f7bea1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bab0ae2-1271-4471-81f9-1add4ddba68e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7bb537e-30e3-47a6-a37b-a9a5a852d722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ebceef-0600-4734-899d-1d3f57bd0462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ac975ff-36f3-45ae-b1ec-a82265b4c73b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d532fd06-4370-4749-b12d-dc8de8e632d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26fbb2c9-b53e-4bd5-96a5-90d55c37624e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b16803-c4b1-4e80-9fc7-f6a49be39af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20ff7a89-bd7d-40ca-a368-c150ff71020a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe2d1528-1502-47f7-84d3-7f72bd1aec2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6b667a8-9148-4094-89d0-81ad3703e7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a71d55f-56b1-45c3-91bc-6ccd22dc096a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f77b18c7-1d40-4ca9-b716-da3650c9c800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00e50ff9-9c87-4e58-9957-4ea21c043681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 083d7072-0c03-432c-8e70-615ef37ec458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55396494-9820-4655-9f64-c6a5363c2c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ab4e8c-f5d0-4647-bd75-d65c9d933cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11a6c695-7cdb-4ed9-9b31-5696f6cece42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ccaf869-268e-4451-92e1-4a9617463315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 427b47e8-6605-4037-8ee6-a9159b2aa3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 130996cd-3b45-40b0-b624-7bd30a2c4ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48ff8643-b2a4-4e2e-a524-f35b1b56c7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b929d3bd-6fa9-4fee-b2fa-ee2e826d5380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26a4beb7-9bf5-4b56-8589-a268054cd4df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce7632a5-f634-4dc5-9997-dbf5fddf69c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ceef88-002e-4c5e-abf6-14a2b4ccf61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f701f7-d3d1-4892-918d-b8815f4169b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a96d02-2d3c-4f3f-924c-bc2868029e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77247097-9605-4ca7-bb92-ae3e7006bcce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98f39e7-c03a-47fd-a62f-01447484056c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2ab44a6-eb73-495f-872d-84650ad285f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 554a2970-8c2b-4031-adff-898279b187bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c63c4a4-817c-451f-bb6c-3f74a3da623e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43325c62-f43a-4201-ad8f-ad8ac2e22048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f14a2a9-36aa-4e7f-9a0a-39d08b46e449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2353fb8c-d71d-473f-974c-7ad1794525fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 804768ce-426e-45bc-8ce4-f4948e8c158d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f11846-aee5-4d80-ac55-9a3f998e91f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e925578f-c896-4549-87da-fb7bbc57f607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1bd7bf2-7016-4399-a191-7ca8f631ee4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 314a63ee-acd2-4a29-8c68-e6727a96905c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fae80d9-3814-46ff-a3a9-5cfa321e9d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 742b40de-f21d-409b-8593-a75545a449ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 604bbc04-5b61-4bfd-b6cb-3251f02b1053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dc42794-d61b-4402-a94a-e6311153f078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 870316ec-c1ce-4c54-8c9e-79daf41d439b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b5e81d3-96ee-4480-bcc7-c7c19fa062ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f17a08f2-b9a4-4ea6-8fae-009ea15b2d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5ee86ea-f9fb-45ec-af7b-6c27f1e8876d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b124d5db-0b48-4611-b239-798dfb1c0ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82ddd70f-e98f-4de5-adf2-c4beeff3bb30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7000583b-2452-4b9b-960e-a16c05b93db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4af24bee-1b15-47ff-8bcf-571c99530789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 762c2e9b-f127-41f2-8fb2-334b6761aa93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e563ead-f3bb-4a68-a83c-20ee3aadfe6f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_58
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/test_labels.txt

📊 Raw data loaded:
   Train: X=(864, 24), y=(864,)
   Test:  X=(217, 24), y=(217,)

⚠️  Limiting training data: 864 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  208 samples, 5 features
✅ Client client_58 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1788, RMSE: 0.4229, MAE: 0.3388, R²: -1.1518

📊 Round 0 Test Metrics:
   Loss: 0.1724, RMSE: 0.4152, MAE: 0.3317, R²: -1.0745

============================================================
🔄 Round 8 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1051, val=0.0788 (↓), lr=0.001000
   • Epoch   2/100: train=0.0834, val=0.0790, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0838, val=0.0808, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0835, val=0.0808, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0831, val=0.0802, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0815, val=0.0803, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 8 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0039
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0067
============================================================


============================================================
🔄 Round 9 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1392, val=0.1145 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0904, val=0.0817 (↓), lr=0.000250
   • Epoch   3/100: train=0.0830, val=0.0830, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0826, val=0.0829, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0825, val=0.0827, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0822, val=0.0830, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 9 Summary - Client client_58
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0163
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0019
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1601, RMSE: 0.4002, MAE: 0.3186, R²: -0.9269

============================================================
🔄 Round 14 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1347, val=0.1345 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1145, val=0.1129 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0971, val=0.0971 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0864, val=0.0889 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0824, val=0.0870 (↓), lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0815, val=0.0868, patience=6/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 14 Summary - Client client_58
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0015
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0058
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2514, R²: -0.0216

============================================================
🔄 Round 22 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0801 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.0842, val=0.0796 (↓), lr=0.000008
   • Epoch   3/100: train=0.0839, val=0.0793, patience=1/15, lr=0.000008
   • Epoch   4/100: train=0.0838, val=0.0792, patience=2/15, lr=0.000008
   ✓ Epoch   5/100: train=0.0837, val=0.0790 (↓), lr=0.000008
   • Epoch  11/100: train=0.0835, val=0.0785, patience=6/15, lr=0.000008
   • Epoch  21/100: train=0.0834, val=0.0783, patience=9/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 22 Summary - Client client_58
   Epochs: 27/100 (early stopped)
   LR: 0.000016 → 0.000008 (1 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0021
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0050
============================================================


============================================================
🔄 Round 24 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0776 (↓), lr=0.000008
   • Epoch   2/100: train=0.0845, val=0.0775, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0843, val=0.0774, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0842, val=0.0773, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0842, val=0.0772, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0840, val=0.0771, patience=2/15, lr=0.000008
   • Epoch  21/100: train=0.0839, val=0.0771, patience=12/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 24 Summary - Client client_58
   Epochs: 24/100 (early stopped)
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0002
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0091
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2507, R²: 0.0025

============================================================
🔄 Round 25 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0756 (↓), lr=0.000008
   • Epoch   2/100: train=0.0845, val=0.0757, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0843, val=0.0758, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0842, val=0.0759, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0842, val=0.0759, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0840, val=0.0762, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 25 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0090
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0011
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2508, R²: 0.0035

============================================================
🔄 Round 27 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0863 (↓), lr=0.000002
   • Epoch   2/100: train=0.0817, val=0.0863, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0817, val=0.0864, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0816, val=0.0864, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0816, val=0.0865, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0814, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 27 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0112
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0033
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2508, R²: 0.0042

============================================================
🔄 Round 28 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 28 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0033
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0142
============================================================


============================================================
🔄 Round 29 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 29 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0093
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0076
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2508, R²: 0.0050

============================================================
🔄 Round 30 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 30 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0054
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0004
============================================================


============================================================
🔄 Round 34 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 34 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0025
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0140
============================================================


============================================================
🔄 Round 35 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 35 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0004
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0322
============================================================


============================================================
🔄 Round 36 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 36 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0028
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0063
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2509, R²: 0.0064

============================================================
🔄 Round 38 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 38 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0049
   Val:   Loss=0.0983, RMSE=0.3136, R²=-0.0048
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2509, R²: 0.0066

============================================================
🔄 Round 42 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 42 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0029
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0194
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2510, R²: 0.0070

============================================================
🔄 Round 44 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 44 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0029
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0025
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2510, R²: 0.0070

============================================================
🔄 Round 47 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 47 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0046
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0053
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2510, R²: 0.0072

📊 Round 47 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2510, R²: 0.0072

============================================================
🔄 Round 54 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 54 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0018
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0067
============================================================


============================================================
🔄 Round 62 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 62 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0020
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0081
============================================================


============================================================
🔄 Round 63 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 63 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0034
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0006
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2511, R²: 0.0075

📊 Round 63 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2511, R²: 0.0075

============================================================
🔄 Round 68 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 68 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0056
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0017
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2511, R²: 0.0076

============================================================
🔄 Round 73 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 73 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0037
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0152
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2511, R²: 0.0077

📊 Round 73 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2512, R²: 0.0078

📊 Round 73 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2512, R²: 0.0078

============================================================
🔄 Round 78 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 78 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0022
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0012
============================================================


============================================================
🔄 Round 79 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 79 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0014
   Val:   Loss=0.0702, RMSE=0.2649, R²=-0.0052
============================================================


============================================================
🔄 Round 80 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 80 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0041
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0043
============================================================


============================================================
🔄 Round 81 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 81 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0044
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0055
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2512, R²: 0.0079

============================================================
🔄 Round 84 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 84 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0042
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0077
============================================================


============================================================
🔄 Round 85 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 85 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0029
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0017
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2512, R²: 0.0079

============================================================
🔄 Round 89 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 89 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0002
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0275
============================================================


============================================================
🔄 Round 91 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 91 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0010
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0094
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2512, R²: 0.0080

📊 Round 91 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2512, R²: 0.0081

============================================================
🔄 Round 98 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 98 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0022
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0001
============================================================


============================================================
🔄 Round 99 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 99 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0013
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0081
============================================================


============================================================
🔄 Round 100 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 100 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0019
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0012
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0081

============================================================
🔄 Round 103 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 103 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0029
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0004
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

============================================================
🔄 Round 105 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 105 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0012
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0057
============================================================


============================================================
🔄 Round 107 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 107 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0029
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0001
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

📊 Round 107 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

============================================================
🔄 Round 111 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 111 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0021
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0012
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

📊 Round 111 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

📊 Round 111 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

📊 Round 111 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

============================================================
🔄 Round 118 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 118 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0026
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0021
============================================================


============================================================
🔄 Round 119 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 119 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0010
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0092
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

============================================================
🔄 Round 120 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 120 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0002
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0200
============================================================


============================================================
🔄 Round 124 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 124 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0029
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0017
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2513, R²: 0.0082

📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0083

============================================================
🔄 Round 135 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 135 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0031
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0000
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0083

============================================================
🔄 Round 139 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 139 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0027
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0014
============================================================


============================================================
🔄 Round 140 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 140 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0003
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0087
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0083

============================================================
🔄 Round 142 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 142 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0004
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0151
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0083

📊 Round 142 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

📊 Round 142 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

============================================================
🔄 Round 148 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 148 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0027
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0001
============================================================


============================================================
🔄 Round 149 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 149 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0024
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0477
============================================================


============================================================
🔄 Round 150 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 150 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0011
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0077
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

📊 Round 150 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0081

============================================================
🔄 Round 153 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 153 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0013
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0075
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0081

============================================================
🔄 Round 160 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 160 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0021
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0008
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

============================================================
🔄 Round 161 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 161 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0014
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0064
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0081

============================================================
🔄 Round 163 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 163 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0026
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0040
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0081

============================================================
🔄 Round 164 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 164 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0015
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0072
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0081

📊 Round 164 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

📊 Round 164 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

📊 Round 164 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

📊 Round 164 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

============================================================
🔄 Round 170 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 170 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0020
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0017
============================================================


============================================================
🔄 Round 171 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 171 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0003
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0157
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

📊 Round 171 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

============================================================
🔄 Round 173 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 173 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0023
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0002
============================================================


============================================================
🔄 Round 174 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 174 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0025
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0040
============================================================


============================================================
🔄 Round 175 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 175 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0002
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0098
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

📊 Round 175 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

📊 Round 175 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

📊 Round 175 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

📊 Round 175 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

============================================================
🔄 Round 183 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 183 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0004
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0093
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

============================================================
🔄 Round 185 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 185 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0030
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0380
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

============================================================
🔄 Round 186 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 186 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0028
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0008
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0081

📊 Round 186 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0081

📊 Round 186 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0081

============================================================
🔄 Round 189 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 189 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0029
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0051
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0081

============================================================
🔄 Round 190 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 190 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0002
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0058
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0082

📊 Round 190 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2515, R²: 0.0082

============================================================
🔄 Round 194 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 194 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0014
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0150
============================================================


============================================================
🔄 Round 195 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 195 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0011
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0138
============================================================


============================================================
🔄 Round 196 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 196 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0013
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0055
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0081

📊 Round 196 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2514, R²: 0.0081

============================================================
🔄 Round 198 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 198 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0013
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0042
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2515, R²: 0.0081

📊 Round 198 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2515, R²: 0.0082

📊 Round 198 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2515, R²: 0.0082

============================================================
🔄 Round 205 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 205 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0026
   Val:   Loss=0.0929, RMSE=0.3049, R²=0.0038
============================================================


============================================================
🔄 Round 206 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 206 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0002
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0419
============================================================


============================================================
🔄 Round 207 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 207 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0031
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0036
============================================================


============================================================
🔄 Round 208 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 208 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0001
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0067
============================================================


============================================================
🔄 Round 209 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 209 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0019
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0003
============================================================


============================================================
🔄 Round 210 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 210 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0015
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0059
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2515, R²: 0.0081

❌ Client client_58 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
