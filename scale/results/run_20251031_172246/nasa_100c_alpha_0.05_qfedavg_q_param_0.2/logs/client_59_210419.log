[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5437f541-6c75-4b69-b7a8-3e77494c6a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca4757a2-5af3-479e-a531-137718a8cf41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b248bbbf-d16e-44b9-80f1-3c432e38be10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88760acf-3e4c-4bd5-b315-7439bdc0cc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c424e06-7439-4f7d-9b08-b0b2db703778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6909d7d-5047-49da-98a1-17cd07d50bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ced62d9-518b-44fb-b830-ee573070a295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd999f5-9f6c-4e31-aea9-90e34363edba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3d86909-b47d-465b-8494-a5dd7eaf36bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7835ee3-b5f5-4559-b20b-412acf0ba4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f4dd84c-6b4a-4c13-90ef-2dc0aa6b5f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20251251-f94b-48c4-82ba-c0bb410b6af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3200930-783c-4f82-b6f5-82c76a40a9ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2051893-4545-4d70-bf2d-0eda596e2878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e9f533-4e7e-41d7-b98a-68abe13da6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f76091d6-d7f9-4f6f-947c-75a85b08df30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3457aa38-3dbe-4161-a62a-a4c1e2a29d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ec5ec5-f84f-4f19-9e78-3255d09d72d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf84933c-5c99-4a5f-b102-5a2dce4ebfe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e126f66-2437-4059-8a95-5edbd080636b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8798c859-20dd-4f0f-8cd0-2929bce47a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d44d16-ffba-4e26-a0c5-2b8e5ec18b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 982e54b0-b15e-4ca2-afe1-b9ee174ef426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d4be0c8-7099-4d70-845a-be3d31a89e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed6033b-4450-4ecf-b024-fcb891db0ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8f43a40-2f4d-4340-a38f-9e0eb87c0769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa3bbd8-196b-43ed-a3f7-590b0b89e90f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c363feb-a433-423e-8cd1-9c0af517e357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ec55e2c-6363-4a89-a015-b12ef952fd75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5247b78-c1b6-49fb-b755-4c6e06d8ba6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ed1b45f-df88-4194-8efa-c8dce0e0f703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e3c47a-7f98-455a-a96e-9a2d58b05a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 352a0a95-ab32-43c6-8a45-1b81c9c31184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8564b46d-e8b2-4e1f-9040-ef05770aa2a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caf5ed07-fb39-4fec-b0b9-5ac5ea72fefa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d58ca72d-c058-4a4b-ac8e-87a3793e320a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f7baabb-d214-44c6-aadb-27bdbc89f187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a00fcd4-6dd6-4b15-877d-029dd5c09ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80f92b04-6a0d-4cde-8a54-9ee447f12084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f5a85b-4bc1-4e9c-bd5a-641c22fe5b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453b5f80-5e90-4ff4-b550-42f8c2791549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b734b19d-fa13-4341-909a-bd9bc5f4f6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29955304-0bb1-4de1-8ca0-99b69449b105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba59655-f5b5-4cd6-ba2b-c051805d6c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 261a968c-e4c8-4984-b655-674b081eee4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 467c72f2-a7b7-4553-b6ec-0e061581a19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f134b3-0518-43e8-bca5-e2b15651054b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a739f5af-3ca5-46ea-8100-18d8e7cec3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3fd693e-9cf6-4ab3-be05-938309544f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 924cbf0c-451d-4b2d-8b1b-3825d157bb9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 214ee201-84a8-4145-a11e-42cb2fdd4ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a37379c0-60b6-4689-a70a-d65a48c290bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67a2897-49a0-4f75-8b22-c69cab517947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbb78d48-06a1-41a7-a49f-a6c6745d1ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0958450c-8c16-4e22-9322-bacc2bcef25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f1e4ba-286b-4bfb-8704-046fc43fbcb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 111e1786-9655-475e-b274-d78ca55c0f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa22c9ce-d1cd-437b-a1d2-f71e542395b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88f6eadd-3d59-4266-9569-8d646f7a49d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bfdf026-99c9-42c6-ba00-261215f555a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d7c1913-a8f3-42e8-b6dc-587ea38254e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59d8da00-23d7-494d-b344-53f189a96bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b7025be-fce6-4150-bdc5-0b9a2a69260b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d34ed53c-18de-402d-8406-eb97968ba32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8477fac2-f6b4-4e90-8815-426d289954af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b8b749-9cd4-4f41-9a89-a9088ecfbca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3951d170-ff62-4ad4-b0bf-3d16d90a77d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41076c00-d5e9-4a56-a16e-40f055c6c6f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0891ae19-9461-4dff-9362-434d1cd5a23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad2486a-ba7f-46dc-994c-19c61a867c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cec8c4d0-2e79-429c-924e-6c2dc1ca6ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a4ead5b-270b-4a00-8772-435645c2faf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86701279-2656-47a9-a28c-502c41878b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2303a32-f11d-4bd8-9670-c74f956e22f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77b28ad6-2fe8-4f07-bc5d-6c9d70ff4399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 011b6007-2761-45af-b01d-9384deb690ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090156d2-2a86-4a8f-9433-38e4044c1834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22648fcf-d816-46d4-9bdb-ec1cab9c44a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a86807cc-2b3a-4565-bfbd-a3136cef0639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c408877-4b05-453a-915c-cbf21a86bf4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af1e315a-c540-4ecd-a46c-3d4318968dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bad21fc-06e2-4028-9841-34e4cb1c1dbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96f2c761-3e08-4f48-ae5f-e0beb5d3bdb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3eab762-57b1-4f93-bdd1-e67dd213851c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a4782c9-e69b-466d-8268-d4a7783a558b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51d87436-4f07-4747-b356-587d313c62d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 195c170c-93e4-469b-b58b-48e247261e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5228b563-1d2b-4651-8d21-f0db0a886628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 881d20ba-223e-45c9-a203-694669fc40e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a65e9d4d-4d6d-4e7c-8f09-3aa5ea906644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39f13eb2-ca71-4918-a98c-1788a85f6554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 068065ec-fd25-40c2-990c-516ee98dd982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c5914de-b2d9-4789-82ab-596bf1199fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 281167bc-7fbf-434b-963a-0e2d792e0248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d233f42a-50b8-4ae3-bc73-9c4a58d096ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6bba945-d873-4a50-b66b-4d65f3f4612e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48139350-61dc-40db-9482-9121ac337d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c625b0b-0616-4e57-adbf-7a8585b062fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc65af1e-73a0-4294-8ff3-d4f31787cb57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fe7ab88-b4ab-4b5e-8f47-e6e4a8eddd9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf309308-b0c9-4bd1-8bcb-1d1eb5c238d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1415b5f2-495d-4585-a61f-27ac58e92844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ed13b75-1873-4ff2-99dc-6b42c9ff1855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b2bebbb-2265-4f0f-b765-b7ccfd7cf156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5c9a68b-0bab-4ee5-b366-e554b51479ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79897e0-43b8-411b-ba4d-24d00a005bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b83aa97b-20b2-4b0a-9df7-3f3ac3298fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d111aa-6ec7-4a68-96e7-5655662d7540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81b5c50b-9a14-46de-91a5-54c3a7bc9de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8fe0c37-b864-4b68-b309-5187a4265354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff40efc5-40e5-44db-9bf6-f60b74e10480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9400f5b2-a84a-43f0-af11-fd825e2ae4f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6114aa35-ee27-4434-b66e-cccfea3414ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d1548e8-cf45-46e6-8544-41ea582ade3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8349a269-e2c9-4ea6-abfa-5313ec7a2fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a37dd921-0f74-4899-bb1d-dff53fb8ebb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b6ea52-2ad8-4e80-aa6d-b629a38d6352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6506af70-c7dc-4ebb-9556-94b4a26b1e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30294df9-968f-4d7e-b337-d10afb1486f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8cf13dd-5021-4e93-8178-c9f867711762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ea3f1c-8a6f-417a-9e03-4e861bbafaad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12cf0bb5-b691-4154-a515-41175878e3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4842b532-0883-4b92-b361-ecf37b3d2317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e747fa7-2fcd-47f3-aa30-24f6843222b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ffcf5c9-40f3-4fd9-83de-08439945ac8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc0bfb8a-41e3-4611-9a0c-0d506b23fb96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b051e160-abf4-4208-b22d-9453b3b20a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fae963e-03a1-4af0-9892-81f1218dd993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18fec0f0-f5eb-4251-83c9-730de90d61ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7c78849-ea91-4418-9717-1722fd75743d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53df7cd4-a227-4d0e-acb7-9aae13da4f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8619d620-ae54-471a-985d-3aaef57f57af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e7a5a8-97dd-419f-a2bd-c4433af747fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39524883-3f24-4d26-8ece-3721c249f315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7dc809a-9449-4e15-ab06-73055bdb9c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9bdd3b1-abf0-4cec-ab61-56d71ad218e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda4fdc6-8575-4504-ad39-414f27d797ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585a1601-df5e-4d6d-9adc-45bf5d56065c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73db0dcd-80ac-45ec-b585-4c90230853a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b836d66d-cfe7-4a52-a898-985c0ad60c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77eff201-5af1-43d2-8b29-005dccbd591b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee5ff4e7-297d-4cde-b145-71bfc4e0bd96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5524a729-1a2d-4425-af5e-b8beaef232ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f42d2df-1954-4fb6-aef8-71549bfe4083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7479656c-ebf8-42ae-b542-f66196ee1ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff521265-4759-446d-ad74-a51bf4d881af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c93a5d7a-7d07-4040-935a-fbe430f91151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f76a278-d14a-47b1-9d3c-443da9a7d1ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55925121-a6c3-4280-b0fd-ea0d0de0db81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b4c10e-9bde-4d88-8fcf-b8e75ecdfe05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b346bf8-0c0e-4b29-af30-88e5a823564d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1d6757a-470f-4449-a6ed-6192be8789e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe7a5f69-4287-4876-b4c8-dbe686835292
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_59
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/test_labels.txt

📊 Raw data loaded:
   Train: X=(1113, 24), y=(1113,)
   Test:  X=(279, 24), y=(279,)

⚠️  Limiting training data: 1113 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  270 samples, 5 features
✅ Client client_59 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 7 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1062, val=0.0866 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0818, val=0.0817 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0834, val=0.0802 (↓), lr=0.001000
   • Epoch   4/100: train=0.0818, val=0.0808, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0813, val=0.0811, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0803, val=0.0810, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 7 Summary - Client client_59
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0005
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0087
============================================================


============================================================
🔄 Round 10 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1378, val=0.0964 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0883, val=0.0742 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0834, val=0.0735 (↓), lr=0.000250
   • Epoch   4/100: train=0.0825, val=0.0733, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0825, val=0.0734, patience=2/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0821, val=0.0738, patience=8/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 10 Summary - Client client_59
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0004
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0095
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1750, RMSE: 0.4183, MAE: 0.3428, R²: -1.0968

============================================================
🔄 Round 11 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1464, val=0.1529 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1253, val=0.1294 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1070, val=0.1098 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0929, val=0.0946 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0842, val=0.0856 (↓), lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0806, val=0.0819, patience=4/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0805, val=0.0820, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 11 Summary - Client client_59
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0006
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0127
============================================================


============================================================
🔄 Round 12 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1509, val=0.1532 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.1451, val=0.1473 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1407, val=0.1446 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1380, val=0.1421 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1355, val=0.1398 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1229, val=0.1283 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.1148, val=0.1207, patience=1/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.1115, val=0.1177, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1095, val=0.1158 (↓), lr=0.000001
   • Epoch  51/100: train=0.1076, val=0.1139, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1057, val=0.1121, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1039, val=0.1104 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.1022, val=0.1087 (↓), lr=0.000001
   • Epoch  91/100: train=0.1005, val=0.1071, patience=2/15, lr=0.000001

============================================================
📊 Round 12 Summary - Client client_59
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0987, RMSE=0.3142, R²=-0.2492
   Val:   Loss=0.1057, RMSE=0.3251, R²=-0.2066
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1648, RMSE: 0.4060, MAE: 0.3326, R²: -0.9752

📊 Round 12 Test Metrics:
   Loss: 0.1587, RMSE: 0.3984, MAE: 0.3264, R²: -0.9020

============================================================
🔄 Round 14 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1405, val=0.1482 (↓), lr=0.000001
   • Epoch   2/100: train=0.1402, val=0.1479, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1399, val=0.1477 (↓), lr=0.000001
   • Epoch   4/100: train=0.1396, val=0.1474, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1394, val=0.1471 (↓), lr=0.000001
   • Epoch  11/100: train=0.1379, val=0.1457, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1357, val=0.1434, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1335, val=0.1413 (↓), lr=0.000001
   • Epoch  41/100: train=0.1315, val=0.1392, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1295, val=0.1372, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1275, val=0.1352 (↓), lr=0.000001
   • Epoch  71/100: train=0.1255, val=0.1332, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1236, val=0.1312, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1216, val=0.1293 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_59
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1203, RMSE=0.3469, R²=-0.5146
   Val:   Loss=0.1275, RMSE=0.3571, R²=-0.4854
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1478, RMSE: 0.3845, MAE: 0.3151, R²: -0.7717

============================================================
🔄 Round 16 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1307, val=0.1176 (↓), lr=0.000001
   • Epoch   2/100: train=0.1305, val=0.1174, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1303, val=0.1172, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1301, val=0.1170 (↓), lr=0.000001
   • Epoch   5/100: train=0.1299, val=0.1168, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1286, val=0.1156, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1266, val=0.1137, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1246, val=0.1117 (↓), lr=0.000001
   • Epoch  41/100: train=0.1225, val=0.1098, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1205, val=0.1079, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1186, val=0.1060 (↓), lr=0.000001
   • Epoch  71/100: train=0.1166, val=0.1041, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1146, val=0.1022, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1127, val=0.1004 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_59
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1107, RMSE=0.3327, R²=-0.3388
   Val:   Loss=0.0987, RMSE=0.3142, R²=-0.3536
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1381, RMSE: 0.3717, MAE: 0.3052, R²: -0.6556

============================================================
🔄 Round 19 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0987, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0985, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0984, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0982, val=0.0955, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0980, val=0.0954 (↓), lr=0.000001
   • Epoch  11/100: train=0.0971, val=0.0945, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0956, val=0.0932 (↓), lr=0.000001
   • Epoch  31/100: train=0.0942, val=0.0920, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0928, val=0.0908, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0915, val=0.0897, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0903, val=0.0887, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0892, val=0.0877, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0881, val=0.0869, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0871, val=0.0861, patience=6/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_59
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0688
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0536
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0966, RMSE: 0.3108, MAE: 0.2633, R²: -0.1577

============================================================
🔄 Round 21 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0882, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0812, val=0.0879, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 21 Summary - Client client_59
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0232
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0236
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2534, R²: -0.0376

============================================================
🔄 Round 23 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 23 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0160
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0054
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2531, R²: -0.0338

============================================================
🔄 Round 25 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 25 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0070
   Val:   Loss=0.0705, RMSE=0.2656, R²=-0.0099
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2525, R²: -0.0266

📊 Round 25 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2522, R²: -0.0232

📊 Round 25 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2522, R²: -0.0230

============================================================
🔄 Round 36 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 36 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0021
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0101
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2521, R²: -0.0215

============================================================
🔄 Round 38 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 38 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0025
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0183
============================================================


============================================================
🔄 Round 39 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 39 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0000
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0372
============================================================


============================================================
🔄 Round 41 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 41 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0026
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0025
============================================================


============================================================
🔄 Round 44 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 44 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0011
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0140
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2520, R²: -0.0198

📊 Round 44 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2520, R²: -0.0197

📊 Round 44 Test Metrics:
   Loss: 0.0851, RMSE: 0.2916, MAE: 0.2519, R²: -0.0194

============================================================
🔄 Round 49 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 49 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0057
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0007
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2519, R²: -0.0192

============================================================
🔄 Round 50 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 50 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0035
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0019
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2519, R²: -0.0191

📊 Round 50 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2519, R²: -0.0190

📊 Round 50 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2519, R²: -0.0190

============================================================
🔄 Round 54 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 54 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0032
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0110
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2519, R²: -0.0191

============================================================
🔄 Round 55 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 55 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0039
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0016
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2519, R²: -0.0189

============================================================
🔄 Round 56 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 56 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0001
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0125
============================================================


============================================================
🔄 Round 57 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 57 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0016
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0035
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2519, R²: -0.0186

📊 Round 57 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2518, R²: -0.0182

============================================================
🔄 Round 65 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 65 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0011
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0080
============================================================


============================================================
🔄 Round 68 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 68 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0047
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0054
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0849, RMSE: 0.2915, MAE: 0.2518, R²: -0.0180

============================================================
🔄 Round 71 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 71 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0018
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0080
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2518, R²: -0.0175

============================================================
🔄 Round 73 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 73 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0004
   Val:   Loss=0.0676, RMSE=0.2601, R²=-0.0110
============================================================


============================================================
🔄 Round 74 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 74 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0020
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0004
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2518, R²: -0.0172

============================================================
🔄 Round 78 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 78 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0030
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0011
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2517, R²: -0.0167

📊 Round 78 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2517, R²: -0.0166

📊 Round 78 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2517, R²: -0.0165

============================================================
🔄 Round 84 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 84 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0031
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0073
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2517, R²: -0.0167

============================================================
🔄 Round 90 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 90 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0001
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0060
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2517, R²: -0.0163

============================================================
🔄 Round 91 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 91 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0032
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0070
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2517, R²: -0.0162

============================================================
🔄 Round 92 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 92 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0000
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0101
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2517, R²: -0.0161

📊 Round 92 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2517, R²: -0.0159

📊 Round 92 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2517, R²: -0.0158

============================================================
🔄 Round 96 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 96 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0000
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0062
============================================================


============================================================
🔄 Round 97 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 97 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0009
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0045
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2517, R²: -0.0157

============================================================
🔄 Round 101 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 101 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0002
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0068
============================================================


============================================================
🔄 Round 102 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 102 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0023
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0019
============================================================


============================================================
🔄 Round 103 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 103 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0007
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0050
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2517, R²: -0.0154

============================================================
🔄 Round 105 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 105 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0024
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0282
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2517, R²: -0.0154

============================================================
🔄 Round 106 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 106 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0043
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0030
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2517, R²: -0.0154

📊 Round 106 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2516, R²: -0.0152

============================================================
🔄 Round 108 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 108 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0014
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0136
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2516, R²: -0.0151

============================================================
🔄 Round 110 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 110 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0032
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0201
============================================================


============================================================
🔄 Round 111 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 111 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0024
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0047
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2516, R²: -0.0150

============================================================
🔄 Round 115 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 115 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0027
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0067
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2516, R²: -0.0150

============================================================
🔄 Round 120 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 120 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0034
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0081
============================================================


============================================================
🔄 Round 121 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 121 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=-0.0005
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0024
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2516, R²: -0.0148

📊 Round 121 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2516, R²: -0.0147

📊 Round 121 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2516, R²: -0.0146

============================================================
🔄 Round 128 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 128 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0010
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0085
============================================================


============================================================
🔄 Round 129 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 129 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0016
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0029
============================================================


============================================================
🔄 Round 130 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 130 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0012
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0188
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2516, R²: -0.0146

============================================================
🔄 Round 131 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 131 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0001
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0058
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2516, R²: -0.0145

📊 Round 131 Test Metrics:
   Loss: 0.0847, RMSE: 0.2909, MAE: 0.2516, R²: -0.0145

📊 Round 131 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2516, R²: -0.0144

============================================================
🔄 Round 135 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 135 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0010
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0267
============================================================


============================================================
🔄 Round 136 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 136 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0028
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0061
============================================================


============================================================
🔄 Round 137 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 137 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0001
   Val:   Loss=0.0701, RMSE=0.2647, R²=-0.0046
============================================================


============================================================
🔄 Round 139 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 139 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0018
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0037
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2516, R²: -0.0140

📊 Round 139 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2516, R²: -0.0142

============================================================
🔄 Round 143 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 143 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0023
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0067
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2516, R²: -0.0143

📊 Round 143 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2516, R²: -0.0144

============================================================
🔄 Round 148 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 148 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0002
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0074
============================================================


============================================================
🔄 Round 151 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 151 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0025
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0132
============================================================


============================================================
🔄 Round 152 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 152 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0012
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0076
============================================================


============================================================
🔄 Round 153 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 153 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0000
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0038
============================================================


============================================================
🔄 Round 154 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 154 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0012
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0008
============================================================


============================================================
🔄 Round 156 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 156 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0010
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0082
============================================================


============================================================
🔄 Round 157 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 157 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0004
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0045
============================================================


============================================================
🔄 Round 159 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 159 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0207
============================================================


============================================================
🔄 Round 161 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 161 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0005
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0100
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2516, R²: -0.0142

============================================================
🔄 Round 162 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 162 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0172
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2516, R²: -0.0143

============================================================
🔄 Round 163 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 163 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0002
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0040
============================================================


============================================================
🔄 Round 166 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 166 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0011
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0002
============================================================


============================================================
🔄 Round 168 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 168 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0047
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0136
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0137

📊 Round 168 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0136

============================================================
🔄 Round 172 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 172 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0011
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0005
============================================================


============================================================
🔄 Round 173 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 173 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0010
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0061
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0136

📊 Round 173 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0136

============================================================
🔄 Round 178 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 178 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0030
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0068
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0136

============================================================
🔄 Round 179 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 179 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0015
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0228
============================================================


============================================================
🔄 Round 182 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 182 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0000
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0052
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0136

📊 Round 182 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0135

============================================================
🔄 Round 186 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 186 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0025
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0078
============================================================


============================================================
🔄 Round 187 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 187 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0012
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0271
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0137

============================================================
🔄 Round 189 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 189 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0007
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0018
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0136

📊 Round 189 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0135

📊 Round 189 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0135

============================================================
🔄 Round 194 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 194 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0007
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0114
============================================================


============================================================
🔄 Round 195 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 195 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0013
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0307
============================================================


============================================================
🔄 Round 196 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 196 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0027
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0141
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0136

============================================================
🔄 Round 199 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 199 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0012
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0084
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0136

📊 Round 199 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0135

============================================================
🔄 Round 204 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 204 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0017
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0089
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0133

============================================================
🔄 Round 208 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 208 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0016
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0034
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0134

📊 Round 208 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2515, R²: -0.0133

❌ Client client_59 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
