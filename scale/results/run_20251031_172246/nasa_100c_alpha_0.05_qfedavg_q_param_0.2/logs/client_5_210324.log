[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ffaa3e7-908f-481e-9851-cfa26416bbb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56536e57-a25b-4b7e-a0de-cbe288168734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27efb926-4627-416d-bbf7-e3262ba78c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1249ccf-a8a2-4283-a8d9-9f0b8f3063d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faf525da-5b30-4be7-8afd-b65c7a884e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be7e96d4-5bf1-44ba-a154-6c13df7f273a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd5007fb-784d-49ec-b783-96b327435c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca7ab50-fc78-484d-b869-43aa6f050e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a873fca5-851d-4b8c-b5bb-58c73e5f0d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 701b828b-acc6-4540-a857-b0d3e036dfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f91dea4-4fbc-4a73-8b79-28925c9e5b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e5d341-3b97-4d0a-bdbb-67e65084f117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5557ad58-5c4a-445c-8ebd-eade491b8a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cefda945-0fb1-48f5-8e1f-56b83c7dad96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fa84418-534d-4a0b-8cba-965955d0f72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c1d1f0e-d641-4e21-831c-7b2cc01a3a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 882575a0-ad15-4004-9ff5-6bc38789202e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b52f13f-24ff-4f27-8a9f-6782a8c24ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7160b2ac-44f2-4113-a962-250adaeb4d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1adf0782-d26f-4ec4-9291-c0861a7191be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb471e66-d637-46be-9858-56efd94a68d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94e7d003-d5d0-4dbf-a64d-0ae2e78069b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec10c52b-359c-467d-bf40-99a010aa0f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac50f27e-adcc-4b3d-8d9c-f2bcf5015c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11628a42-409c-4b9a-b473-d3169470443c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b5dd319-9d50-4cc3-a71c-075dc968d59d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ed426a-1f72-4eb1-b7b7-6372af4dafa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f455eee-e1b1-4d1e-a211-b1c4f3f17990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f85629de-3002-4150-ab98-e813c1f1e1d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfc45a6-b2ae-45f8-97df-ddd9434382c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f5feb59-284e-4366-9042-b3d10ca5bb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b57938a-071c-46cf-b76e-b45fde6a6c2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921c5dd4-70de-44e8-99c7-434501711d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01c152db-ba25-413a-9f7a-861e0861dab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a0d25a2-102d-4289-a029-353c5703e0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a509b31-4583-4cbe-b96b-7fee923a0d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8baf5af-7dd4-4085-b40d-64a990a0e946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9589a64f-edc6-4d5e-a007-918ee8d6e557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d468c862-e09d-4589-8239-7b5c9c6328a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7971a8f-9ff3-4039-b934-ad1b6e63304f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a70156a-79a7-470d-aa7f-648bcf666e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71281632-6891-4793-be2e-1ec5583b53af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a87a1b17-8b59-4a09-b809-6a3490fd3671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b44e0ef-0979-44e7-bee1-05583266877a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b756ac76-0051-4500-9640-991a0f5ae76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 928b282c-7e19-49b8-9264-65da39598c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5a6854e-73d2-468a-894f-429cf5870c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8fcd9a1-38b3-4b87-8a8e-c3387eb2acd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee6c5484-7357-496a-ab39-d403edbf6f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac9ec28f-3282-41e2-a03f-d02e19cbc754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d305790-bae8-4a45-ba4c-a748829a25be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1f0244e-8939-4f1e-98ab-bbaf45c4b050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f015eb-693c-4705-8c49-d91bb8867e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3069ed45-6f63-4bf4-b50b-19c3573ee422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9519b13-15e9-4dc6-bd12-0d8321bbbc88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a3eb1f9-2775-445f-9fb6-b9c8bfd3fb60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c36c7fa6-ede2-4e54-8bb7-19bb27c69f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a08f9b-ab46-448f-b90d-5abfb5be639e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40fb2a7e-8207-4d46-a290-6e4e8f541ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfcab058-c787-47cb-97be-a694e9c5e7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c09d6ad-bfe3-4812-9750-e4e4486d4db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7d96544-bb1d-4311-a6f0-3f42fec013db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 648fa0e7-b112-4cd5-86c6-f15b0454c62f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42c897f8-c743-45e3-bd85-0654e6dc73d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c231fae6-47b6-4a38-a039-ace277ea2bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a7d658e-5f52-4ea3-92ab-4d8a7bee04cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17b5c8c7-a870-4879-a386-39013a3ea30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c20e5762-2f3a-4893-9ca0-6031205e3244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c084e49f-7520-4862-b028-9c91e01db555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa33d63-8266-4868-8ffc-6daa36b8e9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 676adf20-c4b3-4020-85f8-968a7ea147dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b48468d-6a45-46ba-9947-39be35ad2577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81c01d2f-6713-46dc-84f4-019c3b0569b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f6e9b68-70fb-401c-b691-c7e4a2fba398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ad9a88-60df-463f-931e-ee95b9e08fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07500904-31a0-4537-a4d7-9aa747d769fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f08ad0d-ab34-4566-b726-e903f570d655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a9506d6-4e2d-4279-b451-22116aa24939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b09564d-49a7-4570-9c54-7954ef4313bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 128a3259-3cbc-4ff2-bfab-b6ad93e659fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36f2cd67-b5d5-4702-a245-fc69ac864022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3efb94c-61a4-4d99-b4db-de35075a9549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 580df841-d593-43b7-9f1b-5bf76346102d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 411dc918-25ae-4e50-82bb-4752d588158e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38bcba95-212b-4c1a-a6ff-984ae5c9c04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90e42708-85ad-4c96-8084-23eff65d01b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c6d83ae-4529-48e1-ae25-459aae7519e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b25a6c2-6e2a-40d1-900b-f0497e56a86a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dd3e975-d019-4ef1-805b-0be49c32d7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b9f53a6-bf66-4818-b7d9-2bec1fa25c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17c08d33-8f17-427f-ae16-915744d808cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a5127b-2f95-451f-b66a-0fdf829395af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd9ca9f-a294-42ac-b56a-eeb5346f7b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c76c6f6d-7a4d-4611-a2e0-6e1672bd97aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d8cb9a-7290-41a5-9941-ab2f21e0e85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 780d9418-da07-4c0c-90c6-525405cb3d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message effcd1cf-9925-458f-a3b2-27589aa81aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e0e2a38-3ce2-45a1-b11a-cf243de69d25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0360cf-ef62-455a-9e7e-fcd99816e763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f92d157f-7632-4f39-9082-6d410a1bd4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95ddb801-2f93-4a7b-b09d-7648866d43c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5feb98eb-b720-4371-ad7d-4bcefba07daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37fabd39-711d-47d8-9771-e454026b2be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d42b9d58-b56d-4baf-82ee-a112fa5cface
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec29168-cc39-42d8-8af2-a8c4084c6c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a34ae97-a721-40aa-a432-48dde9d9486c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f92bad69-91a1-402d-9d3f-c086d46b5a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cef1247-b38b-4dd5-bada-f43d49d0c3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a89896be-11cd-48c8-bdcc-78ffd9e64dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36fbce5d-b7b8-4854-8b00-5657f1b060de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f0faa3-5a8b-476f-ba5f-17df303f140b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de52bbb8-d116-4ab8-b7e0-b9a1b4b9ef05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ff9b1f2-4310-481e-b816-f595fab2915a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502ab291-b20d-4584-b8a9-6b8119f7e313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 824a9d4d-1b57-4d2a-83c5-759a967d06ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7a5afad-4719-4d2d-8b1b-a93611fb4603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2577d63c-03dc-458e-a28a-d9e07a0b734f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3e7c3f2-69a4-47fe-ae2d-2aaea14f6bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11b0829e-0889-403d-bef6-df7365714c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 435a50ad-cc6f-4d92-9a92-57cb4745f446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80cf0a6e-f42c-4c66-b1b8-e1485f0532dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ce1740-71a1-4c17-b7e3-0f980546635e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e35f94-6393-4591-b326-c4b4d4e962ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ad2efde-438a-44d9-89b3-acf9b9957163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 470acd64-1f2c-423f-87eb-b90947a079e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d37d95b4-7f78-45fb-be18-f2e9c3b4c698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13cbe440-b31e-467e-8a8c-0d8489244869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 512cfeb5-a8d6-4c08-95e9-23d64b51f828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41e540d4-6f08-49b7-9a67-892251a21da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4086eec7-a8fc-48ef-b85e-10c398d54d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 078806f5-61ce-47d3-afde-178c1154b131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6cc4e74-2edd-4a7b-a635-8a01bec5a9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c8948eb-84b1-4240-b6d2-817cd647ea43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0193e5fa-869c-405a-9cf7-6ee9a7fcb28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53d9005d-de30-4a90-911f-00834179b104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b9950f3-abaa-4c39-b59b-a1a10cedca8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0cb2546-b915-411d-8760-8d41c4485253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b92465e-15d5-48e0-a6d1-a55d9dec7c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46ab50be-6b8f-4a59-848d-8b8e337504e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85865dbd-6c36-4e2f-b6cc-871a3c7c142b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de40f12a-d828-430f-98a1-ece9bdbd557d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 119f68ca-57e4-46a9-a429-19b29ab96c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a87b686-fcb2-458a-b0a7-aa5cc742c896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f26ef86-ecd8-400e-8201-6fa872c89509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74def22c-d188-4e3f-83bc-ae7fdff23279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b1d2ea-84f8-407a-807d-ebebea3a539c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ca959a-c8ac-4aa1-86a1-d89005422c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44b3fb61-d985-4e5e-b72a-8a8aa2349367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb68f5e1-0d48-4401-bc37-27b3908abaec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14f2c25e-d11b-45e1-b1d6-4060a50b3850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 477a266e-d2c9-4bda-a965-105d04105ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea4047b3-32ae-486e-b16c-e6005a4097ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ebe1c90-dfda-4053-a5c0-db3cde5ceede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c4927c-7410-4e99-a33c-90e5b896c978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 701455b9-830c-4928-ae0b-b98d3c8cd8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0154e82f-3d38-49a0-8c5d-99ce4e005cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5a1b58d-72b5-439c-ac17-635cf21e801a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 076521fd-9a9a-433f-bbcd-ad94e4b87ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba4d83d5-89d5-456c-bab5-019860a970cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d939b745-3554-40fb-9550-906884ce376b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ba8d27-e8dd-4d08-8665-2ccb01454460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 698e0e98-49db-4eba-8b62-b267e0957ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b068ad-e394-416e-8c0c-803dbe136646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ff5596-da9e-4b49-a5f0-60b4bfa0879e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef17958a-6133-4826-be11-9859ff159003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4377cf52-f7a7-4927-8581-f87666791e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c136bb8-fe42-40d3-9bd0-cb4ca9ac389d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00711410-3256-4c8e-9c81-2584783d7c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 990c3fa9-cdab-453e-9a68-c5337ebc95db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e93a621-bca9-484e-92ba-a9b7b2b06bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13b192b7-6345-41c5-8dd0-43fd279cebae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6782159-9810-43fe-b00e-edb7768eb8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9354116b-e12f-44c9-aa78-69917690ff9b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_5
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/test_labels.txt

📊 Raw data loaded:
   Train: X=(660, 24), y=(660,)
   Test:  X=(166, 24), y=(166,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 651 samples, 5 features
   Test:  157 samples, 5 features
✅ Client client_5 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1926, RMSE: 0.4389, MAE: 0.3552, R²: -1.4064

📊 Round 0 Test Metrics:
   Loss: 0.1886, RMSE: 0.4342, MAE: 0.3509, R²: -1.3557

============================================================
🔄 Round 3 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1354, val=0.1032 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0937, val=0.0834 (↓), lr=0.001000
   • Epoch   3/100: train=0.0866, val=0.0844, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0862, val=0.0826 (↓), lr=0.001000
   • Epoch   5/100: train=0.0859, val=0.0830, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0847, val=0.0839, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 3 Summary - Client client_5
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0018
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0096
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.1751, RMSE: 0.4184, MAE: 0.3368, R²: -1.1872

📊 Round 3 Test Metrics:
   Loss: 0.1459, RMSE: 0.3820, MAE: 0.3073, R²: -0.8232

============================================================
🔄 Round 11 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1447, val=0.1073 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0976, val=0.0750 (↓), lr=0.000250
   • Epoch   3/100: train=0.0863, val=0.0752, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0852, val=0.0752, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0850, val=0.0751, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0847, val=0.0752, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 11 Summary - Client client_5
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0017
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0015
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1420, RMSE: 0.3769, MAE: 0.3032, R²: -0.7745

============================================================
🔄 Round 12 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1536, val=0.1527 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1356, val=0.1347 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1184, val=0.1193 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1040, val=0.1069 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0929, val=0.0983 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0822, val=0.0932, patience=4/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0820, val=0.0935, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 12 Summary - Client client_5
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0027
   Val:   Loss=0.0931, RMSE=0.3052, R²=0.0030
============================================================


============================================================
🔄 Round 14 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.1444, val=0.1678 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1412, val=0.1652 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1388, val=0.1626 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1364, val=0.1601 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1342, val=0.1578 (↓), lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1238, val=0.1471 (↓), lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1168, val=0.1397 (↓), lr=0.000002
   📉 Epoch 25: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1140, val=0.1367 (↓), lr=0.000001
   • Epoch  41/100: train=0.1122, val=0.1347, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1105, val=0.1328, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1088, val=0.1309 (↓), lr=0.000001
   • Epoch  71/100: train=0.1072, val=0.1291, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1057, val=0.1274, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1041, val=0.1256 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_5
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.1028, RMSE=0.3207, R²=-0.2586
   Val:   Loss=0.1241, RMSE=0.3523, R²=-0.2991
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1230, RMSE: 0.3508, MAE: 0.2820, R²: -0.5369

📊 Round 14 Test Metrics:
   Loss: 0.1187, RMSE: 0.3445, MAE: 0.2770, R²: -0.4830

============================================================
🔄 Round 16 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1371, val=0.1157 (↓), lr=0.000001
   • Epoch   2/100: train=0.1369, val=0.1155, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1367, val=0.1153, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1364, val=0.1151 (↓), lr=0.000001
   • Epoch   5/100: train=0.1362, val=0.1149, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1350, val=0.1139, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1330, val=0.1123, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.1310, val=0.1108, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1292, val=0.1093, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.1273, val=0.1078, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1255, val=0.1064, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.1238, val=0.1050, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1220, val=0.1036, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.1203, val=0.1022, patience=1/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_5
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1213, RMSE=0.3483, R²=-0.4279
   Val:   Loss=0.1010, RMSE=0.3179, R²=-0.2485
============================================================


============================================================
🔄 Round 18 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1128, val=0.1295 (↓), lr=0.000001
   • Epoch   2/100: train=0.1126, val=0.1293, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1125, val=0.1291, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1123, val=0.1289 (↓), lr=0.000001
   • Epoch   5/100: train=0.1122, val=0.1287, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1113, val=0.1277, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1097, val=0.1258, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1082, val=0.1240 (↓), lr=0.000001
   • Epoch  41/100: train=0.1068, val=0.1222, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1053, val=0.1205, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1039, val=0.1187 (↓), lr=0.000001
   • Epoch  71/100: train=0.1025, val=0.1170, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1011, val=0.1153, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0998, val=0.1136, patience=2/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_5
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0990, RMSE=0.3146, R²=-0.1870
   Val:   Loss=0.1122, RMSE=0.3349, R²=-0.2710
============================================================


============================================================
🔄 Round 19 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1078, val=0.1000 (↓), lr=0.000001
   • Epoch   2/100: train=0.1076, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1075, val=0.0996, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1074, val=0.0994 (↓), lr=0.000001
   • Epoch   5/100: train=0.1072, val=0.0993, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1064, val=0.0982, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1051, val=0.0965, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.1038, val=0.0948, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.1025, val=0.0932, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1013, val=0.0916, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.1002, val=0.0901, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0991, val=0.0886, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0981, val=0.0872, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0971, val=0.0858, patience=3/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_5
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0938, RMSE=0.3063, R²=-0.0692
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.2012
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2424, R²: -0.0604

============================================================
🔄 Round 20 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.1006 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.1005, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.1003, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.1002, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0886, val=0.0996 (↓), lr=0.000001
   • Epoch  21/100: train=0.0877, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  31/100: train=0.0868, val=0.0977, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0860, val=0.0969, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0853, val=0.0962, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0847, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0841, val=0.0950, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0836, val=0.0944, patience=6/15, lr=0.000001
   • Epoch  91/100: train=0.0832, val=0.0940, patience=5/15, lr=0.000001

============================================================
📊 Round 20 Summary - Client client_5
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0243
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0273
============================================================


============================================================
🔄 Round 21 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0941, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0841, val=0.0938, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 21 Summary - Client client_5
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0339
   Val:   Loss=0.0940, RMSE=0.3065, R²=-0.0138
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2418, R²: -0.0069

============================================================
🔄 Round 23 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 23 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0116
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0383
============================================================


============================================================
🔄 Round 24 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 24 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0119
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0136
============================================================


============================================================
🔄 Round 27 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 27 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0063
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0180
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2425, R²: -0.0061

============================================================
🔄 Round 28 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 28 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0026
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0344
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2426, R²: -0.0061

📊 Round 28 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2427, R²: -0.0063

============================================================
🔄 Round 31 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 31 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0070
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0053
============================================================


============================================================
🔄 Round 32 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 32 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0014
   Val:   Loss=0.0921, RMSE=0.3036, R²=-0.0460
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2428, R²: -0.0064

📊 Round 32 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 34 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 34 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0066
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0027
============================================================


============================================================
🔄 Round 35 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 35 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0057
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0055
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2428, R²: -0.0066

============================================================
🔄 Round 36 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 36 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0046
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0083
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2430, R²: -0.0070

============================================================
🔄 Round 41 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 41 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0060
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0020
============================================================


============================================================
🔄 Round 42 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 42 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0020
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0162
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2430, R²: -0.0070

============================================================
🔄 Round 43 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 43 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0075
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0082
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: -0.0071

============================================================
🔄 Round 45 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 45 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0001
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0456
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: -0.0071

============================================================
🔄 Round 47 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 47 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0046
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0030
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2431, R²: -0.0072

============================================================
🔄 Round 48 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 48 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0067
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0043
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: -0.0073

============================================================
🔄 Round 50 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 50 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0037
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0045
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: -0.0073

============================================================
🔄 Round 52 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 52 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0094
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0077
============================================================


============================================================
🔄 Round 53 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 53 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0039
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0042
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: -0.0073

============================================================
🔄 Round 54 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 54 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0024
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0090
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2431, R²: -0.0073

============================================================
🔄 Round 56 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 56 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0045
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0005
============================================================


============================================================
🔄 Round 57 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 57 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0051
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0021
============================================================


============================================================
🔄 Round 58 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 58 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0028
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0088
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: -0.0073

============================================================
🔄 Round 63 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 63 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0043
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0004
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: -0.0074

📊 Round 63 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: -0.0074

============================================================
🔄 Round 65 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 65 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0046
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0013
============================================================


============================================================
🔄 Round 66 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 66 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0075
   Val:   Loss=0.0996, RMSE=0.3156, R²=0.0083
============================================================


============================================================
🔄 Round 67 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 67 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0044
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0009
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2432, R²: -0.0075

============================================================
🔄 Round 68 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 68 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0030
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0058
============================================================


============================================================
🔄 Round 73 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 73 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0027
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0063
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: -0.0077

📊 Round 73 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: -0.0077

📊 Round 73 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: -0.0078

📊 Round 73 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2434, R²: -0.0079

============================================================
🔄 Round 79 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 79 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0032
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0007
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2434, R²: -0.0078

============================================================
🔄 Round 82 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 82 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0009
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0103
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2434, R²: -0.0079

============================================================
🔄 Round 83 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 83 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0009
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0302
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2434, R²: -0.0078

============================================================
🔄 Round 85 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 85 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0034
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0094
============================================================


============================================================
🔄 Round 87 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 87 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0019
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0147
============================================================


============================================================
🔄 Round 88 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 88 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0018
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0092
============================================================


============================================================
🔄 Round 89 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 89 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0049
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0071
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2434, R²: -0.0079

============================================================
🔄 Round 92 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 92 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0033
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0005
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: -0.0080

============================================================
🔄 Round 94 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 94 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0040
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0008
============================================================


============================================================
🔄 Round 95 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 95 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0011
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0249
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0081

============================================================
🔄 Round 96 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 96 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0014
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0152
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0080

============================================================
🔄 Round 100 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 100 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0004
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0103
============================================================


============================================================
🔄 Round 101 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 101 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0018
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0048
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0081

📊 Round 101 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0082

============================================================
🔄 Round 105 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 105 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0035
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0034
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0081

📊 Round 105 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0082

============================================================
🔄 Round 108 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 108 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0053
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0014
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0082

============================================================
🔄 Round 109 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 109 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0011
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0515
============================================================


============================================================
🔄 Round 111 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 111 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0063
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0056
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0082

📊 Round 111 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0082

============================================================
🔄 Round 115 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 115 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0008
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0062
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0082

============================================================
🔄 Round 117 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 117 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0045
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0026
============================================================


============================================================
🔄 Round 118 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 118 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0012
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0196
============================================================


============================================================
🔄 Round 119 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 119 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0006
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0192
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0082

📊 Round 119 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0082

============================================================
🔄 Round 125 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 125 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0006
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0300
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0083

📊 Round 125 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0083

============================================================
🔄 Round 133 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 133 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0009
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0058
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0083

============================================================
🔄 Round 134 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 134 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0033
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0034
============================================================


============================================================
🔄 Round 135 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 135 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0010
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0048
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0083

📊 Round 135 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0084

📊 Round 135 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0084

============================================================
🔄 Round 138 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 138 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0018
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0027
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0084

============================================================
🔄 Round 139 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 139 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0020
   Val:   Loss=0.0996, RMSE=0.3155, R²=-0.0204
============================================================


============================================================
🔄 Round 140 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 140 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0022
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0007
============================================================


============================================================
🔄 Round 144 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 144 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0009
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0058
============================================================


============================================================
🔄 Round 145 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 145 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0036
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0053
============================================================


============================================================
🔄 Round 146 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 146 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0021
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0014
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0081

📊 Round 146 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0081

============================================================
🔄 Round 149 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 149 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0012
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0071
============================================================


============================================================
🔄 Round 150 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 150 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0002
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0162
============================================================


============================================================
🔄 Round 151 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 151 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0018
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0034
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0079

============================================================
🔄 Round 155 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 155 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0016
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0031
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0080

📊 Round 155 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0080

📊 Round 155 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0081

📊 Round 155 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0080

📊 Round 155 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0080

📊 Round 155 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0080

📊 Round 155 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0081

============================================================
🔄 Round 166 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 166 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0042
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0012
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0083

============================================================
🔄 Round 172 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 172 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0001
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0163
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2437, R²: -0.0083

============================================================
🔄 Round 173 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 173 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0010
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0036
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2437, R²: -0.0083

📊 Round 173 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0082

📊 Round 173 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2437, R²: -0.0082

📊 Round 173 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0081

📊 Round 173 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0082

============================================================
🔄 Round 180 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 180 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0034
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0012
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0082

============================================================
🔄 Round 183 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 183 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0016
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0290
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0081

📊 Round 183 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0082

============================================================
🔄 Round 187 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 187 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0021
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0028
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0080

📊 Round 187 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0080

============================================================
🔄 Round 190 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 190 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0007
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0159
============================================================


============================================================
🔄 Round 194 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 194 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0054
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0037
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2437, R²: -0.0082

📊 Round 194 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2437, R²: -0.0082

============================================================
🔄 Round 197 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 197 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0011
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0149
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0080

============================================================
🔄 Round 200 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 200 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0051
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0058
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0080

📊 Round 200 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0081

============================================================
🔄 Round 202 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 202 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0004
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0076
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0081

============================================================
🔄 Round 205 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 205 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0038
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0066
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0081

📊 Round 205 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0080

============================================================
🔄 Round 209 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 209 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0053
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0083
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2436, R²: -0.0080

============================================================
🔄 Round 210 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 210 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0009
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0240
============================================================


❌ Client client_5 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
