[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18857252-cb98-4bc7-a7f8-13ae38cd3173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b56a336-e6f5-425f-9de2-7631b075d6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d56f01b-62b0-43ce-ae7e-25823ff4aeab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9987991e-af60-4e95-8d39-a69294976c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f269216-5bed-4173-b31e-c5015f1ca79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d3e808e-e4d2-47e9-a55f-5c615b2d8651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0738f509-82ff-4e3f-bdda-6540efbe7b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7daf34d-7d66-4e1d-8a93-884985b95944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38605f18-acfc-4712-8d3d-360e579e72bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af721431-492d-4b32-9b91-3a93d7c8077f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 383a9a85-d052-4201-adeb-839ab08ea224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1d11de3-6629-4654-b095-5120a4e8589d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7af2d107-f0b9-4390-819d-e4a69348d6f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 607b80b0-8caf-46b5-a287-56610b96d376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5c47aaf-81f5-4153-bbac-c8caa2c76958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d30f38-2897-4b5f-b864-be6b59afed8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2fffb8e-edd0-4fba-99c7-49d0d173969b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48d4c2da-1d3c-4a63-b0b0-2e3b04ac1ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eef023c-9be9-4bd1-8bda-5402654d0841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f70c8059-7d92-4c16-aed9-2a438634025a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc6784e-83d5-4846-97d1-7989b9cbfb06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9a03fc9-5d83-4bd1-a2b2-047cbf8527f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d70f6d4a-a51f-4a03-9e6d-4045b4c6208e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8b33ef9-3a37-4348-b132-beec2d519b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 478236e8-6de3-4fbf-8ef8-45ba5a51c896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 612fff93-b888-4931-b3d6-b3373a0baabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a05dd05-fd36-415d-89e7-bd38ee890c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c588185-bff7-4b7a-929f-9013dfa8969d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3da1f201-3530-4a64-b0c1-e7bb50d1a39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faf3401e-5bab-4d51-8ef0-06b897d9b590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00871200-9528-451c-977e-c040ca5d13a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 815f7f29-3f74-4dd7-b895-8c1faf75d841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0861a1a3-4d84-44ee-a921-8d4b64584f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e93f8660-6871-4948-a591-3d23773e19b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 247e474f-2ed3-4396-abda-c12eae04158b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12035b0a-5e68-4fbb-8f52-960201264e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d478cd42-a1ff-4fb2-96be-d72f947b442a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90b01130-b77c-4db0-ac18-44cc41ef0cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a39b93-7eee-4ae1-8477-fc534c59469c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a0c6af6-8349-4dbb-94a7-e7e784b4b1e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a448510-1d35-46cf-9a88-1c9828d23cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d934bc-00fc-4e55-81c6-9d27cadfe27c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 943801e7-5f05-49e7-b7e7-737222474d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b588546-a55c-4a2f-9743-499159fa1a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e68e62-8eff-45c9-8ea2-482fafa48aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62263ec9-8202-4428-b6f3-79641a5628f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb57b3c3-b27a-4646-9b86-a5d1d76522be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a3dc99a-00a4-419d-8d28-3f08a3b9472a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0bb3975-38c8-4555-b149-a31e97179f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c09b62e3-2ca3-43f2-b47c-7a5cc1794f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fbcb12a-6446-4f58-90d3-2443d0b7489a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a29c645c-b322-4b98-90b6-c8b89e4a37ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47dfdbe8-4159-476c-bbe6-fbc4b5cbbef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce5c2a35-1941-4ff0-b7c5-a4ef2fed4839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a56bf4bc-9c13-4600-8733-2208b3a61b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e10f768-c9f8-48cf-9d0e-0d63929c7ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 089b8212-e984-4c0c-a3d5-4a6fc201256a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56361cca-9e4e-4675-a1bb-fcc90ed2b2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 918085d0-81db-4a58-9848-5f6e46f03495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b926be8c-1a75-4d8b-b226-56b6b7d99e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59abb3e0-3bfd-48ff-bae4-b7ff019b773c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 648e184c-8e27-4e30-b5ca-7b2114796fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 820f94d9-1483-4982-aadc-58e742545fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb7ea729-ec2e-4e32-8792-aa68b47d2c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5458c09-2a15-4532-9ffe-283ad4d1699d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3266cb5-9872-4858-9b72-95083a4dfe32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 493988d4-f26a-42b7-8e99-ed4a68ef14b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 519ec146-c60b-4545-a7d6-0d962bcb2c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa989e8-6c2b-48e1-a001-5e5cc35f160a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bae0fdb-1bcd-426e-99d1-d56acef6d40c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08b5da76-bcf9-42fe-bf7e-59c15159052d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48663fae-d6b0-42a0-8649-0bd7c3a1c36c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6b8362-b15d-4b4b-9f0a-8d968f95b1c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b72249f-7a5f-4b75-a4e1-52e02e87c4a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c2ec373-b14d-43a7-b00c-df2daf09b2bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8474ebf6-042a-4d3c-b78b-e1935b0795e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 458639ec-ba7c-4c59-b24c-30b8b2708f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1afb5a1f-8d00-4e3c-8868-062dc482dbe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 962dcf38-62d0-497e-8c21-edd215396121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c523238-f55b-4b27-8cf6-9b6d82c14aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f854f2-4bcd-4acc-aa0c-d3b46faeb0d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a5284ff-adb0-4ff8-9044-cda4688b40de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cdac555-7221-4fc9-b055-ea5263c51fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2a72752-09a3-4bab-b14a-7921b24bec8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76086c27-5240-4efc-8597-d1826fa51aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 703b0d10-d7a8-4d50-9439-0357093ca063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea756c87-7781-466c-a084-827eb68b9b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4fb57d9-dd07-4cd8-8ff0-c57b77cf9bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ae5e5d2-de72-435d-bdb9-bb4a4b75de96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d3e6eb-ac46-4f66-a2db-94ab198000f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07457732-5ec5-4980-b6d3-44af90cd7b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7115e21-b3c7-44de-ba13-8380c2fb35e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d44f1b1-9e58-4e62-851e-aea08ed1bff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c58a77bf-3dd9-42e4-84ed-75c869f38371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c0ea9f6-ca1f-4ed0-b597-b087d698cd31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef59fec6-ff83-4970-ae21-12fd26069ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7be8f43-47f4-4b24-b7d9-26b3e6b780f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7b80097-e2e5-4225-933e-ae494b508869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c19aa73-5b8c-476b-8a6a-d0ccd6b0f4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75224c30-fc6e-4d51-8bad-4aea42434fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d0cb666-eeb3-4221-906e-e9abe0569768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea42b58-9d4e-4d02-843a-72f6396b7204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5746700a-0f2f-45ba-8a30-7fce76e1cb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a6029b-623f-4019-9522-8e6f925e96f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a472377-8770-4676-b9f3-510cd1e01d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726c80ea-531b-46d7-ac44-3aaeaaea8d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd37bf3-baa7-4dcc-b96b-fcf77908a567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18ade4e-68a3-41ec-8e82-e69781123daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1661bd9d-3ede-425c-8b08-f06952054e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a1d716e-65af-4ded-a803-41c1785957a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22574485-d38b-4f0d-85cf-1f12c4ba9dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 628798b9-b870-4bd7-a761-603e2abab8ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d2818c-7117-43c6-bee6-d41369e30dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c502a0-c842-44b3-8db1-1701c17aa166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b35d315-5b70-49e0-bc45-142d04c68574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a523b88d-15ab-4cea-b578-07c528f30981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4236a1fd-379a-450f-99b0-a745891819ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcaf0f28-e66e-4b37-ada1-f66522665776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f60625da-feb9-4bae-a1b6-708de115081e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8b39c75-79b2-4021-91a7-5c7670d6e220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cd4efb4-86d4-4d74-8ec5-487947d5c112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c5ea32-0ed2-40ca-bf40-8b204d823909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af4771c-dc99-47d2-a427-daf782e48fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e4673a-9aef-4709-8393-9a61f8800f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 971dce2e-b341-4970-9183-4184a7327084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44864c75-a118-4613-bac8-8b001d9e0e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae70197-3a1d-4d39-b931-4b29941b2716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf463482-b3b2-4883-98c3-3c306ea16852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3762d074-a44d-4298-8efd-bd54ed446211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19274349-1d53-4aba-964d-217b73bcd5e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72eab026-f5ff-4800-9c8d-6a29e833a900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6c69f28-4a67-4833-8540-e641c13e3935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d064fe12-ff7d-4cb8-afd5-2a8c611bb927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dde6c87e-9827-4011-a6f3-3becf929f5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a88a82a-1c18-480d-a58e-25a4c8fb15dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fab40d2-e7bd-4a9c-97e9-d5b59430dc91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2998e4d-ea00-4869-a2ba-f0ed4f3a34b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26beae98-4e06-4fee-a852-0a587ad26d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f493a18b-f0e7-4b52-8419-e8747aeb06a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c6e89b-7165-4777-8ce6-b71cee35b97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be272372-5eb2-4fdf-82be-69914e555948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c664321-1589-415c-90cf-77213b89967e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5a97cab-4b6a-4798-af19-1a8d75334f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94ad1bb4-4af8-4dc0-87c6-ee6ff2574074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5f8d1a0-d867-4b52-b438-91e05ff62090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c59f67ea-610d-48d3-a893-fe474fe39101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b518080e-b40f-4d4c-9027-961aa2650d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4af34af-276e-4414-9263-e72a6e8ccf8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 267a4a62-d3dc-43f4-93bf-52371af7a0b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93bfadcd-0213-443d-9eb7-bc1e4a4d6d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27529117-bfe1-453a-a82a-1e50622d3bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b481e567-3e02-4af6-b495-3a9199f8ba17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e67bbc5-ba2c-4e80-b595-e130130da1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 323862c2-b297-458c-addc-8bdf91c7d7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fef305f-a44d-4e57-98eb-4c2a9fc089fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efaddc62-ef29-40ec-afbc-f4545b6f712c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f24a6194-7655-48bf-8b00-36995c80127a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2c04382-97cb-411f-8fec-dbd814e221d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be9e84f2-7b12-4043-9762-e5666611a610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d67937-8ad7-4d2f-8713-80263cc4be12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b04dca21-14e6-4c5d-9de4-35caee8a692a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fc031d9-6faf-4d5b-99ac-1530e8f9830f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c2b33e9-2ce1-4e51-aa9f-186b32f14cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4baf8c95-3f14-4a18-8bec-e7870dc8dea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d580862f-8aa3-43a6-ae69-c0a89fe1cb60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1883b85-dfdb-4a48-abff-ee8699f1d971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 664ba2a4-c056-4bf4-b6a2-d443e3fef054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c2a6eac-4cd6-434a-8032-2149162fae33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37eb7430-f59c-4877-8084-9b97b0567bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ca34ac-f68f-4b0b-96f7-8b9443dceee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a38dbf4-cc57-4ba7-a3f9-854b318afd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 864a29c0-876c-4dbc-bf1f-2da4d437dad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8f22c4-cca3-44a4-bd52-f0746e4d3241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0dfd065-b8e9-4cd0-b3c0-77b63fa29322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ef96749-9375-4317-9f5c-bdbdb929784b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8003524-e59c-4151-93dd-1967624ad297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637783a6-1402-4a92-b652-ab1b67f3bdfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3564fba-625e-4775-94e9-1ad5b1896638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 362507d2-2cb4-4d87-baab-5fd3614fe0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a3059d1-deaf-415d-a40b-da292a68a34c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5a2849c-e004-4326-8646-86370c6dc760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a938a659-c754-4161-a777-e70f6be4b98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c1a4c1-8422-40c3-91c4-adece68c89d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a391c75-85f0-4854-b6a5-33edc49f95ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd4c965a-2a34-4be1-ad16-19a08ba1526b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cc4cd03-2454-4c20-86c6-25f0a1cdb393
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_60
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/test_labels.txt

📊 Raw data loaded:
   Train: X=(1436, 24), y=(1436,)
   Test:  X=(359, 24), y=(359,)

⚠️  Limiting training data: 1436 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  350 samples, 5 features
✅ Client client_60 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 8 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1067, val=0.0858 (↓), lr=0.001000
   • Epoch   2/100: train=0.0832, val=0.0859, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0817, val=0.0867, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0820, val=0.0865, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0819, val=0.0862, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0795, val=0.0846, patience=3/15, lr=0.000500
   ✓ Epoch  21/100: train=0.0730, val=0.0801 (↓), lr=0.000500
   ✓ Epoch  31/100: train=0.0647, val=0.0740 (↓), lr=0.000500
   • Epoch  41/100: train=0.0607, val=0.0739, patience=10/15, lr=0.000500
   📉 Epoch 42: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 8 Summary - Client client_60
   Epochs: 46/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0627, RMSE=0.2504, R²=0.2319
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.1332
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1811, RMSE: 0.4256, MAE: 0.3521, R²: -1.1891

============================================================
🔄 Round 10 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1335, val=0.1046 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0875, val=0.0845 (↓), lr=0.000250
   • Epoch   3/100: train=0.0825, val=0.0854, patience=1/15, lr=0.000250
   📉 Epoch 4: LR reduced 0.000250 → 0.000125
   • Epoch   4/100: train=0.0825, val=0.0847, patience=2/15, lr=0.000125
   • Epoch   5/100: train=0.0822, val=0.0846, patience=3/15, lr=0.000125
   • Epoch  11/100: train=0.0820, val=0.0846, patience=9/15, lr=0.000125
   📉 Epoch 12: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 10 Summary - Client client_60
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0118
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0074
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1711, RMSE: 0.4136, MAE: 0.3423, R²: -1.0672

📊 Round 10 Test Metrics:
   Loss: 0.1666, RMSE: 0.4081, MAE: 0.3379, R²: -1.0129

============================================================
🔄 Round 12 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1489, val=0.1195 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1261, val=0.1011 (↓), lr=0.000063
   📉 Epoch 3: LR reduced 0.000063 → 0.000031
   ✓ Epoch   3/100: train=0.1061, val=0.0879 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.0945, val=0.0838 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.0893, val=0.0815 (↓), lr=0.000031
   📉 Epoch 11: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0828, val=0.0819, patience=5/15, lr=0.000016
   📉 Epoch 19: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0827, val=0.0820, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 12 Summary - Client client_60
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0249
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0031
============================================================


============================================================
🔄 Round 13 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1492, val=0.1365 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1462, val=0.1333 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1430, val=0.1304 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1401, val=0.1276 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1374, val=0.1251 (↓), lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1284, val=0.1171 (↓), lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.1216, val=0.1108, patience=1/15, lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1190, val=0.1084 (↓), lr=0.000001
   • Epoch  41/100: train=0.1168, val=0.1064, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1148, val=0.1044, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1129, val=0.1026 (↓), lr=0.000001
   • Epoch  71/100: train=0.1110, val=0.1008, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1092, val=0.0991, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.1075, val=0.0974, patience=3/15, lr=0.000001

============================================================
📊 Round 13 Summary - Client client_60
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.1056, RMSE=0.3249, R²=-0.2572
   Val:   Loss=0.0960, RMSE=0.3098, R²=-0.2584
============================================================


============================================================
🔄 Round 14 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1373, val=0.1609 (↓), lr=0.000001
   • Epoch   2/100: train=0.1370, val=0.1606, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1368, val=0.1604 (↓), lr=0.000001
   • Epoch   4/100: train=0.1365, val=0.1601, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1363, val=0.1598 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1349, val=0.1582 (↓), lr=0.000001
   • Epoch  21/100: train=0.1328, val=0.1558, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1309, val=0.1534 (↓), lr=0.000001
   • Epoch  41/100: train=0.1289, val=0.1511, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1271, val=0.1489, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1252, val=0.1466 (↓), lr=0.000001
   • Epoch  71/100: train=0.1233, val=0.1444, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1215, val=0.1422, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1196, val=0.1400 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_60
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1178, RMSE=0.3433, R²=-0.4435
   Val:   Loss=0.1379, RMSE=0.3714, R²=-0.6389
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1442, RMSE: 0.3798, MAE: 0.3156, R²: -0.7431

============================================================
🔄 Round 16 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1267, val=0.1321 (↓), lr=0.000001
   • Epoch   2/100: train=0.1265, val=0.1319, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1263, val=0.1316, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1261, val=0.1314 (↓), lr=0.000001
   • Epoch   5/100: train=0.1259, val=0.1312, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1247, val=0.1299, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1228, val=0.1277, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1209, val=0.1256 (↓), lr=0.000001
   • Epoch  41/100: train=0.1190, val=0.1235, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1171, val=0.1214, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1152, val=0.1193 (↓), lr=0.000001
   • Epoch  71/100: train=0.1134, val=0.1172, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1116, val=0.1151, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1098, val=0.1131 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_60
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1081, RMSE=0.3287, R²=-0.2963
   Val:   Loss=0.1113, RMSE=0.3336, R²=-0.4227
============================================================


============================================================
🔄 Round 18 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1118, val=0.1047 (↓), lr=0.000001
   • Epoch   2/100: train=0.1116, val=0.1046, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1114, val=0.1044, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1112, val=0.1042, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1110, val=0.1041 (↓), lr=0.000001
   • Epoch  11/100: train=0.1099, val=0.1031, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1081, val=0.1015 (↓), lr=0.000001
   • Epoch  31/100: train=0.1063, val=0.1000, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1045, val=0.0985 (↓), lr=0.000001
   • Epoch  51/100: train=0.1028, val=0.0970, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1011, val=0.0957 (↓), lr=0.000001
   • Epoch  71/100: train=0.0995, val=0.0943, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0980, val=0.0930 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.0965, val=0.0918 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_60
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0947, RMSE=0.3078, R²=-0.1531
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0922
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2533, R²: -0.0687

============================================================
🔄 Round 22 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 22 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0197
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0002
============================================================


============================================================
🔄 Round 24 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 24 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0059
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0142
============================================================


============================================================
🔄 Round 27 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 27 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0091
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0145
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2501, R²: -0.0313

============================================================
🔄 Round 28 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 28 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0046
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0025
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2500, R²: -0.0298

============================================================
🔄 Round 30 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 30 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0049
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0025
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2500, R²: -0.0295

📊 Round 30 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2499, R²: -0.0286

============================================================
🔄 Round 34 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 34 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0020
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0066
============================================================


============================================================
🔄 Round 36 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 36 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0036
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0025
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2498, R²: -0.0273

============================================================
🔄 Round 37 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 37 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0061
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0068
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2497, R²: -0.0265

============================================================
🔄 Round 41 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 41 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0024
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0176
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2497, R²: -0.0263

============================================================
🔄 Round 42 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 42 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0010
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0081
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2497, R²: -0.0262

============================================================
🔄 Round 44 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 44 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0008
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0084
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2497, R²: -0.0259

📊 Round 44 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2497, R²: -0.0259

📊 Round 44 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2497, R²: -0.0256

📊 Round 44 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2496, R²: -0.0254

============================================================
🔄 Round 50 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 50 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0004
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0129
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2496, R²: -0.0253

============================================================
🔄 Round 51 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 51 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0037
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0038
============================================================


============================================================
🔄 Round 53 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 53 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0006
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0128
============================================================


============================================================
🔄 Round 54 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 54 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0006
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0079
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2496, R²: -0.0251

📊 Round 54 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2496, R²: -0.0251

============================================================
🔄 Round 57 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 57 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0060
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0140
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2496, R²: -0.0252

============================================================
🔄 Round 58 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 58 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0010
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0160
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2496, R²: -0.0248

============================================================
🔄 Round 61 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 61 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0031
   Val:   Loss=0.0773, RMSE=0.2779, R²=0.0033
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2496, R²: -0.0247

📊 Round 61 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2496, R²: -0.0246

============================================================
🔄 Round 63 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 63 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0006
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0110
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2496, R²: -0.0244

============================================================
🔄 Round 66 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 66 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0003
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0164
============================================================


============================================================
🔄 Round 69 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 69 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0026
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0189
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2495, R²: -0.0240

============================================================
🔄 Round 71 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 71 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0001
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0084
============================================================


============================================================
🔄 Round 72 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 72 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0002
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0103
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2495, R²: -0.0237

📊 Round 72 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2495, R²: -0.0235

============================================================
🔄 Round 77 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 77 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0011
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0055
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2495, R²: -0.0233

============================================================
🔄 Round 78 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 78 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0001
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0076
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2495, R²: -0.0233

============================================================
🔄 Round 80 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 80 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0002
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0110
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2495, R²: -0.0232

============================================================
🔄 Round 83 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 83 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0014
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0056
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2495, R²: -0.0232

============================================================
🔄 Round 85 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 85 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0027
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0039
============================================================


============================================================
🔄 Round 87 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 87 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0012
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0045
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2495, R²: -0.0231

============================================================
🔄 Round 88 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 88 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0040
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0097
============================================================


============================================================
🔄 Round 89 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 89 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0049
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0106
============================================================


============================================================
🔄 Round 90 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 90 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0041
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0083
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2494, R²: -0.0228

📊 Round 90 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2494, R²: -0.0226

============================================================
🔄 Round 95 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 95 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0015
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0082
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2494, R²: -0.0224

============================================================
🔄 Round 97 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 97 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0005
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0129
============================================================


============================================================
🔄 Round 98 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 98 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0043
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0038
============================================================


============================================================
🔄 Round 99 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 99 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0030
   Val:   Loss=0.0917, RMSE=0.3029, R²=0.0044
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2494, R²: -0.0224

📊 Round 99 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2494, R²: -0.0223

============================================================
🔄 Round 102 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 102 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0037
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0095
============================================================


============================================================
🔄 Round 105 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 105 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0000
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0072
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2494, R²: -0.0220

============================================================
🔄 Round 106 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 106 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0023
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0057
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2494, R²: -0.0219

📊 Round 106 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2494, R²: -0.0218

============================================================
🔄 Round 108 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 108 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0002
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0076
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2494, R²: -0.0218

============================================================
🔄 Round 113 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 113 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0010
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0027
============================================================


============================================================
🔄 Round 114 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 114 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0021
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0001
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2493, R²: -0.0216

============================================================
🔄 Round 115 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 115 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0006
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0412
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2493, R²: -0.0216

============================================================
🔄 Round 116 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 116 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0015
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0114
============================================================


============================================================
🔄 Round 117 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 117 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0005
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0127
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2493, R²: -0.0215

============================================================
🔄 Round 121 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 121 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0014
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0012
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2493, R²: -0.0214

============================================================
🔄 Round 123 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 123 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0004
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0059
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2493, R²: -0.0213

============================================================
🔄 Round 125 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 125 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0011
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0020
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2493, R²: -0.0212

============================================================
🔄 Round 126 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 126 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0014
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0147
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2493, R²: -0.0212

============================================================
🔄 Round 128 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 128 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0018
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0028
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2493, R²: -0.0210

📊 Round 128 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2493, R²: -0.0211

============================================================
🔄 Round 132 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 132 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0010
   Val:   Loss=0.0699, RMSE=0.2644, R²=-0.0170
============================================================


============================================================
🔄 Round 133 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 133 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0009
   Val:   Loss=0.0696, RMSE=0.2639, R²=-0.0070
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2493, R²: -0.0209

============================================================
🔄 Round 135 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 135 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0016
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0025
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2493, R²: -0.0208

============================================================
🔄 Round 138 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 138 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0021
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0051
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2493, R²: -0.0207

============================================================
🔄 Round 140 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 140 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0018
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0019
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2493, R²: -0.0207

============================================================
🔄 Round 146 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 146 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0032
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0071
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2493, R²: -0.0208

============================================================
🔄 Round 147 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 147 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0006
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0057
============================================================


============================================================
🔄 Round 148 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 148 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0013
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0221
============================================================


============================================================
🔄 Round 149 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 149 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0010
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0131
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2493, R²: -0.0208

============================================================
🔄 Round 150 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 150 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0023
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0076
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2493, R²: -0.0207

============================================================
🔄 Round 153 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 153 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0016
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0023
============================================================


============================================================
🔄 Round 154 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 154 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0016
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0019
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2493, R²: -0.0207

============================================================
🔄 Round 155 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 155 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0002
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0116
============================================================


============================================================
🔄 Round 157 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 157 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0001
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0120
============================================================


============================================================
🔄 Round 158 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 158 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0036
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0061
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2492, R²: -0.0205

📊 Round 158 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2492, R²: -0.0205

============================================================
🔄 Round 160 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 160 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0011
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0046
============================================================


============================================================
🔄 Round 161 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 161 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0016
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0008
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2492, R²: -0.0204

📊 Round 161 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2492, R²: -0.0205

============================================================
🔄 Round 163 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 163 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0007
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0052
============================================================


============================================================
🔄 Round 164 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 164 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0015
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0005
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2492, R²: -0.0204

📊 Round 164 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2492, R²: -0.0203

============================================================
🔄 Round 166 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 166 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0041
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0089
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2492, R²: -0.0202

============================================================
🔄 Round 167 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 167 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0020
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0076
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0202

📊 Round 167 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0200

📊 Round 167 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0199

============================================================
🔄 Round 172 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 172 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0008
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0059
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0199

============================================================
🔄 Round 173 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 173 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0022
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0020
============================================================


============================================================
🔄 Round 174 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 174 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0045
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0079
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0198

============================================================
🔄 Round 176 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 176 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0027
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0034
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0199

📊 Round 176 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0199

============================================================
🔄 Round 178 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 178 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0010
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0016
============================================================


============================================================
🔄 Round 179 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 179 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0019
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0039
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0198

============================================================
🔄 Round 182 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 182 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0015
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0211
============================================================


============================================================
🔄 Round 183 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 183 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0011
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0112
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0198

============================================================
🔄 Round 184 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 184 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0014
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0042
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0197

============================================================
🔄 Round 185 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 185 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0005
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0040
============================================================


============================================================
🔄 Round 187 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 187 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0007
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0033
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0198

============================================================
🔄 Round 188 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 188 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0013
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0150
============================================================


============================================================
🔄 Round 189 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 189 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0025
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0050
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0197

📊 Round 189 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0197

============================================================
🔄 Round 192 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 192 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0010
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0119
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0195

============================================================
🔄 Round 196 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 196 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0013
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0096
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2492, R²: -0.0197

============================================================
🔄 Round 199 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 199 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0016
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0066
============================================================


============================================================
🔄 Round 200 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 200 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0015
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0004
============================================================


============================================================
🔄 Round 202 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 202 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0006
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0082
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2492, R²: -0.0194

📊 Round 202 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2491, R²: -0.0194

============================================================
🔄 Round 204 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 204 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0010
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0093
============================================================


============================================================
🔄 Round 205 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 205 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0030
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0078
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2492, R²: -0.0194

📊 Round 205 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2491, R²: -0.0193

============================================================
🔄 Round 208 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 208 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0035
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0033
============================================================


============================================================
🔄 Round 209 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 209 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0021
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0031
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2491, R²: -0.0194

❌ Client client_60 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
