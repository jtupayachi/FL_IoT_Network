[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d499a63-ce22-4d96-aaa2-53c20fc91421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66fe8c11-289f-47d5-8d38-7a611f920e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc20b3d-29ce-4268-b50e-9f95bb2243a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eb06d7f-6f6c-4619-8d66-6b48799d3132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a4e6de8-2ded-4af4-8662-0e57f2c9a27f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2356008-5aec-476e-ae98-ff0f65bf1d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eeee095-e516-471e-a17d-89154f8f27bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa710b6d-308c-41cc-93ff-f7257594dcd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6f494b-6bd0-4163-9c8b-da0b74332d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29d6b8b9-d761-4557-8dde-fe1e4c95c858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e01ce578-4362-4c2b-ba5a-9a85d8fdfabd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9fc53de-64f0-4672-9eb9-f1ad69e221f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99973043-9193-4566-9d3f-1cf824a3173a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 174980a8-a345-4c98-adad-d265593923f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e030de-6cfd-4c46-95f4-55ca074874a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a4cd970-53fd-4bd1-92ab-443c7399a89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e42a8de1-b7f1-44be-8b93-dc3c0f45102d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db8b874e-f9cb-4a94-a7ae-d6e1ffe0cf8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 754ec65c-0495-4546-875b-95f7b41b002f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2da8e0ce-7426-472c-a7cb-baeda160fac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6438b554-caff-48e6-8682-4f0723a84538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa0fe925-4167-47e7-8767-f89f47955935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bc20309-c130-4ce8-93ab-d30f3f448917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d09f297-22c8-46a8-a143-c0d3afcf658a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49850dda-7846-4baa-a515-9a21145f73a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90fe6cab-3116-489c-89ba-141bfc3d98f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 108f6514-9f44-4ea7-ab6f-8a715fe6aaa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83e8386-51c0-407a-bf59-6badbb22b767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0b4a920-d8ae-48b0-a5fa-6726354dc4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11502d4a-5982-4dd3-8321-77de78087871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9955cf2-07b2-4eac-aba3-610a095dac21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69e04f12-8eb1-43ed-8dca-09797607c6b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 001746ac-759c-439e-9d36-07f7b40cfd39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bba1ac67-a68f-4861-9e94-139f5280bfea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58c254f0-c249-4f69-9b7d-222b0ad7e865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22d27150-d5c8-4d97-829e-0dbfdfe6f112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9acae0cc-cfab-4c3e-94a3-765948c413f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e169df6-bc2d-4e9e-972b-4a3526c6f720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 867dceb8-0c96-4327-9a1e-1ba037223b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a581ade5-be71-433d-8668-3acec5845bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e39f46e8-f779-4b08-97b2-1740a1e89798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7467efe5-5c8f-4274-a904-f3d020bf3700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e4ef592-dbe6-4010-9f21-7a81f0a7cdf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ba69dea-2303-4e3f-922c-3dcc7fcb2c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26ce1ae3-c2d7-458d-a863-7a0c23f3169c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0d142f8-c511-4343-8b6d-624baa1ada59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8f25dd0-b8ec-410b-8773-35e45f0d8004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f41c7e2f-8447-46fc-98d8-830f79f83e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b4c9560-05a0-45ae-8e10-3bda93198cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8ef285b-bbb3-4408-816b-a308fa9ccd4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 830a0e28-fc6b-4d73-a887-25913d0ff763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ea42028-90e5-4eb9-87fb-bcc20a321b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ff44c22-aeba-4354-91ea-59c4bdd7bc25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 157e4622-081f-4225-80fd-dc895c9e6ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eee29dc-7c93-4952-9858-372261231280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2489b72c-b1fc-4135-bdfa-e821e073885e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee8ea617-9c48-4d3f-a489-ecfaa5add72c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2dfc73c-c54c-409f-994b-e9f37c56f269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcc9a75c-d8d6-4eb7-88ae-770d7dbcc05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ea5a5b9-8ea3-4d99-894a-9f01c84a4bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3839262-593a-48c8-9d93-ffc9f354ceb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e268d0-07ef-40c5-8007-26e7a00514dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e6fd3b5-5e28-4cbc-83a4-4b286a027f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7daa0684-3b96-4350-a131-aacb3ff928e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 009fefd5-3659-44f0-af38-ef9bff16d026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8f5d0ee-e7ea-455b-9b04-8b078dc64980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a22a005b-79be-44f6-91dc-ede81224ea92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30575871-49d8-4a28-8d9b-fae6be895602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96265271-51e3-4237-ac66-8c87a3dea7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 550ef9f6-c5c3-4151-a52d-35ce44294dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00adb5a1-6ab2-4749-b7e4-d60523589e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da157c02-045a-401c-a71d-8c06cdbe20bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f39b8ef8-1988-490d-bb58-18c358f16af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37436520-0625-4734-96e9-58c046846011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5c9c4c5-e4f9-42af-be52-8b45ea164b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 668c1112-33d2-4011-b8aa-96b3c1b60716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19ee0e31-0d32-414b-b8d5-6e8e75c8a64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dbe19b3-7e7a-4a90-bf7a-ba2ab8e9dd48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40283fd5-f7eb-469b-bf4d-b8ed08194380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32570b82-0d27-4104-8280-e6c49491ae8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c152e41-42ec-4e80-b4b7-e57a44a60604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8014ba42-bc84-4ed1-b0ac-df1e9bee044d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3344495-2709-44f6-87bf-2f5c14f38bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3606bf36-f124-44c3-89e7-68f22383da5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f2662a8-acd5-4470-8b78-0e90cc51e543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85ec73b1-08fb-4902-9202-303501631e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fb3b8d5-2607-401e-839c-07c649e1f674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 206775f1-4cc3-45b6-821e-28c1009232ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54e413a1-1926-4088-93aa-327f4cb5d2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08be601f-37b5-4d50-a205-6928b3caaba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 837b8bb0-586a-425e-aa15-84f88f6fddb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba2942f3-1fbd-4fb5-81ec-95fad3e8ae76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 917999b6-a539-45ab-94f3-21a980b0b00c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64150e45-1d4c-4883-b97b-2dbcb0943c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b384071a-d4b7-4353-a175-413106856b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 028744d4-02db-42c3-88a0-0dfe98ce07bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d084b3ca-4558-4b35-92bf-a9d068f1425b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ac3853-6a20-4db7-8910-5a8500a38472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a0670f5-de2c-438c-94ff-45002ae9093f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 981c1ceb-66c5-40a2-ba10-ecefb4af7de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e623d0a5-abad-40ec-9195-dffd076d4f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92b05458-9c94-4d21-9d55-2fa376e15029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9eba04e6-0392-48e9-91fd-a97ec90c1f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 856c9947-ebbf-46d4-91c1-a0671293f77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c2c98cf-d92a-4393-8d09-1d386f257789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3554226-4078-4e21-b8c6-8951360405e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4342560d-d06a-484d-9819-5ce6e76d8c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc75212e-54bd-4478-95b0-263dc6b87c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a07187cc-dd90-4aa0-9f3a-a01aa8d09c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bbe2509-e8bb-474c-a650-1953cc7d8753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c864e17-0c98-4f87-8270-64e080852b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f796d3a-b6fe-4591-a5b4-f44ce776b175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 939d36e5-2174-4506-9f5c-66ab9b36dbd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f7a0051-247d-4755-9763-3f3d51a56592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 110d7d6e-fda8-4bf8-8f72-f1cb7847ba01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a97321b8-6f11-4674-af1b-30440d59c2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6189538-70f4-4853-aafa-28d4fbe488ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efd5fc01-ba8c-48e4-9e96-ecbfba3f8513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b08423af-f8e9-4bf7-ba21-c1eead03a4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f451ed1-8c3c-4694-8900-effd9138da64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3910597c-549f-4c8b-b242-67664e4562cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09870b8c-d906-4dc0-8bf7-1fd137d4bfa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 333f3a53-8250-4102-ad50-8762d53b8d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65608418-22f6-45ce-a6c8-6c99de0fa822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2727d4d-2ca2-4c8b-b562-66fb74bf1358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67a9993d-7cae-4b3c-8460-c94c7b8a0dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c80cdae5-e60d-4360-beca-96353775b068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63006e91-ef8f-45cd-bc1b-00347df2c901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1d0e621-566d-43de-a979-abc64c2c5759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6829bbce-5db0-49ab-9df7-c11251fceb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e04d2094-6aae-45a7-b147-c55851b0de56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70246126-3f81-478b-892c-e48cb065875c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 075cbd39-5a81-466c-aa45-40a2a0b944f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce692673-aec1-43c7-84a2-298242ec0d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eaa640e-8e67-4680-9146-213d6f8e707c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 960071f2-5743-44ea-99a8-e749a2f7780b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c1b07d9-6652-49fe-a4d6-c013d30bd2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a140b3df-1760-4a38-a8a0-a1b4d55cbd3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 535ae790-ddef-4931-a9ce-074675801bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5136c0b-3a76-43c7-a089-eb08545f8d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77698420-c4f4-4e89-8bd7-c532558124a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e556ace-a6a1-43fe-a9b8-148b316a606e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1eae343-1bf8-497a-92cf-aae7581cafbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32921ee0-581c-49a0-a02b-21a95f98c420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbe9ecbb-03d2-43e3-9e59-bd9de3f7878b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 093a5c6b-1928-4881-8974-15e83effe0d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c6c1c8d-2374-4570-a10c-28d667e48eb4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_61
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/test_labels.txt

📊 Raw data loaded:
   Train: X=(1000, 24), y=(1000,)
   Test:  X=(251, 24), y=(251,)

⚠️  Limiting training data: 1000 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  242 samples, 5 features
✅ Client client_61 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1796, RMSE: 0.4238, MAE: 0.3447, R²: -1.2594

============================================================
🔄 Round 7 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1056, val=0.0879 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0926, val=0.0859 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0883, val=0.0842 (↓), lr=0.001000
   • Epoch   4/100: train=0.0870, val=0.0855, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0875, val=0.0852, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0843, val=0.0843, patience=1/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0814, val=0.0856, patience=11/15, lr=0.000250
   📉 Epoch 25: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 7 Summary - Client client_61
   Epochs: 25/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0262
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0105
============================================================


============================================================
🔄 Round 8 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1601, val=0.1213 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1181, val=0.0956 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0905, val=0.0925 (↓), lr=0.000125
   • Epoch   4/100: train=0.0843, val=0.0955, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0837, val=0.0940, patience=2/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0834, val=0.0950, patience=8/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 8 Summary - Client client_61
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0027
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0229
============================================================


============================================================
🔄 Round 9 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1657, val=0.1667 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1529, val=0.1538 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1413, val=0.1428 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.1311, val=0.1330 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1221, val=0.1242 (↓), lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   ✓ Epoch  11/100: train=0.0961, val=0.1004 (↓), lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008
   ✓ Epoch  21/100: train=0.0866, val=0.0913 (↓), lr=0.000008
   📉 Epoch 22: LR reduced 0.000008 → 0.000004
   📉 Epoch 30: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0856, val=0.0902, patience=1/15, lr=0.000002
   📉 Epoch 38: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0854, val=0.0900, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 9 Summary - Client client_61
   Epochs: 45/100 (early stopped)
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0076
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0181
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1606, RMSE: 0.4007, MAE: 0.3248, R²: -1.0202

============================================================
🔄 Round 12 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1613, val=0.1442 (↓), lr=0.000001
   • Epoch   2/100: train=0.1608, val=0.1438, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1603, val=0.1434 (↓), lr=0.000001
   • Epoch   4/100: train=0.1599, val=0.1430, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1595, val=0.1427 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1572, val=0.1408 (↓), lr=0.000001
   • Epoch  21/100: train=0.1541, val=0.1382, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1513, val=0.1359 (↓), lr=0.000001
   • Epoch  41/100: train=0.1488, val=0.1338, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1465, val=0.1318, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1442, val=0.1299 (↓), lr=0.000001
   • Epoch  71/100: train=0.1420, val=0.1280, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1398, val=0.1262, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1376, val=0.1244 (↓), lr=0.000001

============================================================
📊 Round 12 Summary - Client client_61
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1352, RMSE=0.3677, R²=-0.5929
   Val:   Loss=0.1228, RMSE=0.3505, R²=-0.4018
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1510, RMSE: 0.3886, MAE: 0.3152, R²: -0.8996

============================================================
🔄 Round 14 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1439, val=0.1585 (↓), lr=0.000001
   • Epoch   2/100: train=0.1437, val=0.1583, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1435, val=0.1580, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1433, val=0.1578 (↓), lr=0.000001
   • Epoch   5/100: train=0.1430, val=0.1576, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1418, val=0.1562, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1399, val=0.1539, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1379, val=0.1516 (↓), lr=0.000001
   • Epoch  41/100: train=0.1360, val=0.1494, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1341, val=0.1471, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1321, val=0.1448 (↓), lr=0.000001
   • Epoch  71/100: train=0.1302, val=0.1425, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1283, val=0.1403, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1264, val=0.1380 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_61
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1245, RMSE=0.3528, R²=-0.4437
   Val:   Loss=0.1359, RMSE=0.3686, R²=-0.6554
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1351, RMSE: 0.3676, MAE: 0.2990, R²: -0.7000

============================================================
🔄 Round 15 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1401, val=0.1232 (↓), lr=0.000001
   • Epoch   2/100: train=0.1399, val=0.1230, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1397, val=0.1228, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1394, val=0.1226 (↓), lr=0.000001
   • Epoch   5/100: train=0.1392, val=0.1225, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1379, val=0.1214, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1357, val=0.1196, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1336, val=0.1179 (↓), lr=0.000001
   • Epoch  41/100: train=0.1314, val=0.1162, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1293, val=0.1145, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.1272, val=0.1129, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1251, val=0.1112 (↓), lr=0.000001
   • Epoch  81/100: train=0.1230, val=0.1096, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1209, val=0.1080 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_61
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1191, RMSE=0.3451, R²=-0.4069
   Val:   Loss=0.1066, RMSE=0.3265, R²=-0.2156
============================================================


============================================================
🔄 Round 16 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1305, val=0.1401 (↓), lr=0.000001
   • Epoch   2/100: train=0.1303, val=0.1399, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1302, val=0.1397, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1300, val=0.1395 (↓), lr=0.000001
   • Epoch   5/100: train=0.1298, val=0.1393, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1286, val=0.1381, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1267, val=0.1361, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1248, val=0.1341 (↓), lr=0.000001
   • Epoch  41/100: train=0.1229, val=0.1322, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1210, val=0.1302, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1191, val=0.1282 (↓), lr=0.000001
   • Epoch  71/100: train=0.1172, val=0.1263, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1154, val=0.1243, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1135, val=0.1224 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_61
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1115, RMSE=0.3340, R²=-0.3229
   Val:   Loss=0.1207, RMSE=0.3474, R²=-0.3285
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0990, RMSE: 0.3147, MAE: 0.2611, R²: -0.2460

📊 Round 16 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2506, R²: -0.1175

📊 Round 16 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2441, R²: -0.0420

📊 Round 16 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2424, R²: -0.0174

============================================================
🔄 Round 23 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 23 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0089
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0155
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2422, R²: -0.0147

📊 Round 23 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2421, R²: -0.0109

📊 Round 23 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2420, R²: -0.0098

📊 Round 23 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2419, R²: -0.0086

============================================================
🔄 Round 30 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 30 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0069
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0198
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2419, R²: -0.0084

📊 Round 30 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0079

📊 Round 30 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0077

============================================================
🔄 Round 33 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 33 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0016
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0368
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2419, R²: -0.0076

📊 Round 33 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2418, R²: -0.0068

============================================================
🔄 Round 37 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 37 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0013
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0295
============================================================


============================================================
🔄 Round 38 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 38 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0061
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0092
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2418, R²: -0.0065

============================================================
🔄 Round 39 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 39 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0021
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0158
============================================================


============================================================
🔄 Round 40 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 40 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0039
   Val:   Loss=0.0873, RMSE=0.2956, R²=-0.0022
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: -0.0059

============================================================
🔄 Round 45 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 45 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0014
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0278
============================================================


============================================================
🔄 Round 46 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 46 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0031
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0091
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: -0.0057

📊 Round 46 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: -0.0055

============================================================
🔄 Round 48 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 48 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0034
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0026
============================================================


============================================================
🔄 Round 49 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 49 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0049
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0035
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: -0.0053

📊 Round 49 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: -0.0052

============================================================
🔄 Round 54 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 54 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0021
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0068
============================================================


============================================================
🔄 Round 56 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 56 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0031
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0026
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: -0.0053

============================================================
🔄 Round 58 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 58 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0043
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0029
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2418, R²: -0.0051

============================================================
🔄 Round 59 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 59 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0018
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0476
============================================================


============================================================
🔄 Round 61 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 61 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0042
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0039
============================================================


============================================================
🔄 Round 62 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 62 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0028
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0034
============================================================


============================================================
🔄 Round 63 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 63 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0022
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0126
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: -0.0048

📊 Round 63 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2417, R²: -0.0047

📊 Round 63 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2417, R²: -0.0047

============================================================
🔄 Round 69 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 69 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0026
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0030
============================================================


============================================================
🔄 Round 70 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 70 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0039
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0037
============================================================


============================================================
🔄 Round 71 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 71 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0017
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0076
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: -0.0045

📊 Round 71 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: -0.0044

📊 Round 71 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: -0.0042

============================================================
🔄 Round 80 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 80 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0043
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0005
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 81 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 81 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0028
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0271
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2417, R²: -0.0040

📊 Round 81 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2417, R²: -0.0036

📊 Round 81 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2417, R²: -0.0036

============================================================
🔄 Round 99 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.1036 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.1036, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.1036, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.1036, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.1036, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.1036, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1036)

============================================================
📊 Round 99 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0013
   Val:   Loss=0.1036, RMSE=0.3219, R²=-0.0055
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2417, R²: -0.0035

📊 Round 99 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2417, R²: -0.0035

============================================================
🔄 Round 101 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 101 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0030
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0022
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2417, R²: -0.0034

📊 Round 101 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2417, R²: -0.0032

============================================================
🔄 Round 109 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 109 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0039
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0014
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2417, R²: -0.0031

📊 Round 109 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2417, R²: -0.0031

============================================================
🔄 Round 115 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 115 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0010
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0122
============================================================


============================================================
🔄 Round 116 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 116 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0026
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0048
============================================================


============================================================
🔄 Round 117 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 117 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0026
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0033
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0031

📊 Round 117 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0030

📊 Round 117 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0030

============================================================
🔄 Round 121 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 121 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0020
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0034
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0029

📊 Round 121 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0029

📊 Round 121 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0029

============================================================
🔄 Round 129 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 129 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0005
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0215
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0028

📊 Round 129 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0028

============================================================
🔄 Round 131 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 131 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0021
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0050
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0028

============================================================
🔄 Round 132 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 132 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0019
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0066
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0027

📊 Round 132 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0026

📊 Round 132 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0026

============================================================
🔄 Round 140 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 140 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0027
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0003
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 143 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 143 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0018
   Val:   Loss=0.0704, RMSE=0.2654, R²=-0.0140
============================================================


============================================================
🔄 Round 146 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 146 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0032
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0113
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0027

============================================================
🔄 Round 147 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 147 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0024
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0023
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0027

============================================================
🔄 Round 150 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 150 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0025
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0066
============================================================


============================================================
🔄 Round 154 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 154 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0020
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0020
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0027

📊 Round 154 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0026

📊 Round 154 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0026

📊 Round 154 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0026

============================================================
🔄 Round 160 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 160 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0026
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0006
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 161 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 161 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0025
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0071
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 163 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 163 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0018
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0030
============================================================


============================================================
🔄 Round 164 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 164 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0018
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0084
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2416, R²: -0.0025

============================================================
🔄 Round 165 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 165 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0030
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0014
============================================================


============================================================
🔄 Round 166 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 166 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0038
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0005
============================================================


============================================================
🔄 Round 167 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 167 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0015
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0036
============================================================


============================================================
🔄 Round 168 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 168 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0049
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0331
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2416, R²: -0.0023

============================================================
🔄 Round 169 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 169 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0039
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0022
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2416, R²: -0.0023

============================================================
🔄 Round 170 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 170 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0002
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0099
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2416, R²: -0.0023

📊 Round 170 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2416, R²: -0.0022

📊 Round 170 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2416, R²: -0.0022

📊 Round 170 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2416, R²: -0.0022

============================================================
🔄 Round 181 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 181 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0011
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0071
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2416, R²: -0.0022

📊 Round 181 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2416, R²: -0.0022

============================================================
🔄 Round 184 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 184 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0026
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0007
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2416, R²: -0.0022

📊 Round 184 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2416, R²: -0.0022

============================================================
🔄 Round 189 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 189 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0014
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0060
============================================================


============================================================
🔄 Round 191 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 191 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0040
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0086
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2416, R²: -0.0021

📊 Round 191 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2416, R²: -0.0021

📊 Round 191 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2416, R²: -0.0021

============================================================
🔄 Round 194 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 194 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0025
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0044
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2416, R²: -0.0022

============================================================
🔄 Round 198 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 198 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0019
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0074
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2416, R²: -0.0021

============================================================
🔄 Round 203 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 203 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0021
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0006
============================================================


============================================================
🔄 Round 204 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 204 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0022
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0126
============================================================


============================================================
🔄 Round 205 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 205 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0035
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0061
============================================================


============================================================
🔄 Round 208 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 208 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0003
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0081
============================================================


============================================================
🔄 Round 209 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 209 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0031
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0004
============================================================


============================================================
🔄 Round 210 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 210 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0033
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0007
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2416, R²: -0.0020

❌ Client client_61 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
