[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 150bc54c-0845-48b0-9d87-1d8a81a422b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36591d64-8eb3-4adf-992c-9db50964bd6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad20db29-6eab-47a9-bf68-20028f942aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a02ca5a-59ac-4b82-bab6-5e7906174a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 231c0f3d-3f12-4f97-892c-25b7947b1463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c06a1e6c-22c4-489d-831d-b0b5b449fefd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9afd9104-a4a9-430b-a15b-0200919ebc6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c063504-83d9-4952-8eb6-3e6f54c3dc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcaf8bfe-f9e3-4736-adc0-33b025748d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f83f551-1a43-48bf-9a47-8b32ab78cb9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c89f3fcb-d434-4f31-841e-a2b2dee1f441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82992845-c03b-4d2d-b2dd-4fee06ba0fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 243ef94e-5ede-4c02-8c0b-a1117f6edc07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a0f1be5-221f-4914-ae03-e968a964eade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62da80fe-5673-4487-87c0-bb109ae8dda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dd6a874-8795-4016-bb74-be6fa2f5c8ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7e08f94-9906-4fbb-a6ae-bce1ffa15c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2439f6e-f2eb-4440-8994-af36a12b850e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b112fd5-7809-4988-86c2-72315ad35a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37ff97d3-3f6c-4580-8ab9-699fbf44cb1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ffa9fd-38fa-44a3-a192-9a4ae667d5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a9042cc-74f7-4fc2-9bef-522308574d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c51d1ea7-de65-44e4-968b-5f5abb2dc3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9d69801-5540-4ad1-82d8-08b40a13d275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e27e93a-0dc7-44c5-9b42-6f8eb74501f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6551b20b-a41f-4f76-b7d3-3fb628a3a898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48429f45-2c9c-4e03-b871-33bd51ca6605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1b10c58-e842-497f-8c8d-51e04880b2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eccfb4a-19a9-43f5-bee5-da639174b534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3fe24de-b405-4bb7-bf74-84939bc9fa48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8f2035-28bf-49ad-8ecd-64849f9fd803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e69af2b-c500-41ab-bd15-5b523d4d3f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 498c531e-642d-4597-976f-9d66a039c7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cf60f0b-27ce-41df-80f2-8043c8410a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90108950-3004-4199-b00a-9f0ca0f91bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 166b03dc-3ffe-4661-941a-46789286cc61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e30a55-0ff7-4a08-8104-05877d1e3afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 305e63c8-e9de-48ba-b9c7-ccd592b78098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f968a593-3b9d-4136-a626-6e2f9f43f348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8bf4010-bbed-4cb0-99f4-47ac9c0c21f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52c43599-b546-426f-b835-8b02a3490873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63b25753-4bf0-48a1-b28f-5f23b2efd37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83c1f7be-c3ab-4938-8636-2229953d6831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c82e34ce-a00d-4039-b4f5-2dd45575afe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ad9c7f0-6fc4-4092-84a5-597affbb2912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25583bf0-50d1-49dd-85f1-2d8ba64e85b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5e29a4d-6ebb-43ff-8d3d-f8fa0b29e83b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfe1703c-c8e0-4b4c-b388-ff3d4b190dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 551b0d45-db2f-46cb-b2b1-6fef68b5aec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8885cc10-e2be-47d2-ac6b-dd99ecb8bec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaf75037-ddcb-45b4-bd67-ce287a70fe27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d236c2d7-d917-4b47-9ce5-5ab8a9918f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8272b5-988f-4120-8e54-e3ff8bcb1823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dec9a7c-cd72-4c1a-bd02-4d05e61f632c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb12faf-8e85-435a-b12f-58f4ebdc7606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5318465a-9adf-4eb4-bdba-bb8c51546463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb68c4c-26af-46a7-91a8-bebd632f88a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f961dc-a390-402b-ab1a-4540a587cbde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ed0a7d-41b5-4668-80c9-e0add9ebd60e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77fc24a7-fff2-490a-a50e-962e7ec80ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a59460b-e610-4513-8954-bd27eb2f6d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e0cce87-4e51-43f6-bcab-7422320ff6bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b73e8ea7-7ea3-4c8f-a595-6921940addca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02c8160c-0f02-46df-8707-d1b7fbf7e051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55c92357-2560-4f9d-8216-6ce7e4ca6f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14d270a-1faf-41de-b31e-cc01c137609b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 337760b6-c313-4d0d-a76b-ad4f66721b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 156d69b5-7dba-4d03-ba60-61b5aef12075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f3ce78-0b94-4531-b4eb-667fcafad835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f763807-a777-4144-8055-b06c293ecacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 630dc91f-8262-4c73-ba57-3c1d833b231e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1abc5f2d-ea19-45ca-bd66-9acf3f497e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a67cf8f0-5942-46b3-a1d4-fcabecb99a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 839efb82-6ad4-4b04-ba8a-a815a09024c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d188cfcb-d854-46c7-9131-50d4c45c7667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d894e8d-5ac5-434b-98af-fea002ce6c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e8bd751-ea9e-4dab-ac7b-c785b17af2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70ec5759-a323-4d4c-8176-c89e5fd5178a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31a3bb1a-b9ec-4186-a1df-32308104ca06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c56dedf-6608-42fd-8a0c-198bf2448324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e5773f6-f278-465d-9282-647ecfb0938f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8162988b-2838-4ce0-b5d9-cc06952cde46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24d55f9e-38c5-421d-a087-f8a83999939a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78479be-107b-4563-bc4b-474ab5c4b299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1243666-9d10-45c2-a165-deb525504565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9b15359-e23e-4412-8fec-2b16751d39ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1436b93a-8792-4672-92a9-d36bc809405e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3296ec-9cd9-4c39-a2f0-ec9bfb7aeb49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 792c06a6-28bf-4cc7-ac4b-83571499a799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e22d122-50d5-4fcb-aef1-77975eabca57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce8f9f4-26a7-4aef-8f3e-770d24064e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5795783-534f-48c4-97e1-1e2b35501838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cade88a6-f3e1-4185-8e3b-d92c4d6eb707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf49f047-ab11-4723-8c26-9118062ab78a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b34e11f0-0411-4118-8e2b-dc10827b8a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a407765e-695f-49c6-9fd6-8769a7463174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67818c29-0f08-410b-bb90-0ea3bf72e4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2262b48-884d-47b4-a10d-87396162605f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198b69f3-f87e-4552-be33-f1c527bf35e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 433087c2-9ed5-429e-9cf3-182cf11db200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41f5686-ca27-408f-a6a4-196a3b02e950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1638c20c-3acb-482b-a401-50b6980bd50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a8e92c-5a97-46ea-8743-5d0caa116a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efc033cf-3ee4-414f-9a64-9805881fe719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b4a6fd3-eacf-433b-a505-338a21d5d5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9762aabe-15b5-4ad7-969f-b76557256b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9069ee-e900-42c9-bd05-4894fc366875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 271ca559-8e7e-4241-9afc-46778dda5dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6092d881-0cf4-4b39-ae6e-cb362fc2bb06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65cff163-335e-4311-8cd3-1c51bbd1a919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe8dbd6a-87f3-42db-b4d1-5afb22b3123c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7247c207-1c39-4e46-aefd-e8243bab7b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d65b09a-7bb3-4b9b-9f92-b0144188e428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd7ad2e-c7a0-44c9-a7ed-4d2acfbcd9a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55ca4399-2895-4712-9bb0-dc2af211399e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd9afaae-a405-4744-a0a4-ea15f7a3390e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23abded6-65ef-45e9-a655-8476671e51f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd14f065-de9f-4394-9917-c3bdd6ae78c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 918b6155-0254-404b-9913-4fb2a62c8739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e23db7de-50a1-4f91-838f-51fc42dddca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e05eed82-2918-49da-bdd6-4eba9c516260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05449da2-c1e6-4d89-906f-58cceaec8ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18491878-4553-4dea-9720-3eaa8dbb760a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12ce3be2-93f7-4b01-a38f-63460aebcc05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38145fb8-3016-484f-a33e-742d1a395933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97019250-ad15-41b4-804b-c9d855d6b1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80875800-7c7b-4f44-aaa2-1c2bb73f13a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b32951c-bd63-450f-93e9-9b8e06c08cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b64e892a-174c-48cb-88b3-12c14f57b626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 926bc1c4-be74-41af-bfda-3783721b0c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e6b081-d84a-4f6d-8b31-3b32e6ce63bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3899e829-99b5-4741-95cf-5046b0bcc9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 495784e3-3909-455d-8928-11dca817098d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ab0ea32-5469-401b-ac78-3d1f2951fdcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b687f777-a817-411f-9969-cce56fba950c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f4e5263-a233-41f2-bcbf-b81d993e44c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a03fb82d-9cf6-4f9f-89d6-d0f541356c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18ce4e1-7f78-469f-bcda-05703fb31b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0cd42bf-9c45-43ec-a9a4-26217b36fb9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0159ce6-b7cd-4bb0-926b-2ae1dace4b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17f9cf61-ed74-4a44-ab83-ce77bb7e9957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9303ce04-4dfb-4f33-8499-bed32ce81299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36ee01f4-b6bb-48a7-9ed2-54f7125a8e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eae61865-c0af-4efd-9005-6671d33b76f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde0d297-0447-425a-8ce6-52e170a8a7a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68141950-85c2-470a-b424-21b463a6e170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14c2bb6f-f712-4510-b038-98e1fd689bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5d92cc7-27ee-46a2-969c-e8cd2bc8b863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddedcd4e-26bc-485f-aeca-c0f14b2be8d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ca9806-9ab4-4ee1-89dd-4591b2880788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba766541-730e-4a04-a52a-a1f849a9881b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cbdcb08-ecf9-4982-ae1b-dc743ca8f916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f81e25d-00e9-47a1-8183-a61abb90286c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07737290-4652-48cc-97f7-a23c3b3bd342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4907773-ddc4-459c-b51c-90c6879cb169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac1e9de-3fcc-4cf4-9f7d-a42db848a6c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c791d67-cf97-4fb6-b31f-780b985d3d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 337b6113-0ece-42a8-9df7-04b46295af5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3be20ae1-dc2b-466e-b782-5a5b3e42e8b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa043571-60be-4b51-acb3-a80b387c7f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d48203-dc00-41b0-ad79-da1b1a4104a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e19efcbb-1962-43c2-bee5-222a3e44e3c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5960537-7f52-4641-bfee-d6fd1ac1a5fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 187be1c7-8c9a-4556-a68b-7aee07b9af8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f69b9b87-8e5d-4a92-a49b-2b1cf1388b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5179a825-3954-4f74-9663-1a7bde185fc5
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_62
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/test_labels.txt

📊 Raw data loaded:
   Train: X=(1464, 24), y=(1464,)
   Test:  X=(367, 24), y=(367,)

⚠️  Limiting training data: 1464 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  358 samples, 5 features
✅ Client client_62 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 8 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1125, val=0.0875 (↓), lr=0.001000
   • Epoch   2/100: train=0.0867, val=0.0893, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0839, val=0.0868 (↓), lr=0.001000
   • Epoch   4/100: train=0.0846, val=0.0877, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0843, val=0.0875, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0826, val=0.0871, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 8 Summary - Client client_62
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0093
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0471
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1768, RMSE: 0.4205, MAE: 0.3430, R²: -1.1337

============================================================
🔄 Round 10 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1426, val=0.1186 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0966, val=0.0864 (↓), lr=0.000250
   • Epoch   3/100: train=0.0835, val=0.0865, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0830, val=0.0864, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0830, val=0.0864, patience=3/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0825, val=0.0865, patience=9/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 10 Summary - Client client_62
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0008
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0045
============================================================


============================================================
🔄 Round 15 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.1203, val=0.1248 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0989, val=0.1091 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0883, val=0.0987 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0832, val=0.0941 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0818, val=0.0928 (↓), lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0816, val=0.0928, patience=6/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 15 Summary - Client client_62
   Epochs: 20/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0020
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0116
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1320, RMSE: 0.3633, MAE: 0.3001, R²: -0.5929

📊 Round 15 Test Metrics:
   Loss: 0.1169, RMSE: 0.3419, MAE: 0.2858, R²: -0.4107

📊 Round 15 Test Metrics:
   Loss: 0.1041, RMSE: 0.3227, MAE: 0.2733, R²: -0.2568

============================================================
🔄 Round 19 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1021, val=0.0875 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0990, val=0.0845 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.0959, val=0.0818 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.0933, val=0.0796 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.0912, val=0.0780 (↓), lr=0.000016
   • Epoch  11/100: train=0.0862, val=0.0746, patience=1/15, lr=0.000016
   📉 Epoch 19: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0858, val=0.0746, patience=11/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 19 Summary - Client client_62
   Epochs: 25/100 (early stopped)
   LR: 0.000016 → 0.000008 (1 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0070
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0064
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0936, RMSE: 0.3060, MAE: 0.2633, R²: -0.1298

============================================================
🔄 Round 21 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0888 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0848, val=0.0885, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0845, val=0.0884, patience=2/15, lr=0.000004
   ✓ Epoch   4/100: train=0.0843, val=0.0882 (↓), lr=0.000004
   • Epoch   5/100: train=0.0842, val=0.0881, patience=1/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0835, val=0.0876, patience=1/15, lr=0.000002
   📉 Epoch 18: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0833, val=0.0875, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 21 Summary - Client client_62
   Epochs: 25/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0067
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0091
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2542, R²: -0.0281

============================================================
🔄 Round 23 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 23 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0078
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0115
============================================================


============================================================
🔄 Round 25 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 25 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0049
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0060
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2533, R²: -0.0193

============================================================
🔄 Round 29 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 29 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0048
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0032
============================================================


============================================================
🔄 Round 30 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 30 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0009
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0111
============================================================


============================================================
🔄 Round 32 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 32 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0036
   Val:   Loss=0.0948, RMSE=0.3079, R²=0.0009
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2531, R²: -0.0175

📊 Round 32 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2530, R²: -0.0166

📊 Round 32 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2529, R²: -0.0163

📊 Round 32 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2529, R²: -0.0161

📊 Round 32 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2529, R²: -0.0159

============================================================
🔄 Round 41 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 41 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0005
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0087
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2529, R²: -0.0158

📊 Round 41 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2528, R²: -0.0154

============================================================
🔄 Round 47 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 47 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0022
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0006
============================================================


============================================================
🔄 Round 50 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 50 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0009
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0107
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2528, R²: -0.0149

============================================================
🔄 Round 53 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 53 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0011
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0221
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2528, R²: -0.0149

📊 Round 53 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2528, R²: -0.0149

📊 Round 53 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2528, R²: -0.0149

============================================================
🔄 Round 57 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 57 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0008
   Val:   Loss=0.0666, RMSE=0.2580, R²=-0.0039
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2528, R²: -0.0149

============================================================
🔄 Round 58 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 58 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0001
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0126
============================================================


============================================================
🔄 Round 59 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 59 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0029
   Val:   Loss=0.0752, RMSE=0.2741, R²=0.0037
============================================================


============================================================
🔄 Round 60 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0976, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 60 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0025
   Val:   Loss=0.0976, RMSE=0.3125, R²=-0.0024
============================================================


============================================================
🔄 Round 62 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 62 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0037
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0066
============================================================


============================================================
🔄 Round 63 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 63 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0007
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0078
============================================================


============================================================
🔄 Round 64 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 64 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0006
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0096
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2527, R²: -0.0144

============================================================
🔄 Round 65 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 65 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0004
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0064
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2527, R²: -0.0143

📊 Round 65 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2527, R²: -0.0142

============================================================
🔄 Round 67 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 67 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0007
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0199
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2527, R²: -0.0143

============================================================
🔄 Round 68 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 68 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0000
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0049
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2527, R²: -0.0143

📊 Round 68 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2527, R²: -0.0142

============================================================
🔄 Round 70 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 70 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0021
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0363
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2527, R²: -0.0140

============================================================
🔄 Round 71 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 71 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0006
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0049
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2527, R²: -0.0139

📊 Round 71 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2527, R²: -0.0139

📊 Round 71 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: -0.0137

============================================================
🔄 Round 75 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 75 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0004
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0073
============================================================


============================================================
🔄 Round 76 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 76 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0050
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0071
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: -0.0136

============================================================
🔄 Round 78 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 78 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0046
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0136
============================================================


============================================================
🔄 Round 81 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 81 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0002
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0045
============================================================


============================================================
🔄 Round 82 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.1034 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.1034, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.1034, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.1034, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.1034, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.1034, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1034)

============================================================
📊 Round 82 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0013
   Val:   Loss=0.1034, RMSE=0.3216, R²=-0.0078
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: -0.0134

📊 Round 82 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: -0.0133

============================================================
🔄 Round 84 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 84 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0014
   Val:   Loss=0.0821, RMSE=0.2864, R²=-0.0173
============================================================


============================================================
🔄 Round 85 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 85 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0016
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0104
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2526, R²: -0.0134

============================================================
🔄 Round 87 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 87 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0002
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0030
============================================================


============================================================
🔄 Round 88 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 88 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0020
   Val:   Loss=0.0698, RMSE=0.2643, R²=-0.0137
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2526, R²: -0.0132

📊 Round 88 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2526, R²: -0.0132

============================================================
🔄 Round 92 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 92 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0009
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0074
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2525, R²: -0.0130

============================================================
🔄 Round 93 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 93 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0042
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0042
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2525, R²: -0.0130

============================================================
🔄 Round 94 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 94 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0006
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0053
============================================================


============================================================
🔄 Round 96 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 96 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0014
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0106
============================================================


============================================================
🔄 Round 97 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 97 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0006
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0069
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2525, R²: -0.0129

📊 Round 97 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2525, R²: -0.0129

============================================================
🔄 Round 100 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 100 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0005
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0090
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2525, R²: -0.0128

============================================================
🔄 Round 101 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 101 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0027
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0063
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2525, R²: -0.0127

📊 Round 101 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2525, R²: -0.0126

📊 Round 101 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2525, R²: -0.0126

============================================================
🔄 Round 107 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 107 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0026
   Val:   Loss=0.0989, RMSE=0.3145, R²=0.0015
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2525, R²: -0.0125

📊 Round 107 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2525, R²: -0.0124

📊 Round 107 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2525, R²: -0.0124

============================================================
🔄 Round 111 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 111 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0018
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0098
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2525, R²: -0.0124

============================================================
🔄 Round 114 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 114 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0029
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0038
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2525, R²: -0.0124

📊 Round 114 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2525, R²: -0.0123

============================================================
🔄 Round 118 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 118 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0003
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0061
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2525, R²: -0.0124

============================================================
🔄 Round 119 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 119 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0020
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0242
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2525, R²: -0.0123

📊 Round 119 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2524, R²: -0.0123

📊 Round 119 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2524, R²: -0.0122

📊 Round 119 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2524, R²: -0.0122

📊 Round 119 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2524, R²: -0.0122

============================================================
🔄 Round 124 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 124 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0002
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0042
============================================================


============================================================
🔄 Round 126 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 126 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0001
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0012
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2524, R²: -0.0121

============================================================
🔄 Round 127 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 127 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0009
   Val:   Loss=0.0954, RMSE=0.3088, R²=-0.0047
============================================================


============================================================
🔄 Round 128 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 128 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0004
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0004
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2524, R²: -0.0121

============================================================
🔄 Round 129 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 129 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0003
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0006
============================================================


============================================================
🔄 Round 135 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 135 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0014
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0071
============================================================


============================================================
🔄 Round 136 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 136 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0023
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0127
============================================================


============================================================
🔄 Round 137 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 137 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0038
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0136
============================================================


============================================================
🔄 Round 138 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 138 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0003
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0045
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2524, R²: -0.0117

============================================================
🔄 Round 140 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 140 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0013
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0145
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2524, R²: -0.0117

============================================================
🔄 Round 141 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 141 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0011
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0090
============================================================


============================================================
🔄 Round 142 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 142 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0003
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0079
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2524, R²: -0.0118

📊 Round 142 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2524, R²: -0.0119

============================================================
🔄 Round 147 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 147 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0032
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0153
============================================================


============================================================
🔄 Round 148 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 148 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0008
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0056
============================================================


============================================================
🔄 Round 150 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 150 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0009
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0009
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2524, R²: -0.0119

📊 Round 150 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2524, R²: -0.0120

📊 Round 150 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2524, R²: -0.0120

📊 Round 150 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2524, R²: -0.0120

============================================================
🔄 Round 155 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 155 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0021
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0064
============================================================


============================================================
🔄 Round 156 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 156 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0026
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0053
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2524, R²: -0.0119

============================================================
🔄 Round 161 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 161 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0022
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0049
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2524, R²: -0.0118

📊 Round 161 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2524, R²: -0.0118

📊 Round 161 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2524, R²: -0.0117

📊 Round 161 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2524, R²: -0.0116

============================================================
🔄 Round 169 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 169 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0027
   Val:   Loss=0.0692, RMSE=0.2632, R²=-0.0153
============================================================


============================================================
🔄 Round 171 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 171 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0021
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0080
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

============================================================
🔄 Round 172 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 172 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0045
   Val:   Loss=0.0813, RMSE=0.2850, R²=0.0036
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

📊 Round 172 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

📊 Round 172 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

============================================================
🔄 Round 178 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 178 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0006
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0057
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

📊 Round 178 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

============================================================
🔄 Round 180 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 180 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0008
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0046
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

============================================================
🔄 Round 181 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 181 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0018
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0109
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

============================================================
🔄 Round 183 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 183 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0032
   Val:   Loss=0.0856, RMSE=0.2927, R²=0.0115
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

============================================================
🔄 Round 184 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 184 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0034
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0136
============================================================


============================================================
🔄 Round 186 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 186 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0023
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0095
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

📊 Round 186 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0112

📊 Round 186 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0112

============================================================
🔄 Round 197 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 197 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0020
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0093
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

============================================================
🔄 Round 198 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 198 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0016
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0057
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0114

📊 Round 198 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0113

============================================================
🔄 Round 202 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 202 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0004
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0046
============================================================


============================================================
🔄 Round 206 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 206 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0008
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0195
============================================================


============================================================
🔄 Round 208 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 208 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0013
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0045
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2523, R²: -0.0113

============================================================
🔄 Round 210 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 210 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0023
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0109
============================================================


❌ Client client_62 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
