[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a435908-1283-4607-9534-efe927fead10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e55e42fd-cf9e-4660-98c1-b706c8d03613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a85d2c8-8610-4ac0-9ee2-4833e11f24a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9f674ca-a1ed-426f-a8a2-c7841ccac48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b3970d9-e1a1-4c79-8e45-0732bb344884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c117857-68d2-4821-842c-f2ab47128f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d468371-2ed5-4101-a489-1ab2285128b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0256a0d9-6603-4de5-a671-6691b1f46a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 476bc182-fb80-451a-a009-3d2fc7bcaa93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 334fe1f5-1911-403d-a15d-c7074bc4bbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1336ed89-642a-4822-a21d-204df334aded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12ffbdc4-a3f8-4044-9cb4-7ca475792f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33b75e6f-1357-4c5c-8fda-ee92317450a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34ac80a1-52da-4a97-89a5-90ccc0276a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b477b8b8-8c06-455f-8227-f612905a513e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65362372-e40c-4f87-9131-febaf8968cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93a605fa-31c6-4d97-b3a5-109383f6bb49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e8c640-a388-44cb-a46a-70d254fe0957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72bdcc29-a934-49df-abb5-dcaf8a6e0b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70622caa-1f29-48ff-8c96-f7475ad4d45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1625c5-401d-4c23-b67a-f6e8829639d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2052a504-3933-42f8-8b70-233ead565a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76819589-63f9-49a6-8e6e-3d2055991792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f7dd9e4-23af-4b89-a28a-9c9446c96781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7487dbd-f1f7-40dc-9f96-94b22f478f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae92a4f7-19c1-43c9-8d6c-dd5a05227843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5124f911-aea0-4a9a-ad96-078d1bd80b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69fd3c77-f88a-4b92-9a4e-0688c46daa93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d003d41c-b05e-4eb0-a3e7-923a9cbe8b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0c60a72-37b9-4c15-b5d8-212767ce8299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f367fdb5-518c-46a4-a4f1-8a75017cac3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09161772-378e-4f20-b9e7-28a066f880d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d14e9f4c-ac8b-4773-93b1-b976c1697209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a05ff64-9195-4e8b-a211-b9c18950de9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07ca0339-da82-43a0-8e4a-1ad09af3dbc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7bfc7b-e742-48ce-a597-cf2a59fb29cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e4d0f5-3674-4bec-8e40-27940730fac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 615cc1d2-ff41-4ad1-bc91-5e76c6cd2966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96f3f91b-64bf-43a3-80ec-ebb1b2dcec58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dd7d85b-dc5a-4368-baa4-eee80e18f9c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce8e50c7-b302-4846-8754-cb08418afdfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ca56528-1bfe-4b06-b046-8ddb69bfd8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb90879-dd0e-41aa-a60d-54c81f66161a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a07bf2-fc85-483b-b072-e0d40ccc8318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 196221d1-213a-40f4-b685-82012acce437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0724b4f-19b3-41f5-91de-e09c393c03dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e2f6d22-aed9-46bc-befb-b12ad4581d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83e6e448-f648-4a2e-9cdf-8e0f2fb506bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38d1d8a0-27b0-4086-965c-6b26f139eeca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f63dcbb8-1b13-437c-88ed-02054aa48fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d095c8c8-80f6-45c4-8d7f-73cf23c638f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5233d6e-38a6-4f36-a446-66c4a396041f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2793163f-400b-4113-8ddc-e083bca4ed53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15ef99c8-fe7c-422a-8fce-5a8151fc4c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91450ceb-88c1-46cb-bcfd-9f9abd2fd892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39dd9ab7-701f-414a-9762-c92e5e165365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d728e4fe-5810-4a2a-8166-96d625acf3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8030ef15-452d-4ae2-9372-a21442357534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c4f1842-97b8-4eb2-9394-5bcbbb6f9efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d43705-fd32-4a12-91e1-4ecc986062e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f48768-9862-4652-a183-dd8d5e5072e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15695461-eead-4b9f-95e7-c8b08fdb189f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d593f76-782a-499c-bb9b-46d9c9737648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dafd910-93be-42cf-96fd-5b581882f4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 196be099-3259-4f43-a92f-41e9e3453f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ffcb45d-0796-447c-ab31-4420070331b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c2128c4-7b50-402f-a159-74d672779c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4313fc98-9655-4e89-ad08-d5b8f0f21b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c1676ab-183a-4c38-9467-3d73a3a1be0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e85c152f-c0b9-4d44-ae58-0b7a5a732614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1632e871-0ee3-455e-bffe-cb0c9057386b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8636d387-3885-4fe6-b671-a65e2ec6a01a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1973f3d-5a3e-437f-a800-0f420512a8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 138996a5-4ca1-4612-a960-059178ddd322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbce9869-624d-4c7c-9e10-f306870754e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f465346d-a678-4340-b498-97d5beac9c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a9d4a6-2fea-4108-8947-10b61ba67764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38c3c659-5a9e-4dd1-921d-7d1a1af2d9e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2e65e72-103b-42b9-8c6c-477be0a1435d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a580819-0faf-41ff-87f0-bd5d47127601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 797c4cd1-cca7-45e6-8a06-72ad0da4af68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1992778c-2b62-4040-b6af-b25ee3894e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16237fd7-4e5e-4fa5-8609-cec5dc6eee4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca6fcb2a-e334-472a-b18a-0a67045bb9fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1ff4abc-82f3-484a-bce7-ea8563f0c843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65e50a77-255e-4a6a-a035-0dfc9bbf1f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80f37f5b-95e4-4a9f-8df7-cc2f20831652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55759556-5ca5-4fc8-bbfe-4ef834841486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c65d37d-61b0-4c55-9bd1-347db9e76a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10211ea9-b8f0-4a20-9b06-004d2167179b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f0042e0-c80d-41ae-a80e-7db22763fd51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb56c4d1-6bf4-4602-b22e-582f0834e6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76a8de2f-cd07-4182-bcad-07a2d9401e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d61ca123-a7d9-4de9-904e-c9f73f186a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5541c262-f8cb-46b2-bc4d-aef90d84e3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c00e8f8f-e6dc-4935-bae0-fe7ce8cf3eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ccea97a-50a8-4cd5-94ed-f1e79f5911af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b99c7847-f53c-47a9-91a9-a773c5e5d6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0708efef-9ed7-4cb0-abd1-b38881ab05cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50ac8ef2-c4af-44d9-b7fa-d34c9531d652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f196f62-0fe1-46d8-a665-d9892bf750c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b612be1a-03e7-402d-a352-0410f9073085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f1c8de-0021-4dca-835e-350636707d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff6784ed-2510-49ad-9345-adf8797db0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8563e002-3bf3-4e16-b9d4-975a622a69ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8833fc42-72e6-4be8-832c-00d9123bda56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c7a4d6c-e8e4-4bc9-ac2e-290af8c54775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bcbcd28-9f93-4b92-8a4a-69fdc2d50537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b0fd463-58a7-4dbf-ab69-62a0f620340c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8302a439-c917-478b-8f6b-3ca385a6a7df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27e37feb-e584-4a32-b761-661b85a95466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfeb5d43-fb7d-4b3a-908b-a0ac63ced1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba9c87b2-ced7-4abf-ac9b-ef8559e7e7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc3b5d58-d905-4bf5-a478-376cb7a77dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad069365-e6d9-47d9-8cf2-3a947ef2bff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1763c61f-c9eb-4adf-84ce-3d7a31fe5394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9a538d1-0f00-455e-9c18-26f67b9f9e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e5ba9e-8a57-47ea-a4cc-a6d0ccd2f03d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4597593-88da-4997-a2ee-49244deceb0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0530882-04cc-42df-bed6-1b3872f23e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e45636c6-d55d-43c0-bb27-32e7f220277a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a622ebc1-32fc-418d-8b5b-3e84710222bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d3258f4-ec0b-416d-b793-e91990efb5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17a8154c-5948-4cf4-8516-604abcfd4408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611b5ef2-0c25-4346-bfb6-238a3893e36f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df4e9f06-8eef-4971-93b1-050a4714ff0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2445b0d-e57c-4847-9a58-a3ab7a6e71a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9cd346c-f3b8-480c-92f7-8649a5bf8f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 302a6585-3add-471d-8e0d-6a2cb5ba112b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11ebfe63-4902-4b7a-b8f4-5d33399992eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7e4981a-8ab1-4e79-8076-fd8c8b0de468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42a823f7-8013-406d-a634-a181c472d924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 848499ff-69a0-4a81-a3ff-e64c99e8094a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cccec2f6-ade4-4750-a8ae-9e694b09af70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca2bf610-02ad-49c9-a009-56e90b54d136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf0c4dc-94d7-41d1-9ff8-05940eb8c9b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 169f9371-4af2-425d-bf0b-b83a1a48ee6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff22365f-906f-4885-8e89-b58c1e3e7249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5df8fc3-e363-48b3-a8ad-fb44d9ba1197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 166623ee-5105-4fc5-ba19-294e247d1fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eae9fb56-da35-4e1d-9d54-f58583bb2062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1891b902-5417-44ca-9379-dbf1c4629059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dc06abf-bb45-4ba0-bd6c-bd6514dd4cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db6941e-9ac5-48e7-b71b-6e4b947dc340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa42ebdb-a6fd-4dc9-ae0b-ed72fa0ae475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68d5d073-d586-4a72-8bec-5c66b37d3bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e47baec-a82b-4564-9f6c-ac52865eea70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 782c8f33-f540-4e34-bbea-3d9019dd4a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3f97372-61ad-4e1e-83f0-cf06d74ebc33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43a20fc1-a9f1-4b4c-9182-1b1004bd1969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf50539-aa54-49f5-af9d-31515e6f5b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd0e05f5-500a-4621-93f6-7636446d9984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 059df459-e23a-4840-85b8-27fc46a57f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93114851-21ac-45f1-8314-0bebe0b5772d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ef8ee78-9b0e-49b9-86e6-f0ccce5cb1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b32a035b-9314-415b-98a0-3832bdbe172c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6141288-1a89-44b6-b7ee-37f02131d7df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a7c9487-f702-488d-9e7e-7874266a174e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc38c1f7-eae8-4314-b26e-8f07e045e01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7938790b-04fe-40f2-84d0-be0582f5b9d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd6470fa-9771-49a9-bcfa-926f887e46de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cd14b82-3a14-4cf7-8a73-f0aaed7159a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ea62351-7a1b-4354-b1eb-51d62bbe2bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7c3af46-ff3c-4950-b5dc-1b61b4657327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd02bf51-e78d-46d2-9146-da2ebb379b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c23399-ef43-4c2e-b803-9305d6b018ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3b1458b-838f-4dfa-9789-f1f352f51762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2641ff0-7679-4684-b6dd-f372d40fada9
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_64
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/test_labels.txt

📊 Raw data loaded:
   Train: X=(1040, 24), y=(1040,)
   Test:  X=(261, 24), y=(261,)

⚠️  Limiting training data: 1040 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  252 samples, 5 features
✅ Client client_64 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1616, RMSE: 0.4020, MAE: 0.3233, R²: -0.8774

📊 Round 0 Test Metrics:
   Loss: 0.1564, RMSE: 0.3955, MAE: 0.3179, R²: -0.8169

============================================================
🔄 Round 11 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1015, val=0.0857 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0808, val=0.0834 (↓), lr=0.001000
   • Epoch   3/100: train=0.0797, val=0.0853, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0799, val=0.0858, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0798, val=0.0855, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0783, val=0.0827, patience=2/15, lr=0.000500
   ✓ Epoch  21/100: train=0.0767, val=0.0804 (↓), lr=0.000500
   ✓ Epoch  31/100: train=0.0698, val=0.0753 (↓), lr=0.000500
   • Epoch  41/100: train=0.0609, val=0.0722, patience=1/15, lr=0.000500
   • Epoch  51/100: train=0.0552, val=0.0727, patience=11/15, lr=0.000500
   📉 Epoch 54: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 11 Summary - Client client_64
   Epochs: 55/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0601, RMSE=0.2452, R²=0.2472
   Val:   Loss=0.0720, RMSE=0.2682, R²=0.1326
============================================================


============================================================
🔄 Round 12 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1286, val=0.0953 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0821, val=0.0930 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0783, val=0.0899 (↓), lr=0.000250
   • Epoch   4/100: train=0.0785, val=0.0904, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0783, val=0.0903, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0780, val=0.0904, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 12 Summary - Client client_64
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0018
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0049
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1426, RMSE: 0.3776, MAE: 0.3044, R²: -0.6563

============================================================
🔄 Round 14 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1441, val=0.1191 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1224, val=0.0982 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1035, val=0.0831 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0908, val=0.0747 (↓), lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   ✓ Epoch   5/100: train=0.0847, val=0.0721 (↓), lr=0.000031
   • Epoch  11/100: train=0.0828, val=0.0719, patience=6/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 14 Summary - Client client_64
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0052
   Val:   Loss=0.0721, RMSE=0.2684, R²=-0.0005
============================================================


============================================================
🔄 Round 18 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.1104, val=0.1163 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1072, val=0.1137 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1048, val=0.1113 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1026, val=0.1090 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1006, val=0.1068 (↓), lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.0919, val=0.0980 (↓), lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.0872, val=0.0929 (↓), lr=0.000002
   📉 Epoch 25: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.0857, val=0.0912 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.0847, val=0.0901 (↓), lr=0.000001
   • Epoch  51/100: train=0.0839, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  61/100: train=0.0832, val=0.0883, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0826, val=0.0876, patience=5/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0820, val=0.0869 (↓), lr=0.000001
   • Epoch  91/100: train=0.0816, val=0.0864, patience=1/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_64
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0123
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0514
============================================================


============================================================
🔄 Round 19 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0985, val=0.1089 (↓), lr=0.000001
   • Epoch   2/100: train=0.0983, val=0.1086, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.0980, val=0.1083 (↓), lr=0.000001
   • Epoch   4/100: train=0.0978, val=0.1081, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0976, val=0.1078 (↓), lr=0.000001
   • Epoch  11/100: train=0.0962, val=0.1063, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0943, val=0.1041, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0926, val=0.1021 (↓), lr=0.000001
   • Epoch  41/100: train=0.0910, val=0.1002, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0895, val=0.0985, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0882, val=0.0969 (↓), lr=0.000001
   • Epoch  71/100: train=0.0870, val=0.0955, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0859, val=0.0941 (↓), lr=0.000001
   • Epoch  91/100: train=0.0849, val=0.0929, patience=1/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_64
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0516
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.1050
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0929, RMSE: 0.3047, MAE: 0.2596, R²: -0.0787

📊 Round 19 Test Metrics:
   Loss: 0.0882, RMSE: 0.2969, MAE: 0.2556, R²: -0.0241

📊 Round 19 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2550, R²: -0.0135

============================================================
🔄 Round 22 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0816, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0825, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  31/100: train=0.0823, val=0.0805, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0822, val=0.0800, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0821, val=0.0796, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0820, val=0.0792, patience=13/15, lr=0.000001
   • Epoch  71/100: train=0.0819, val=0.0789, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 22 Summary - Client client_64
   Epochs: 77/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0021
   Val:   Loss=0.0792, RMSE=0.2813, R²=-0.0631
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2548, R²: -0.0087

============================================================
🔄 Round 26 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 26 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0156
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0036
============================================================


============================================================
🔄 Round 30 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 30 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0153
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0068
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2545, R²: -0.0041

============================================================
🔄 Round 32 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 32 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0085
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0039
============================================================


============================================================
🔄 Round 34 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 34 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0064
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0160
============================================================


============================================================
🔄 Round 36 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 36 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0040
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0189
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0037

============================================================
🔄 Round 37 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 37 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0105
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0039
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0037

📊 Round 37 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0035

============================================================
🔄 Round 42 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 42 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0067
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0005
============================================================


============================================================
🔄 Round 43 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 43 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0059
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0034
============================================================


============================================================
🔄 Round 44 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 44 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0054
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0051
============================================================


============================================================
🔄 Round 45 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 45 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0168
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0195
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0034

============================================================
🔄 Round 47 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 47 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0102
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0103
============================================================


============================================================
🔄 Round 50 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 50 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0025
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0201
============================================================


============================================================
🔄 Round 51 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 51 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0045
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0071
============================================================


============================================================
🔄 Round 54 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 54 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0006
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0393
============================================================


============================================================
🔄 Round 55 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 55 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0069
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0018
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0033

📊 Round 55 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0033

============================================================
🔄 Round 59 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 59 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0026
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0169
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0033

============================================================
🔄 Round 60 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 60 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0098
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0045
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0033

📊 Round 60 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0033

============================================================
🔄 Round 62 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 62 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0010
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0427
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0032

============================================================
🔄 Round 64 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 64 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0029
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0148
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0032

============================================================
🔄 Round 66 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 66 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0098
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0009
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0032

============================================================
🔄 Round 67 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 67 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0064
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0012
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0032

============================================================
🔄 Round 68 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 68 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0053
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0005
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0032

============================================================
🔄 Round 71 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 71 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0053
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0012
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0032

📊 Round 71 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0032

📊 Round 71 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0031

📊 Round 71 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0031

============================================================
🔄 Round 75 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 75 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0066
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0038
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0031

============================================================
🔄 Round 76 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 76 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0018
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0364
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0031

============================================================
🔄 Round 79 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 79 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0007
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0457
============================================================


============================================================
🔄 Round 80 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 80 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0043
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0016
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0031

📊 Round 80 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0031

============================================================
🔄 Round 82 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 82 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0056
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0005
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2544, R²: -0.0031

============================================================
🔄 Round 86 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 86 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0023
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0127
============================================================


============================================================
🔄 Round 87 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 87 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0080
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0007
============================================================


============================================================
🔄 Round 88 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 88 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0005
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0189
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0863, RMSE: 0.2939, MAE: 0.2544, R²: -0.0031

============================================================
🔄 Round 89 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 89 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0120
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0066
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0863, RMSE: 0.2939, MAE: 0.2544, R²: -0.0031

📊 Round 89 Test Metrics:
   Loss: 0.0863, RMSE: 0.2939, MAE: 0.2544, R²: -0.0031

📊 Round 89 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

📊 Round 89 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

============================================================
🔄 Round 94 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 94 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0042
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0003
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

📊 Round 94 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

📊 Round 94 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

📊 Round 94 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

============================================================
🔄 Round 103 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 103 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0010
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0208
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

============================================================
🔄 Round 104 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 104 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0047
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0051
============================================================


============================================================
🔄 Round 106 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 106 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0029
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0036
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

============================================================
🔄 Round 110 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 110 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0061
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0023
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

============================================================
🔄 Round 111 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 111 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0010
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0131
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

============================================================
🔄 Round 112 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 112 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0025
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0039
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

📊 Round 112 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

📊 Round 112 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

📊 Round 112 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

📊 Round 112 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

📊 Round 112 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

📊 Round 112 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

📊 Round 112 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 124 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 124 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0065
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0003
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 125 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 125 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0024
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0062
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 126 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 126 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0021
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0053
============================================================


============================================================
🔄 Round 127 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 127 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0034
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0025
============================================================


============================================================
🔄 Round 129 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 129 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0027
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0030
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

📊 Round 129 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 134 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 134 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0009
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0136
============================================================


============================================================
🔄 Round 135 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 135 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0002
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0220
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

📊 Round 135 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 139 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 139 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0009
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0181
============================================================


============================================================
🔄 Round 140 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 140 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0025
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0026
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0030

============================================================
🔄 Round 141 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 141 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0009
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0192
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 145 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 145 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0031
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0015
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 146 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 146 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0023
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0057
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 148 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 148 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0026
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0030
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 149 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 149 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0017
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0077
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 152 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 152 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0056
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0063
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

📊 Round 152 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 156 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 156 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0003
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0149
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

📊 Round 156 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

📊 Round 156 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

📊 Round 156 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 161 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 161 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0054
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0008
============================================================


============================================================
🔄 Round 165 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 165 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0032
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0002
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 166 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 166 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0051
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0040
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 167 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 167 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0016
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0068
============================================================


============================================================
🔄 Round 169 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 169 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0003
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0320
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 171 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 171 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0013
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0077
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 172 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 172 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0034
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0018
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

📊 Round 172 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

📊 Round 172 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0029

============================================================
🔄 Round 179 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 179 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0001
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0217
============================================================


============================================================
🔄 Round 180 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 180 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0020
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0101
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

============================================================
🔄 Round 184 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 184 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0059
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0059
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

============================================================
🔄 Round 185 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 185 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0043
   Val:   Loss=0.0690, RMSE=0.2627, R²=0.0020
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

📊 Round 185 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

📊 Round 185 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

📊 Round 185 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

📊 Round 185 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

============================================================
🔄 Round 191 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 191 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0022
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0040
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

📊 Round 191 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

📊 Round 191 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

📊 Round 191 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

============================================================
🔄 Round 201 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 201 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0047
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0030
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

============================================================
🔄 Round 204 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 204 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0027
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0027
============================================================


============================================================
🔄 Round 205 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 205 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0014
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0133
============================================================


============================================================
🔄 Round 206 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 206 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0020
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0052
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

📊 Round 206 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2544, R²: -0.0028

❌ Client client_64 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
