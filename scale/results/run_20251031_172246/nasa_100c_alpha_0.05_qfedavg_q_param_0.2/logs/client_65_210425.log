[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c2d3bd2-67e3-4a0b-b6cf-b4cd2317b82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39d504d2-e03f-408f-b2aa-e8786b04db45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25ff7683-9331-4b61-8ab9-3f865755e958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f20a1e68-821e-4cc1-9ee2-1a2311a5fdf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db2a2a5-f4d2-483d-8109-7f8926d6bbde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfca7a4e-4e8e-4a6b-90b0-7a846bf09e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce8055a-62c7-4afb-8f77-5ac0629f45be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8395614-8afc-4bc7-83a7-5aaacb7d2519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddfb4def-c669-4526-b6d2-600c2f083678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96c8377f-fdcc-4b3c-aa08-e8782be8393a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cd80ef8-8ac6-4d86-ae31-d89cc0b52b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2194157c-c7f9-4764-aeb4-d397e5b2d36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53144bd2-3205-44a5-8e4b-0074ba25cf8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0664de80-9b5b-437a-b608-08f68ac94555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d35dd4e-54ba-4628-9f7d-13aabe3ad046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f672d7-b017-4428-9f90-e6be9e7be3bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e2dabe-6639-405d-a785-2c097af165b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78c4a06c-861c-4966-8e6d-4e603c708c7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d6b0dc7-9e48-4df7-8f9c-30e334e4db30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c13929-efad-4c11-979c-ec392c4f4f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 259840e2-64ad-4283-a7fd-2f7a59db77a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af75157-fdc8-4a02-af44-a503fe5238a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b389aa-42fa-47f3-bf76-eb8cccf32f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ec80ba-0e9b-4e5b-a8ce-613a52517fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f276388b-d448-4d1a-bc2c-04195963147a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b026b31-fdd4-4caf-91d9-40500c0551cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffe92cfb-1501-4e58-aebb-56cd342f6997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d68b0f2-fd01-4a54-8e69-88cbab839f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92e66db1-49ea-47aa-b987-30eff6a4e30e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ded0e3f1-7ec1-46e0-87b1-ba9f98a73729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 128c71b6-d091-4274-a631-3f19d5f00754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 435d16f9-b8fe-4955-aa5c-471116f162a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44fcc989-63ff-4f75-98ab-ccc5b5d046b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa254bd0-2879-434e-8af4-13f98a30cb42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de48568-572c-45aa-b4e6-a417f12025ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaf100ef-e256-4647-a739-bd5bd1a5a0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e28ff6b4-f7a8-4035-9dd0-9a7d4b6fe7fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eaa2330-269a-425f-be1d-fb5abf48665a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2db4635-6370-439e-84c5-0bfc73f35fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19fe3f62-c5c2-452b-aaf4-221da4130fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f822df8-e7cd-4a77-a1fe-e60737099b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf88d326-07ac-4996-9526-bd0138426a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d496190c-ef2b-4155-b7cb-525019109cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27f6bf1c-f1f6-4181-8c3a-1915656f2ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a480235-9aec-4c31-874a-e29fff885ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 419c2f3c-a22b-4649-b31d-3df39767ada9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84117283-bf82-4a4b-b5d5-7c41bee0ffb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e9aadd8-117b-4de5-9a83-c1badd72c83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dda7c31-9ab0-416a-a31c-6f85baa94ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28231d7c-12d0-4807-abc6-e0f9a8562708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06a29d79-07b9-438c-aad2-2ae1a431fdf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1466a35b-0121-496e-86e7-e0fd881a3877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f56f2cd-3893-473d-9091-2be2b3d4bfd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e487f8-8ecd-48c0-86e3-d43aa882b989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81716a0e-963d-44ec-aba8-f76edf68f273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33c80d2-abc4-4248-8f53-3c84736cbd72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813493af-e4c5-4122-a9b0-fc9b9310e446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff2844cf-338c-413c-97e0-92a8e43769a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e379c900-59be-4cd3-b123-44e82aa18270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47faf883-9de8-4d89-b37b-2a620038a402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 831ec1ac-31fc-4329-aaf3-6d52ca66cded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3232a1e3-83e7-4354-8cfc-1c194c9094f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d126b47c-0b17-40f1-bf5a-336893062e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c55547a-d77b-4070-a45d-89be1d230727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d11f4803-b7fe-4dab-bb48-5ebf9b2fb83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab31375b-10ad-43b0-95d7-347881b3446e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17c987a2-d925-4e38-a292-993d2ab1ca8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9357007-22dc-4b85-b41f-a75b3cf96162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f68723-e502-418d-a76a-75970f28fd5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 727d09eb-63df-4c9a-b042-5cc640949c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5f4d581-ea33-4dfe-9b8e-220b6e8c5cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d27e24c-412e-4740-87b4-5c1054dce661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2718f0aa-73eb-4b6f-a91c-b28370a24087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d44f43-4729-4595-8624-7e16bf64fb91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16193ea5-6947-4718-bcb1-e7027b4ea484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbcec28f-9f13-4ea6-9a02-aea8e5a34226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a139f251-5672-4f74-9f85-c9403c3a64df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcf11d6a-b50b-45fd-8899-b5364a1f20ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c34f847-204f-426c-9d95-fe6657cb04d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f667aa-3bee-4a82-a98a-8f0bb07afce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6753bbe4-2e45-4eb3-a013-7ec55d6c05df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7ca3f61-22ef-4bdc-bc56-d15fac59349f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ba6f43-1b00-42f4-945e-71b040f099d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8ea403b-dc35-4288-a772-769fe57d3054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c45563e4-f4cd-4557-91bd-d4605eb763f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0eced2b-50f5-4f7e-ac92-628f963047bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a3903fb-4cd2-4747-bd61-baf153645fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cac1f40-3248-4ec2-80b2-fc5abb02ec32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bff9720-1359-4b77-a444-26449ea2bec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b98dec7c-72c6-4611-9356-1da774fd4b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d86eac2e-8b18-4dc0-937e-1bc8beb8cac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f759bf45-60e3-4d30-bfaf-b9389fea61dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a21d89e-628d-41fb-ab86-7aab6844b491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b095cb7-9b5b-4af0-aa83-68b7d97a95c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aebbba0-bcc7-4f62-a78a-3de0bfde4f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 222f6a71-51f0-44b8-951f-2aec7462b9e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e1d5758-b56c-4eb2-a96f-9a54e7ed71ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64410e68-1935-4125-acff-c3543f10aca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f0613f5-ab6c-456b-811b-eacf529b2645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4195d435-d8fb-425f-a222-17a23a1d0b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc87cc4b-44f3-4291-ac41-c12863178451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d60ac7fc-17f5-4ec9-abd0-b34e816bcde0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b7bcfe-c111-4b5f-bf07-2952a9b79a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fdf768e-978f-4222-b1da-b041dee715c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbdfc356-ffa0-4dd0-b93e-e45b783d7dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 348c1fa7-85c0-4476-a0d3-428cbd2f74d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39329b19-32d5-48e9-9b57-43bba9215c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f415f05b-967c-425e-93d7-b8f8f1daa8be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 421875a3-24e1-4978-9360-d1aac43f2926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1376a3eb-e38a-4f7b-99ab-cc04337bb233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59afe1d5-d473-4130-8767-ffd06c221a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d354fde-defa-4d73-b462-6b61d65d676f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0f7ccf1-5f1f-4e75-91dd-8f2b39a73797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a8924a-7c8a-4c06-8c5e-eb3ccdfbc295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1507a64a-f251-4b91-aa08-7c6f73154c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5ef398e-3f91-43d6-b8d7-e051992cd384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4d8180-df4a-46e4-9dcb-705d17d72288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5cf82e0-ed18-4f11-97a0-1ec0b73bcc77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8876f892-9a78-4ab0-89d5-431972d9382b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fff90bd-0fea-47d9-ac01-fed06fdbe961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99f6e859-e33d-47af-b53b-d94b6ea5740b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d678700d-2615-47dc-a97d-7929894a0c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c5743d-b1a7-410c-a078-cc7ba7d78858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dae5e46e-d8d0-4b87-94b5-8de64a9c9f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1feeb16-8d5c-4159-98fd-1f32d9e22c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6347a392-79c2-4041-a463-9eb62466f372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 834123b1-ec8f-48ad-be29-0d459ce1a426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8225278-fc00-4bc1-9f12-f7701c9f3b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 612ec4d6-6f84-456d-a337-c7272890b279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9dc8e11-9e5c-4764-854f-c1aa055ba6d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4f6880f-1db0-4138-b366-57620724d6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67547007-c8d3-49aa-992e-5a397d5c0fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d19f2223-8fee-4ae1-893e-5a9b1bf2be7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b4e34f-8e6c-49cc-8e8a-128f0b693281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1723e32-ce1d-4a86-ba8a-e3d959dca69e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1bbc6a9-8486-4f61-ab2a-13fac3ef06d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfcec523-f27b-414c-a677-70f78e525ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5a97683-2e5e-4689-b0dd-4cdb3268fb38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43e161f3-b74d-4037-90fd-d02d72a4f153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0a85a9-0ab2-42e1-8531-2a825dfb3a86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0568c166-a298-4bdb-8c90-1202e6036567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ac71e7-90d0-4948-8da4-d99fbdb5e168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 547aad81-8056-4117-a37c-89d69fc93c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fdc187f-4805-4d16-bf3f-5f3d3fe0361d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7acf8b45-289f-43bd-9c44-ec87e2515c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 183d5fad-f534-4b60-ba1f-ba23ba5561f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a9c7450-370e-4443-9959-1112ccc50405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a39747e4-e7e7-4662-bf7d-cbf373612afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcb4cd1a-455d-41fb-adab-0dbf8d8b1267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8292378c-d166-400a-8571-28c3c26ce47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3a3e6f3-353a-43b1-bccf-99bbc307affd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f52cb8bc-0460-4579-b929-3d2dd702ca92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b410113d-ec27-4152-a7c2-ccd9e6fbb4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a077c39-3da6-4585-ba3d-136d7690e812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46470f81-bf72-48ca-bcd4-d8dfe2401de6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_65
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/test_labels.txt

📊 Raw data loaded:
   Train: X=(1919, 24), y=(1919,)
   Test:  X=(480, 24), y=(480,)

⚠️  Limiting training data: 1919 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  471 samples, 5 features
✅ Client client_65 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 8 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1073, val=0.0795 (↓), lr=0.001000
   • Epoch   2/100: train=0.0852, val=0.0791, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0852, val=0.0787 (↓), lr=0.001000
   • Epoch   4/100: train=0.0851, val=0.0786, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0847, val=0.0785, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0831, val=0.0786, patience=8/15, lr=0.001000
   📉 Epoch 14: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 8 Summary - Client client_65
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0041
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0042
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1577, RMSE: 0.3971, MAE: 0.3186, R²: -0.9832

============================================================
🔄 Round 9 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1204, val=0.0893 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0845, val=0.0870 (↓), lr=0.000500
   • Epoch   3/100: train=0.0836, val=0.0871, patience=1/15, lr=0.000500
   📉 Epoch 4: LR reduced 0.000500 → 0.000250
   • Epoch   4/100: train=0.0832, val=0.0872, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0831, val=0.0872, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0828, val=0.0871, patience=9/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 9 Summary - Client client_65
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0067
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0177
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1450, RMSE: 0.3808, MAE: 0.3050, R²: -0.8232

============================================================
🔄 Round 13 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1274, val=0.1123 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0990, val=0.0913 (↓), lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   ✓ Epoch   3/100: train=0.0843, val=0.0879 (↓), lr=0.000063
   • Epoch   4/100: train=0.0831, val=0.0881, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0831, val=0.0879, patience=2/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0829, val=0.0880, patience=8/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 13 Summary - Client client_65
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0053
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0115
============================================================


============================================================
🔄 Round 14 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.1270, val=0.1389 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1202, val=0.1335 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1157, val=0.1286 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1115, val=0.1241 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1078, val=0.1199 (↓), lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0930, val=0.1032 (↓), lr=0.000008
   📉 Epoch 17: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.0865, val=0.0947 (↓), lr=0.000004
   📉 Epoch 25: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0849, val=0.0924, patience=2/15, lr=0.000002
   📉 Epoch 33: LR reduced 0.000002 → 0.000001
   ✓ Epoch  41/100: train=0.0844, val=0.0915 (↓), lr=0.000001
   • Epoch  51/100: train=0.0841, val=0.0909, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0838, val=0.0904, patience=1/15, lr=0.000001
   ✓ Epoch  71/100: train=0.0835, val=0.0899 (↓), lr=0.000001
   • Epoch  81/100: train=0.0833, val=0.0895, patience=10/15, lr=0.000001
   • Epoch  91/100: train=0.0832, val=0.0891, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 14 Summary - Client client_65
   Epochs: 99/100 (early stopped)
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0012
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0506
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1257, RMSE: 0.3545, MAE: 0.2850, R²: -0.5803

📊 Round 14 Test Metrics:
   Loss: 0.1176, RMSE: 0.3429, MAE: 0.2766, R²: -0.4786

============================================================
🔄 Round 17 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1137, val=0.1291 (↓), lr=0.000001
   • Epoch   2/100: train=0.1134, val=0.1287, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1131, val=0.1283 (↓), lr=0.000001
   • Epoch   4/100: train=0.1128, val=0.1280, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1126, val=0.1277 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1110, val=0.1259 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1089, val=0.1232 (↓), lr=0.000001
   • Epoch  31/100: train=0.1069, val=0.1208, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1051, val=0.1186, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1035, val=0.1166 (↓), lr=0.000001
   • Epoch  61/100: train=0.1019, val=0.1146, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1004, val=0.1127, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0990, val=0.1109 (↓), lr=0.000001
   • Epoch  91/100: train=0.0976, val=0.1091, patience=1/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_65
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0964, RMSE=0.3105, R²=-0.1527
   Val:   Loss=0.1076, RMSE=0.3280, R²=-0.2754
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1045, RMSE: 0.3233, MAE: 0.2632, R²: -0.3145

============================================================
🔄 Round 18 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1036, val=0.1083 (↓), lr=0.000001
   • Epoch   2/100: train=0.1034, val=0.1081, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1033, val=0.1079, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1031, val=0.1077 (↓), lr=0.000001
   • Epoch   5/100: train=0.1029, val=0.1075, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1020, val=0.1064, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1005, val=0.1046, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0991, val=0.1029 (↓), lr=0.000001
   • Epoch  41/100: train=0.0977, val=0.1013, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0964, val=0.0997 (↓), lr=0.000001
   • Epoch  61/100: train=0.0952, val=0.0982, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.0940, val=0.0967 (↓), lr=0.000001
   • Epoch  81/100: train=0.0929, val=0.0953, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0918, val=0.0940 (↓), lr=0.000001

============================================================
📊 Round 18 Summary - Client client_65
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3016, R²=-0.0771
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.1378
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0939, RMSE: 0.3064, MAE: 0.2524, R²: -0.1803

📊 Round 18 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2448, R²: -0.0765

============================================================
🔄 Round 21 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 21 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0060
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0059
============================================================


============================================================
🔄 Round 22 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 22 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0007
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0012
============================================================


============================================================
🔄 Round 24 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 24 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0037
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0084
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: -0.0068

📊 Round 24 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2428, R²: -0.0067

============================================================
🔄 Round 29 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 29 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0000
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0055
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2428, R²: -0.0066

============================================================
🔄 Round 30 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 30 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0022
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0163
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2428, R²: -0.0065

============================================================
🔄 Round 32 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 32 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0004
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0009
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2429, R²: -0.0065

============================================================
🔄 Round 38 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 38 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0020
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0077
============================================================


============================================================
🔄 Round 40 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 40 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0037
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0060
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2430, R²: -0.0065

============================================================
🔄 Round 43 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 43 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0026
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0082
============================================================


============================================================
🔄 Round 44 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 44 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0006
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0063
============================================================


============================================================
🔄 Round 45 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 45 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0029
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0076
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2431, R²: -0.0065

============================================================
🔄 Round 47 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 47 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0055
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0170
============================================================


============================================================
🔄 Round 48 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0990, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0990, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0990, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 48 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0025
   Val:   Loss=0.0990, RMSE=0.3146, R²=-0.0112
============================================================


============================================================
🔄 Round 49 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 49 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0032
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0035
============================================================


============================================================
🔄 Round 50 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 50 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0019
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0008
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2431, R²: -0.0065

============================================================
🔄 Round 52 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 52 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0015
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0016
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2431, R²: -0.0065

============================================================
🔄 Round 54 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 54 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0014
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0010
============================================================


============================================================
🔄 Round 58 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 58 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0025
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0052
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2431, R²: -0.0065

============================================================
🔄 Round 59 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 59 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0032
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0316
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2431, R²: -0.0065

============================================================
🔄 Round 62 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 62 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0003
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0081
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2431, R²: -0.0065

============================================================
🔄 Round 63 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 63 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0013
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0183
============================================================


============================================================
🔄 Round 64 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 64 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0029
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0383
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2432, R²: -0.0065

============================================================
🔄 Round 65 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 65 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0027
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0055
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2432, R²: -0.0065

============================================================
🔄 Round 71 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 71 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0012
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0129
============================================================


============================================================
🔄 Round 72 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 72 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0053
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0079
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2432, R²: -0.0066

============================================================
🔄 Round 75 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 75 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0011
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0042
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2433, R²: -0.0066

============================================================
🔄 Round 79 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 79 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0013
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0055
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2433, R²: -0.0066

📊 Round 79 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2433, R²: -0.0066

📊 Round 79 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2433, R²: -0.0066

============================================================
🔄 Round 83 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 83 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0009
   Val:   Loss=0.0705, RMSE=0.2656, R²=-0.0072
============================================================


============================================================
🔄 Round 84 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 84 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0035
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0034
============================================================


============================================================
🔄 Round 85 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 85 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0002
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0272
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2433, R²: -0.0066

📊 Round 85 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2433, R²: -0.0066

📊 Round 85 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2433, R²: -0.0066

============================================================
🔄 Round 90 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 90 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0001
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0102
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2433, R²: -0.0067

============================================================
🔄 Round 92 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 92 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0003
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0145
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2433, R²: -0.0067

📊 Round 92 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2434, R²: -0.0067

📊 Round 92 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2434, R²: -0.0067

============================================================
🔄 Round 95 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 95 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0017
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0041
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2434, R²: -0.0067

📊 Round 95 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2434, R²: -0.0067

📊 Round 95 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2434, R²: -0.0067

============================================================
🔄 Round 102 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 102 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0019
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0063
============================================================


============================================================
🔄 Round 103 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 103 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0021
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0056
============================================================


============================================================
🔄 Round 104 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 104 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0029
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0060
============================================================


============================================================
🔄 Round 105 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 105 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0030
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0087
============================================================


============================================================
🔄 Round 107 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 107 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0061
   Val:   Loss=0.0926, RMSE=0.3042, R²=0.0067
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2434, R²: -0.0068

============================================================
🔄 Round 109 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 109 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0004
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0138
============================================================


============================================================
🔄 Round 110 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 110 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0015
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0085
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0069

============================================================
🔄 Round 114 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 114 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0022
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0049
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2434, R²: -0.0068

============================================================
🔄 Round 118 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 118 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0019
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0057
============================================================


============================================================
🔄 Round 119 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 119 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0007
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0158
============================================================


============================================================
🔄 Round 120 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 120 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0042
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0029
============================================================


============================================================
🔄 Round 121 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 121 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0146
   Val:   Loss=0.0887, RMSE=0.2977, R²=-0.0266
============================================================


============================================================
🔄 Round 122 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 122 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0003
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0175
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0068

============================================================
🔄 Round 123 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 123 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0073
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0008
============================================================


============================================================
🔄 Round 124 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 124 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0080
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0124
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0069

============================================================
🔄 Round 128 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 128 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0057
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0080
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0069

============================================================
🔄 Round 130 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 130 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0085
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0032
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0068

============================================================
🔄 Round 131 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 131 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0011
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0363
============================================================


============================================================
🔄 Round 132 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 132 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0004
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0128
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0069

============================================================
🔄 Round 134 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 134 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0052
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0002
============================================================


============================================================
🔄 Round 137 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 137 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0008
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0152
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0069

============================================================
🔄 Round 138 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 138 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0007
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0176
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0069

📊 Round 138 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0069

============================================================
🔄 Round 142 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 142 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0059
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0000
============================================================


============================================================
🔄 Round 144 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 144 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0011
   Val:   Loss=0.0700, RMSE=0.2645, R²=-0.0131
============================================================


============================================================
🔄 Round 145 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 145 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0049
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0035
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0068

📊 Round 145 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0068

============================================================
🔄 Round 150 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 150 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0040
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0010
============================================================


============================================================
🔄 Round 153 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 153 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0041
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0013
============================================================


============================================================
🔄 Round 156 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 156 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0023
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0293
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0068

📊 Round 156 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0068

============================================================
🔄 Round 159 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 159 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0004
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0242
============================================================


============================================================
🔄 Round 160 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 160 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0024
   Val:   Loss=0.0964, RMSE=0.3104, R²=-0.0053
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0068

============================================================
🔄 Round 163 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 163 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0007
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0171
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0068

📊 Round 163 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2435, R²: -0.0068

============================================================
🔄 Round 167 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 167 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0025
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0074
============================================================


============================================================
🔄 Round 169 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 169 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0085
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0060
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0069

============================================================
🔄 Round 176 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 176 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0003
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0477
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

============================================================
🔄 Round 177 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 177 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0103
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0064
============================================================


============================================================
🔄 Round 181 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 181 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0022
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0081
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0069

============================================================
🔄 Round 183 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 183 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0047
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0036
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

============================================================
🔄 Round 185 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 185 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0035
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0035
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

============================================================
🔄 Round 189 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 189 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0038
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0021
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

📊 Round 189 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

============================================================
🔄 Round 192 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 192 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0027
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0071
============================================================


============================================================
🔄 Round 193 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 193 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0077
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0006
============================================================


============================================================
🔄 Round 195 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 195 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0040
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0094
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0069

============================================================
🔄 Round 196 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 196 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0078
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0019
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

============================================================
🔄 Round 197 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 197 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0019
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0095
============================================================


============================================================
🔄 Round 199 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 199 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0068
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0082
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

============================================================
🔄 Round 201 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 201 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0030
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0059
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

📊 Round 201 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

📊 Round 201 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

📊 Round 201 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

📊 Round 201 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2436, R²: -0.0068

============================================================
🔄 Round 211 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 211 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0039
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0016
============================================================


❌ Client client_65 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
