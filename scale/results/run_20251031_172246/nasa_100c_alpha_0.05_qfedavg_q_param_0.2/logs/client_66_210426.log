[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 362946d0-cb9b-455a-811e-d091ca80e5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a9b857b-bca3-4a1a-96cc-2ab99a25c56d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90575c73-c16f-4be5-8958-be138bb0b357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb9f0d4-426d-4afd-81b4-b08538c78b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28cdc3d3-6f70-4a9b-8ce3-fc094b0d7fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822a69ef-d259-4fcd-8c88-539db0fa725c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea9cc50e-1335-4775-9897-4eb1d9bf8c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e5bfe62-67c7-4db8-ab4f-309cf992ffcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8a89306-ebd1-41b8-9173-4a0e2a04f510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14968cd6-8d2a-420d-bc1c-be76f1f9d0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58ed25a1-b143-4748-95c8-4e4456d42bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e43522d-6805-4b6b-99e4-099db7b0fc4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d08016a-c4ae-4ca9-8f22-793ee145cce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e55f493-ac07-475e-94f0-7e5dadffaa51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c3578e2-a43f-4b69-acb5-6610208a6b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bcee1f8-a463-4d49-adfa-acbdf3e4b18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b7c7fa-e925-43ef-b335-7677ef5bc12c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27a9993b-fef0-48ab-85a0-648c17fc0103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d6eb71d-48a1-40de-bf9b-cee4290e1b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 236d29cf-5847-4eeb-85ab-37c9bf50f0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878f4939-2d7b-49d2-a0cd-da4c169d81b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad9ae366-0d5d-4986-856c-4029216d6a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f6b0f67-140d-4bcc-83c1-47d2795bb246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 543f1398-7fd1-4023-8ff1-951d4367652f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee5a0ea0-6f70-4dd4-9207-b7e5153b84c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e72f3d-12c9-47eb-931c-0dc8bd857da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c731fa5b-d737-4a60-b847-ffa60c8d5d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da80031e-10ff-4a91-9762-e89ab4260927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d836d05-9e7c-48ae-96ad-2b3c525dc558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 468ff7dc-c6ac-4187-9049-cb964f9cfd70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc527d4a-db80-4b21-9b13-72f30082ba43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c521a53d-3e9d-48fe-870c-6e22b6c03783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e149b2f-a533-4ee0-8546-51d877c87c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb162308-fd6b-445e-965e-f3f7d1556b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f9fbdd7-edb9-483f-9fa1-83c95f748d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc9d0954-6d44-4742-8e1a-c30720f0c7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b5dbe7a-b084-4544-b691-22a417b5d3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a294811-ab81-4694-b022-1923bba85058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f807ce15-43de-43c2-99f4-79423815a00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b81fd349-9e58-4bc6-b052-9334fe132973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d39d9196-d6a1-4f4d-a2f3-0ece144e2e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d474db1-2e63-43cc-8de5-6d11ef5c7b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4570df80-32f6-4b33-8e5e-a0003a4880c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9110bd4c-46a9-447d-888c-edf3c74121ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0575764b-4ce7-4976-995d-720895c3d474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d984ef-36bf-4c2f-b065-7fd578daa110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aadf32a2-7cb1-4fb4-aa9d-e980a2519a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd22c744-0232-4187-b576-c093fd140b4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 516a6313-afcb-4ca1-adac-75319d248d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 965c9b0d-6b55-4d4f-b47e-27a2023c5fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8b7c9f1-1484-4e59-a37a-45e1cae724da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4b8598-d8ce-480f-a5d1-33b9c6d9a494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70dc0efb-b715-4e74-aa6f-b91a1bf414a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c547a50a-43f7-4c46-87d3-0f1387c8031f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b8f5494-1fd3-4f34-ad33-fbb77cd8038c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 082d7ffa-2214-402d-8a7c-3dc9f9fc66f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd77bf2-78b9-431d-be41-c52278759287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f33b34a2-c05d-458d-b079-b09754f9fd39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc62d61f-4310-456f-9fac-cdce0d7eb9ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c624098b-97f7-436f-add6-54027eac551e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf1030b0-d34e-4d11-80d7-f624c373b552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c576ae1c-7774-4df5-9e86-83a38c01d173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec35a25e-03eb-43c6-8388-a81ff149960f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b72c54f9-3daa-44d2-a50b-fb1a7e944253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66edbad5-71a8-44f1-b8c2-4b5f27ae8d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5a11985-ad6d-4e7c-8cd6-7a4d0ba3d708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a926ad6f-cc34-4b93-bde2-4baf27070587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d320769d-5c93-460d-a848-026da3482f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16874f05-6bdc-46de-a606-24f5266859b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e822cc9-81e1-4133-bc2e-25ef7a3efc09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b98ed826-8ca2-40e2-ae9e-156f2f9c4432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 596dac75-722d-4c21-b509-3091dce61cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 562dd3ea-294e-4fee-83d2-2ff6c8097c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c868e1d-ca7f-488c-9f97-f06a7971f183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5972d7a3-1ed1-4ded-864e-57440c8dc672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e07b528-f331-42a3-8dd0-c010d917104b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 930fc029-f052-427f-9c24-7bec445a6c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9835a32-7679-48d4-b3c6-d4ef425f03bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1a660d-2276-4640-90b2-59ae280be4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63b1eadf-7468-4ee2-aba6-90c1b9227d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f91aeaf2-a631-419c-95a7-564ef2831e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb6abc21-9737-4679-a522-3f536c82089c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce2df97-3ee5-4960-8476-55395786dc92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58259359-b555-49fe-96b7-20e18f6d7f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8cdab3c-5c8f-44db-8a30-b7698ff54923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e6aa87-ee34-4ff3-a0ea-ff9e6420c4a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b48571b0-8764-40a1-86cf-0e0762d0b2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38d63cde-5bcb-48ea-88cf-36604625c0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 899fc10b-b0c0-4b5e-b00f-a4c8642a9719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec6b5fcd-fb02-446d-874b-64b013e795c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f6db5f2-cb9f-4ce7-848b-59e226dc8240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caf54dc1-4062-4385-9367-d5154da489bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf9fcc54-78e6-41ad-bd95-3434437183fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa3d625-c386-467b-9fc2-ccbe5ffe28e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a469c55-5fbf-4430-a31b-9e4ab520df4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb1a77c6-f878-4dbb-93f7-73f2ae5ec879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff5f99ef-15ad-4dd2-b985-8860a2afd978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2d1c7c-d8a0-4dba-a349-762777089910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d9c83ff-30e3-4229-b9a3-96263f176832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84408fd5-ee02-4a79-a716-4256b8ac7ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84d1051a-26f1-4eb6-b70d-2f585d329a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa66b9fb-fdbe-469b-b821-388fdd3ef08e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f65e8e5b-0229-453e-81bc-7fc01d18f4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 964591bc-46d5-4344-8904-a60810ba6c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5229b1b7-2975-4596-884e-d555617c51a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bed26f9-c4a4-4040-beb3-30cb78642c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df129fa3-aa21-40af-b1ac-ce980e49afcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6739f5f-dff3-4d1b-ab43-aca41716d594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d06d00-9599-4277-ae87-8f8937d8b412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0f46b9e-0775-41c4-a703-3a921214a67f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 207f113d-6550-476b-8966-e78eb99f5057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e228beb-3b54-4f83-82c6-668ef9b1fcc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc29120-78fd-4a17-ad2c-ee27eb022864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1034120f-4e40-4db2-9ad1-a314ffc1f617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9439f81a-cae9-45ac-9cb1-b48be3f968c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2388930-008e-4fc2-a704-9446ba42e9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a2f2ff-96bf-4ddd-9d4e-ba989865b3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52247098-d765-47da-8c0b-5925274eaf9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4d62f4a-082d-49ba-9e74-f64bb5e61563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4dd0a6b-9094-4670-bb20-74117800aeca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26dc9e89-3fde-42ff-8035-6568137a3156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0566d443-a5d0-493c-87e4-e756d7ed5538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b7ad530-6886-434a-b17b-b5510d9b95d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1722829b-f207-42c5-abd5-d9d919a28c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ed51cee-c404-4897-b32c-e94027785407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ff3604-fd87-48ff-91ef-e916c2e04c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 474ce89d-940d-4cb3-9ef6-750cea56bb5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8ed054-0771-4d04-beb5-10346e9e53c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4174b830-5dd2-4d0b-b97e-8e7d47be6ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ea27700-f03c-4811-837f-2383709d9089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff0db16-7900-42ee-bfc6-d480acba66f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8455de7-e051-4fc5-9d3b-1204eb72c3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f48d5ca3-bd17-4b08-8570-e2a18ce5bb97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eb405d5-170a-4148-ad60-1201cb5cbae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d32408cf-9dca-4c31-9fc5-6873e25c4f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bacde2d8-50e1-4b50-8d4b-e198d49806e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee74d561-7a7c-46e7-8b02-971cdc600fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf12b43-a148-4ab3-933c-411ec29e0076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ccf48a-ba74-45e9-8646-42cb576a828c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d2ba1e-7df2-4c91-9660-c2c8d15f7ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3dfda23-0932-4c2c-a633-1a4acb3d2a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a91257d0-9ef9-4e38-b8c9-6f679e1eeb62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aab48d59-4d8e-460d-ac9a-7be73dd7c957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1a15f0f-6304-4fb1-ac2d-12431eb9e56b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3fef9a6-296a-485a-9e82-695a2110a111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ff7602-6e37-4281-9c9d-a69ca345c5ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eefff469-96de-47c6-b49b-e632dcaeea77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9d07429-e7ae-4059-b641-351407624faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b809a32-7211-4c39-a697-90f3a5bfda26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12518af2-79b0-4223-b0a4-e5809df296c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25dc9724-6633-497d-b5d6-f336411f0139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f665267e-2c6a-4a1c-aaa8-077ce174cd85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 560919b1-0a26-46fa-837a-5582042386bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6967536b-58a9-4517-8c37-366cb5ca4be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc1b5349-5bfd-4cb9-9783-713971c78468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa2ab54b-445a-4713-8c48-25cfc3455e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a9e7be-2574-4d4b-be16-84dc0175690e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2536c79-8205-4cee-85ea-fa0b9dbcab6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bc1810f-b185-4552-89d0-8fd6bd54c851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2af1013-3c07-459b-8e6d-993af787de4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15ce1659-4569-4ae7-ba53-af918b2c7bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3c5642d-9d8f-46df-acc5-bdb12e7fac30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 145e25f1-3940-46cb-a4b7-7867345ff543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7885a2a9-0cc5-4ec2-a131-00463654318f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_66
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/test_labels.txt

📊 Raw data loaded:
   Train: X=(1796, 24), y=(1796,)
   Test:  X=(450, 24), y=(450,)

⚠️  Limiting training data: 1796 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  441 samples, 5 features
✅ Client client_66 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1726, RMSE: 0.4154, MAE: 0.3386, R²: -1.0385

============================================================
🔄 Round 9 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1136, val=0.0854 (↓), lr=0.001000
   • Epoch   2/100: train=0.0838, val=0.0866, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0818, val=0.0864, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0824, val=0.0866, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0821, val=0.0868, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0808, val=0.0880, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 9 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0040
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0191
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1660, RMSE: 0.4074, MAE: 0.3320, R²: -0.9606

📊 Round 9 Test Metrics:
   Loss: 0.1562, RMSE: 0.3953, MAE: 0.3225, R²: -0.8452

============================================================
🔄 Round 12 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1437, val=0.0887 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0910, val=0.0814 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0848, val=0.0768 (↓), lr=0.000250
   • Epoch   4/100: train=0.0838, val=0.0770, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0837, val=0.0775, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0835, val=0.0773, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 12 Summary - Client client_66
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0031
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0318
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1511, RMSE: 0.3887, MAE: 0.3174, R²: -0.7842

📊 Round 12 Test Metrics:
   Loss: 0.1455, RMSE: 0.3814, MAE: 0.3119, R²: -0.7182

============================================================
🔄 Round 14 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1399, val=0.1471 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1197, val=0.1225 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1021, val=0.1024 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0900, val=0.0886 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0843, val=0.0820 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0829, val=0.0801, patience=5/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0828, val=0.0801, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 14 Summary - Client client_66
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0002
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0250
============================================================


============================================================
🔄 Round 16 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1288, val=0.1478 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.1236, val=0.1414 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1194, val=0.1383 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1168, val=0.1355 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1144, val=0.1327 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1025, val=0.1197 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0955, val=0.1116, patience=1/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0929, val=0.1085, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0913, val=0.1066 (↓), lr=0.000001
   • Epoch  51/100: train=0.0899, val=0.1048, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0886, val=0.1031, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0875, val=0.1016, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0864, val=0.1002, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0854, val=0.0988, patience=3/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_66
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0553
   Val:   Loss=0.0977, RMSE=0.3126, R²=-0.0988
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1269, RMSE: 0.3563, MAE: 0.2932, R²: -0.4992

============================================================
🔄 Round 17 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1300, val=0.1343 (↓), lr=0.000001
   • Epoch   2/100: train=0.1297, val=0.1339, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1294, val=0.1336 (↓), lr=0.000001
   • Epoch   4/100: train=0.1290, val=0.1333, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1287, val=0.1330 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1269, val=0.1312 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1242, val=0.1285 (↓), lr=0.000001
   • Epoch  31/100: train=0.1218, val=0.1260, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1195, val=0.1237 (↓), lr=0.000001
   • Epoch  51/100: train=0.1173, val=0.1215, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1151, val=0.1194, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1131, val=0.1173 (↓), lr=0.000001
   • Epoch  81/100: train=0.1111, val=0.1153, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1091, val=0.1133, patience=2/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_66
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1072, RMSE=0.3275, R²=-0.3164
   Val:   Loss=0.1116, RMSE=0.3340, R²=-0.3068
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1012, RMSE: 0.3181, MAE: 0.2674, R²: -0.1951

============================================================
🔄 Round 19 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1055, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.1053, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1051, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1049, val=0.0923, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1047, val=0.0922 (↓), lr=0.000001
   • Epoch  11/100: train=0.1035, val=0.0913, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1017, val=0.0900 (↓), lr=0.000001
   • Epoch  31/100: train=0.0998, val=0.0887, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0981, val=0.0876, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0965, val=0.0865, patience=1/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0949, val=0.0855 (↓), lr=0.000001
   • Epoch  71/100: train=0.0934, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0920, val=0.0838, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0907, val=0.0830, patience=4/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_66
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0856
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0293
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2575, R²: -0.0855

============================================================
🔄 Round 20 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.1003, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.1001, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.1000, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0999, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0889, val=0.0992 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.0877, val=0.0982 (↓), lr=0.000001
   • Epoch  31/100: train=0.0865, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0855, val=0.0963, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0846, val=0.0956, patience=5/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0838, val=0.0949 (↓), lr=0.000001
   • Epoch  71/100: train=0.0830, val=0.0943, patience=1/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0824, val=0.0938 (↓), lr=0.000001
   • Epoch  91/100: train=0.0819, val=0.0934, patience=10/15, lr=0.000001

============================================================
📊 Round 20 Summary - Client client_66
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0212
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0146
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2523, R²: -0.0251

============================================================
🔄 Round 21 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0902, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0835, val=0.0896, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0830, val=0.0891, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0826, val=0.0887, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0822, val=0.0884, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 21 Summary - Client client_66
   Epochs: 55/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0210
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0088
============================================================


============================================================
🔄 Round 22 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0951, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0808, val=0.0947, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0805, val=0.0944, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0802, val=0.0942, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 22 Summary - Client client_66
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0180
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.0031
============================================================


============================================================
🔄 Round 25 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 25 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0175
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0044
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2509, R²: -0.0038

📊 Round 25 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2509, R²: -0.0037

============================================================
🔄 Round 30 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 30 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0189
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0071
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2508, R²: -0.0028

============================================================
🔄 Round 33 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 33 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0085
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0163
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2508, R²: -0.0026

============================================================
🔄 Round 35 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 35 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0071
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0191
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2508, R²: -0.0024

📊 Round 35 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2508, R²: -0.0022

============================================================
🔄 Round 38 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 38 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0110
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0010
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2508, R²: -0.0021

============================================================
🔄 Round 39 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 39 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0100
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0026
============================================================


============================================================
🔄 Round 40 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 40 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0093
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0060
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0019

📊 Round 40 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0018

📊 Round 40 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0017

============================================================
🔄 Round 48 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 48 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0145
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0011
============================================================


============================================================
🔄 Round 49 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 49 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0096
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0015
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0017

============================================================
🔄 Round 51 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 51 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0038
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0232
============================================================


============================================================
🔄 Round 52 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 52 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0140
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0021
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0016

============================================================
🔄 Round 54 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 54 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0085
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0026
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0016

============================================================
🔄 Round 57 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 57 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0083
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0041
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0016

============================================================
🔄 Round 59 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 59 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0056
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0139
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0016

📊 Round 59 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0016

============================================================
🔄 Round 61 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 61 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0079
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0051
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0015

============================================================
🔄 Round 62 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 62 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0060
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0113
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0015

📊 Round 62 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0015

============================================================
🔄 Round 66 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 66 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0057
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0114
============================================================


============================================================
🔄 Round 68 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 68 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0027
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0293
============================================================


============================================================
🔄 Round 70 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 70 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0039
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0215
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0013

📊 Round 70 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2509, R²: -0.0013

============================================================
🔄 Round 77 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 77 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0041
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0272
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2509, R²: -0.0012

============================================================
🔄 Round 82 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 82 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0056
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0092
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2509, R²: -0.0012

============================================================
🔄 Round 83 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 83 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0094
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0093
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2509, R²: -0.0012

============================================================
🔄 Round 84 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 84 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0075
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0051
============================================================


============================================================
🔄 Round 85 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 85 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0047
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0106
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2509, R²: -0.0012

============================================================
🔄 Round 86 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 86 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0020
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0314
============================================================


============================================================
🔄 Round 87 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 87 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0054
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0086
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2509, R²: -0.0012

============================================================
🔄 Round 90 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 90 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0018
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0208
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2509, R²: -0.0011

============================================================
🔄 Round 92 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 92 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0036
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0136
============================================================


============================================================
🔄 Round 93 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 93 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0106
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0044
============================================================


============================================================
🔄 Round 94 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 94 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0040
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0115
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2509, R²: -0.0011

============================================================
🔄 Round 96 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 96 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0085
   Val:   Loss=0.0721, RMSE=0.2686, R²=-0.0048
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2509, R²: -0.0011

============================================================
🔄 Round 101 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 101 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0080
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0062
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2509, R²: -0.0010

============================================================
🔄 Round 104 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 104 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0025
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0198
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2509, R²: -0.0010

============================================================
🔄 Round 109 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 109 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0045
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0083
============================================================


============================================================
🔄 Round 110 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 110 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0085
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0044
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0010

============================================================
🔄 Round 113 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 113 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0085
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0021
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0009

============================================================
🔄 Round 115 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 115 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0067
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0105
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0009

============================================================
🔄 Round 117 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 117 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0028
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0156
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0009

📊 Round 117 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0009

============================================================
🔄 Round 122 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 122 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0043
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0088
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0009

============================================================
🔄 Round 127 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 127 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0095
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0055
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0009

============================================================
🔄 Round 129 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 129 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0009
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0345
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0009

📊 Round 129 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0009

============================================================
🔄 Round 134 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 134 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0046
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0093
============================================================


============================================================
🔄 Round 135 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 135 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0005
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0389
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0009

============================================================
🔄 Round 136 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 136 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0072
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0049
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

============================================================
🔄 Round 138 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 138 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0090
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0056
============================================================


============================================================
🔄 Round 139 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 139 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0002
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0382
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

📊 Round 139 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

📊 Round 139 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

============================================================
🔄 Round 146 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 146 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0049
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0062
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

============================================================
🔄 Round 147 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 147 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0012
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0216
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

============================================================
🔄 Round 148 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 148 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0082
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0056
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

📊 Round 148 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

📊 Round 148 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

============================================================
🔄 Round 151 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 151 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0057
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0018
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

============================================================
🔄 Round 152 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 152 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0046
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0071
============================================================


============================================================
🔄 Round 154 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 154 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0024
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0224
============================================================


============================================================
🔄 Round 156 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 156 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0016
   Val:   Loss=0.0706, RMSE=0.2657, R²=-0.0429
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

============================================================
🔄 Round 159 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 159 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0083
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0053
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

============================================================
🔄 Round 165 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 165 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0063
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0014
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0008

============================================================
🔄 Round 166 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 166 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0044
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0060
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

📊 Round 166 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

📊 Round 166 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

============================================================
🔄 Round 170 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 170 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0015
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0215
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

📊 Round 170 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

============================================================
🔄 Round 173 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 173 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0053
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0007
============================================================


============================================================
🔄 Round 174 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 174 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0064
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0033
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

============================================================
🔄 Round 182 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 182 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0084
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0054
============================================================


============================================================
🔄 Round 183 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 183 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0043
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0046
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

📊 Round 183 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

============================================================
🔄 Round 186 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 186 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0029
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0104
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2508, R²: -0.0007

📊 Round 186 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

📊 Round 186 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

============================================================
🔄 Round 191 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 191 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0054
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0002
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

============================================================
🔄 Round 192 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 192 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0069
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0050
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

📊 Round 192 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

============================================================
🔄 Round 195 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 195 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0029
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0104
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

============================================================
🔄 Round 197 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 197 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0032
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0121
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2508, R²: -0.0007

📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2508, R²: -0.0007

📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0007

============================================================
🔄 Round 203 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 203 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0027
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0198
============================================================


============================================================
🔄 Round 204 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 204 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0053
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0012
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0006

============================================================
🔄 Round 206 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 206 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0025
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0187
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2509, R²: -0.0006

============================================================
🔄 Round 211 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 211 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0010
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0403
============================================================


❌ Client client_66 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
