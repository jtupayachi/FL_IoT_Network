[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2db896b7-a536-4aa6-b134-51b170a5b57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68eb910a-0bdc-4185-a150-80953ca4a414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 527f861e-47c0-4cda-b762-0abd14b9a389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44ee31f4-c2db-4c94-9238-77fc34d7ac79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15c1f0ed-6f6a-4686-8221-9ad9880e3efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3476b987-addf-45bc-84b6-16ea3bfb0ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0ee6970-f849-448a-9bc8-fa25734c3e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8979c531-3d8e-4696-8131-cb8bafe46310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b6915f9-17db-4705-8fc3-15f612e59db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16a17388-09e0-40fa-89b1-2749a0a0cce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a62b578c-6405-4323-baa8-378875514e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d02daea5-b2bc-483b-9d6c-592001ae0d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8264884e-f5e0-4996-9890-2e2d0548164d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2e51bac-8e7f-4241-9aec-dfdd6f767554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8a5f319-552c-4755-8a63-eb64affe45d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba974050-105c-4e63-86f2-572c8cab18e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ca9a51-e47e-4a28-9ae2-a8359c169cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37df0fe6-780c-4f85-aa92-4274e416474c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5e67db3-fb8e-4d65-aaa2-60e7ae1da73d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb14ef9f-1ba0-45a8-bb44-9237963135c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99c000d4-31cd-4e82-a683-511089448719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 700f067d-ee7f-49ae-854d-fbe5903c92b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4962f19b-b11b-435e-a29a-52c2de1f89ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c2d9f3-d566-4125-b018-96c32fba9087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15fe4831-38aa-422d-8310-97595b737d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72ba2d30-4160-4cd0-b17f-00d98dc55217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b8c704d-3e51-40ae-88bc-09dd564cece0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5137809-8f12-4071-baa6-d80a9945a4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e47bb9e-bbc4-4131-a564-a37d943bb5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ba6da29-09cc-4d2b-a57a-4749b22374b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f683cb70-f37b-446a-a7ed-1fa828e1e7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21af7de2-3b8a-4db8-8f0d-5efaa22b41dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abe58171-917b-4b79-98d8-132627efc4d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5b47bd1-27ba-4b1e-9d3a-cd25d7439874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0a8f377-a479-488a-a8e6-d58249fe3670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 684daf38-484a-47d6-9c4b-1bfc7f318c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00c3558-ed78-4881-a75e-4f6062556a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f915365-518d-49b2-b59f-ecae13691866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1629ecf-9590-4471-aabb-e3f83f61b497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2a9ce9c-958d-4da7-a1c8-b9cd8a29b8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af219730-c2b2-4abd-a542-94f3f1f9cf43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d1a9c22-93d7-4da0-a58e-ed2c35b35269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a8b6d65-4df5-4d39-88e6-2be0e1ff6522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7638aa58-772b-47a6-a732-70b8723fc480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26810fca-b307-4ab2-870e-208c1435b518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d807e147-7e2d-4fc5-82e8-cf4f167a2b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5cd2902-00fc-4912-8d25-540270b964b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c997b7e-70b8-4fe6-8392-d5c90f0f762c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31578083-31b9-4ec3-b7ec-8b51b5fefa19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3af85d8-fae5-4cfb-9aa4-d34209f0e9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26650982-4bdf-4a08-98d7-b5a62b9feaad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85814618-3387-4493-b2f6-730f5e03b84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17192a1c-fd4c-44f8-99da-849fa303e902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bae37218-827f-4544-b916-32f5aad0e67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53284627-26a1-445a-b447-54a3a1735792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78701e4b-e299-4d7a-845d-87ae82a84849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4522e6d-f915-4723-bc13-ef1ef63e54a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3e7fb6b-3ece-4dfd-9718-2596985e4c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc2fb92-70f1-4e36-8ed8-1f47345133ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c026f168-ecdd-4234-8c38-cafc5fc0ad37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fbe3551-c320-4faa-9492-8fb90fada9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef5bf38c-513a-43c3-8833-bfb9bd438328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb1377f-5347-423a-a9b4-e1965d0f5564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce2cca28-d243-4a0f-ae98-62b761806bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a831058a-9f4d-4a90-9dab-4579f7273670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7370e52c-9dab-441a-be9a-895a54c9c60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ce1b37-7eff-4c1c-b7d9-5e09b4709438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0cb4353-aebb-4b6a-a8e3-88d18e2a9e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73eb6d4e-f4aa-441e-bc38-f927bfa27278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7af3c03-393b-42a1-a2ea-1b697592404c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06e80de2-464d-4b7d-8586-f30cf79b174a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8337fe6c-bfba-4353-a6c6-0dea4565dcc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 441adf1b-c4e0-482d-b4e3-c6fea1cb8c2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7b85664-e524-4e30-b171-0fac77f84710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38ca6ea6-c987-45ed-ae64-fa15b0a1a901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d8799a5-abcb-491c-8c7a-93eb05388a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d3fef6-7940-443a-81e8-6f80b27b2fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 371853de-670c-47d8-b0af-888abc792285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44dc96aa-b0be-498d-abff-d8c227414b49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c771b7a-df13-4f13-a17f-b0e3deefb4df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb35db3-2406-49c3-9a33-ffc1b6968be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd90aaa-1eb1-4ecc-a81a-9fa072f2f5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cdc312f-2f4f-4d95-98d3-6fe2511a87fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d7b443-5e98-4fb8-8b32-a0d0ec21ccc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c5dad1-03ba-46e4-bdc4-751d5bb92244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d40e206-a512-406e-b25c-ef32e6c0d2fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40ac5f20-ffef-40e7-b22c-ec40210d8787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3daa8be-86cd-4cc7-9e19-19c5e7536588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bad3299-e010-41f8-9a81-48cd3a15d7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc090666-fda2-4266-b425-0408a70d07de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4cadb47-5b86-4dc0-92b3-1e05432fe405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15cad666-ffb6-4cbc-8ec3-218f5b4d16fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d21d04b-c762-4f9c-8b5d-394dedcab65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e80fea-f957-474d-bd3f-41f747fe47a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a16dff1b-b539-4c12-9a34-0a2036584b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de8e092b-920d-4f87-a911-dc54aacb2708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d05eff05-ebe0-4d14-9c64-ce2727986eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f191bd1e-d4d5-46a7-97f0-73506dd997c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd2128a5-ed0e-4c08-87a2-37b1f072e3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d55e185e-6406-4af8-9ee2-6ac98fc99fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df4d6515-cd7d-4cd4-bd02-54f23c2c60c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d31669b-5ba4-431a-93da-e5a1184e48dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6447f24c-d437-49c3-bda0-3133926bcc8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad4b4357-17d4-4c22-a623-6b3a3531e481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c0dbc5-0a8a-483a-8784-19fffeff76ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29a97f14-859c-4ef8-97d4-3a7496ee402b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df756ffe-a749-4048-b30a-6c323ccb4bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17bdb5b3-2754-46c9-b39c-6fa59a0e710c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a639a2-c497-4aab-8131-037aea31b5a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb5f1213-b798-4154-a885-d04b66fa15f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4b84c29-aa30-4c27-806f-a036ca29491f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef143845-d580-4356-babd-0295101705e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6399f7b-6cbc-4e81-ba7f-a79f21b5bed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25bbd174-3937-4ba0-b79e-afec20960753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f41e74ec-4e8f-4265-95f6-898dca412024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1199e28d-fe48-4ea6-a5b8-e04b16bc24da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c117ec-8575-4c9a-8e00-6fa753e15896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f94e4d5-feda-4cf8-976c-545d0865ed63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61bd39d4-da9c-475f-b0c0-f33aa6ba39c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83168666-55b4-409b-b6c6-dde6542cc2c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8da30025-747d-44d7-87f9-1dc72a7da15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 950775d6-45aa-4f5a-81ff-1b20ae3e6cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7642b174-e333-46b0-ad04-ae60fc0cc080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19048be-dc2c-4c83-93c9-648b960e3356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e779b70-295d-4476-ba3e-32754e8a9c7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7269d89d-3259-4a39-87ca-d9fd38867433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52ce1385-ef00-4b82-b138-9f338efe9db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 323a6b33-2f9a-4566-81ad-15f5c248e72e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b9bbc6b-8251-4967-88f4-2b4df52479af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de34361b-9090-4d71-a6b4-81bf6536fac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8b77773-d737-48a0-ae43-cd9a8e5c5216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89b1ea37-4867-4ea0-bc45-51c57e0cba2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b815bbbf-0514-401f-913b-39ae07d5ba9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6309b7f3-0d99-4572-a879-24f6b28e1a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74566b9e-e398-4908-9b31-2827b61dae0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54ff36b-7a78-4465-a228-1ad84846bda2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33415a3f-8029-40d5-b583-3c985cf76026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60df3215-8271-4811-b083-93ef74ace860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 512b1a56-4b35-4a36-b197-408417695960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 416ee1db-1a21-47f3-8949-9dd5f2c66c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52b8ef8f-a74c-44ab-bcda-9beddbb1c4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 628516e9-15e6-4440-ae27-1c375d0998c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 029e59cb-daa7-4797-846d-36225a9481d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d7dd9d4-7261-4f6d-a13d-f6f712dd8476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f960c5-5835-44af-96fe-aa21be86e438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d45c2529-7bf1-4cff-b444-7841762a32a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c5dbbed-bcb4-4390-8aa6-f5211121ac9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 213c8363-87ee-45a3-8568-f363b210e3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9831353d-494a-4236-8b6c-885abcdc0f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a38127c-2b9a-4250-bb59-ca475cc1f348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 515408b1-38dd-49e4-8fbc-1b77b16f04ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad4294f-c95d-409a-aed6-84319ccf835b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 856dceb7-ba44-4505-b1d5-d7d9d4abaef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message babb1f7e-d682-4759-8e1b-a1bd4753bbdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e286038-800c-46f6-b294-83270e82feb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d13bb9c7-ac90-485c-8abe-bbc33c533d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1878d2e7-5011-4782-83c2-d42cfb97e8cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a196e29c-8b3f-4883-9bfb-87d785687039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef58508-099c-4f4b-aae1-18bd4f77279e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07cc6b52-9a4e-421f-bbb2-5a70142236c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94105772-3383-4c68-8b68-72ecc4d2e6d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d0ff313-dcf1-411d-b71c-e5ada561c2b9
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_69
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/test_labels.txt

📊 Raw data loaded:
   Train: X=(824, 24), y=(824,)
   Test:  X=(207, 24), y=(207,)

⚠️  Limiting training data: 824 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  198 samples, 5 features
✅ Client client_69 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 8 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1083, val=0.0814 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0854, val=0.0808 (↓), lr=0.001000
   • Epoch   3/100: train=0.0828, val=0.0815, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0824, val=0.0813, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0812, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0818, val=0.0817, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 8 Summary - Client client_69
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0031
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0044
============================================================


============================================================
🔄 Round 11 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1367, val=0.1036 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0854, val=0.0850 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0837, val=0.0834 (↓), lr=0.000250
   • Epoch   4/100: train=0.0818, val=0.0834, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0818, val=0.0838, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0813, val=0.0844, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 11 Summary - Client client_69
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0065
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0086
============================================================


============================================================
🔄 Round 13 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1500, val=0.1265 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1252, val=0.1058 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1036, val=0.0909 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0887, val=0.0841 (↓), lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0825, val=0.0842, patience=1/15, lr=0.000031
   • Epoch  11/100: train=0.0816, val=0.0843, patience=7/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 13 Summary - Client client_69
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0283
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0006
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1456, RMSE: 0.3816, MAE: 0.3081, R²: -0.6483

📊 Round 13 Test Metrics:
   Loss: 0.1318, RMSE: 0.3631, MAE: 0.2951, R²: -0.4920

============================================================
🔄 Round 20 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0915 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.0894, val=0.0886 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.0877, val=0.0874 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.0868, val=0.0863 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.0859, val=0.0854 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0833, val=0.0824, patience=1/15, lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0827, val=0.0816, patience=7/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0826, val=0.0814, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 20 Summary - Client client_69
   Epochs: 37/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0015
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0109
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2603, R²: -0.0208

📊 Round 20 Test Metrics:
   Loss: 0.0893, RMSE: 0.2988, MAE: 0.2598, R²: -0.0106

📊 Round 20 Test Metrics:
   Loss: 0.0889, RMSE: 0.2981, MAE: 0.2596, R²: -0.0059

============================================================
🔄 Round 23 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 23 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0259
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0038
============================================================


============================================================
🔄 Round 26 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 26 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0145
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0050
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2596, R²: -0.0024

============================================================
🔄 Round 27 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 27 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0156
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0041
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2596, R²: -0.0023

============================================================
🔄 Round 28 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 28 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0212
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0053
============================================================


============================================================
🔄 Round 29 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0822, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0833, val=0.0818, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0833, val=0.0815, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0832, val=0.0812, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 29 Summary - Client client_69
   Epochs: 43/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0002
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0452
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2596, R²: -0.0018

============================================================
🔄 Round 31 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 31 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0087
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0109
============================================================


============================================================
🔄 Round 32 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 32 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0197
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0063
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2596, R²: -0.0016

============================================================
🔄 Round 33 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 33 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0094
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0044
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2596, R²: -0.0015

📊 Round 33 Test Metrics:
   Loss: 0.0885, RMSE: 0.2974, MAE: 0.2596, R²: -0.0014

============================================================
🔄 Round 35 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 35 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0076
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0144
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0885, RMSE: 0.2974, MAE: 0.2596, R²: -0.0013

📊 Round 35 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2596, R²: -0.0012

📊 Round 35 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2596, R²: -0.0011

============================================================
🔄 Round 41 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 41 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0119
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0057
============================================================


============================================================
🔄 Round 42 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 42 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0086
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0017
============================================================


============================================================
🔄 Round 43 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 43 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0044
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0133
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2596, R²: -0.0010

============================================================
🔄 Round 45 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 45 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0052
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0115
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2596, R²: -0.0010

============================================================
🔄 Round 46 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 46 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0041
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0167
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2596, R²: -0.0009

📊 Round 46 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2596, R²: -0.0009

============================================================
🔄 Round 52 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 52 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0052
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0077
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2596, R²: -0.0009

📊 Round 52 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2596, R²: -0.0009

============================================================
🔄 Round 57 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 57 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0047
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0097
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2596, R²: -0.0009

============================================================
🔄 Round 58 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.1030 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.1030, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.1030, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.1030, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.1030, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.1029, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1030)

============================================================
📊 Round 58 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0022
   Val:   Loss=0.1030, RMSE=0.3210, R²=-0.0159
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2596, R²: -0.0009

============================================================
🔄 Round 60 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 60 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0073
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0018
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2596, R²: -0.0009

============================================================
🔄 Round 66 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 66 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0070
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0037
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0008

============================================================
🔄 Round 70 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 70 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0043
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0075
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0008

============================================================
🔄 Round 71 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 71 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0060
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0003
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0008

============================================================
🔄 Round 73 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 73 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0034
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0275
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

============================================================
🔄 Round 75 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 75 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0122
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0045
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

============================================================
🔄 Round 76 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 76 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0065
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0017
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

📊 Round 76 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

============================================================
🔄 Round 81 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 81 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0082
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0120
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

============================================================
🔄 Round 82 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 82 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0030
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0086
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

============================================================
🔄 Round 83 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 83 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0015
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0167
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

============================================================
🔄 Round 84 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 84 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0006
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0386
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

📊 Round 84 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

📊 Round 84 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

📊 Round 84 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

============================================================
🔄 Round 91 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 91 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0037
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0044
============================================================


============================================================
🔄 Round 93 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 93 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0049
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0000
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

============================================================
🔄 Round 95 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 95 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0003
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0283
============================================================


============================================================
🔄 Round 97 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 97 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0045
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0001
============================================================


============================================================
🔄 Round 98 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 98 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0015
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0355
============================================================


============================================================
🔄 Round 99 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 99 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0066
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0041
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

📊 Round 99 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

============================================================
🔄 Round 102 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 102 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0042
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0000
============================================================


============================================================
🔄 Round 104 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 104 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0082
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0122
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

============================================================
🔄 Round 105 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 105 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0019
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0132
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

📊 Round 105 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0007

📊 Round 105 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2597, R²: -0.0006

📊 Round 105 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0006

📊 Round 105 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0006

============================================================
🔄 Round 112 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 112 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0045
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0018
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0006

============================================================
🔄 Round 114 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 114 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0052
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0068
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0006

📊 Round 114 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 114 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 122 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 122 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0059
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0046
============================================================


============================================================
🔄 Round 124 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 124 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0028
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0063
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 124 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 126 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 126 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0001
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0142
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 128 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 128 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0004
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0206
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 128 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 130 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 130 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0002
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0236
============================================================


============================================================
🔄 Round 131 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 131 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0048
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0046
============================================================


============================================================
🔄 Round 135 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 135 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0025
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0088
============================================================


============================================================
🔄 Round 136 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 136 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0017
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0400
============================================================


============================================================
🔄 Round 137 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 137 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0055
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0001
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 138 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 138 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0028
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0008
============================================================


============================================================
🔄 Round 143 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 143 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0054
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0013
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0006

============================================================
🔄 Round 144 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 144 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0027
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0027
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 144 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 147 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 147 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0070
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0052
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 150 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 150 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0020
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0087
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 150 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 153 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 153 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0002
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0154
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 155 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 155 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0025
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0067
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0006

============================================================
🔄 Round 157 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 157 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0044
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0037
============================================================


============================================================
🔄 Round 158 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 158 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0027
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0023
============================================================


============================================================
🔄 Round 159 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 159 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0018
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0049
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 162 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 162 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0019
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0057
============================================================


============================================================
🔄 Round 164 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 164 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0011
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0133
============================================================


============================================================
🔄 Round 165 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 165 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0043
   Val:   Loss=0.0707, RMSE=0.2659, R²=-0.0009
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0006

============================================================
🔄 Round 167 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 167 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0042
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0050
============================================================


============================================================
🔄 Round 168 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 168 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0043
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0070
============================================================


============================================================
🔄 Round 170 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 170 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0057
   Val:   Loss=0.0672, RMSE=0.2593, R²=0.0003
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 170 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 173 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 173 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0011
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0075
============================================================


============================================================
🔄 Round 174 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 174 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0000
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0095
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 175 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 175 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0020
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0270
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 175 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 179 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 179 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0082
   Val:   Loss=0.0918, RMSE=0.3031, R²=0.0095
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 179 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 179 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 179 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 187 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 187 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0017
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0105
============================================================


============================================================
🔄 Round 188 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 188 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0025
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0016
============================================================


============================================================
🔄 Round 191 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 191 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0015
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0130
============================================================


============================================================
🔄 Round 192 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 192 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0035
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0010
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 194 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 194 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0092
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0126
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 194 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 194 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 194 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 205 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 205 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0074
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0049
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

============================================================
🔄 Round 208 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 208 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0061
   Val:   Loss=0.0953, RMSE=0.3088, R²=0.0118
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

📊 Round 208 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2598, R²: -0.0007

❌ Client client_69 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
