[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fabff8c9-0e5b-450e-99f7-8a7fdf544ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd99c8f9-3c69-4f55-b5b3-e78f33053622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68877a39-f3b3-40be-910c-b56a59938896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 301e0d69-bbc0-450f-b7b2-5df49eb01c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 257dbe9a-400c-4d12-a3b7-daa07d7ffba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d0d0977-7de6-4237-8624-b0ed7d80187b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8128bc0-838a-4463-9f91-c20594a36008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11c5ef6-7fa1-4707-a1ea-254cc00f763a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a20458f-f248-475f-8846-a1b7a73f9be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message facb49f0-d2ac-409f-8ab1-ba6a1d18d719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68cad1db-67e7-47d5-a18c-a055d8a6c3a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9040eb1e-6ed3-4afd-ad4e-703211c9870d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f36cccd-452a-4eed-9ab7-71db4271714d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2288a77a-e85e-4e35-8f77-a87d60ecb9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b182aa9-3dbe-4818-a049-5cceaca22b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5984b0b-8275-4da2-bfbe-f32ff4ded633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0b05dbe-107d-4754-95a7-a284e7f305e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2cc863e-5077-49a1-82dd-63288f678e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9caec348-a151-4650-91be-a4cc95ea307c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3bfc885-a123-4042-b087-567bc29db310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a46ba82-91be-4bd9-94d8-ab91d1cdb9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb1c36d6-b122-4bda-9d72-a1c3656d0de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92880577-ea88-4a90-b204-c14a0eb238c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd2d35e2-0013-413c-a85c-934e5c98167e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929dd748-2cbd-4056-91d3-68a1a7982464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b5c1a1-0bff-415d-a64d-1b95974e3fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86251c97-17ce-4de9-b778-865ed7652772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d57a543f-44a8-4c0d-9697-c23e2bcacfaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21f1fdd0-5b2e-4145-8273-4c845a075171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0ba9a75-70cb-4807-a8b0-d894b650b52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb77f2e-340e-40fa-913d-e7e2510f202e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eb4cbcf-fe53-4b56-a2fb-bddfd76b3689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 052d79dc-1056-4235-8d49-3219974ab35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5693ae7c-7dee-47a7-955d-103a8955166f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eca1786c-d158-462f-aa2e-974ad927d055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c427cb50-8b12-4706-8155-bc0c06ab11aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0ef20bd-61ad-4140-850f-75da9ff07815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4e899db-0ab4-40f1-bee3-6ad40de255d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c0673f2-00e1-4c25-ac98-46dee67cd673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4e6fa95-89fb-420a-b9ea-2344ee391755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef929ade-8c58-4d6d-bb91-c29dcfd2c82b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6bb2786-6459-4dc0-883d-14cd63a7ac58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1523e4af-0641-4d99-bcc3-3b4c4595ffd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ae83f43-5465-435b-917e-861a8e1b9bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aeecdc7-55b8-4f10-90db-fc9cb949eb9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94129958-b504-41e2-a9f9-c8c9911a0824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 623ac789-59c5-468d-b5d8-360e22529deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c5d6531-42f0-476d-84b6-cdb6ab3ab207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 680e6287-d30c-4725-82e9-e57931c55be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96f4cd9b-9405-4616-b664-efd2fe1eca42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9885772-a514-4f9a-96a6-153c89ff7d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb7e167e-b16e-49b8-91cd-f0b01f0448cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be65260c-f390-4c9e-bf74-7df28a1bf616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68ff150f-7c1c-4403-a157-84f538b37a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db547cd-fca4-448b-ab98-6e54d06642e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c06561e0-be14-413a-a0fd-5360bfb9ee99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e40e3876-1603-4953-97e2-0b6315096ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62a546b2-4ad1-4165-9040-3a2eba23632c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e0c7acf-7d8e-41b1-9716-84c3e880a93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0b3248d-342f-438d-ba49-f1befcfde192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86364210-0f7c-4967-9b2b-7f324aad7abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37687035-d6aa-48ac-8969-24c2c3b46e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e010e00-2de2-4f41-bfa1-63d878968110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 459c2511-aece-426a-93fd-9ef02b7205dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dab0412a-e669-4021-ab95-1e4673ca2124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8276d1ea-3a54-4286-9167-691cac2c3d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa3c9b27-4acd-4647-a1a0-d7c6550a9826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88fc949a-bd47-47b4-946b-6f984373ed8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f628c48e-f9ae-495f-96ca-871d1c599d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c791104-0a4d-42b9-b46d-84bee39ee48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e0327c-9fe3-46ba-8209-f514e9e80838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b72a3ea2-38ff-40ae-8025-c4c5facec69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e0805e5-d2c3-46d1-8f06-25bd889132f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48a333ff-f6a3-4f94-83d5-e2669c982a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dfe80b6-94e9-4033-95bc-6528cbd99f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 769e4e32-946e-48f9-a277-543e880dd20e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dbba386-45ca-49e5-a91f-15bd1273f486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 314bbe4d-0ebd-4551-abed-5898f902e7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ca49965-bac1-4428-8709-0ef875a06eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46df11d0-e528-46ec-8fa9-d601954f7ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 015bea0c-c857-4fdb-8095-be76699f1bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d9bf07-bb1c-4f42-a691-d0e3bc2bcc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ce09ce5-a497-4a3f-b094-2f690806007e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9e6226f-4738-4427-b5f0-12c9d2bdfd7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3135f878-1fbd-4773-b842-0eed6f4411e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc1e19ea-1ec7-4715-b1c4-2735e0feb7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd80b148-d8c9-4e35-8b11-4e744435a466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b1bc5d8-eec0-4aa4-a0eb-47716937585c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae28685a-8abc-49a0-b348-8da4d08d41b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee0098b9-a4a5-4823-869e-996c203cf993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33c7977-1f47-401d-93c3-f51ff67c690f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f83efaee-320e-4cc2-8cef-fc31f70123fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d62c24-dc71-47dd-9d45-660645741e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec842dc7-12a6-44fd-8940-fd183f202a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e281e4c-d4a6-4731-aa82-ea307f158089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d82c8366-1488-49f2-9ffb-eb85fc6db6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7406365c-9cb9-401e-8e00-0115742bf2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2284eb1-9f31-45f6-9049-39b2c3a9522a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 474b7648-2c99-4746-a57e-700e2d9f6b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d6dd2eb-1cb6-4272-8d47-aaf426872552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e90c08fa-31c6-4e32-929b-4971878dec7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd9d4d07-2306-4926-ab97-7d0b6002583a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dba1209d-4674-48e9-853a-cbe9e602df65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db29146-872b-49d7-af70-c0041f8d1a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fed6fe8-2abc-49a9-9380-fd6e815f6a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6278269e-b9a6-40d3-8918-8a80ac11eb02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3220fece-2200-4bbc-9df8-e1f21a2e84a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba76892-089b-4717-ad03-b67794efb3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a750a258-223e-4e26-be37-64c5bc5f8a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 054018e9-0c25-4cb9-b7d9-c21894881df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f3e8132-30d1-4e3d-b12b-fa6c788b454d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f08f74e0-239b-42c2-89ff-5bb3f9f01609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7389e141-8416-4c77-993a-fc8969918a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f32404b-63e0-4aa8-94a4-da82797baf91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4855b3-6e3b-4d2e-9b5e-7acf48784255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb2ea037-fd33-4fc4-b37b-290e99ff0c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35f38ab9-7ccd-422e-ad2b-bebca4a44518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28ec7291-c62f-4370-848b-b33a638f8203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c9eae1-37db-4748-a242-0344e9523d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d02d524-0136-4c5d-b428-b2ebd324862f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0050ef65-1efb-4a07-ac60-f0d2b9e91a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3de1ca92-4db5-4f80-ab5d-890267101ff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69d73664-a808-480f-b50f-61b9a7ff452b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8808b879-3dd2-43c2-b6a7-2abd04f41547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2adc959-fe79-4c6a-bb4d-1f7f18d467fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fcb3ca0-3f0d-445a-8f05-987fa1ab64dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58774099-60dc-468a-8e35-8535365e0e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d66b912-a434-45e4-9d54-f978975d1c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2f028ce-4793-48cc-bde0-5f493956d404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d85d18b-4f9d-4da6-b940-34e148386636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85a21452-d81e-4bd3-a2d0-8b1b248b3225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c72696bc-e544-46fc-ac8d-1cdaa21e21e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63c8de9d-d8d8-465c-ab2b-e8aab127b551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b12bf1b7-294f-4957-8f0e-b64e4193b5c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 964c26cd-bb02-4aea-a146-c9a4c660e219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 060ac87f-8541-4213-beb9-9c65db9c9029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1d57fce-593c-4fa0-9430-d1d8d20c3cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3954a3f-bc0c-4689-a637-8cbce467ba6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b3292f0-0f4f-4eed-bdc2-e8d7c9f1eeab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee49ca11-034a-4d53-932d-cce57671416e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 422a59a2-3e48-46a8-a578-310f452e7886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82782929-655d-482b-9922-18fa4acff12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65577b9-67ad-4940-96c0-23f79ce78db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8325bbdd-0d5a-4784-a216-15038bca0593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 916a894a-c4c7-452b-8b6b-ee1b2ac54e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 727763a8-33de-4cb2-954a-dcd519f75b14
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_70
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/test_labels.txt

📊 Raw data loaded:
   Train: X=(1108, 24), y=(1108,)
   Test:  X=(278, 24), y=(278,)

⚠️  Limiting training data: 1108 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  269 samples, 5 features
✅ Client client_70 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1632, RMSE: 0.4039, MAE: 0.3285, R²: -1.0174

📊 Round 0 Test Metrics:
   Loss: 0.1587, RMSE: 0.3984, MAE: 0.3239, R²: -0.9627

============================================================
🔄 Round 12 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1027, val=0.0878 (↓), lr=0.001000
   • Epoch   2/100: train=0.0834, val=0.0875, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0828, val=0.0873, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0830, val=0.0875, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0829, val=0.0877, patience=4/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0810, val=0.0888, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 12 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0059
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0060
============================================================


============================================================
🔄 Round 14 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1082, val=0.0847 (↓), lr=0.000500
   • Epoch   2/100: train=0.0843, val=0.0969, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0830, val=0.0903, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0821, val=0.0925, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0822, val=0.0915, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0816, val=0.0908, patience=10/15, lr=0.000250
   📉 Epoch 15: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 14 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0197
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0071
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1369, RMSE: 0.3701, MAE: 0.3006, R²: -0.6931

📊 Round 14 Test Metrics:
   Loss: 0.1319, RMSE: 0.3631, MAE: 0.2951, R²: -0.6302

📊 Round 14 Test Metrics:
   Loss: 0.1277, RMSE: 0.3573, MAE: 0.2907, R²: -0.5782

📊 Round 14 Test Metrics:
   Loss: 0.0998, RMSE: 0.3160, MAE: 0.2607, R²: -0.2343

📊 Round 14 Test Metrics:
   Loss: 0.0896, RMSE: 0.2994, MAE: 0.2512, R²: -0.1084

📊 Round 14 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2464, R²: -0.0363

📊 Round 14 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2458, R²: -0.0215

============================================================
🔄 Round 22 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0820 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0851, val=0.0814 (↓), lr=0.000125
   • Epoch   3/100: train=0.0847, val=0.0810, patience=1/15, lr=0.000125
   ✓ Epoch   4/100: train=0.0846, val=0.0808 (↓), lr=0.000125
   • Epoch   5/100: train=0.0845, val=0.0807, patience=1/15, lr=0.000125
   • Epoch  11/100: train=0.0841, val=0.0807, patience=7/15, lr=0.000125
   📉 Epoch 14: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 22 Summary - Client client_70
   Epochs: 19/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0054
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0142
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2456, R²: -0.0121

============================================================
🔄 Round 24 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0813 (↓), lr=0.000063
   • Epoch   2/100: train=0.0852, val=0.0808, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0850, val=0.0806 (↓), lr=0.000063
   • Epoch   4/100: train=0.0848, val=0.0805, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0847, val=0.0805, patience=2/15, lr=0.000063
   • Epoch  11/100: train=0.0843, val=0.0804, patience=8/15, lr=0.000063
   📉 Epoch 13: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 24 Summary - Client client_70
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0021
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0002
============================================================


============================================================
🔄 Round 26 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0786 (↓), lr=0.000031
   • Epoch   2/100: train=0.0862, val=0.0783, patience=1/15, lr=0.000031
   ✓ Epoch   3/100: train=0.0861, val=0.0781 (↓), lr=0.000031
   • Epoch   4/100: train=0.0861, val=0.0779, patience=1/15, lr=0.000031
   • Epoch   5/100: train=0.0860, val=0.0778, patience=2/15, lr=0.000031
   • Epoch  11/100: train=0.0857, val=0.0772, patience=4/15, lr=0.000031
   • Epoch  21/100: train=0.0855, val=0.0769, patience=6/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 26 Summary - Client client_70
   Epochs: 30/100 (early stopped)
   LR: 0.000031 → 0.000031 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0047
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0066
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2455, R²: -0.0080

============================================================
🔄 Round 28 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0785 (↓), lr=0.000031
   • Epoch   2/100: train=0.0858, val=0.0785, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0856, val=0.0785, patience=2/15, lr=0.000031
   📉 Epoch 4: LR reduced 0.000031 → 0.000016
   • Epoch   4/100: train=0.0855, val=0.0785, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0854, val=0.0784, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0852, val=0.0783, patience=10/15, lr=0.000016
   📉 Epoch 12: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 28 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0039
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0075
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2455, R²: -0.0071

============================================================
🔄 Round 31 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0926 (↓), lr=0.000008
   • Epoch   2/100: train=0.0826, val=0.0926, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0826, val=0.0925, patience=2/15, lr=0.000008
   📉 Epoch 4: LR reduced 0.000008 → 0.000004
   • Epoch   4/100: train=0.0826, val=0.0924, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0825, val=0.0923, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0825, val=0.0921, patience=10/15, lr=0.000004
   📉 Epoch 12: LR reduced 0.000004 → 0.000002
   📉 Epoch 20: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0824, val=0.0920, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 31 Summary - Client client_70
   Epochs: 27/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0018
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0123
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2455, R²: -0.0065

============================================================
🔄 Round 32 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 32 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0049
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0082
============================================================


============================================================
🔄 Round 33 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 33 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0034
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0154
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2455, R²: -0.0060

============================================================
🔄 Round 37 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 37 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0049
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0084
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2455, R²: -0.0053

📊 Round 37 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2456, R²: -0.0050

============================================================
🔄 Round 43 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 43 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0041
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0041
============================================================


============================================================
🔄 Round 44 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 44 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0027
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0099
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2456, R²: -0.0049

============================================================
🔄 Round 46 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 46 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0088
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0191
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2456, R²: -0.0047

📊 Round 46 Test Metrics:
   Loss: 0.0813, RMSE: 0.2850, MAE: 0.2456, R²: -0.0046

============================================================
🔄 Round 51 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 51 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0026
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0168
============================================================


============================================================
🔄 Round 54 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 54 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0031
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0193
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2456, R²: -0.0045

📊 Round 54 Test Metrics:
   Loss: 0.0813, RMSE: 0.2850, MAE: 0.2456, R²: -0.0045

============================================================
🔄 Round 58 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 58 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0046
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0025
============================================================


============================================================
🔄 Round 60 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 60 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0062
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0042
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2456, R²: -0.0044

============================================================
🔄 Round 61 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 61 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0020
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0134
============================================================


============================================================
🔄 Round 62 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 62 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0072
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0350
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2456, R²: -0.0042

============================================================
🔄 Round 68 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 68 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0021
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0097
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2456, R²: -0.0042

============================================================
🔄 Round 71 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 71 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0036
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0063
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2456, R²: -0.0039

============================================================
🔄 Round 76 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 76 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0026
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0070
============================================================


============================================================
🔄 Round 78 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 78 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0045
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0348
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0037

============================================================
🔄 Round 81 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 81 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0040
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0077
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0037

📊 Round 81 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0037

============================================================
🔄 Round 86 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 86 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0009
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0290
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2456, R²: -0.0037

============================================================
🔄 Round 87 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 87 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0051
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0026
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0037

📊 Round 87 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0036

📊 Round 87 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0036

============================================================
🔄 Round 90 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 90 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0032
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0073
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0035

📊 Round 90 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0035

📊 Round 90 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0034

============================================================
🔄 Round 94 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 94 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0030
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0052
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0035

============================================================
🔄 Round 98 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 98 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0044
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0030
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0034

============================================================
🔄 Round 99 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 99 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0046
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0004
============================================================


============================================================
🔄 Round 101 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 101 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0047
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0011
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2457, R²: -0.0033

============================================================
🔄 Round 103 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 103 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0033
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0115
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: -0.0033

============================================================
🔄 Round 104 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 104 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0070
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0309
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: -0.0032

📊 Round 104 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: -0.0032

============================================================
🔄 Round 107 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 107 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0037
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0038
============================================================


============================================================
🔄 Round 108 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 108 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0039
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0028
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0031

============================================================
🔄 Round 109 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 109 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0033
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0011
============================================================


============================================================
🔄 Round 110 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 110 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0042
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0025
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0031

📊 Round 110 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0031

============================================================
🔄 Round 116 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 116 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0043
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0102
============================================================


============================================================
🔄 Round 118 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 118 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0031
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0033
============================================================


============================================================
🔄 Round 120 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 120 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0026
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0043
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0030

============================================================
🔄 Round 122 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 122 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0024
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0105
============================================================


============================================================
🔄 Round 124 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 124 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0031
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0201
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0030

📊 Round 124 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0030

============================================================
🔄 Round 127 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 127 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0027
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0119
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0030

============================================================
🔄 Round 128 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 128 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0033
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0009
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0030

📊 Round 128 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0029

📊 Round 128 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0029

============================================================
🔄 Round 136 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 136 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0030
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0116
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0029

============================================================
🔄 Round 138 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 138 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0030
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0054
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0028

============================================================
🔄 Round 140 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 140 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0029
   Val:   Loss=0.0866, RMSE=0.2944, R²=-0.0027
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0028

============================================================
🔄 Round 141 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 141 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0031
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0168
============================================================


============================================================
🔄 Round 147 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 147 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0022
   Val:   Loss=0.0911, RMSE=0.3017, R²=-0.0092
============================================================


============================================================
🔄 Round 148 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 148 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0052
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0361
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0030

📊 Round 148 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0030

📊 Round 148 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0029

📊 Round 148 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0029

📊 Round 148 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0029

============================================================
🔄 Round 156 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 156 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0013
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0103
============================================================


============================================================
🔄 Round 157 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 157 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0036
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0061
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0029

📊 Round 157 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0028

📊 Round 157 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0028

📊 Round 157 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0028

============================================================
🔄 Round 165 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 165 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0033
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0014
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0028

📊 Round 165 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0028

============================================================
🔄 Round 169 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 169 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0016
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0061
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0027

📊 Round 169 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0027

📊 Round 169 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0026

============================================================
🔄 Round 174 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 174 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0021
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0053
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0027

============================================================
🔄 Round 181 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 181 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0026
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0089
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0026

📊 Round 181 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0026

============================================================
🔄 Round 183 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 183 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0013
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0060
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0027

============================================================
🔄 Round 184 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 184 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0017
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0184
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0026

📊 Round 184 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0027

============================================================
🔄 Round 187 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 187 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0015
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0055
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0027

============================================================
🔄 Round 190 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 190 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0010
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0069
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0026

📊 Round 190 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0026

📊 Round 190 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0027

============================================================
🔄 Round 199 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 199 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0035
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0129
============================================================


============================================================
🔄 Round 203 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 203 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0024
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0021
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0026

📊 Round 203 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0026

📊 Round 203 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0026

📊 Round 203 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0026

📊 Round 203 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0026

============================================================
🔄 Round 209 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 209 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0028
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0004
============================================================


❌ Client client_70 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
