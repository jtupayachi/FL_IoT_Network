[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68b22803-5cde-41b7-b418-667968b34568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfa90d35-f2ca-4eaa-bb90-22df65afb186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4a91c57-9008-44e2-990d-0cccf013fc13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7c2c494-2052-4993-84d2-ce1b0d7fd69d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17fb56bc-3c27-4a8f-b9e3-d2baa5247f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c356f7-07aa-4d9f-bdae-f1d258f0bd4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50d53247-cc78-4956-afdc-c3abef65ffb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 851e9159-375e-4952-8116-2e07d9222f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79c81407-1979-438a-affc-fc5611afb42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4577063-1412-425f-b82f-a4f05f25b19d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 600fb503-687d-42f7-b4ed-8dc2ca1772d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ee8289-164f-4f7b-97f1-07b17dc62337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87472cb4-1a9c-4913-b84c-288fedaae48f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc2be9b3-653c-4c02-8bb2-393b0e5d1cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4004be4-5984-407e-98b6-b0fa81af8b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e67de57f-d1a5-4f71-9b34-6d4a916e9246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92218421-259a-4576-bb4a-6006393b7c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f20e3294-8d9c-4bbd-b199-4ced85233b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa65c492-44c0-4773-95c3-1fc94c055b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54e63fdb-4605-42c9-8f14-b18fb4f69ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87f71f69-a82c-4cc5-acb3-4ecf6ff32801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28decfed-4edf-4187-a4fe-f6c10610ee68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6437b491-6ecf-4bdb-bc83-886ea568288c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5a7f780-b5ea-4678-9fb2-1c7ada76f438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c33ba96-ab44-4f02-830b-74b274ee3486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 656e72c4-ec09-49fe-b20e-c191b25ade2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da57dba5-6f7e-4ad5-ab94-4db9ca6701ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2af6d274-7a15-4fc3-a756-b3b232451718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 138d14ac-c3a8-4c54-a14d-38277bf065dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056a5f87-a5c2-4d5f-b8c4-a70fba6ff766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71a10d85-aefa-48b5-87af-eeefd1867d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a839a154-b2b5-482b-b8f6-f5f3809c616b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27a55163-3d1e-4935-8d1c-c4e8fb8ae90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80d108e5-7938-411e-b2a4-f44ac4e05713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad4d0b6e-4830-479b-97a0-9c6bf8296199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6beeb5e0-94c8-419b-b662-77be6e66f96d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c801b475-348a-4246-87c0-9a7b7cedafdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21ad668c-ee56-4952-9e55-65049793ca46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 735ac55d-71aa-4367-9c2a-62989267650e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd9d9564-ca0b-4875-9420-9f9b66e70c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4365588e-69fa-4527-b88e-5f6cfa6b1cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 482d3609-5964-4c78-a644-3545223bc801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a806ad9d-1ea3-499a-afe4-6cb2a36c3f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e0290df-534a-4d43-8752-84e3fdddcdc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb7b562d-d5ba-4931-9145-3b9f72fbf2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d3efd53-3d60-4884-98ba-6d8537b29196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6de1df93-86f8-4eca-b3b0-fcc970d99f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56ef52c1-a867-456a-89ad-f0faf040ac49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3c783e6-d31a-478a-ac5d-98152df961fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb78b8e3-b98d-4815-b31c-2c4bfeb3e5ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23f3fb0-4b56-46be-bd4d-06893a3a6ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce8344b0-b436-4f72-813e-0db9a5eb51a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b9b15a3-c162-474e-952a-f33acd627e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f7f4dc6-ec7f-4ac6-b2ec-36f111703201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a299b3ce-a563-41c5-9513-e17952989cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ad7e508-2c52-49d5-a030-28481b1ad01a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c6fc6cb-7fba-4b9c-84be-e907654ca980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f777f2f-20eb-4f17-b3e3-0402a888f4a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a08a4025-2a69-4512-8534-ed0538b99c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83994a50-7514-44ca-a3c1-cd7fd6283ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4340b48-9839-4499-b036-63af1caac3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58ef1b18-033a-4290-9225-11667428ef8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d04b927b-8ab2-48e2-9bf0-083ec78cc19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9efc56df-846e-478c-b79f-33c64c85ae2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2a36a66-3e7d-42e1-8dcf-9a2e5746bb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13adabd-ba92-4062-b8cf-e813b49e9316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d78b8357-122c-4c42-b371-7ee8a599dcb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c30ffa58-9ff9-451b-86e4-1deaaabe1944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2fb58cc-ca15-434b-9e64-771ef0fefc09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57085e48-a46b-42e0-9f5b-355e36ce1203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f444e1b0-f986-4a8b-8362-f9fca7453d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a184af40-d37e-4634-9c46-f94aff25c627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8636057-575a-409e-80a1-5c214b96efa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c533b6bc-159e-4de7-978f-66a284695b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f61a96-0489-41e6-881e-3cd7cf4185bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd13338-b496-4201-990f-7027ca20d720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aff1496c-957c-4520-9876-16f466e0e6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e35715-5d22-45eb-8d35-0aa2125b639d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c0bc5ad-6c53-4f5b-8172-c2c7f7f51216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d885f16-2141-4187-8ad2-5adf3f15dc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df5fbe72-2700-49a4-ab7d-108ba93a0d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f323fb1-df4b-4cbd-bed0-885352c22acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 834c9933-4574-4c18-a1e1-3ee33bf1d83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68aa8bca-671e-4544-997c-ab4bde07f14a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1632d11f-95a7-4e9a-a908-7396e84a6d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 404a9f87-b984-4a99-9eb5-fcc2c8eac378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61da6923-a4b7-4c82-9011-d03ef6b50af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aac32c15-4b36-4dbb-9fe5-776c23c6c1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91206026-1f60-4101-8aef-aeb3edc6e93c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15832588-8de2-433f-8fe2-0a9c4c175e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9370f9c-7e4e-4a62-b85a-b21b930dab37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cc1bd8c-3fb3-41bc-9f42-533d206c8a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 433d0717-76e5-4591-94c8-69200cadb06f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d32756e9-5dfa-4a3f-8ca5-64c420befe1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48e9b873-a9c1-4a30-a5c2-c2fed318e7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 950ee9fe-6780-4373-a675-3525e9536df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 563a2d18-7d51-4a3f-9941-456211fdc30f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 806f72a7-dd1f-44d6-a81d-85a5ea379954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c632cca-2b0a-43de-862f-1e97c2d85253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6aacdf-4653-4b7e-961d-9b7621795b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfad0c76-2e0a-4514-90b2-f76cc9de3cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b1bfd63-05db-4de4-bd4d-230ad1a5c639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ce96a39-b508-4fe9-aa37-e46e38bcdbf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cd78c0c-46a7-49fc-95f6-637c18af0fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b3612e4-e918-4146-a361-7e16c0391735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9565c012-e122-44c8-87a4-720b8d354401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a28646b4-f2f8-481b-a68a-c37e453416f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47e3523b-0cad-4683-aead-ce18c1848b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56b2877c-4928-4351-b627-34a35db03514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c41ffcae-b796-49f6-b63f-b26b46693465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4b869a2-5045-4497-9369-f653210fcf18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 088d07c7-7388-4d4c-a4e8-031d8b2ac471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6026a30-e155-45fd-9a61-af843d5929ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6c8433-8f22-4db5-90d4-0e0a2812f20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f7a022-f77b-43ea-8b68-31b66f5ddc17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a293b884-7161-4a2d-8673-2b398dbb69cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e7e3c1b-cafd-4fb5-9ff3-696d71b620f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8286c0af-46f0-42c2-9e21-a6d55467e32a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73d91ca-90b8-4e49-856a-a07c2f97562c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf3fa11-b344-4400-b469-c448082b42b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91e7522c-88ec-4047-a6ff-76e954c10cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b88934df-3f4e-47bf-9e04-fd05c36dc4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccea0276-da8a-430c-865e-ed809cc80570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c884c7a2-ffb3-4885-a79f-d550cd48b5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe1a837-8608-4e22-8c73-c73c96809b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12600c0f-7cd0-44bf-875c-ede78be8955c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f90e441a-8a18-4747-9abc-35603b98eedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38ec4474-975a-42ec-bbd9-d607ed31103d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0459706-bb66-4f09-b92d-2d73bfc5fcee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54744d7-938d-4a0b-902b-3a5a06877ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4709d8-e040-4f53-a618-4449baa45123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6e4cb6c-ec4d-4533-912b-5df35797ab18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1d5949f-6b1d-4bb6-8b2c-1f8273b27aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e796d9-cd02-4102-924c-e04574f62bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d4bbb6-0980-4ce8-8bb2-46fa2a7ebc4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53f53a2f-3fc4-4f66-8493-3c85f30dc313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c462fbd2-7b04-414d-9890-c4d03e38db70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34bcb1a5-84c7-4a3e-9b6e-09ab4db99e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 569945d5-5f59-4f42-8a04-a5e76a1d59aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72d64cec-2d59-4af2-963c-78023375b113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5b2e874-e0e2-4131-bdd2-31fa9ad57a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6150bc5e-f520-44a4-b2a7-548373eacd9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41410f97-b2ae-482e-b949-624ffc8a7d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28c06a83-a864-47f3-a51f-99de9c984748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e033226-422e-4114-a91a-532e20c21c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44937601-f34d-463b-b761-bb8692e7d00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7c84b3f-86b5-4c26-af9e-f61359213ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67fb75c9-ec3a-4df5-a58a-d1b05d9adc34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c1beaac-e9eb-41e2-9dbf-17c5df87beaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca88a0d-04ee-4b23-ad94-676b0c8a763a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cbbb067-31a7-41cf-b2b4-5f1b9ec3cf05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb24b661-ecb6-4417-9d94-0643675aaf3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4245ff8a-5b63-4b49-ac82-33c1eebecf20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17bb8802-5dfb-49f1-a2ba-56f2f348e492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba6780b2-dab6-4c16-ae8d-90c5313c20a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec113f9e-af8d-470c-97ca-4f66d9c7d3f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9283cd8a-a0d5-45b3-b2d2-8063746d7a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fc16464-cb35-480f-9a88-af4f53d68faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30e4eaae-64e2-48c3-8d02-733a44e8b643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1c0e7d6-fbe6-451e-95b7-56013ecb3e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcec6c8c-7d91-4210-aa55-82f4b63af472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c999246-e1ff-46bb-81fe-044b6d795dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8137f0cf-3e32-4a83-aa4f-24c26644e9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64955388-36a4-4b3f-b2a7-86733aa23abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4614f652-d9ae-4eb4-88a2-0f0b27506f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf96dd07-662d-4171-a826-0aaa87ae8077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d89822d8-fa3d-402b-b244-3482257e552d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34ad242f-e522-464a-aafd-317014cc020d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85886e1c-95d7-430b-8e12-796b43c07a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c640f263-2cae-4f70-9d8e-7f5384c97fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 022b8f6c-84be-421c-8f61-b5dfb4200c11
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_71
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/test_labels.txt

📊 Raw data loaded:
   Train: X=(1127, 24), y=(1127,)
   Test:  X=(282, 24), y=(282,)

⚠️  Limiting training data: 1127 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  273 samples, 5 features
✅ Client client_71 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 8 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1105, val=0.0838 (↓), lr=0.001000
   • Epoch   2/100: train=0.0858, val=0.0851, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0847, val=0.0845, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0844, val=0.0846, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0842, val=0.0848, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0829, val=0.0859, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 8 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0038
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0175
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.1673, RMSE: 0.4091, MAE: 0.3289, R²: -0.9396

📊 Round 8 Test Metrics:
   Loss: 0.1616, RMSE: 0.4020, MAE: 0.3235, R²: -0.8737

============================================================
🔄 Round 11 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1373, val=0.1002 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0928, val=0.0785 (↓), lr=0.000250
   • Epoch   3/100: train=0.0865, val=0.0790, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0862, val=0.0788, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0860, val=0.0788, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0854, val=0.0791, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 11 Summary - Client client_71
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0161
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0041
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1574, RMSE: 0.3968, MAE: 0.3196, R²: -0.8247

📊 Round 11 Test Metrics:
   Loss: 0.1522, RMSE: 0.3901, MAE: 0.3150, R²: -0.7638

📊 Round 11 Test Metrics:
   Loss: 0.1319, RMSE: 0.3632, MAE: 0.2975, R²: -0.5292

📊 Round 11 Test Metrics:
   Loss: 0.1280, RMSE: 0.3578, MAE: 0.2940, R²: -0.4838

============================================================
🔄 Round 17 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1186, val=0.1324 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1021, val=0.1112 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0897, val=0.0969 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0846, val=0.0908 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0841, val=0.0892 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0841, val=0.0889, patience=6/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0840, val=0.0887, patience=5/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008
   📉 Epoch 31: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0840, val=0.0886, patience=15/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 17 Summary - Client client_71
   Epochs: 31/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0007
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0348
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1140, RMSE: 0.3376, MAE: 0.2814, R²: -0.3209

📊 Round 17 Test Metrics:
   Loss: 0.1023, RMSE: 0.3198, MAE: 0.2722, R²: -0.1855

============================================================
🔄 Round 19 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1044, val=0.0905 (↓), lr=0.000004
   ✓ Epoch   2/100: train=0.1035, val=0.0896 (↓), lr=0.000004
   ✓ Epoch   3/100: train=0.1025, val=0.0886 (↓), lr=0.000004
   ✓ Epoch   4/100: train=0.1016, val=0.0878 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.1007, val=0.0869 (↓), lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0972, val=0.0838, patience=1/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0949, val=0.0817, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0937, val=0.0805, patience=1/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0927, val=0.0795 (↓), lr=0.000001
   • Epoch  51/100: train=0.0918, val=0.0787, patience=4/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0910, val=0.0779 (↓), lr=0.000001
   • Epoch  71/100: train=0.0903, val=0.0773, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0897, val=0.0767, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0892, val=0.0763, patience=2/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_71
   Epochs: 100/100
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0189
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0327
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2613, R²: -0.0096

============================================================
🔄 Round 22 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 22 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0212
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0147
============================================================


============================================================
🔄 Round 23 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 23 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0082
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0481
============================================================


============================================================
🔄 Round 24 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 24 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0123
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0054
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2609, R²: -0.0022

============================================================
🔄 Round 25 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 25 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0062
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0508
============================================================


============================================================
🔄 Round 26 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 26 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0095
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0039
============================================================


============================================================
🔄 Round 28 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 28 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0073
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0090
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2609, R²: -0.0006

📊 Round 28 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2609, R²: -0.0005

============================================================
🔄 Round 32 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 32 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0038
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0381
============================================================


============================================================
🔄 Round 33 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 33 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0069
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0057
============================================================


============================================================
🔄 Round 37 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 37 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0039
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0405
============================================================


============================================================
🔄 Round 38 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 38 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0053
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0101
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2608, R²: 0.0002

============================================================
🔄 Round 39 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 39 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0075
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0008
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0862, RMSE: 0.2937, MAE: 0.2608, R²: 0.0004

📊 Round 39 Test Metrics:
   Loss: 0.0862, RMSE: 0.2937, MAE: 0.2608, R²: 0.0004

============================================================
🔄 Round 44 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 44 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0055
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0040
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0005

============================================================
🔄 Round 47 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 47 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0052
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0103
============================================================


============================================================
🔄 Round 48 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 48 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0044
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0088
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0006

============================================================
🔄 Round 51 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 51 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0076
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0001
============================================================


============================================================
🔄 Round 54 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 54 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0053
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0043
============================================================


============================================================
🔄 Round 55 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 55 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0040
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0257
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0006

📊 Round 55 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0006

============================================================
🔄 Round 59 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 59 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0057
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0017
============================================================


============================================================
🔄 Round 60 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 60 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0044
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0070
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0006

============================================================
🔄 Round 61 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 61 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0037
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0102
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0007

============================================================
🔄 Round 63 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 63 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0018
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0303
============================================================


============================================================
🔄 Round 64 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 64 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0034
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0151
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0007

============================================================
🔄 Round 66 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 66 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0040
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0086
============================================================


============================================================
🔄 Round 67 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 67 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0012
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0374
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0007

============================================================
🔄 Round 69 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 69 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0028
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0416
============================================================


============================================================
🔄 Round 70 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 70 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0048
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0049
============================================================


============================================================
🔄 Round 71 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 71 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0039
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0076
============================================================


============================================================
🔄 Round 73 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 73 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0050
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0110
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 74 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 74 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0049
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0071
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 75 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 75 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0034
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0411
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 77 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 77 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0059
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0002
============================================================


============================================================
🔄 Round 79 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 79 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0038
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0074
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 80 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 80 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0045
   Val:   Loss=0.0690, RMSE=0.2627, R²=-0.0041
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 81 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 81 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0047
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0067
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 83 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 83 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0057
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0036
============================================================


============================================================
🔄 Round 84 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 84 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0027
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0154
============================================================


============================================================
🔄 Round 85 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 85 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0040
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0135
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 87 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 87 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0030
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0264
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 95 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 95 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0061
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0002
============================================================


============================================================
🔄 Round 96 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 96 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0025
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0194
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 99 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 99 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0055
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0005
============================================================


============================================================
🔄 Round 101 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 101 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0041
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0052
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

📊 Round 101 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

📊 Round 101 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

📊 Round 101 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 107 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 107 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0034
   Val:   Loss=0.0716, RMSE=0.2675, R²=-0.0063
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

📊 Round 107 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 113 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 113 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0045
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0053
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 114 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 114 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0022
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0123
============================================================


============================================================
🔄 Round 116 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 116 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0052
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0020
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 118 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 118 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0040
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0158
============================================================


============================================================
🔄 Round 120 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 120 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0026
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0280
============================================================


============================================================
🔄 Round 121 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 121 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0056
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0016
============================================================


============================================================
🔄 Round 123 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 123 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0060
   Val:   Loss=0.0831, RMSE=0.2884, R²=-0.0048
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 126 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 126 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0028
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0090
============================================================


============================================================
🔄 Round 127 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 127 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0039
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0028
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

📊 Round 127 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 131 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 131 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0049
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0047
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

📊 Round 131 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 134 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 134 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0085
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0170
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 139 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 139 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0033
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0069
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

📊 Round 139 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 141 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 141 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0025
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0074
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 142 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 142 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0032
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0067
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

📊 Round 142 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 145 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 145 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0038
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0077
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 146 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 146 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0012
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0417
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0009

============================================================
🔄 Round 148 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 148 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0048
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0016
============================================================


============================================================
🔄 Round 149 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 149 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0041
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0072
============================================================


============================================================
🔄 Round 152 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 152 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0043
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0066
============================================================


============================================================
🔄 Round 153 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 153 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0044
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0019
============================================================


============================================================
🔄 Round 154 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 154 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0082
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0002
============================================================


============================================================
🔄 Round 155 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 155 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0035
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0044
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 156 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 156 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0053
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0019
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 157 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 157 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0033
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0050
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 159 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 159 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0061
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0315
============================================================


============================================================
🔄 Round 160 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 160 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0047
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0008
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

📊 Round 160 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

📊 Round 160 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 166 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 166 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0056
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0045
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

📊 Round 166 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 169 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 169 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0018
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0394
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

📊 Round 169 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 171 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 171 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0051
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0194
============================================================


============================================================
🔄 Round 172 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 172 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0066
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0053
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

📊 Round 172 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

📊 Round 172 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 184 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 184 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0028
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0052
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 186 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 186 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0033
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0063
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 189 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 189 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0051
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0002
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 190 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 190 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0031
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0051
============================================================


============================================================
🔄 Round 191 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 191 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0044
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0012
============================================================


============================================================
🔄 Round 193 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 193 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0053
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0297
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

📊 Round 193 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 195 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 195 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0030
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0104
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 196 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 196 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0046
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0009
============================================================


============================================================
🔄 Round 197 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 197 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0030
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0117
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

📊 Round 197 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 202 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 202 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0043
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0021
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 205 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 205 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0049
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0145
============================================================


============================================================
🔄 Round 206 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 206 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0024
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0087
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 207 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 207 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0021
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0195
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 208 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 208 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0025
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0096
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2608, R²: 0.0008

============================================================
🔄 Round 210 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 210 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0023
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0083
============================================================


============================================================
🔄 Round 211 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 211 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0035
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0082
============================================================


❌ Client client_71 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
