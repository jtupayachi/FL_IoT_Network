[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a86763-0738-4405-b760-cace25bd8915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d7003c3-25ec-46bc-89c5-2526bc053889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de181465-fa1b-4d68-a370-f2a625d708b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 199af10b-c75c-4cd8-9b9a-d26807fb033e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a87b496d-3b8a-467c-952d-b0d02118b7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c77c46d-1833-44a9-9d46-75e74c291224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67670a93-10a5-488f-8159-71e607bee7fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c181c0-bf70-4a90-b404-9895c2e6f3ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ea4c99a-2302-4562-adab-8f9e349aa316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0664f6cf-4aec-4206-8e0d-515119264a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b36b719-3364-497f-b46c-92c54df23f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d3c8f06-59fd-444a-b297-f7034620ab2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9165148b-7391-498b-bf30-8de8a37ef3c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb01990e-8ed7-4b18-9743-a304198e40e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd4e67c4-85aa-4789-b7f0-0fce53dfc526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 157a4aab-ea46-4ae8-be4b-f9e641ac53bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85e5205b-3b88-4d57-908b-111e207b3455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d2ed800-f2ad-4ab3-9f6b-fdf12e76ad03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9acc41ff-d34c-41bf-a6c9-6057cdbe5cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41340512-6147-47d3-99df-ed93dc2ae9eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb5bbc21-cc12-4229-9b9a-fae5891c30a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77c7d704-0dad-4c2e-820f-c522bfa40645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d780c92-6bda-40d7-8dad-b084a6168551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea8cbac-b506-475e-b016-0d492d81234b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e657d45-2889-438c-b052-9c3e60a1cff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b73454c2-162f-4922-97ec-de07da53f69f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 199ba6b6-0ff7-48e1-99c0-9f94a5fa2431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c7e20e-7edf-406c-a958-5e992c94ec2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 389d66c8-c8ea-4a60-9ebb-9c9608df0628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f41c9879-64a8-43a1-aca7-48e72a912e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5ce686-9c5f-417c-816f-a17376a0ab77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31ac2f0e-7c34-4d61-a64b-3c601ed13db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4755db55-38e2-418d-b091-b9a00521dd36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20041059-6528-4538-b148-21cc4dfe5450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4af52fc-6339-48cc-b92f-0932d1eb1e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message def30de3-f187-488d-9b8b-1ebd46e2d7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9325428f-ed8d-4775-b38b-2a99fa3191e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0856abe2-bd2f-4b52-a022-0a673529a1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f8d2482-1193-486d-8667-3ea6ba4eca60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee446360-e701-44db-8c43-7d0bb298e83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb393d55-3dd0-4e47-ab67-f6f0f666d745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 934581c8-16e0-4af3-b6a0-ef24c19fa8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee86706-d754-4943-a8f7-54c85b7ce07c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8c77a16-4733-44db-a688-55d893e05de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 146d849b-1062-470d-8f42-7c3ef145ad5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc566987-bd10-4880-87de-714e09488179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f52ffff-8533-4e78-afb1-214182642fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 255f4c59-436f-4680-9a49-76bae886583a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ae01c90-71a2-48bb-b442-1852102c1b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 812ddaa0-0dcd-4dc6-82da-8b865990f755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10c6fff4-6673-422f-8cd1-7d5e07889ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e63016b2-bf3a-4219-a143-0e7ba91cab9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f6490f7-558a-4a96-b358-5d3979dc2170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fa5ce10-92cb-4a64-9d55-5ba93b2d07b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7050fa8-a7d6-4616-9186-5b31da6239f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7ba5d39-c255-4d57-9b24-8812bae8ce8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c5db4ff-5d2b-4721-8bbb-7476a36fa78b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3d02ebc-d2fa-4ab3-aa21-0314a6b6fba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a295db5-282c-4680-aef7-02217d4aaeb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd4c487a-ed20-42b9-b436-7e8ea06c6288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1275005-b685-4588-b0e8-d34a153eeb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3c6bb3e-a0b3-4849-a402-c14c53fa7ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 497fc36b-0889-4c66-ae3a-a9dd457e9c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 205efd04-535c-44c6-ba02-bb9aa70f6eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5b2fc30-a961-465e-b56e-2b290ff1842e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e0784c9-d66d-4502-a0d1-0f8595b37b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fcbc9af-a1c4-4994-9fd4-61d5dc8eaeaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2c76ee3-8661-4b43-ba4d-d411d8ab6ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90e9d706-bec4-4397-a6c1-a545e78c29ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813b3ce3-3a79-45b9-95ed-169dff4ce866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efa899a1-1ada-4e17-bab4-5eb794977345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73ad1171-de55-4795-9f19-e33e3530fbcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b0f5b06-0be8-40d4-bb6d-cea22f0788a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 839a7ba8-e7cf-4e94-81ad-48f85a70b331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1c59a99-f508-4ab2-8e9e-905a885def67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f08ffc6-05ee-46d8-9594-5962939bac9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c07d3a0-c0bf-488d-9e05-e7cd8232149e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95d351ec-eaa1-4516-a732-c98583eae95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66bba658-6e8a-4a7b-92dc-27d4449b6736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b8d786-f517-49fb-9c62-e01c54db6d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58cb5990-f81f-40a1-bd48-c91ba580605a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7c849d2-eafc-4299-9285-54aabbf6cb8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ebbcec7-e672-474e-9092-03cb495bb962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff61cc32-3c4a-4a5c-9f36-9da38d8f5f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20a47168-97c1-474c-aea6-cedd616569d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f504c3-63f1-4b8b-9211-51b0b8676689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1302cf6c-ac08-4026-ab53-818113f5818b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a8a5487-9feb-4b74-a051-ff18f1db78cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 401e2417-f31e-46b3-a749-94f1f04515ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde18a4e-686e-4885-aed9-2f408eea4999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 333c911a-45fd-496f-b6a7-29d9cbbbb1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 674f6d66-5fe3-4eb9-8b31-2cba3b869385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 778a493d-ab3e-4471-ba89-9b5046f3f452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14767506-066a-4577-81c0-095bd90c9873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d8fe45-a8c4-4ecd-9cca-dfbaed567c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 569b4e0a-2436-4d6f-b758-59f436e1bcdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db803942-79eb-4b8c-8940-90f97bb59c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b4ed7d2-1495-4556-8f21-520547b24f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e547855-a44f-4b6d-9580-9e06a3f5eff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75481d90-95d6-433b-a2dc-3e07955b5f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da6f8c63-a43c-41a8-b614-d5d8cd9a1da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b678c759-684c-4e28-a71a-db342b9ae632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12d6502a-81c5-44f5-aa69-a16c217da16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2f8e110-6cbc-45ec-b708-8b570defe04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4f9a8b7-7413-4bb4-950b-6aaa99da24bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4827d271-04f2-458f-bec4-372c7502e7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f87c87-820d-44e5-a227-d1589e48f639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1553430e-1a25-4217-8129-a1b9f9df8b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 365204c0-b13c-42dd-b1d1-cf7725e34cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 721d2660-1052-498f-897f-27221502521f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c3239f-d257-4a3c-b2eb-62b0ce2abd2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c4e44c0-3021-402e-a7ac-93f6641126ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f8ccf9-7efb-4ec2-b15c-4ba939fe3e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e02651f-164c-48ea-84b6-265ebe0f7494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b242677-8848-4570-94f0-f6881c12e490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b18199-a129-465f-9eb3-97817b7563b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb195b05-53c3-405a-a5c4-98f3a5527c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67d439b8-8a01-4082-94e1-5067f638c5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72f594d-9956-44c2-abb0-af4622ca87a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beef951c-d4bc-457b-975d-ee3bb8ca3415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 125504a8-124f-4636-bd75-28c177d779ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bf6e379-7d25-4f6a-855c-e16153e20433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1927055f-6da5-45d5-bb3d-46413ff84f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bf6fa69-aaaf-4b9b-b1fe-576917b70314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c798229e-1a8b-44e5-add6-1bcba41d8f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f03438d-d293-47c3-a2d3-dbcb4d5d4416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd313d40-4df1-4784-bdf8-49f806e981cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b49761e-4589-4992-9428-e50120d0dd08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b07ffb5e-3397-449f-a6b7-40ed12705504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3841d4a-a639-4582-b06e-766fa352d441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d17cdce-7b86-40e5-b8dd-4232b548f98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba8336bd-5a99-4d78-a85d-1a41cf7c547a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35680889-49a6-4d9e-a9b8-45a5d0535869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f50fc6f-173c-485c-a76f-b5796a8538c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e370e83c-de2a-4423-af15-dcfdd572625a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3099ed9e-af35-45a0-b755-d2d3359bdf17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f67829-abdd-453b-b758-6f66ca0bfd62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 869c513d-39d2-4c2b-ab54-3602d3e96a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a65227-80e0-4952-92f3-22c7650cadf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff242649-c92d-47e0-90dd-49591f49a5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5d79bad-0789-49a1-8d72-5b7b6eb4be14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e8839d4-3938-4ef0-b629-17935834e5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dc95b8d-fc1c-4775-b861-28d100b9a4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ec913b9-e20d-43b2-b7a1-592327c33f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1c40208-5d20-4de4-b802-2cbd8c152ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e2dfadb-8bcc-47c6-8f49-ca863ccb74b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c8cc409-e8e7-45c1-80a1-fcad3461c69a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7d472b-b519-4267-80fa-8ddafc8b6e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f51ccfc-8971-4982-a729-2b50c6631844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73c2cb5d-7345-49be-9daf-963e3ce19a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fdc4806-9812-4b06-8772-ca1620e91373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3971c80e-61f8-43f7-b63e-a4ac95c660df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd3ca301-58e9-4847-80f6-280e99368910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 157cd978-a906-4b97-84cb-4066991d73c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 532c3dbe-3a42-44f1-911b-6790086e3733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 240bc463-c36f-4ae5-a078-fd9cc5652521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44f2f3b9-cc81-4f2b-8998-35e1334d104c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47a9741f-26b3-49bf-ba18-6c613a4ef6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 244bf3c3-3b7d-467a-a1d2-5a226c92a7f7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_72
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/test_labels.txt

📊 Raw data loaded:
   Train: X=(2172, 24), y=(2172,)
   Test:  X=(543, 24), y=(543,)

⚠️  Limiting training data: 2172 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  534 samples, 5 features
✅ Client client_72 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1618, RMSE: 0.4022, MAE: 0.3297, R²: -0.9811

📊 Round 0 Test Metrics:
   Loss: 0.1562, RMSE: 0.3952, MAE: 0.3240, R²: -0.9127

📊 Round 0 Test Metrics:
   Loss: 0.1469, RMSE: 0.3833, MAE: 0.3146, R²: -0.7989

============================================================
🔄 Round 13 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1036, val=0.0760 (↓), lr=0.001000
   • Epoch   2/100: train=0.0896, val=0.0847, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0882, val=0.0796, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0872, val=0.0796, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0871, val=0.0805, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0860, val=0.0787, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 13 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0061
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0305
============================================================


============================================================
🔄 Round 17 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1118, val=0.0894 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0855, val=0.0888 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0841, val=0.0878 (↓), lr=0.000250
   • Epoch   4/100: train=0.0838, val=0.0884, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0836, val=0.0884, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0832, val=0.0888, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 17 Summary - Client client_72
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0046
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0123
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1091, RMSE: 0.3303, MAE: 0.2754, R²: -0.3364

📊 Round 17 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2545, R²: -0.0849

📊 Round 17 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: -0.0246

📊 Round 17 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2480, R²: -0.0132

============================================================
🔄 Round 24 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0858 (↓), lr=0.000063
   • Epoch   2/100: train=0.0847, val=0.0870, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0847, val=0.0872, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0847, val=0.0870, patience=3/15, lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0846, val=0.0869, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0844, val=0.0868, patience=10/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 24 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0080
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0117
============================================================


============================================================
🔄 Round 25 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0825 (↓), lr=0.000016
   • Epoch   2/100: train=0.0864, val=0.0822, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0863, val=0.0820, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0862, val=0.0818 (↓), lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0861, val=0.0817, patience=1/15, lr=0.000008
   • Epoch  11/100: train=0.0860, val=0.0816, patience=7/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 25 Summary - Client client_72
   Epochs: 19/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0036
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0096
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2471, R²: -0.0041

============================================================
🔄 Round 28 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0817 (↓), lr=0.000004
   📉 Epoch 2: LR reduced 0.000004 → 0.000002
   • Epoch   2/100: train=0.0865, val=0.0817, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0865, val=0.0816, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0864, val=0.0816, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0864, val=0.0816, patience=4/15, lr=0.000002
   📉 Epoch 10: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0863, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 28 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0101
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0068
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2471, R²: -0.0038

============================================================
🔄 Round 29 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 29 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0091
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0096
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2471, R²: -0.0035

📊 Round 29 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2470, R²: -0.0034

📊 Round 29 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2470, R²: -0.0032

============================================================
🔄 Round 32 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 32 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0076
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0120
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2470, R²: -0.0031

============================================================
🔄 Round 33 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 33 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0065
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0155
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2470, R²: -0.0031

============================================================
🔄 Round 36 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 36 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0096
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0005
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2469, R²: -0.0027

📊 Round 36 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2469, R²: -0.0027

📊 Round 36 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2469, R²: -0.0026

============================================================
🔄 Round 40 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 40 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0080
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0059
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2469, R²: -0.0025

============================================================
🔄 Round 42 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 42 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0072
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0053
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0024

============================================================
🔄 Round 44 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 44 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0112
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0054
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0024

============================================================
🔄 Round 46 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 46 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0078
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0022
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0024

============================================================
🔄 Round 48 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 48 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0086
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0070
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0023

📊 Round 48 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0023

============================================================
🔄 Round 51 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 51 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0048
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0195
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0023

📊 Round 51 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0022

============================================================
🔄 Round 53 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 53 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0052
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0105
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0023

📊 Round 53 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0023

============================================================
🔄 Round 56 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 56 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0060
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0085
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0022

============================================================
🔄 Round 57 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 57 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0014
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0376
============================================================


============================================================
🔄 Round 59 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 59 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0073
   Val:   Loss=0.0723, RMSE=0.2688, R²=-0.0007
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2469, R²: -0.0021

📊 Round 59 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0021

============================================================
🔄 Round 64 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 64 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0090
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0003
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0021

============================================================
🔄 Round 66 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 66 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0048
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0299
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0021

============================================================
🔄 Round 67 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 67 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0059
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0055
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0021

============================================================
🔄 Round 68 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 68 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0055
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0118
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0020

============================================================
🔄 Round 72 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 72 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0040
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0125
============================================================


============================================================
🔄 Round 73 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 73 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0072
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0077
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0020

============================================================
🔄 Round 74 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 74 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0086
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0010
============================================================


============================================================
🔄 Round 75 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 75 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0030
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0271
============================================================


============================================================
🔄 Round 78 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 78 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0087
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0070
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0019

============================================================
🔄 Round 84 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 84 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0044
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0084
============================================================


============================================================
🔄 Round 86 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 86 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0068
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0128
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0019

============================================================
🔄 Round 88 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 88 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0075
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0033
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0018

📊 Round 88 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0018

============================================================
🔄 Round 90 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 90 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0070
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0011
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0018

============================================================
🔄 Round 91 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 91 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0029
   Val:   Loss=0.0959, RMSE=0.3097, R²=-0.0148
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0018

============================================================
🔄 Round 94 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 94 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0019
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0252
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0018

============================================================
🔄 Round 97 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 97 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0044
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0077
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0018

============================================================
🔄 Round 101 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 101 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0024
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0157
============================================================


============================================================
🔄 Round 102 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 102 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0052
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0047
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0017

============================================================
🔄 Round 103 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 103 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0121
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0083
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0017

📊 Round 103 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0017

============================================================
🔄 Round 107 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 107 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0049
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0063
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2468, R²: -0.0017

📊 Round 107 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0017

============================================================
🔄 Round 111 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 111 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0072
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0057
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0017

📊 Round 111 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0017

📊 Round 111 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0017

============================================================
🔄 Round 119 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 119 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0042
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0061
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0016

============================================================
🔄 Round 122 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 122 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0043
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0055
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0016

============================================================
🔄 Round 124 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 124 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0039
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0073
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0016

============================================================
🔄 Round 127 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 127 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0024
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0211
============================================================


============================================================
🔄 Round 128 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 128 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0023
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0348
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0016

============================================================
🔄 Round 130 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 130 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0009
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0266
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0016

📊 Round 130 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0016

============================================================
🔄 Round 134 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 134 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0032
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0195
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0016

============================================================
🔄 Round 136 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 136 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0031
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0100
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0016

============================================================
🔄 Round 140 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 140 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0059
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0117
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0016

📊 Round 140 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0015

📊 Round 140 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0015

📊 Round 140 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0015

============================================================
🔄 Round 148 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 148 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0047
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0027
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0015

📊 Round 148 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0015

============================================================
🔄 Round 159 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 159 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0065
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0129
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0015

============================================================
🔄 Round 160 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 160 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0078
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0009
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0015

============================================================
🔄 Round 163 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 163 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0082
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0020
============================================================


============================================================
🔄 Round 166 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 166 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0037
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0149
============================================================


============================================================
🔄 Round 167 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 167 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0037
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0058
============================================================


============================================================
🔄 Round 168 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 168 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0038
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0053
============================================================


============================================================
🔄 Round 169 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 169 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0043
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0036
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2467, R²: -0.0014

============================================================
🔄 Round 173 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 173 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0029
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0082
============================================================


============================================================
🔄 Round 175 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 175 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0044
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0097
============================================================


============================================================
🔄 Round 176 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 176 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0047
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0064
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

📊 Round 176 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

📊 Round 176 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

============================================================
🔄 Round 180 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 180 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0033
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0073
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

============================================================
🔄 Round 181 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 181 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0049
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.0046
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

============================================================
🔄 Round 186 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 186 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0070
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0052
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

============================================================
🔄 Round 187 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 187 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0055
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0034
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

============================================================
🔄 Round 188 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 188 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0100
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0170
============================================================


============================================================
🔄 Round 192 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 192 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0049
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0015
============================================================


============================================================
🔄 Round 194 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 194 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0056
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0027
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

============================================================
🔄 Round 196 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 196 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0047
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0052
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0014

📊 Round 196 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0013

============================================================
🔄 Round 198 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 198 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0024
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0119
============================================================


============================================================
🔄 Round 199 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 199 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0015
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0141
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0013

============================================================
🔄 Round 200 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 200 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0044
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0033
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0013

============================================================
🔄 Round 201 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 201 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0050
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0080
============================================================


============================================================
🔄 Round 202 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 202 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0024
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0179
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0013

============================================================
🔄 Round 207 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 207 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0046
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0021
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2467, R²: -0.0013

❌ Client client_72 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
