[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4273cdc6-0f24-4f85-adcd-ea44bfb8f663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7ff1171-1f48-4e88-a0ee-ee33a44791f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 810c3cc0-c039-478d-b46a-93a81e5258bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86c01073-4b89-4432-a47a-1e90a0a51ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d4ce906-99d3-41f0-9d78-76017edf5851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b593852f-6b28-438f-baac-33e460e8edd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a44c4ae-1483-4cbb-adbe-7e2f8dd8707f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12ac2bf3-e290-43ee-ad1a-5ffde774235d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a24deba-7989-4330-ac2d-44f72ccc3ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 601878e7-df21-49bb-b426-cd8d2793d490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 067d8163-3a6e-4658-bb97-6b6436e0c433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 941f7d6f-9b55-439e-8fd2-f27fe5708d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f39db14-5931-4361-928c-8fdd9464c19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff62c32a-a335-4515-abd4-a7509c4a9d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28c2dca5-2b41-4480-a54a-6cfdbdc905e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cade0df-2b41-4252-96f5-0c1a58bdd9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5644616a-2f8b-4658-8f2a-aba335a94b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25209d92-54a7-4dff-a82e-af439d1b5ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 007b41ab-0e06-422d-ae72-c7e84befc463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d55852b9-6877-41be-a26f-3e9e9eff687c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44f8b292-76e7-468b-af45-143a44716a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53b4bed1-40c7-47b6-a0ef-c653c3b14d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c6dfba4-6d34-4697-a01d-3ab4891d9ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d6c554a-bea3-46f1-a15a-1a5585661636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cef15c3-4c4f-43ad-bdfa-ec6ecb9a6c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fe4d8b3-eb7b-4664-bb67-6a2c079da180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 230b69f5-e8d5-4030-84ff-c4bca1daed31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb013f0e-c682-40c7-a392-ab5d085b81bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73621e37-1c97-47f2-b414-5ee679dccc7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 302949d6-b5c6-4892-add2-6073ffac0cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4177449-b1b0-42d6-bd36-fa552191776c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eca4f81-ba28-49fa-b77d-811a0be39e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff3ef804-8ca1-4a0e-84fb-e96b244d0c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b534218-27da-425c-bf51-2486fdbaf3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9de72fb0-8956-4504-91af-e9d332045183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcf07163-e28a-49da-9058-92749fb1868f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf3242ff-9d2f-4519-b622-9d8e67e333d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3c38c25-8e1b-48cc-acd2-041f61731f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dd651cb-636f-4469-8294-3d60ca4bc8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2873ea-edb7-4364-8048-b91e36ad3c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7c95aca-a897-4ab0-b851-aff7674f8a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ca513d-380e-4dee-8a6a-5240f231db6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4d57006-b718-48be-bbed-86b3a964b7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd0d57fe-bf04-47f6-be85-cfac25a5d76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45bf34ac-5424-48e8-8622-e75e729afe79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0bf3807-9348-46c1-a3c6-379f16a3f48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f523804-6f11-496d-9716-d5d6e8a38201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d616e610-bf1c-4225-b57d-a6ab88d923bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5cd5da5-ca38-4765-8f1d-943efff6550c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc6cb1ba-dab3-40e2-b8a3-e01fe2c3f4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66ad1ca8-f6f3-4899-b138-eced4b290e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d74618f8-1df5-4f1d-90af-e13a8b2fbd4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6a497a0-ba75-49f3-b03b-2648187f1f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4f7817a-be65-449f-8480-cff3a3c6ece9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 316d1b72-2442-42e6-a317-e64279451796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 499ca79b-25fc-4263-87b6-f6b042a86d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 383a56f4-c2d7-4731-9bfe-281e32f8c0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1826d777-9747-4657-a0aa-9f0c3664a381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1794149f-cf29-4e13-9b3f-5760b62a5c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e56101ad-420c-4455-b3e3-4007cbb22af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d67baa-f28b-47cf-932d-7d35d62c66ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc5c9ead-2815-4a0b-a16f-a9f38e95989a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5ae8bd2-f226-435f-8e0e-c35fbd8c7991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 748ccb7b-c3b3-433f-9532-5af6f4e8dace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aff3599a-5340-4abe-91b0-4bcd612e5bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95e3f88f-574b-42d4-a8c4-3d24cc9a8052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1a5bdec-0c6f-449b-8c18-2cfc98081477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbef1eee-b108-49f9-8c03-d797db81608f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cfbae78-b145-4810-9056-9437df8e5426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d62263d-9802-4317-a9f5-b35ffdfcbcf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eac21a6-4224-4b97-be22-76556ca43da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc2f37c6-802c-4cbf-bc5a-b3e7fd0c6237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8393eecf-2700-4970-bc76-4f6154b9de6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c202072-60cc-4362-b023-589f2af9ca9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1637bab-e177-4bad-8f21-8ded2053c9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aab567e-23f8-4559-b14c-e7a8d7e18612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8156c1b8-e613-46ce-85f4-72ca6d40f5e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b4d43d-54ac-4242-940d-3402ec45601e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c386d182-2c79-4353-a59e-0571ec589e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13d66716-fb50-431a-b098-82eb807d4c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b038af0e-bce7-4741-bea3-25b5e6333f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab20d49-4982-44c9-ab97-4be752f80bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb9432b8-b0c6-4fdf-8ffa-278cac09ce37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 669926ec-3a60-431c-a31f-a00f5e9dfd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df3b6315-ae55-496c-a9e5-a3daadd07624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f3dc8af-10a5-4e7c-9acd-def324b508e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e46d116-531c-40c6-922d-c75fd4f7fa2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21579f2e-f0d6-431b-af1c-39e3b84f72dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fdd3d6e-c1df-4ed9-8f17-c71c8cbfa5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffc83d87-f9c6-4071-9c02-7983f0c43709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b46b50fe-6fe2-4768-8255-981fc5df24d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56299d9e-f9a3-4716-8eff-bad6eda2f9e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55c754b2-db2c-4708-a92a-69d30f25c3a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40f99bf4-78e9-47c0-8412-d3b460b7c1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a57279-489a-4e15-9059-19050b8fbe38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdbc7f2d-5ad7-4fa4-bf03-a2af66e29b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1d5f2e3-ee64-42d6-a6ae-f77d080fce65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96ecf9e4-b2f9-4ef6-9a05-fa2f02204a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98551546-2c2a-44a7-8fac-a23661d25f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4bbd6a7-9f10-45c8-8114-c7672fdc6551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 005985c5-1973-4840-b3ea-8ab1ba0b532a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5084aed7-8468-4e3f-bcd6-c5d204443f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48b3d33c-e022-4fed-93c3-83a2300947d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a946e693-5209-47d2-9a38-fff2b7fc81d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77c68dc9-6061-4f51-9f9c-d058330edc4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2705a44f-184b-4566-b695-c584c69f2402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f01936-3661-4b60-afc7-8417311f07af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2b4922a-93e5-434e-acd8-f6afd07372d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 291853af-1491-4243-9698-f57dc4224e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 690f342a-be5a-4784-a90b-eb43ce497c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cc2dcda-4b11-4ae3-aae8-db3dcae4c453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd2e2186-05da-4fe0-a1c1-6d38670a4b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a30065fb-470e-47ac-abdd-b99b64b18b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75d0d1d3-ae37-4666-b6b2-b90df11ae7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b90b9a8b-a17f-4f85-9d5c-7a2d2507a016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f12052f4-6c0a-4a8c-a5a1-8b86a1cc8757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 243d2fa2-2a3b-4557-9646-17af623ddcf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df42ea0e-81e0-4cc3-8853-6730f658b39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e32fd7d4-1265-40a1-b83d-0c7d52799922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71f36cd-2eb5-446c-9fd2-b8197197ed75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2c00ee3-23ee-46be-8019-33362bcce549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11fff988-7ed0-4c9e-ae88-f4ceb83d931f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83daaf72-bea5-4c59-8388-a31da8ff42e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6e23059-b4e2-4b6b-8673-aafde87e9c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caf1334e-f2ff-4d51-af90-3981e4554637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bebc88c8-3eec-4179-af93-12ee723957d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a9f29e6-f2ca-47a2-8827-3c7efd9ec969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda4540d-b036-45be-b46b-430ab4365d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4698680-2425-47e8-9728-b35dfb4ff695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43415a3a-8973-44ad-a5fa-4850044094ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb29bdc-38f7-492e-a817-77f684186400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bc791db-b7d5-4692-af8b-67f7189ae08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f659aea9-bfff-425c-9198-30f5c4d497f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05f86226-e3d9-4403-8636-cad81868416d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7a4116b-3cd5-4f16-b81e-5c061eae5569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed9e8e1d-87b3-4a44-b195-bba80609ab98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8c58538-ae42-4764-9e4a-27b31ea035b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a6bb9c9-ec25-46b8-a20d-250bf82ccf40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c42b7a9a-ddc2-4211-bb17-a2c43b0fa9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a561fb15-f190-4e74-a46a-bdf6f7461df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef81f3a5-8308-42b6-a2a7-b4592bf307a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e7ffe1-89ed-4f24-9026-50bfef584006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 145de49b-ffc2-42d2-89d2-a1d948b6dbfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89e0da44-8e88-4a8c-9a57-02014bc54c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99c48139-4c56-47f9-a8ed-a24442720923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cdbac85-7707-4d15-a3c2-daf00bcdb44f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50426d75-7b0e-4e6c-85cd-f8a6fdb12c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eabfea9-a0a9-4cab-a940-c862e1a5d7f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb8d6c08-efe9-40ac-acb3-2cf1284e075c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8355f29-aaf7-437d-9e9b-4a28896e11cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5d51d34-d12e-48d6-8f39-22d4a222a194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b669c24-509a-48f4-8359-f61d75f5afb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f017a4-ebb5-4b49-9334-50b6180b12d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc4e18fc-712d-40e0-9f9e-64619b0c0fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee542b36-3c71-43b3-b059-821efb79d5a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15f78d04-9612-4325-9db1-2d7d759f3d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b295f09-b3b9-4235-a942-f3329cabba91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6c03b44-3d04-4a09-becb-7f79ecb7ae4b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_73
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/test_labels.txt

📊 Raw data loaded:
   Train: X=(1311, 24), y=(1311,)
   Test:  X=(328, 24), y=(328,)

⚠️  Limiting training data: 1311 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  319 samples, 5 features
✅ Client client_73 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1663, RMSE: 0.4078, MAE: 0.3331, R²: -1.0070

📊 Round 0 Test Metrics:
   Loss: 0.1563, RMSE: 0.3953, MAE: 0.3228, R²: -0.8860

📊 Round 0 Test Metrics:
   Loss: 0.1398, RMSE: 0.3739, MAE: 0.3055, R²: -0.6868

============================================================
🔄 Round 16 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0856 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0850, val=0.0840 (↓), lr=0.001000
   • Epoch   3/100: train=0.0846, val=0.0845, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0836, val=0.0836, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0830, val=0.0836, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0824, val=0.0833, patience=2/15, lr=0.001000
   • Epoch  21/100: train=0.0796, val=0.0820, patience=1/15, lr=0.001000
   • Epoch  31/100: train=0.0724, val=0.0815, patience=8/15, lr=0.001000
   📉 Epoch 32: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 16 Summary - Client client_73
   Epochs: 38/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0744
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0116
============================================================


============================================================
🔄 Round 17 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0942, val=0.0931 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   ✓ Epoch   2/100: train=0.0829, val=0.0871 (↓), lr=0.000250
   • Epoch   3/100: train=0.0807, val=0.0871, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0808, val=0.0871, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0806, val=0.0872, patience=3/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0803, val=0.0877, patience=9/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 17 Summary - Client client_73
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0071
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0009
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1024, RMSE: 0.3200, MAE: 0.2655, R²: -0.2354

============================================================
🔄 Round 19 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0937, val=0.0717 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0861, val=0.0706 (↓), lr=0.000125
   • Epoch   3/100: train=0.0854, val=0.0706, patience=1/15, lr=0.000125
   • Epoch   4/100: train=0.0854, val=0.0704, patience=2/15, lr=0.000125
   • Epoch   5/100: train=0.0853, val=0.0703, patience=3/15, lr=0.000125
   ✓ Epoch  11/100: train=0.0851, val=0.0701 (↓), lr=0.000125
   • Epoch  21/100: train=0.0850, val=0.0701, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 19 Summary - Client client_73
   Epochs: 26/100 (early stopped)
   LR: 0.000125 → 0.000125 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0084
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0044
============================================================


============================================================
🔄 Round 21 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0888 (↓), lr=0.000125
   • Epoch   2/100: train=0.0811, val=0.0901, patience=1/15, lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   • Epoch   3/100: train=0.0814, val=0.0885, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0811, val=0.0885, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0810, val=0.0885, patience=4/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0810, val=0.0882, patience=3/15, lr=0.000031
   📉 Epoch 19: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0808, val=0.0880, patience=13/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 21 Summary - Client client_73
   Epochs: 23/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0046
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0260
============================================================


============================================================
🔄 Round 22 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0874 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0819, val=0.0869 (↓), lr=0.000016
   • Epoch   3/100: train=0.0817, val=0.0865, patience=1/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   ✓ Epoch   4/100: train=0.0815, val=0.0863 (↓), lr=0.000008
   • Epoch   5/100: train=0.0815, val=0.0862, patience=1/15, lr=0.000008
   • Epoch  11/100: train=0.0813, val=0.0859, patience=7/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 22 Summary - Client client_73
   Epochs: 19/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0014
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0129
============================================================


============================================================
🔄 Round 23 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0858, val=0.0712 (↓), lr=0.000002
   • Epoch   2/100: train=0.0857, val=0.0712, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0856, val=0.0712, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0856, val=0.0711, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0856, val=0.0711, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0854, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 23 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0054
   Val:   Loss=0.0712, RMSE=0.2669, R²=-0.0054
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2466, R²: -0.0088

📊 Round 23 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2465, R²: -0.0067

============================================================
🔄 Round 26 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 26 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0004
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0123
============================================================


============================================================
🔄 Round 27 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 27 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0035
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0124
============================================================


============================================================
🔄 Round 28 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 28 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0013
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0034
============================================================


============================================================
🔄 Round 30 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 30 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0026
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0033
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2464, R²: -0.0031

📊 Round 30 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2464, R²: -0.0027

📊 Round 30 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2464, R²: -0.0025

============================================================
🔄 Round 34 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 34 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0009
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0015
============================================================


============================================================
🔄 Round 35 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 35 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0013
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0042
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2464, R²: -0.0019

============================================================
🔄 Round 36 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 36 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0020
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0032
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2463, R²: -0.0012

📊 Round 36 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2463, R²: -0.0010

============================================================
🔄 Round 43 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 43 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0027
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0112
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2463, R²: -0.0006

📊 Round 43 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2463, R²: -0.0006

============================================================
🔄 Round 46 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 46 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0003
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0083
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2463, R²: -0.0004

📊 Round 46 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2463, R²: -0.0002

📊 Round 46 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2463, R²: -0.0002

📊 Round 46 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2463, R²: -0.0003

============================================================
🔄 Round 55 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 55 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0000
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0012
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2463, R²: -0.0002

📊 Round 55 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2463, R²: -0.0001

============================================================
🔄 Round 62 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 62 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0003
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0025
============================================================


============================================================
🔄 Round 63 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 63 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0002
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0043
============================================================


============================================================
🔄 Round 64 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 64 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0028
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0073
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2463, R²: 0.0001

📊 Round 64 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2463, R²: 0.0003

============================================================
🔄 Round 67 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 67 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0003
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0058
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2463, R²: 0.0002

============================================================
🔄 Round 68 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 68 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0000
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0078
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2463, R²: 0.0004

============================================================
🔄 Round 71 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 71 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0002
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0050
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2463, R²: 0.0007

============================================================
🔄 Round 77 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 77 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0011
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0003
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0009

============================================================
🔄 Round 78 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 78 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0030
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0190
============================================================


============================================================
🔄 Round 79 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 79 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0015
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0010
============================================================


============================================================
🔄 Round 80 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 80 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0000
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0061
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0009

📊 Round 80 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0009

============================================================
🔄 Round 84 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 84 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0007
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0026
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2463, R²: 0.0008

============================================================
🔄 Round 86 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 86 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0011
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0058
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2463, R²: 0.0008

============================================================
🔄 Round 88 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 88 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0009
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0010
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0009

============================================================
🔄 Round 90 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 90 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0012
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0103
============================================================


============================================================
🔄 Round 91 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 91 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0034
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0082
============================================================


============================================================
🔄 Round 92 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 92 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0010
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0060
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0012

📊 Round 92 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0012

============================================================
🔄 Round 96 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 96 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0001
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0023
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0011

============================================================
🔄 Round 97 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 97 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0004
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0008
============================================================


============================================================
🔄 Round 98 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 98 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0021
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0058
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0011

============================================================
🔄 Round 99 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 99 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0005
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0022
============================================================


============================================================
🔄 Round 100 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 100 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0001
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0028
============================================================


============================================================
🔄 Round 102 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 102 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0015
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0001
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0013

============================================================
🔄 Round 104 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 104 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0016
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0003
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0013

📊 Round 104 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0013

============================================================
🔄 Round 107 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 107 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0016
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0013
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0014

============================================================
🔄 Round 109 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 109 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0002
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0031
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2463, R²: 0.0015

============================================================
🔄 Round 111 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 111 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0010
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0007
============================================================


============================================================
🔄 Round 112 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 112 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0005
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0007
============================================================


============================================================
🔄 Round 113 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 113 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0012
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0022
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2463, R²: 0.0015

============================================================
🔄 Round 114 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 114 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0025
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0165
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0014

============================================================
🔄 Round 116 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 116 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0014
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0114
============================================================


============================================================
🔄 Round 120 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 120 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0012
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0014
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2463, R²: 0.0015

📊 Round 120 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2463, R²: 0.0015

============================================================
🔄 Round 124 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 124 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0008
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0027
============================================================


============================================================
🔄 Round 125 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 125 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0005
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0156
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2463, R²: 0.0015

📊 Round 125 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0015

============================================================
🔄 Round 130 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 130 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0018
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0078
============================================================


============================================================
🔄 Round 132 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 132 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0024
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0075
============================================================


============================================================
🔄 Round 133 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 133 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0027
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0066
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0016

============================================================
🔄 Round 136 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 136 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0007
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0040
============================================================


============================================================
🔄 Round 137 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 137 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0022
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0100
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0018

============================================================
🔄 Round 142 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 142 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0009
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0076
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

📊 Round 142 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0016

📊 Round 142 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0016

📊 Round 142 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2463, R²: 0.0015

============================================================
🔄 Round 149 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 149 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0014
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0011
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2463, R²: 0.0015

📊 Round 149 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2463, R²: 0.0014

============================================================
🔄 Round 152 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 152 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0031
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0054
============================================================


============================================================
🔄 Round 153 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 153 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0013
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0042
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2463, R²: 0.0015

📊 Round 153 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2463, R²: 0.0015

============================================================
🔄 Round 159 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 159 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0014
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0017
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0016

============================================================
🔄 Round 163 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 163 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0012
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0028
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2463, R²: 0.0015

============================================================
🔄 Round 164 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 164 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0011
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0358
============================================================


============================================================
🔄 Round 165 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 165 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0004
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0071
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0016

📊 Round 165 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

============================================================
🔄 Round 168 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 168 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0020
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0025
============================================================


============================================================
🔄 Round 171 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 171 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0009
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0038
============================================================


============================================================
🔄 Round 172 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 172 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0018
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0334
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0018

============================================================
🔄 Round 176 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 176 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0028
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0243
============================================================


============================================================
🔄 Round 177 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 177 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0019
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0461
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

============================================================
🔄 Round 178 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 178 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0007
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0096
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

📊 Round 178 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

============================================================
🔄 Round 182 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 182 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0030
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0059
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

📊 Round 182 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0016

============================================================
🔄 Round 187 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 187 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0021
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0070
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0016

============================================================
🔄 Round 188 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 188 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0028
   Val:   Loss=0.0698, RMSE=0.2642, R²=-0.0097
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0016

📊 Round 188 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0016

📊 Round 188 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

============================================================
🔄 Round 192 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 192 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0004
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0189
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

============================================================
🔄 Round 193 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 193 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0010
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0032
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

📊 Round 193 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0016

============================================================
🔄 Round 201 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 201 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0013
   Val:   Loss=0.0917, RMSE=0.3029, R²=0.0028
============================================================


============================================================
🔄 Round 203 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 203 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0013
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0057
============================================================


============================================================
🔄 Round 205 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 205 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0001
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0002
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

============================================================
🔄 Round 206 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 206 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0011
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0069
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

============================================================
🔄 Round 207 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 207 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0025
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0045
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

============================================================
🔄 Round 208 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 208 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0017
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0039
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0016

📊 Round 208 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

📊 Round 208 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2463, R²: 0.0017

❌ Client client_73 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
