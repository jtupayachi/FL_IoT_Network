[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4fcdf4a-6d14-4a20-94e1-636d96541d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f1019b-fd45-469b-8ee3-f1271b531f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8432083f-c9bc-4f28-9de4-bc9c20123560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1e20256-1411-4fbe-81f5-3dbf43820522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46feeea8-17c5-454f-bed3-0e021f8f37c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8ed93ee-5565-4345-a97f-788af9029174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab4c5413-9fd5-4f12-a546-4c8278f3ae21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91f6a3f4-5fd5-4401-bcbf-3f8b5b22eee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27d85034-a3e4-4ab1-bfa4-e1707412db93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3eb7363-f885-4add-bc53-c0e37f6e9646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c01b5782-f934-4275-9b0d-7361ad830d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c6e8844-5779-4bf7-a52b-135d7961d710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 348a5ec2-44dc-4a6d-9850-d131a143edc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a7629f-877c-44aa-8651-4ca89ef99d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2f54c97-a746-4a2d-84a8-12b0ebcda1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c33737b-2530-4061-b657-368c7c0d40ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b4871c6-ea8a-4b61-b9fa-3e6ef7f2959f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96c1f933-42c7-46c2-98bc-92db7ecf36df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b814b7e5-7040-43bb-a5ad-509f2d2e9274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7655c43-2de4-4b14-b87a-8878a067d2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1514d8f9-15ad-4ea5-af33-047089f2ae9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17cfb750-e971-4ce6-8d08-e974413b2b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed1e720-978b-4f51-9ee6-a3ad327cb41a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cec6e2a-ce78-45d5-b699-515d6be99401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5b2d0c5-a623-41b1-9121-155ddd15cb32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffe76dd8-51dc-4df9-8d7f-079ce6e620ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198ac3e2-84ba-4080-b003-21a5fb21efce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b06dce3-8383-416f-bc5e-1c006943cea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3871ae87-9a1a-40f7-896d-41bf76979e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ef59d3d-4d1d-4cde-b70b-74961404e405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d2e9c5-8fcf-4f8d-ad54-ddc1e63935da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d1fdb88-dd72-432a-872c-eac193ab19df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a945536b-6985-4030-a150-886c93fa0392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 726f8b89-7b3c-4dec-8a8d-9672a1fbd8a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f604462-b455-4f18-87cb-928b29c901a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b10da90-0d45-4deb-a959-9a976332463a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3aabb14-7433-4f4b-81a6-5af41828f604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df42aa31-cf5e-45b7-9e06-6d79846328dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56a78240-db42-4041-bc23-28291e78105c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e82cce3-4de5-436e-9d6a-7f715fbda5d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3854a718-6625-405b-bef5-6da568989eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebf47e21-b304-4021-846e-c73092123723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a58772e-6ee1-4bcf-a704-3991c63fab21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8280924a-95a3-4c61-a509-64d0cf5afbe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a893c565-063b-4d11-b3e3-a1b3f939b2e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3ace8fe-6fd9-4df9-8a81-09100118e98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18f20c31-6a4f-4547-a397-e0f0192a5592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8276f2a6-d00f-44f2-977c-bd8ddcdbab4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33dee278-4cce-49a1-bffd-fcd8e78c5fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cef725dd-d55a-4362-869f-41aa45d178a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c04d87e8-9bb6-4535-8e16-636ca84f8e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7834aef1-7be8-4d7a-8cbb-2657abb5e599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c949ff0-4569-4f3b-8586-2b6b17eb2650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52a8faed-5b39-4970-8a1f-e07ca291902a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea371a11-958f-41ff-ad10-2bcbda09d708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c7585d-0a82-45d0-bd1c-4f9fd0ff39c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40296189-03f2-47c2-8c7c-12dc8412463b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c38e8bb-23e3-4da1-a88c-d864809f7a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde9c511-51f0-473a-84b3-745fd8538513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b267898-b777-4827-a6c1-f98377d1ca32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ab2230e-c8b6-4f2d-81f0-26dce811df31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4febd87e-a5b5-437c-b4b9-f530bb5d80d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f25aff-25b5-4619-8c2c-5ed826b24e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 302fd331-b90c-41d8-9388-3abb04041fa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee364b9f-2a58-425f-904f-8b5be5d660ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bf99590-aba8-4bb2-9d28-c7f556e279d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09622d79-a584-45c7-aa50-6fd2bc488bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56568278-5894-44ce-9c09-5c3dbd865568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 571cc5fe-fd78-4c30-990d-54518dff1c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d67fb01-fd9e-40ea-83e2-685810ee685b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cbf56d3-c740-4034-a9f8-21a18fbe1c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e763a61-7545-43e8-acb4-281bb5b24591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ade41c-7002-45e8-9902-e8e0db9ca7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db6fb98-b667-4bf0-a2d5-bf1debb14b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb8effbe-ce77-4652-92ea-12c0cd634c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59ec8675-4d17-4e72-9d9a-22a22c04659c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aaea649-6d72-4a72-af35-7893d6ed7be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af923697-07ff-43b5-bf67-88dc11d90cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c216b001-0395-4bb0-bcf3-b9b08584bb97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c3f6abf-7625-49a2-a395-6f595824d6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b312fe1-d2dc-46d9-95f8-c87fb421b09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ea3b20-e8ca-4f3c-b501-ed14b5370eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f040be07-f6f0-4150-993b-e1c2d0dbc1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc7c72e3-da9c-4f72-ae4f-33d34b2b2bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e12f610f-4448-4a46-b922-3f1c1f45f54b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17264901-f477-47c3-9d1b-df08552731a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfa2ce6b-2d13-4095-8e98-1354b0d90f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a1979b4-4101-4834-977d-a06773086c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d55e00-ad7c-41f2-980e-611a022c5b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 788f9d5d-2b89-4066-a529-4a94f752f988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccc967af-d246-4ec2-8835-70c1676da6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a53351ae-4f13-4190-9e60-79e2ad186fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 524a0aeb-4e32-4d04-9ecc-37d69b0ac3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5bfa57a-d85d-43e9-9768-fdfa72937cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e338fe9a-767e-4c4b-9502-6ff3ad298337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9277854-202b-4a3b-8ae7-b6fb5c46ec55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6936191c-4f3a-44c1-9dbf-7f5614160829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 886ce6fc-a4b4-4d27-a912-936db91eecfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5182dd75-0ef8-4382-9fd9-95464ce5dd95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e75199bf-4d77-4c80-a190-eca549b9ff32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dcd83f5-d688-4ff8-b9c3-c919ee166c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe83db87-8a48-49dc-91ee-849aeb832f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57722cf7-1ea3-4e39-b980-6ae8086ae762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bdab042-d060-468c-918a-2dc37772635f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6605fc01-caf5-44d3-a0ab-b29419b22387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebfdd309-ba0f-4264-979f-c6c3c6844d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82e1f7ba-6e83-4f10-84cd-446a2289be9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e572460e-d388-42bc-8bbb-16db56f1ecfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3194d38-bf22-44c5-ab25-e9435e3503c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57559880-10ca-46b4-8e2e-91187148a9ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db00feef-a89a-4a30-b430-d70824419c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c3aefcd-d964-419e-8134-f757f91ccc76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef098127-1437-4dad-b421-7fd535358adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e710a3c-5dae-4077-9649-caefef366b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ab6b95-b8da-47c2-9919-0a257b3b6b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1942b130-c85d-4870-9606-9753ff64e1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 371e022e-7c32-4bdd-9b63-e187dd2287b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f644ff89-bdff-4d0d-b26f-60ce85539562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee88989c-6069-4c1e-a12e-689a0095ae52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aadf173d-4a60-4853-a0c4-ebc711802db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ea43d86-ea2b-4155-9ea0-f111b38802ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e87d5e2d-b91a-4784-b190-eb126708adbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 075bfdf8-5edb-4efb-aa51-5e1c9be7bb51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9263f638-8182-4297-915d-83de58139f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ee3409-3fcf-4c86-ae8c-e346c42a9c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b33ffa3e-1f6d-48d7-b07a-28340f763c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae88a1b5-764d-4f2e-aa55-9951f0339526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 346e3232-fce2-4ac2-9f33-9d81e3bac478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e78115f-269c-46ac-8f46-cd4ef00999d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0ff0235-cbd3-46f6-9cc7-239c1f2eb2f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 604fd8ba-a8d3-4555-a6a8-9e365b74a8ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7cb2df3-6602-422e-b103-632a52a8e91e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f85f566-6a35-467d-ab6b-2d632d7b8758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c8d1e8e-6405-4e3c-be90-4803bcb1cf98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76b42fb6-b05a-4214-b5ac-454528ce0036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac11386-5954-4bff-bb77-3864db73741b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a144078a-0286-43b5-89dc-f5e99c65e938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 170e212c-fd04-4f68-b292-cf6df3dc69f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 087ab0f9-f79e-43ae-af4d-0dc1d90d907a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e3331e-14a7-41cf-ac00-0d8bbac29dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0cd8427-9f48-4b4a-9959-e2dada6096a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c167c576-f009-4c04-a248-c4a7e63fc8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e20f1091-db7a-4450-8ba1-b9d93641c43c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56bdbce4-7dec-4b1c-88b4-8fb7907237d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80e6c2e0-4921-4ca2-850e-3b710144654e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03ff50a3-ab67-4578-a933-6a88108b33dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b735aa2c-9360-487d-a01b-cad5c51090a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 119ad3c5-9fe4-43e7-b982-2c47ce091a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a301d8b-273b-4364-af5c-918613f69e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ca2b46-d6d3-4283-a92a-a597ca6e4f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc127dd3-5df9-4d66-9833-84a716b8708d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c171952c-33b4-4b8b-be4a-6248488c6857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 937c8939-72ef-4465-8f55-17f15a1a3a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f54882ed-d76e-4b29-960d-83a071625652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 408d5079-0cb9-44a4-a628-c5de102f4f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9b4cc58-7185-4bad-9a01-12949a77fbb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3b334ad-de05-46b8-8a39-c728220d804e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2417b54f-615a-4178-aa4f-9f35ab1f9512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7520a4e-3835-4e99-89e6-b380dfcfb03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2f184dc-d33c-428f-ba9a-7af52276e198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6652742-1375-411e-84d6-7f3a65f49e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6b88fd-b23f-475f-8731-66c8701408c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a30066dd-97df-42b9-a294-c531f12e298b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76fa8796-f58f-4633-b356-efc50bb5c710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bd4ff6c-9697-4f91-ad67-44b86c40ee8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0aa493a-189d-43fc-a36f-e78e45765dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 844d2da2-62ae-42c8-a331-68dc9a0f565a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba4c2e6e-c5cc-4d7c-8f61-4bc046a86641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 848920fc-8532-461e-a38c-63413e9f0825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5974f2b6-744b-40e0-afce-3cd8066e19b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033654ce-1c70-4d30-a09a-dd5c45d39cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 270956d1-273b-4b56-b912-d19ceea55ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 357e9f14-3ae9-421d-b174-518871b91d5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c61cc6-79d3-40fd-8ae0-d309e46a4257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b1d7e5-a9a8-4312-850c-ae6ad4eda46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69543dd6-8a67-4c90-ac33-20c7780b66cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccaf2a2d-c5fd-415e-9f3f-4f66517b72f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40922762-b28a-47f1-b016-918a916f4035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eff7179f-39fe-4540-8797-8852a8dca32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 126e1f0b-e545-4762-a003-0acb44b01c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 316a4c32-e03a-4bdc-ba90-3903c3d71f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dce234e-c128-47b2-bef9-f284b046c1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7fddb7e-605a-4dbb-8872-3e2447a72769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 437d2e50-b9c3-401e-a734-3b80b795a770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b169a0fb-7c09-4524-bc9b-b04433c38fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e05cd54-99b4-4af4-9e69-e124011daa38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07637027-6663-4322-ac04-c403535531ad
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_74
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/test_labels.txt

📊 Raw data loaded:
   Train: X=(1660, 24), y=(1660,)
   Test:  X=(416, 24), y=(416,)

⚠️  Limiting training data: 1660 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  407 samples, 5 features
✅ Client client_74 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1827, RMSE: 0.4275, MAE: 0.3506, R²: -1.2412

============================================================
🔄 Round 9 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0980, val=0.0824 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0793, val=0.0815 (↓), lr=0.001000
   • Epoch   3/100: train=0.0792, val=0.0829, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0782, val=0.0822, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0781, val=0.0819, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0773, val=0.0819, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 9 Summary - Client client_74
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0070
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0034
============================================================


============================================================
🔄 Round 10 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1342, val=0.1138 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0871, val=0.0769 (↓), lr=0.000250
   • Epoch   3/100: train=0.0795, val=0.0774, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0788, val=0.0780, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0786, val=0.0775, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0784, val=0.0776, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 10 Summary - Client client_74
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0042
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0039
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1724, RMSE: 0.4152, MAE: 0.3399, R²: -1.1145

============================================================
🔄 Round 11 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1471, val=0.1373 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1260, val=0.1163 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1075, val=0.0991 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0931, val=0.0862 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0837, val=0.0791 (↓), lr=0.000063
   • Epoch  11/100: train=0.0794, val=0.0764, patience=5/15, lr=0.000063
   • Epoch  21/100: train=0.0792, val=0.0764, patience=6/15, lr=0.000063
   📉 Epoch 22: LR reduced 0.000063 → 0.000031
   📉 Epoch 30: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 11 Summary - Client client_74
   Epochs: 30/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0036
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0073
============================================================


============================================================
🔄 Round 12 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1456, val=0.1626 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1397, val=0.1555 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1340, val=0.1492 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1289, val=0.1435 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1242, val=0.1381 (↓), lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.1054, val=0.1172 (↓), lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.0940, val=0.1033 (↓), lr=0.000004
   📉 Epoch 24: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0902, val=0.0984, patience=1/15, lr=0.000002
   📉 Epoch 32: LR reduced 0.000002 → 0.000001
   ✓ Epoch  41/100: train=0.0887, val=0.0965 (↓), lr=0.000001
   • Epoch  51/100: train=0.0876, val=0.0949, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0865, val=0.0934 (↓), lr=0.000001
   • Epoch  71/100: train=0.0856, val=0.0920, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0847, val=0.0906 (↓), lr=0.000001
   • Epoch  91/100: train=0.0839, val=0.0894, patience=1/15, lr=0.000001

============================================================
📊 Round 12 Summary - Client client_74
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0528
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.1413
============================================================


============================================================
🔄 Round 13 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1442, val=0.1512 (↓), lr=0.000001
   • Epoch   2/100: train=0.1439, val=0.1508, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1435, val=0.1504 (↓), lr=0.000001
   • Epoch   4/100: train=0.1431, val=0.1501, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1428, val=0.1497 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1409, val=0.1479 (↓), lr=0.000001
   • Epoch  21/100: train=0.1383, val=0.1453, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1359, val=0.1429 (↓), lr=0.000001
   • Epoch  41/100: train=0.1336, val=0.1407, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1315, val=0.1385, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1294, val=0.1364 (↓), lr=0.000001
   • Epoch  71/100: train=0.1273, val=0.1344, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1253, val=0.1323, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1233, val=0.1303 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_74
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1214, RMSE=0.3485, R²=-0.5706
   Val:   Loss=0.1285, RMSE=0.3584, R²=-0.5156
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1449, RMSE: 0.3807, MAE: 0.3120, R²: -0.7774

============================================================
🔄 Round 15 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1313, val=0.1276 (↓), lr=0.000001
   • Epoch   2/100: train=0.1311, val=0.1274, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1309, val=0.1272, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1307, val=0.1270 (↓), lr=0.000001
   • Epoch   5/100: train=0.1304, val=0.1268, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1291, val=0.1256, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1270, val=0.1236, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1249, val=0.1216 (↓), lr=0.000001
   • Epoch  41/100: train=0.1228, val=0.1196, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1208, val=0.1177, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1187, val=0.1158 (↓), lr=0.000001
   • Epoch  71/100: train=0.1167, val=0.1139, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1146, val=0.1120, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1126, val=0.1101 (↓), lr=0.000001

============================================================
📊 Round 15 Summary - Client client_74
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1104, RMSE=0.3323, R²=-0.4079
   Val:   Loss=0.1084, RMSE=0.3293, R²=-0.3532
============================================================


============================================================
🔄 Round 16 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1237, val=0.1321 (↓), lr=0.000001
   • Epoch   2/100: train=0.1235, val=0.1319, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1233, val=0.1317, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1231, val=0.1315 (↓), lr=0.000001
   • Epoch   5/100: train=0.1229, val=0.1313, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1217, val=0.1302, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1197, val=0.1282, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1178, val=0.1262 (↓), lr=0.000001
   • Epoch  41/100: train=0.1158, val=0.1243, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1139, val=0.1224, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1119, val=0.1204 (↓), lr=0.000001
   • Epoch  71/100: train=0.1100, val=0.1185, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1081, val=0.1166, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1062, val=0.1147 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_74
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1046, RMSE=0.3233, R²=-0.3543
   Val:   Loss=0.1130, RMSE=0.3362, R²=-0.3259
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1191, RMSE: 0.3452, MAE: 0.2857, R²: -0.4611

============================================================
🔄 Round 18 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1074, val=0.1061 (↓), lr=0.000001
   • Epoch   2/100: train=0.1073, val=0.1059, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1071, val=0.1057, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1069, val=0.1055 (↓), lr=0.000001
   • Epoch   5/100: train=0.1067, val=0.1054, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1056, val=0.1043, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1038, val=0.1025, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1021, val=0.1008 (↓), lr=0.000001
   • Epoch  41/100: train=0.1004, val=0.0992, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0988, val=0.0975, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0972, val=0.0960, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0957, val=0.0945, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0943, val=0.0930, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0929, val=0.0917, patience=1/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_74
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3031, R²=-0.1641
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.1558
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0938, RMSE: 0.3063, MAE: 0.2608, R²: -0.1503

============================================================
🔄 Round 20 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0794, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0858, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  31/100: train=0.0849, val=0.0783, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0840, val=0.0778, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0832, val=0.0774, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0826, val=0.0770, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 20 Summary - Client client_74
   Epochs: 63/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0528
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0179
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2520, R²: -0.0414

📊 Round 20 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2511, R²: -0.0309

============================================================
🔄 Round 23 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 23 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0127
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0012
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2508, R²: -0.0272

============================================================
🔄 Round 24 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 24 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0054
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0172
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2505, R²: -0.0241

============================================================
🔄 Round 26 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 26 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0068
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0010
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2502, R²: -0.0209

============================================================
🔄 Round 27 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 27 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=-0.0016
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0265
============================================================


============================================================
🔄 Round 28 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 28 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=-0.0042
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0068
============================================================


============================================================
🔄 Round 29 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 29 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0036
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0060
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2500, R²: -0.0188

📊 Round 29 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2498, R²: -0.0173

============================================================
🔄 Round 35 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 35 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0020
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0127
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2497, R²: -0.0165

============================================================
🔄 Round 37 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 37 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0010
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0167
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2497, R²: -0.0159

============================================================
🔄 Round 38 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 38 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0056
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0004
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2496, R²: -0.0156

📊 Round 38 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2495, R²: -0.0147

============================================================
🔄 Round 43 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 43 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0011
   Val:   Loss=0.0813, RMSE=0.2850, R²=-0.0168
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2495, R²: -0.0144

============================================================
🔄 Round 45 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 45 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0016
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0039
============================================================


============================================================
🔄 Round 48 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 48 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=-0.0015
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0063
============================================================


============================================================
🔄 Round 49 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 49 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0007
   Val:   Loss=0.0701, RMSE=0.2647, R²=-0.0088
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2494, R²: -0.0137

============================================================
🔄 Round 52 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 52 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0023
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0033
============================================================


============================================================
🔄 Round 54 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 54 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0029
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0005
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2494, R²: -0.0137

============================================================
🔄 Round 55 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 55 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0012
   Val:   Loss=0.0778, RMSE=0.2788, R²=-0.0127
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2494, R²: -0.0136

============================================================
🔄 Round 57 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 57 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0023
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0002
============================================================


============================================================
🔄 Round 58 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 58 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0025
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0055
============================================================


============================================================
🔄 Round 59 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 59 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0038
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0028
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2494, R²: -0.0134

============================================================
🔄 Round 60 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 60 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0025
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0057
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2494, R²: -0.0133

📊 Round 60 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2494, R²: -0.0131

============================================================
🔄 Round 64 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 64 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0020
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0065
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2494, R²: -0.0130

📊 Round 64 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2493, R²: -0.0129

============================================================
🔄 Round 67 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 67 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0027
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0013
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2493, R²: -0.0129

============================================================
🔄 Round 69 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 69 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0028
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0036
============================================================


============================================================
🔄 Round 70 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 70 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0007
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0169
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2493, R²: -0.0125

📊 Round 70 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2493, R²: -0.0124

📊 Round 70 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2493, R²: -0.0122

📊 Round 70 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2493, R²: -0.0121

============================================================
🔄 Round 76 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 76 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=-0.0024
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0053
============================================================


============================================================
🔄 Round 77 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 77 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0010
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0163
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2492, R²: -0.0117

============================================================
🔄 Round 78 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 78 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0043
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0052
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2492, R²: -0.0118

============================================================
🔄 Round 80 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 80 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0017
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0003
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2492, R²: -0.0117

============================================================
🔄 Round 82 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 82 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0007
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0130
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2492, R²: -0.0117

============================================================
🔄 Round 85 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 85 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0015
   Val:   Loss=0.0722, RMSE=0.2688, R²=-0.0096
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2492, R²: -0.0117

============================================================
🔄 Round 86 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 86 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0034
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0067
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2492, R²: -0.0118

============================================================
🔄 Round 87 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 87 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0007
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0100
============================================================


============================================================
🔄 Round 88 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 88 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0026
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0095
============================================================


============================================================
🔄 Round 89 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 89 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0021
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0105
============================================================


============================================================
🔄 Round 90 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 90 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0001
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0109
============================================================


============================================================
🔄 Round 91 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 91 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0020
   Val:   Loss=0.0704, RMSE=0.2654, R²=-0.0029
============================================================


============================================================
🔄 Round 92 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 92 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0019
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0018
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2492, R²: -0.0112

============================================================
🔄 Round 93 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 93 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0003
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0169
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2491, R²: -0.0110

============================================================
🔄 Round 95 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 95 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0004
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0069
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2492, R²: -0.0111

📊 Round 95 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2492, R²: -0.0112

============================================================
🔄 Round 98 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 98 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0035
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0012
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2492, R²: -0.0112

============================================================
🔄 Round 99 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 99 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=-0.0014
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0016
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2491, R²: -0.0111

📊 Round 99 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2491, R²: -0.0110

============================================================
🔄 Round 103 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 103 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0023
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0037
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2491, R²: -0.0107

============================================================
🔄 Round 105 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 105 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0006
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0071
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2491, R²: -0.0107

============================================================
🔄 Round 106 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 106 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0028
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0018
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2491, R²: -0.0106

============================================================
🔄 Round 107 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 107 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0008
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0122
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0104

📊 Round 107 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0103

============================================================
🔄 Round 111 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 111 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0005
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0066
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0102

============================================================
🔄 Round 112 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 112 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0011
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0018
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0104

============================================================
🔄 Round 117 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 117 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2804, R²=-0.0002
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0129
============================================================


============================================================
🔄 Round 119 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 119 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0007
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0051
============================================================


============================================================
🔄 Round 121 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 121 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0007
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0037
============================================================


============================================================
🔄 Round 122 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 122 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0005
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0113
============================================================


============================================================
🔄 Round 123 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 123 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0019
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0074
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0103

📊 Round 123 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0101

📊 Round 123 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0101

============================================================
🔄 Round 131 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 131 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0011
   Val:   Loss=0.0702, RMSE=0.2650, R²=-0.0247
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0101

📊 Round 131 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: -0.0100

============================================================
🔄 Round 133 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 133 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=-0.0023
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0051
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: -0.0100

============================================================
🔄 Round 134 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 134 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=-0.0027
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0048
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: -0.0099

============================================================
🔄 Round 138 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 138 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0003
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0021
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0097

============================================================
🔄 Round 139 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 139 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0028
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0048
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0096

============================================================
🔄 Round 140 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 140 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0003
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0036
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0098

============================================================
🔄 Round 143 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 143 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0001
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0089
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: -0.0099

📊 Round 143 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0100

============================================================
🔄 Round 145 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 145 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0007
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0103
============================================================


============================================================
🔄 Round 146 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 146 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=-0.0004
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0019
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0101

📊 Round 146 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0100

============================================================
🔄 Round 149 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 149 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0002
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0055
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0101

============================================================
🔄 Round 151 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 151 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0005
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0151
============================================================


============================================================
🔄 Round 153 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 153 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0005
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0072
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: -0.0102

============================================================
🔄 Round 157 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 157 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0001
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0267
============================================================


============================================================
🔄 Round 158 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 158 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0002
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0077
============================================================


============================================================
🔄 Round 159 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 159 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0015
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0002
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2491, R²: -0.0100

📊 Round 159 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0099

============================================================
🔄 Round 164 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 164 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0004
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0149
============================================================


============================================================
🔄 Round 169 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 169 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0021
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0129
============================================================


============================================================
🔄 Round 170 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 170 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0007
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0079
============================================================


============================================================
🔄 Round 171 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 171 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0006
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0140
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0095

============================================================
🔄 Round 172 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 172 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=-0.0028
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0038
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0094

============================================================
🔄 Round 173 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 173 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0017
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0038
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0094

============================================================
🔄 Round 174 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 174 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=-0.0017
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0150
============================================================


============================================================
🔄 Round 177 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 177 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0005
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0479
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0095

📊 Round 177 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0096

📊 Round 177 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0095

============================================================
🔄 Round 183 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 183 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0008
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0049
============================================================


============================================================
🔄 Round 184 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 184 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0014
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0007
============================================================


============================================================
🔄 Round 185 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 185 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0003
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0082
============================================================


============================================================
🔄 Round 187 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 187 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0017
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0065
============================================================


============================================================
🔄 Round 188 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 188 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0008
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0073
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0096

============================================================
🔄 Round 189 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 189 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0001
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0037
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0094

============================================================
🔄 Round 193 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 193 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2760, R²=-0.0017
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0023
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0094

============================================================
🔄 Round 194 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 194 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0006
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0002
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0093

============================================================
🔄 Round 195 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 195 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0000
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0046
============================================================


============================================================
🔄 Round 196 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 196 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0020
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0061
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0095

============================================================
🔄 Round 197 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 197 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0008
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0068
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0096

📊 Round 197 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0096

============================================================
🔄 Round 199 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 199 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0006
   Val:   Loss=0.0705, RMSE=0.2656, R²=-0.0002
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0095

============================================================
🔄 Round 201 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 201 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0007
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0002
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0094

📊 Round 201 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0095

📊 Round 201 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0094

📊 Round 201 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0094

============================================================
🔄 Round 207 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 207 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0005
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0225
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0095

============================================================
🔄 Round 210 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 210 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0032
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0225
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2490, R²: -0.0094

❌ Client client_74 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
