[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37ba7894-c427-4aa7-8ef9-7ef85168e93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eac50a60-8c18-480b-bcc0-aceffecd1220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb38a183-d121-4968-a7bc-1ab614dc9a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87d54d56-536b-41d7-bc66-e808ed363dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 227c5dc4-2f4b-4a22-aef6-455da0f2584e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a48ab50b-7a01-467f-bc36-3ec7984c247e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c81f18-c949-4a2d-abe3-43e19dd5badd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70f91b9b-bc86-4f03-8585-b6cee133257e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ac60ba9-c708-4c45-943b-55c9fbb82c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf93b7d1-b0f3-4a7d-ad18-c40be1b342f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86562cff-f0de-4fd6-a534-0e98ba22d7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08b8658f-8d21-4b9a-bc35-2c3e50a7146d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ecbb67-484a-40d0-90c4-554b70cd9d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecec849c-895b-4339-8c77-d0f2172277c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d70b95b3-3441-4ec8-acee-98df1d90e935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece3f25d-eb2b-49b0-84c7-92865ecbad82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 296419b2-8c75-496b-b52e-cff16c24b155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee56a2dc-42e4-4b18-915d-e76ca1f7fa13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b07a95b-8fb3-4432-b98e-29fe3a70c9af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 241dea54-9b07-498b-9a2b-1f64b3c83ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71600700-5e00-4ac7-873c-42ed66038eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 884f6aab-c9bb-488d-bf12-7c798e25392b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b252297-70ba-4b79-b0fb-b4251b2abcb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42c8870c-8cf9-4daa-a799-4159761cb2e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac451bf0-6746-4942-805d-9965f1401955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52dd6ad8-b249-424d-adbe-122c2adb27a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d0d8c04-93c3-4e37-81da-a73f00e94cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3339dad2-36a5-4716-83f9-1cebfb34039b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f325ed-5fbf-4f57-b851-dbdc1d9ee6c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d8ac94a-f765-4787-9f0d-29f79e404a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ebe5cfd-52f7-4ea8-973e-407717cdcdab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08035b43-5e7e-4afd-9866-13710437edb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e35b4469-675c-4422-a2e9-6b9044d19bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 360ea523-02c5-4ac5-9fa3-c158787662f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 653cd353-e98e-4375-889a-085037a15ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f06f0051-df55-4e1f-a176-11149533781e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9043f7dd-4879-43a7-8262-c2094e80b7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e5f371a-f8a2-4c75-911a-5ab7714560df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fa44f8a-dd56-41a3-a7ad-c1db61806f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51449a9a-4168-4cb5-ac58-22424e4ff387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a641f6-2258-46a2-8605-d2cd32d54dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07d82095-ca33-4586-b6ea-3372508c68be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e82d93-675f-4da1-bd64-a010c735dbb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ba51f2-f17f-4504-ad31-917020259995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c95ca4e-23a5-4bcd-8231-9e8ae2aa4a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21b45ecf-7ab6-4635-9bbf-33b0edd4d036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d95cf6e8-b93d-4d3e-bb57-e42173f71daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23e14b45-b59f-49b5-aec7-47c8fd231da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9838ab01-42d8-4dea-94de-f8f8c029cf7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca7f6f34-e500-46ae-a12c-c57c4cb4235f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c762a700-416b-4d9a-9132-11f87d25f44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06fe67bd-d10f-4323-9094-eea8b6e23773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9966a5c-9be1-4875-bd76-cdfb1e043a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7eb7ad-664e-4d9a-95a7-12c4849e49e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6581bde3-ac2f-45ae-a64d-7a85d3953444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c89f49-2cbe-48a3-b2cd-7c67a6b3a3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f41e59f-9459-47a6-a70c-b5e5b17ef757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da4aa749-f240-43f7-81ac-2cb0c9d7db39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0214109-ac1c-4c63-a65d-844c29428318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4aaf8e3-d576-4ec6-a930-36a0502d9f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a98dc9-8ece-40d6-9324-63063f10d650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dc523eb-4f2b-404e-8a16-726a7440daee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cb87849-851e-4447-b1d3-4ab99cd72c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0132a4be-d6ef-4238-a1b8-dc24301341c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 648ab4d7-8fe8-4d72-9408-f60778ba6e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beb3f926-9363-4325-8441-66932bc9e52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d21afc1b-bbef-4031-b158-bda570e2eb03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4546ba-1215-46c6-8c8c-12014b564de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4df3367f-848f-4879-8add-f90558b570a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d80466e-32b4-4e03-b0b7-c52c69934fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67106a85-7062-4074-bfbe-d8f391ff43b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9231422-1fba-422a-a3cc-0b4edd8807e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49dc9aa-7781-4559-add4-dbece3e5bbb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90b503cd-fae1-4eaf-8f8b-02db6fc9ecdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c292ac9-6d2c-48bc-ac73-3ad7264d456d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f88e8f7-ee5a-4540-a685-c30bad89d54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 808fdc53-562d-4ed8-998a-8be3a8a2fd55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c33ffa-23ad-4f50-abd2-e5e4cb2cd563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c32926-7c0b-4e22-a712-015808cac76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3831877c-f0cf-44c0-8706-c615d9129722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cd3986d-603c-492e-be81-5c04545b8253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beca2634-0fbb-4772-90b2-92adc2feea69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4afc4a51-2903-4199-87b8-839d6aabc369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 987efa72-57a3-45d7-a058-24970e751e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e807cce-8d1e-49bf-9147-a06019e867ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 492066c4-f827-486c-bfb6-9f80818d5e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ddb2a6b-3a49-4896-a6b2-04cfebe57ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ca41e45-b995-4229-8f55-fc62d6d8358d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d1f9c25-5941-4a23-96d6-8911025673cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2d6b32d-89b4-40a0-8730-6776cfc3924c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35b5b669-587b-4457-bba6-22e1da64fea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07665012-7169-416c-9da4-c7daf2a751db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f131f3af-5ec8-4435-912f-e4c9452418b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e5140c2-4898-4930-b288-6a4303e600b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45fa93f7-675e-4c13-9ee5-9467c27e2403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d906bfd6-c7c1-4e11-8ecd-fd41d6777201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f91ac3db-9f3c-4bd8-9d03-9b6750a0c8cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee99a84b-486c-4670-b881-8bb89241d3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6fd5c5c-fa96-4bdb-ad8c-d1f34226a7e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c97e03f-4e96-4b77-8726-a03c8b27c5d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff4d860b-fa68-4626-87e2-7c428f59f7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ae07f1f-9b9d-4967-9b89-4e4c0bd169ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28991b55-4707-4a32-bdf4-68e24308feda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 694fc1f3-70d9-43f4-979a-60b887cec19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db337e71-53d9-4f58-b083-9678b4388af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b6f41d2-7b84-441a-a2d3-66a3c562174f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c88a8aac-e592-4c3d-a42d-cbfef00d348c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510c1708-35a2-4362-92e7-750bb3cbeca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91f5cecc-5e07-4428-8319-7346fd9a36a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca7529f-296c-4de0-874f-f7e555cce154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b13eb35b-d6d5-4882-a887-df05a4487e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfd61904-6563-403b-9857-2d11301848d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e587b094-7883-432c-b095-3510eff72466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb2da39-9cd9-4e22-bcfb-b79e303c92a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29f13baa-a020-4b49-b9cf-cdb9aaa323e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 484f8fd5-0f30-473d-9a5c-f277c4c65cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00eeefc-281f-4193-9c1c-d76b22dedabe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12fc0507-2163-42d1-a372-c2f84d551f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b71903d-37e9-4d37-a893-c53490f53ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab90281d-1247-4ebf-98db-064f00fab64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b47302-b742-48b7-bef8-f2eeb92feb39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ed65812-4f97-4d01-be32-c18c61955e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bb4b681-0ff4-4603-a67d-94401b0f0e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d6de2e8-e98f-448f-851c-992b8762d1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 774eacf0-7ed2-45fc-bed2-323a3bbc129e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79a6308a-ef0c-43f0-a7ef-125729baa799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 671bdbc3-0184-497d-9f16-43255f7dc0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db00d636-4abe-4939-a86e-1ed5dca31634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e9ab03a-5078-431d-a31f-1ad94e0d0e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b05a5e60-361f-4a2d-847d-f1075575e77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a42589-81a4-4bc0-b94f-b98ffcf83338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6388a2bd-a803-4a5c-90d5-ac15d04b7b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79033534-33ed-40fc-a98d-9a70295f914e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a7bca32-e166-4a1e-9e0c-a229dfea7fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16756726-87ed-4e69-a80b-b018398889e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65c41217-4dd3-45ba-910d-6f085a6bcfb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a68a7c84-9467-4b0f-9a61-148ff9840e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5ee6876-d546-4f9f-92b2-d52bb59614cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14226d3-96b4-40cf-8507-cf340282a332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e125254a-9a43-4986-a0e6-3309cdb8c2ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44ee8720-7bdd-44dd-80db-4b99ef7307a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e46e8afe-fca5-4ff0-aa6a-195963af9663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaff5a20-36a7-4ab6-bfff-57e0e7b3fa56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 918bb036-e05d-4e80-ab6a-4bb6b47eb621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6b1c494-4584-46f4-b05b-ac62cb18ed22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 344c6cbb-7d39-4d14-9622-35f524bfdddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 839855df-0506-43b2-badf-3ed60b05477b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d791f0-b06f-4f7d-a5d4-2e552bad1c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b7136de-4890-47b6-be13-3ec97de1bc2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be7f883c-2840-4e4e-a5b9-0bf18a05e28b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c9c212-40a9-4bba-acd5-f324fddfb1f9
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_75
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/test_labels.txt

📊 Raw data loaded:
   Train: X=(883, 24), y=(883,)
   Test:  X=(221, 24), y=(221,)

⚠️  Limiting training data: 883 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  212 samples, 5 features
✅ Client client_75 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1686, RMSE: 0.4106, MAE: 0.3347, R²: -1.0787

📊 Round 0 Test Metrics:
   Loss: 0.1591, RMSE: 0.3989, MAE: 0.3246, R²: -0.9614

📊 Round 0 Test Metrics:
   Loss: 0.1549, RMSE: 0.3935, MAE: 0.3200, R²: -0.9092

============================================================
🔄 Round 15 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0969, val=0.0919 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0843, val=0.0896 (↓), lr=0.001000
   • Epoch   3/100: train=0.0822, val=0.0898, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0824, val=0.0900, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0824, val=0.0901, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0814, val=0.0903, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 15 Summary - Client client_75
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0071
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0098
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1291, RMSE: 0.3594, MAE: 0.2915, R²: -0.5920

📊 Round 15 Test Metrics:
   Loss: 0.1251, RMSE: 0.3537, MAE: 0.2872, R²: -0.5427

============================================================
🔄 Round 17 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1127, val=0.0944 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0851, val=0.0876 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0831, val=0.0870 (↓), lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0871, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0828, val=0.0872, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0826, val=0.0874, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 17 Summary - Client client_75
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0041
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0104
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1107, RMSE: 0.3328, MAE: 0.2719, R²: -0.3654

============================================================
🔄 Round 18 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1109, val=0.0984 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0967, val=0.0855 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0876, val=0.0801 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0849, val=0.0794 (↓), lr=0.000063
   • Epoch   5/100: train=0.0847, val=0.0794, patience=1/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0845, val=0.0796, patience=7/15, lr=0.000031
   📉 Epoch 18: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 18 Summary - Client client_75
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0046
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0090
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0987, RMSE: 0.3142, MAE: 0.2601, R²: -0.2174

============================================================
🔄 Round 22 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0757 (↓), lr=0.000016
   • Epoch   2/100: train=0.0869, val=0.0760, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0862, val=0.0765, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0857, val=0.0769, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0854, val=0.0774, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0851, val=0.0783, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 22 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0241
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0008
============================================================


============================================================
🔄 Round 23 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0931 (↓), lr=0.000004
   • Epoch   2/100: train=0.0825, val=0.0931, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0823, val=0.0931, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0821, val=0.0931, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0820, val=0.0932, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0815, val=0.0933, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 23 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0182
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0009
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2448, R²: -0.0090

============================================================
🔄 Round 25 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 25 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0102
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0101
============================================================


============================================================
🔄 Round 26 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 26 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0066
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0073
============================================================


============================================================
🔄 Round 27 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 27 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0063
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0040
============================================================


============================================================
🔄 Round 29 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 29 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0032
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0148
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2446, R²: -0.0044

============================================================
🔄 Round 30 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 30 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0020
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0221
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2446, R²: -0.0042

============================================================
🔄 Round 31 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 31 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0021
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0149
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2446, R²: -0.0039

📊 Round 31 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2446, R²: -0.0034

============================================================
🔄 Round 35 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 35 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0101
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0084
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2446, R²: -0.0033

📊 Round 35 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2446, R²: -0.0030

============================================================
🔄 Round 38 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 38 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0035
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0014
============================================================


============================================================
🔄 Round 39 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 39 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0030
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0018
============================================================


============================================================
🔄 Round 40 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 40 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0015
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0075
============================================================


============================================================
🔄 Round 41 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 41 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0009
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0275
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2446, R²: -0.0026

============================================================
🔄 Round 44 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 44 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0011
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0153
============================================================


============================================================
🔄 Round 45 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 45 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0030
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0009
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2445, R²: -0.0024

============================================================
🔄 Round 50 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 50 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0027
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0012
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2445, R²: -0.0021

============================================================
🔄 Round 55 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 55 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0007
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0080
============================================================


============================================================
🔄 Round 56 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 56 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0035
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0028
============================================================


============================================================
🔄 Round 58 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 58 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0029
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0029
============================================================


============================================================
🔄 Round 61 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 61 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0004
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0306
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2445, R²: -0.0019

📊 Round 61 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2445, R²: -0.0019

============================================================
🔄 Round 63 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 63 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0019
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0000
============================================================


============================================================
🔄 Round 66 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 66 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0013
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0110
============================================================


============================================================
🔄 Round 68 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 68 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0042
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0087
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2445, R²: -0.0017

============================================================
🔄 Round 73 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 73 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0002
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0194
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2445, R²: -0.0015

📊 Round 73 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2445, R²: -0.0015

============================================================
🔄 Round 75 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 75 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0007
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0074
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2445, R²: -0.0014

📊 Round 75 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2445, R²: -0.0013

============================================================
🔄 Round 79 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 79 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0046
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0006
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2445, R²: -0.0013

============================================================
🔄 Round 84 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 84 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0000
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0061
============================================================


============================================================
🔄 Round 85 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 85 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0006
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0085
============================================================


============================================================
🔄 Round 86 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 86 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0060
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0180
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2445, R²: -0.0012

📊 Round 86 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2445, R²: -0.0010

============================================================
🔄 Round 94 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 94 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0003
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0056
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2445, R²: -0.0010

============================================================
🔄 Round 97 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 97 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0025
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0186
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2445, R²: -0.0010

============================================================
🔄 Round 102 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 102 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0019
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0030
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2444, R²: -0.0009

============================================================
🔄 Round 103 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 103 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0004
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0070
============================================================


============================================================
🔄 Round 105 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 105 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0005
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0177
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2444, R²: -0.0008

📊 Round 105 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2444, R²: -0.0008

============================================================
🔄 Round 108 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 108 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0034
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0326
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2444, R²: -0.0007

============================================================
🔄 Round 111 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 111 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0008
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0182
============================================================


============================================================
🔄 Round 113 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 113 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0029
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0041
============================================================


============================================================
🔄 Round 114 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 114 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0008
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0059
============================================================


============================================================
🔄 Round 115 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 115 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0006
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0007
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2444, R²: -0.0006

📊 Round 115 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2444, R²: -0.0006

============================================================
🔄 Round 122 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 122 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0011
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0049
============================================================


============================================================
🔄 Round 123 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 123 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0004
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0039
============================================================


============================================================
🔄 Round 125 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 125 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0000
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0012
============================================================


============================================================
🔄 Round 126 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 126 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0004
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0229
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2444, R²: -0.0005

📊 Round 126 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2444, R²: -0.0005

============================================================
🔄 Round 129 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0988, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0988, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0988, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 129 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0005
   Val:   Loss=0.0988, RMSE=0.3144, R²=-0.0019
============================================================


============================================================
🔄 Round 130 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 130 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0028
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0261
============================================================


============================================================
🔄 Round 131 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 131 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0001
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0057
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2444, R²: -0.0005

============================================================
🔄 Round 132 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 132 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0008
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0014
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2444, R²: -0.0005

📊 Round 132 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2444, R²: -0.0005

============================================================
🔄 Round 134 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 134 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0005
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0058
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2444, R²: -0.0005

📊 Round 134 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2444, R²: -0.0004

============================================================
🔄 Round 139 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 139 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0031
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0131
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2444, R²: -0.0004

============================================================
🔄 Round 142 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 142 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0008
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0012
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2444, R²: -0.0004

============================================================
🔄 Round 144 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 144 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0028
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0044
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2444, R²: -0.0004

📊 Round 144 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2444, R²: -0.0004

============================================================
🔄 Round 146 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 146 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0035
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0103
============================================================


============================================================
🔄 Round 147 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 147 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0009
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0034
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2444, R²: -0.0004

============================================================
🔄 Round 148 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 148 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0070
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0323
============================================================


============================================================
🔄 Round 150 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 150 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0035
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0082
============================================================


============================================================
🔄 Round 152 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 152 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0001
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0065
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2444, R²: -0.0004

============================================================
🔄 Round 155 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 155 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0017
   Val:   Loss=0.0937, RMSE=0.3060, R²=-0.0064
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2444, R²: -0.0003

============================================================
🔄 Round 156 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 156 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0002
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0013
============================================================


============================================================
🔄 Round 157 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 157 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0002
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0057
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2444, R²: -0.0003

📊 Round 157 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0003

============================================================
🔄 Round 161 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 161 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0007
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0002
============================================================


============================================================
🔄 Round 163 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 163 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0023
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0072
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0003

============================================================
🔄 Round 165 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 165 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0001
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0001
============================================================


============================================================
🔄 Round 168 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 168 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0022
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0011
============================================================


============================================================
🔄 Round 169 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 169 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0027
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0114
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0001

📊 Round 169 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0001

============================================================
🔄 Round 172 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 172 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0001
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0005
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0001

============================================================
🔄 Round 175 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 175 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0017
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0049
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0001

📊 Round 175 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0001

📊 Round 175 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0001

============================================================
🔄 Round 180 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 180 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0032
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0005
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0001

============================================================
🔄 Round 181 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 181 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0030
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0151
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0000

📊 Round 181 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0000

📊 Round 181 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0001

============================================================
🔄 Round 187 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 187 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0024
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0138
============================================================


============================================================
🔄 Round 188 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 188 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0033
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0158
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: -0.0000

============================================================
🔄 Round 190 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 190 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0017
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0055
============================================================


============================================================
🔄 Round 193 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 193 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0014
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0067
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: 0.0000

📊 Round 193 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: 0.0000

📊 Round 193 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: 0.0000

============================================================
🔄 Round 200 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 200 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0037
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0113
============================================================


============================================================
🔄 Round 201 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 201 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0014
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0071
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: 0.0001

============================================================
🔄 Round 202 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 202 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0040
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0159
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: 0.0001

📊 Round 202 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: 0.0001

============================================================
🔄 Round 205 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 205 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0025
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0085
============================================================


============================================================
🔄 Round 206 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 206 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0003
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0064
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2444, R²: 0.0001

============================================================
🔄 Round 210 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 210 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0010
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0080
============================================================


❌ Client client_75 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
