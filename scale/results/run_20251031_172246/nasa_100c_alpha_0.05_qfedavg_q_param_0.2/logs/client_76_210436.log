[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16183cfe-a25e-4494-8f09-55b9b878d992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e345b309-9837-49ad-84d0-867363bc52eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2bca35f-c56f-4065-944c-1578b73c750c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55e1878f-ad8e-4b50-be8a-b77d16e54866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f2c261-65fa-49f6-92cb-f0c76faa9554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e3646d3-ef0b-4631-abb3-37f1ff7a40a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79b757e-03cf-4c87-881f-bd19accbd8cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b21b67f-95c3-4615-b236-88b7b5d6e453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad67c079-cbfb-4209-91fc-b807213765d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c76b3572-bf98-45e3-8141-04783d8bd2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf78ca79-6021-4309-b747-85100eaff414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 033cc515-7450-4c17-b2e4-5cefd6099bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d5b7e78-518e-4ba2-965d-9cea09dbe852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8efdaa0-9d2b-4051-975c-3fd5f174ba01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3415b076-a349-43b9-9241-59be730e2f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26dbfdc0-51b4-485b-a991-86098133b2c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30996058-d6be-43da-bb82-977ea915ffe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8806f8a-541a-4095-a46b-981d435640b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46a6ebd0-0f7e-420f-9bc7-471332bd3412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df702c33-b6f6-4e8c-bee4-ca051bfaf422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 675d276e-0fdc-4877-8792-629ad1515d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b465be-65bb-4c05-97b9-2c7bbaf0406c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0961e548-c1ee-46f7-bc5c-5070b0d919bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a45f58ba-cfc6-420d-a706-77357abaa371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d63aeaf4-afa7-4699-a521-7f7ac0a3f7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04a8dc9e-0a2f-46e9-95b6-4bc2b1c584e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35769056-7c5a-4399-8137-f467a42708d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28c42855-b257-4f6a-9cfc-d51ac0c8140d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1153ec29-88e1-45e9-8a2b-60614b8cd3f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20083306-6adf-433b-be74-fc149a53ae5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8834f834-6a4c-48b1-9671-dac375632788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98de687d-1af9-496a-a08d-61923c710fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db50d522-21e7-45f3-852c-89b3148dbb98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42a3c661-137b-4d43-82be-07063021b679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d7b6140-cbb1-41bf-9e2c-35622eca3319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de2b33b-e149-4068-9587-00aa85b282ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c2fe2b7-c3b1-4c02-90d2-0ded8fcefe39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ee56f7-dfc6-4932-84da-55cab89b287e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eb40357-cfea-4617-81fa-b4f498f50743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7b1bf83-4f99-4968-9344-9f8139b8fcf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d5d5afc-47fd-4658-bde1-0af0f2e73e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 333ca2ad-4a00-468e-a416-eb6751fc6cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3e38f6-2bcb-4d3c-9975-8399a47741a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 358a7cdb-ef57-4bfa-bc72-53761bae6204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5222969-4ceb-4813-92a9-0d76eef1ccc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd224312-1351-4e20-a331-6c6b16052efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6865874-5614-4802-9477-226a39aa3f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e5d9624-b38e-4fe3-b910-95bf35023c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7aa0702-233c-495e-9e32-12703212b094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64baeb34-6b1c-4cb8-8fdd-b3053737f300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb856f42-5f1f-4bbd-b80d-51d0cf7a47b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 963a1abf-85fb-4c1b-80d8-261f665dd5d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a304c93-d65e-4f6e-a65c-3f12604ceceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e00cd66c-b883-4160-9bca-9cd7c155d77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b3f3860-a201-4470-b830-13f6d7a847d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e401aac-3d47-46d5-aa45-faabe60b102e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ca3f3a2-e7db-4410-ac85-23ae16ea3401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5bad9cd-8d2c-4732-82fd-793e9da5be1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed65f825-e96d-4af4-98d6-810382aa7cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc4eb74f-f2b1-445e-b037-fc25231510be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1132a479-99b7-4f95-8887-167590ef702b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 474c3aba-5121-4d80-81c9-c579f2e477f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46dde58e-8242-4fba-8a72-6bd5ccc9404a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff114d59-f22b-4894-8ce9-59b49e217e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e7a2ea6-e7d0-400c-adab-43e3cef27216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab2ad94-3865-47a6-a958-b927cc00b13d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4e1886-761f-48e7-86cf-342f96103759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dedba41b-5720-48d0-80cc-22a2e4953894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01a9ef2c-f610-4cb6-adc7-cd95df7cb95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1e106c9-78f7-4b52-8f51-57c6999788a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b3f4d3-ea25-4e2f-bba3-cd74cdb477a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c915ffb-bd16-4a93-a411-112b47e96194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cedf0eb-5c82-47ea-af43-9756b92c7ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90f057f3-1a53-469d-a73e-7337bc828fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4d1a58-4c31-4053-9e80-a4692d116940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a66c9cfa-0b70-4825-8fa5-bfbdbcd104ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49aae7c7-ee6a-4dfa-97f3-f6d2ec76abf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e46c5e4-03ad-4018-ae54-beecd1272ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600cf4a0-e064-43a2-b14f-64306eaebd04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a59e9d0-9ef4-4402-9ed9-da3bd8a5e6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ec1ec1d-3990-4c48-a637-917b4ba17c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8db68c3-6d61-4f8f-8e60-e96d4f3ffbf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e08134f8-39e5-43ed-b0d2-93d23e7113ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4de81e6c-1d63-4e97-a6b6-086e0ebb7d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26b93924-1352-4816-afb0-d7bc8d37307c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c548c9d3-f7c5-4d2d-ace4-1e97efe1ad81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26e8e629-e81b-428e-b15d-2e74464a488f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bac430d-c1ed-40cd-a5cf-59646564b636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25d9955c-ad33-4131-a9dd-7ea3034fb4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b12ff97-93a7-4c14-8ab5-e3f9e71400e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6719f2d7-08c3-4191-8195-dfacf7eeb073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76eac8bb-8ac5-4f61-8df6-352331893583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0463804e-d720-4adc-adaf-746b2ce56f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53c5ff2c-24de-4c45-8cfa-7d00f430b79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b542a35b-5d31-4574-82c6-b27a7dcec893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d1a443-9b45-4e39-8d8d-7ba1f5a5d34b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f7ffca1-b076-4e9e-a069-0ca014a10915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9f30aee-ecbe-4e6e-a54f-591d41e9080c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e82b82-b585-4d1b-9680-cbd22d44a1ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7088eb4-37b3-4b30-8766-37fbf062a935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71098749-f4d2-418c-91ad-b5c909eca161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 647ccfc1-4bae-468c-91a7-86ffc1e5d169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc112077-b9ee-4012-87c9-56ea1dd279c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7659383-5f55-470f-9dc1-32935fc40704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58bb926f-db96-48e4-b835-d9d44384aec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1bd38d8-f4ff-45db-8d61-7bdaf29a1adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdb50935-6900-4aa4-8d23-960219933e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb259ac1-3725-41ee-8cf1-31e93992ee06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24764b8c-60a0-4730-8e04-69f64c89ab93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cf2ffa4-314b-47e5-9c8d-9267f4631f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9081c53a-c48d-4b5b-a3bd-a1a277b75957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79358765-ea75-4f2c-ab01-9cfa5ff948fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51b7abea-9d04-425f-b220-6399fedb6e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 301b801d-98bc-472b-8b65-5e93b1425910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9296d03f-3155-4a44-aba5-7ab7e9906a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8030c6f0-c497-4c27-8f82-64c06ad8f03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 700efd04-1552-4719-a9e3-4574f1426deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db08c6b2-632d-4f59-a30d-450d5e1e3971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 640600e0-61bc-4347-a4ae-b9412aadc229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31c27d0-3e32-41d9-865f-2884f280c35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b93f0e2-3006-48ff-bb4f-f6e16c6e4cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af1fa9a8-955e-46e1-8492-ff1a0b2dc410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2b625cd-2a5f-4ade-adc4-c4552b7d8de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b930bed4-c2b5-4a2d-8781-24a8919de1e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8c1b0ed-9868-4f72-86e7-dd6da51b48dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82179d3a-b5e9-4dba-9cec-f68d32feafef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f655d5ce-9f8f-4d09-bcc2-8d81eca682a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe34fbfc-b694-4e4e-b8cd-f92475c32e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bdd2d93-a51d-4f58-b1ba-c1a185aa7ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e71897a5-acac-4b81-abf7-29f9f5b54c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 125f8779-22ff-449e-86c6-118d0ac6c8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5225d3b-6818-4685-a302-f41925da2b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69cfb0ba-f1b6-425b-a367-cfcdc3107aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4946d415-1898-47ec-be3d-cf6cbf0ef107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3220955-c0e0-40ee-8550-eb603012da00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5dea276-340b-408c-a233-f017a68be5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 302d6b14-5019-4bed-8489-c731f0f1146f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed0504e2-d0e9-4615-a046-851ec45f1712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 675eb1c2-1ff8-4ccd-9c62-700cbfd6aa07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32d00068-633f-4e66-96fb-a2c34d565c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4478e4c-72af-4e4f-a558-a2df3df91bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a77ccb01-a88b-42c5-8bb0-acc4ab9d56de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea614ce1-ee99-48eb-8db3-1e7a0aab1f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b26266-f7fc-490d-bce2-d0ef8014df7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f5a397-9439-4c4c-ad7a-7d71bc0037ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4991ae7-fe96-4d5a-b9cf-8c546f1e1055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a82c4f8-1c24-4a51-b223-37f8055ed8a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf409e16-8edd-490a-bf67-973091f5b513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb639af3-1484-49eb-8fdc-8fa52f582a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d449fa7c-82fe-4c80-8aae-b4be177cfb6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82515cbb-7f41-46f0-b486-3e323cd17954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5c3395f-ffc7-4eb6-80c3-79a7fa19d2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50851e57-d8bb-46c5-8409-a367e958d953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fab2f83-6ce5-4c19-bd0a-cfd686fc0176
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_76
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/test_labels.txt

📊 Raw data loaded:
   Train: X=(608, 24), y=(608,)
   Test:  X=(152, 24), y=(152,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 599 samples, 5 features
   Test:  143 samples, 5 features
✅ Client client_76 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 9 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1182, val=0.1102 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0865, val=0.0821 (↓), lr=0.001000
   • Epoch   3/100: train=0.0845, val=0.0852, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0825, val=0.0826, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0827, val=0.0828, patience=3/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0797, val=0.0795 (↓), lr=0.001000
   • Epoch  21/100: train=0.0681, val=0.0735, patience=1/15, lr=0.001000
   • Epoch  31/100: train=0.0554, val=0.0690, patience=1/15, lr=0.001000
   📉 Epoch 37: LR reduced 0.001000 → 0.000500
   • Epoch  41/100: train=0.0428, val=0.0738, patience=11/15, lr=0.000500
   📉 Epoch 45: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 9 Summary - Client client_76
   Epochs: 45/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0540, RMSE=0.2324, R²=0.3486
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.1664
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1533, RMSE: 0.3915, MAE: 0.3175, R²: -0.7936

============================================================
🔄 Round 10 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1542, val=0.1156 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1034, val=0.0841 (↓), lr=0.000250
   • Epoch   3/100: train=0.0835, val=0.0885, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0847, val=0.0840, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0834, val=0.0837, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0827, val=0.0839, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 10 Summary - Client client_76
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0357
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0077
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1398, RMSE: 0.3739, MAE: 0.3031, R²: -0.6359

============================================================
🔄 Round 13 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1468, val=0.1563 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1314, val=0.1382 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1159, val=0.1226 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.1030, val=0.1098 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0932, val=0.1003 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0820, val=0.0905, patience=1/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0818, val=0.0901, patience=1/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008
   📉 Epoch 31: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0817, val=0.0900, patience=11/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 13 Summary - Client client_76
   Epochs: 35/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0017
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0079
============================================================


============================================================
🔄 Round 14 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1465, val=0.1591 (↓), lr=0.000004
   ✓ Epoch   2/100: train=0.1455, val=0.1578 (↓), lr=0.000004
   ✓ Epoch   3/100: train=0.1443, val=0.1564 (↓), lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   ✓ Epoch   4/100: train=0.1431, val=0.1550 (↓), lr=0.000002
   ✓ Epoch   5/100: train=0.1422, val=0.1544 (↓), lr=0.000002
   ✓ Epoch  11/100: train=0.1392, val=0.1510 (↓), lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.1367, val=0.1482, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1347, val=0.1460 (↓), lr=0.000001
   • Epoch  41/100: train=0.1329, val=0.1439, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1312, val=0.1419, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1296, val=0.1400 (↓), lr=0.000001
   • Epoch  71/100: train=0.1280, val=0.1381, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1264, val=0.1363, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1249, val=0.1345 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_76
   Epochs: 100/100
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.1234, RMSE=0.3513, R²=-0.4575
   Val:   Loss=0.1329, RMSE=0.3645, R²=-0.7165
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1261, RMSE: 0.3551, MAE: 0.2877, R²: -0.4756

📊 Round 14 Test Metrics:
   Loss: 0.1219, RMSE: 0.3492, MAE: 0.2830, R²: -0.4268

============================================================
🔄 Round 18 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1185, val=0.1020 (↓), lr=0.000001
   • Epoch   2/100: train=0.1183, val=0.1019, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1182, val=0.1017, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1180, val=0.1016, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1178, val=0.1014 (↓), lr=0.000001
   • Epoch  11/100: train=0.1168, val=0.1006, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1152, val=0.0993 (↓), lr=0.000001
   • Epoch  31/100: train=0.1136, val=0.0980, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.1121, val=0.0968, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.1106, val=0.0956, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.1091, val=0.0944, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.1077, val=0.0933, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.1063, val=0.0922, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.1050, val=0.0912, patience=3/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_76
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1037, RMSE=0.3220, R²=-0.2284
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.1442
============================================================


============================================================
🔄 Round 19 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1019, val=0.1061 (↓), lr=0.000001
   • Epoch   2/100: train=0.1018, val=0.1060, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1017, val=0.1059, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1015, val=0.1058, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.1014, val=0.1057, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.1007, val=0.1050 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.0994, val=0.1039 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.0982, val=0.1029 (↓), lr=0.000001
   • Epoch  41/100: train=0.0971, val=0.1019, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0960, val=0.1009, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0949, val=0.1000, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0938, val=0.0991, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0928, val=0.0983, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0918, val=0.0975, patience=6/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_76
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3016, R²=-0.1149
   Val:   Loss=0.0968, RMSE=0.3112, R²=-0.0662
============================================================


============================================================
🔄 Round 20 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0931, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0930, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0929, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0928, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0927, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0921, val=0.0905, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0912, val=0.0899, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0903, val=0.0893, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0895, val=0.0889, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0888, val=0.0884 (↓), lr=0.000001
   • Epoch  61/100: train=0.0880, val=0.0880, patience=10/15, lr=0.000001
   • Epoch  71/100: train=0.0874, val=0.0877, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 20 Summary - Client client_76
   Epochs: 80/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0610
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0245
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2479, R²: -0.0039

============================================================
🔄 Round 21 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0828, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0869, val=0.0823, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0866, val=0.0820, patience=5/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0863, val=0.0816 (↓), lr=0.000001
   • Epoch  51/100: train=0.0861, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 21 Summary - Client client_76
   Epochs: 56/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0219
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0272
============================================================


============================================================
🔄 Round 22 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 22 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0288
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0109
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2487, R²: 0.0022

📊 Round 22 Test Metrics:
   Loss: 0.0853, RMSE: 0.2920, MAE: 0.2488, R²: 0.0022

============================================================
🔄 Round 24 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 24 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0086
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0595
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2493, R²: 0.0016

============================================================
🔄 Round 28 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 28 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0096
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0164
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2494, R²: 0.0014

============================================================
🔄 Round 29 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 29 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0067
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0326
============================================================


============================================================
🔄 Round 30 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 30 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0059
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0309
============================================================


============================================================
🔄 Round 31 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 31 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0062
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0254
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2496, R²: 0.0009

📊 Round 31 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2496, R²: 0.0008

📊 Round 31 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2497, R²: 0.0006

============================================================
🔄 Round 36 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 36 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0079
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0100
============================================================


============================================================
🔄 Round 39 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 39 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0083
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0081
============================================================


============================================================
🔄 Round 40 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 40 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0054
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0209
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2499, R²: 0.0001

============================================================
🔄 Round 41 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 41 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0094
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0011
============================================================


============================================================
🔄 Round 42 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 42 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0090
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0013
============================================================


============================================================
🔄 Round 45 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 45 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0083
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0042
============================================================


============================================================
🔄 Round 50 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 50 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0054
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0121
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2500, R²: -0.0004

============================================================
🔄 Round 51 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 51 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0052
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0120
============================================================


============================================================
🔄 Round 52 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 52 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0097
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0011
============================================================


============================================================
🔄 Round 58 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 58 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0075
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0017
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2501, R²: -0.0005

📊 Round 58 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2501, R²: -0.0006

📊 Round 58 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2501, R²: -0.0006

============================================================
🔄 Round 68 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 68 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0122
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0070
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2501, R²: -0.0008

============================================================
🔄 Round 69 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 69 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0070
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0014
============================================================


============================================================
🔄 Round 71 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 71 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0065
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0018
============================================================


============================================================
🔄 Round 73 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 73 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0055
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0207
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2502, R²: -0.0011

📊 Round 73 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2503, R²: -0.0012

============================================================
🔄 Round 75 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 75 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0051
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0090
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2503, R²: -0.0012

============================================================
🔄 Round 76 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 76 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0093
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0028
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2503, R²: -0.0013

📊 Round 76 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2503, R²: -0.0014

============================================================
🔄 Round 81 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 81 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0110
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0026
============================================================


============================================================
🔄 Round 83 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 83 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0040
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0122
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2503, R²: -0.0015

📊 Round 83 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2503, R²: -0.0014

============================================================
🔄 Round 86 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 86 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0072
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0016
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2503, R²: -0.0014

============================================================
🔄 Round 89 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 89 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0014
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0555
============================================================


============================================================
🔄 Round 91 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 91 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0046
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0072
============================================================


============================================================
🔄 Round 92 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 92 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0048
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0062
============================================================


============================================================
🔄 Round 94 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 94 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0046
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0063
============================================================


============================================================
🔄 Round 95 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 95 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0025
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0268
============================================================


============================================================
🔄 Round 96 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 96 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0059
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0014
============================================================


============================================================
🔄 Round 98 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 98 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0044
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0086
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2504, R²: -0.0018

============================================================
🔄 Round 100 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 100 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0059
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0009
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2505, R²: -0.0020

📊 Round 100 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2505, R²: -0.0021

📊 Round 100 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2505, R²: -0.0020

============================================================
🔄 Round 107 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 107 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0010
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0502
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2505, R²: -0.0021

📊 Round 107 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2505, R²: -0.0022

============================================================
🔄 Round 111 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 111 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0040
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0196
============================================================


============================================================
🔄 Round 113 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 113 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0078
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0020
============================================================


============================================================
🔄 Round 115 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 115 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0052
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0056
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2505, R²: -0.0022

============================================================
🔄 Round 116 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 116 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0041
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0072
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2505, R²: -0.0023

============================================================
🔄 Round 117 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0995 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0995, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0995, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0995, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0995, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0994, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 117 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0049
   Val:   Loss=0.0995, RMSE=0.3154, R²=-0.0031
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2505, R²: -0.0022

📊 Round 117 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2505, R²: -0.0022

============================================================
🔄 Round 119 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 119 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0048
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0038
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2505, R²: -0.0023

📊 Round 119 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0025

============================================================
🔄 Round 129 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 129 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0061
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0001
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0025

============================================================
🔄 Round 132 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 132 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0008
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0332
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0026

============================================================
🔄 Round 135 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 135 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0020
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0218
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0027

============================================================
🔄 Round 138 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 138 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0051
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0048
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2507, R²: -0.0028

📊 Round 138 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2507, R²: -0.0028

============================================================
🔄 Round 141 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 141 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0024
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0105
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0027

📊 Round 141 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0026

📊 Round 141 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0025

============================================================
🔄 Round 147 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 147 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0041
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0040
============================================================


============================================================
🔄 Round 148 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 148 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0044
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0092
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0025

📊 Round 148 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0025

📊 Round 148 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0024

============================================================
🔄 Round 152 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 152 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0056
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0003
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0025

📊 Round 152 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0024

============================================================
🔄 Round 154 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 154 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0048
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0038
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0025

📊 Round 154 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0026

📊 Round 154 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0025

============================================================
🔄 Round 158 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 158 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0037
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0073
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0027

📊 Round 158 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0026

📊 Round 158 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0027

📊 Round 158 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2506, R²: -0.0028

📊 Round 158 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2507, R²: -0.0029

============================================================
🔄 Round 169 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 169 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0041
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0027
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0029

📊 Round 169 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0030

============================================================
🔄 Round 173 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 173 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0016
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0355
============================================================


============================================================
🔄 Round 175 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 175 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0026
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0249
============================================================


============================================================
🔄 Round 176 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 176 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0072
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0050
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2507, R²: -0.0029

📊 Round 176 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0030

============================================================
🔄 Round 179 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 179 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0009
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0248
============================================================


============================================================
🔄 Round 180 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 180 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0062
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0056
============================================================


============================================================
🔄 Round 181 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 181 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0036
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0041
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0030

📊 Round 181 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0031

📊 Round 181 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0029

============================================================
🔄 Round 184 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 184 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0033
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0067
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0030

📊 Round 184 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2507, R²: -0.0029

📊 Round 184 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2507, R²: -0.0029

📊 Round 184 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0030

============================================================
🔄 Round 190 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 190 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0034
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0047
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0030

📊 Round 190 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0031

============================================================
🔄 Round 194 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 194 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0013
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0168
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0030

============================================================
🔄 Round 197 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 197 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0070
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0020
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2507, R²: -0.0029

============================================================
🔄 Round 200 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 200 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0007
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0508
============================================================


============================================================
🔄 Round 201 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 201 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0060
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0019
============================================================


============================================================
🔄 Round 202 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 202 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0048
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0005
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0031

============================================================
🔄 Round 203 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 203 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0050
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0020
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0030

📊 Round 203 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0031

============================================================
🔄 Round 207 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 207 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0058
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0017
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2507, R²: -0.0031

============================================================
🔄 Round 209 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 209 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0022
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0201
============================================================


============================================================
🔄 Round 211 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 211 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0050
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0060
============================================================


❌ Client client_76 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
