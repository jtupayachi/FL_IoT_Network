[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99784478-676c-4978-98d9-ed74d2f5fa35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86e41171-6700-4229-9937-3ea323885377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6970c1a4-0e34-4293-9222-2b39447041e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d805b981-dd21-43af-bece-9107b1972d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0074042b-323d-45ef-924d-6c68c5d03ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a70e684-3a8a-4f92-a567-9daa45512213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e84b7e82-8b87-4d42-a7c0-acf253500526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d1a3d3c-a93d-4b6c-b20f-3045aa20e7a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 571bf681-6673-4969-9a20-a6479841dc30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8ccbf10-b30e-4a8f-b0bf-ab88bf24ee36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b4e3290-a3a0-4603-b338-126dc6a74f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7d4e698-55a2-4d7b-8e0f-63fe0f61b2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14d91c2-a2f7-4d86-bab7-44afab2b4726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ccce8fc-517b-41c7-bdfb-4e34281989f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf908195-85e9-4487-bda8-0dd3faf7325c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab183ec9-6b27-462c-b899-e6b107c2ff1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c23fbe29-4878-4473-aee1-f11e91b9a585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5af1e9d2-41cf-43e5-ab0b-999260b992b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878ae698-60a2-4a1f-8a33-6809214ff8c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b533b85-bf6d-44bd-b36f-f4265cfd87ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e53356-5ac1-4933-bff6-ec8a91bc2455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17bdf451-7371-4c08-84ea-de12cd38589a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e3f4a93-6cd9-4c41-903f-aa6ca6250ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21f3c1a8-4bf9-4d40-9fcc-5640e80a399c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da52822f-2dca-4bb8-99ff-c5005cd6b03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c01ec05b-e0af-4988-af7d-22e68df8be20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae256356-948b-4097-bbcf-e8e849b2bb6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f3ccb79-d8d5-410d-949c-b8d088de4588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72b48ad7-7341-4c31-9190-8d569c51da9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad03968-dac8-4273-8da7-c4e133039cea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d19ac277-aa27-4aeb-a531-4802dfe03442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20157573-003f-4206-88f2-3a91b30cd1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ba5fd6-c307-4fbe-b909-ac5fabd1abd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb87f9c-9662-4e01-b7b7-23b86128a3a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c0c89a1-f0f0-4ec9-9e1d-5326fa70069e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fa2fb8f-51d2-48b1-9113-bf790007cc10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf17e0c-f731-4ef8-8398-1acae62f9eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f5c687e-bb2c-48e4-909e-0e39afefae92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04f489b1-aed0-41d6-8619-73962fadab78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24cad8c3-fec0-4fa6-b41e-899251c9335d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933e2567-b4fa-4bb4-8f9f-29ae0981aaf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c43738f6-3b5f-406f-b3ae-5caed2a88f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0602ecc8-366a-4f11-b05d-e9162d6f6b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d348ab2-1d1f-49cb-91d4-dbaa499739aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb01138d-4cf5-46a9-9359-4ab216cae914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 005d93d0-24ad-4e99-974d-546fdb769947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aeed70d-7598-459c-b8fa-eeccf804a873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1cddf15-14dc-4030-8c06-579dbad625bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a4e8eca-00be-454b-8211-a1706bcc7c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 148ff71c-041f-4062-9c37-f44ad9b028dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3c442bd-c32c-4ce4-99ab-b99e3cf502ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b0a0558-ccce-4023-9886-bff2a62b0275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d02b30a-a48b-4f55-8e82-738088d9dc5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4e10ee7-eb0a-47f5-947b-6a772ccba939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bac9193-5c45-4397-a253-1d4d687f1ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c95c2da3-ac13-493b-a58c-5cdfd17d9eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd36a43e-e039-4550-be6b-a9c8ee626360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c77875b2-9f9d-43f5-8187-0d463c0f3d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbd5af14-d450-4e41-a373-f65ed1b873d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 211e2aef-aa0d-4a0b-b979-8dcc08eba581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f3a065-ab24-4d5a-b80e-d3b0041cdf96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8c49376-4896-40c0-93f3-2293a170efca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc926213-413b-4619-936d-1913d3857c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af86a3d4-9473-420e-94d0-b1c0ee0d330f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1736636-353b-4d50-9fef-cd86bb79dce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b305102-4619-41fc-8f35-6fe205422618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51e2efc0-9b7a-471c-a2df-c1042836664c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d896d65-c135-48ce-9c3a-7cace6d55d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58ea2486-c4f7-40d0-b572-c569ca672c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bb2282d-8cc8-479d-85a4-cc573d1b4323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71d83e4b-c584-4c50-9fdf-69ddd6f631e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2846d2d8-617c-40e5-94e6-345b174c1509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ddd7acd-1453-4322-9f5d-15b24c8e5b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a3b97c-46c7-4490-8b2f-5f20af83a374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2753bba4-0df9-4e1f-8981-bafcebe8c42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5373490b-306a-43e3-8389-c71103718bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b025364e-0a71-496c-9733-dfca210f2b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad9ee33-5b9c-461a-ba33-9329d77ee4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 300550fd-bb27-4d01-9ebc-2c84d7aa4922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77d5c169-9b7c-4245-b970-9c11dd225e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7961dc65-d604-46fd-92d3-b7ce72949d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b62e78d8-d702-4087-a714-37d6321d826a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3c211a6-8aea-47a8-a91d-0314bedba05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 331bd401-3f34-442d-bf88-322de40f796e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6020b440-1f73-4ebe-b9ad-6ef03f42e440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18b00498-e08e-41b3-9582-3d4e74a42c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec6d442-a173-4329-a1bb-18c919c84038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c16d797d-ff2e-4a26-8c54-c6eb83071615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20151dc7-084a-40ca-b4ad-3e0f169afe9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e4f9174-30ac-40b5-aab9-5743824c4e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8b7d576-42c7-42a0-9bfa-99d74b35c6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab46e2a2-8545-44b0-b4e4-6cbbedab5d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3985d22-6dc7-4f2f-a34e-4f15cd964849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5816a9b3-8478-4845-b4fa-4411fa571d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3292f0f-fb2b-43ad-86e7-ccccd5200b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94698c60-bb09-418c-a1b9-8249845fce1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d5b6099-65ba-4f5a-b085-90bbd1dbeb98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 051a9b25-a6de-42a8-9a07-61c0c6a2d097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1245d66-578b-4976-8e3f-c906c53e3627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89712ef4-cd22-4f46-bfc6-254ebcf4ef95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e4279d-c860-4f49-a77f-b9d811744ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16c1596d-7d85-4073-b52a-1cd85a5a444b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ccfe40-a75e-4f79-a1e5-40a33ad9cf0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 686dfe48-a4d6-43f1-a9b4-737e89a60b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b67a3ee-a7ac-48b4-a2e0-b1f42233b298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de812d2a-05d6-4dbb-9b05-d716c1cb490b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71bdb14d-157d-42da-bb02-c4ae81d18049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4afec40f-aaf5-45be-b5bf-bb712e06dbb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b685728-cd49-4511-8b9b-811a69195fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 292222bb-7cc5-4991-96a1-67e656358c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec4d1051-164e-4735-b09c-1e767bf48071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f829703-14a7-4427-9955-2c6ed160be2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b34b92c-2864-4cde-8a5f-20b555d3379e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ab5992-7f7b-4c53-a4f2-c1fc107b7571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03441ddf-44fc-4df3-937d-ed1c0b4b2d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ec0e85-82ba-4dc6-ada3-caadf967b4b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 246be524-5023-4537-92c4-305cbf4e7e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b71c450-9859-48ec-b417-6313957a4392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5935afc3-c163-4960-8817-79a1844ac602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 487fb5da-894c-4745-8d46-79091119a739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c25dc98-e827-4b4b-a2bb-a36febc3b7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0456f10-f886-46f5-b8f1-595236c88c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 067601d0-e33e-4abf-ae31-83010de4524c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f507e2-f531-46c7-bf8f-b627ec35a26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cec16ad-a7a5-4a58-84b1-6d4926da4be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d45d3c-eaa1-4007-955b-e0374017b6ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f3b7bb5-b867-4f4f-87b8-b385b5943940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e9d3d1f-261a-45b9-8463-c55cec18b03c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 988a4d95-e697-4d08-bed1-3a1ec9d59947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db97ffd4-47e8-4160-a232-15ed542392e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 417863dd-290e-4843-91f9-fd188a468907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545fb388-f847-4c2d-bc00-f9ea47edc802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c6e213-a691-425f-9841-1c8b24e09e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bdeecbb-092d-468f-8e6b-d4b88d8d0395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebdbfc5e-2f40-4ffb-bbee-f0464ae2a1b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71e4c28-0d59-4299-b10d-bbbbbae783ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4fdaa9c-9df3-41c7-834b-36e315514664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f24c4d3-5d9e-4a13-a77b-f7c2ac74fd6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41f1cc2f-cecb-4f04-8f5a-1d48db7a9e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50bc6c29-17c0-4c40-845b-e2b448dae49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30b6a140-22b4-4d93-8726-fb04d2ff4029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d497fbb0-f9d0-4f17-bc77-8ece2d43db2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4fe7abe-b84c-4b1d-8db2-94080006b8f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b00db4e6-8c79-4e7f-a436-8ce838094729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b31a3a-56db-426f-9450-3668513f96fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 906abf99-bbbe-48d2-a85d-d80871af61ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5e74313-ee74-41d8-a421-dbb561e336b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2be85be0-5c37-42fc-a02f-6234e732ba46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86e10a22-f175-40c6-861a-ae3082927810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f237db09-a72b-4555-b5f4-ecdd2879e74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27d8d730-22c8-4fad-8205-1e0ee4bb419a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 408e7c24-b50c-4dd9-a661-02e8b2e6a880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb1e555-8f86-4c1c-9efa-5665a895473a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b389e6fc-abe2-402e-93af-2301dd0b3c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 252ae93c-16ac-4618-b80b-cce6bd0e49fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93e59cf7-9ea7-4450-9d77-3555293b663e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb4c3a91-9cd5-465e-aa46-fc4155ef47ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9f1bf6c-cfae-42e8-bd43-64a057bb8750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d77f0b5-5458-4f0c-8a4b-75b84e0f1e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a85304d3-e174-45b6-919f-888e6b1fedb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af9a614-3a4a-4e18-ad7d-a8b376b13f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36ab7648-b76b-4b1f-a0be-564651c6bfa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7944b028-d6ce-44b8-912f-cf173c530949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5811510-b392-4d76-9692-f7830c43a781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f5ecd3-d913-41c9-94c0-e9b8971450d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f0f7ed0-9e03-42f7-99cd-9739f77d24f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 175e7424-d5e9-4fb3-a530-2b97781b98ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9d78687-f6a3-4a47-b5d3-9528b230bef0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_77
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/test_labels.txt

📊 Raw data loaded:
   Train: X=(1518, 24), y=(1518,)
   Test:  X=(380, 24), y=(380,)

⚠️  Limiting training data: 1518 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  371 samples, 5 features
✅ Client client_77 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1742, RMSE: 0.4174, MAE: 0.3395, R²: -1.0825

============================================================
🔄 Round 9 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1021, val=0.0868 (↓), lr=0.001000
   • Epoch   2/100: train=0.0814, val=0.0879, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0804, val=0.0873, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0802, val=0.0872, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0801, val=0.0872, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0789, val=0.0875, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 9 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0008
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0032
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1604, RMSE: 0.4005, MAE: 0.3257, R²: -0.9173

============================================================
🔄 Round 13 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1164, val=0.0932 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0828, val=0.0824 (↓), lr=0.000250
   • Epoch   3/100: train=0.0820, val=0.0837, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0814, val=0.0825, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0815, val=0.0827, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0812, val=0.0824, patience=9/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 13 Summary - Client client_77
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0101
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0043
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1493, RMSE: 0.3864, MAE: 0.3150, R²: -0.7853

============================================================
🔄 Round 14 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1281, val=0.1014 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0945, val=0.0814 (↓), lr=0.000125
   • Epoch   3/100: train=0.0832, val=0.0816, patience=1/15, lr=0.000125
   ✓ Epoch   4/100: train=0.0827, val=0.0803 (↓), lr=0.000125
   • Epoch   5/100: train=0.0825, val=0.0799, patience=1/15, lr=0.000125
   • Epoch  11/100: train=0.0822, val=0.0796, patience=3/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0818, val=0.0798, patience=13/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 14 Summary - Client client_77
   Epochs: 23/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0032
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0077
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1392, RMSE: 0.3731, MAE: 0.3053, R²: -0.6638

============================================================
🔄 Round 15 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1231, val=0.1198 (↓), lr=0.000063
   📉 Epoch 2: LR reduced 0.000063 → 0.000031
   ✓ Epoch   2/100: train=0.1062, val=0.1020 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.0952, val=0.0951 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.0901, val=0.0899 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.0865, val=0.0862 (↓), lr=0.000031
   📉 Epoch 10: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0821, val=0.0812, patience=1/15, lr=0.000016
   📉 Epoch 18: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0819, val=0.0810, patience=11/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 15 Summary - Client client_77
   Epochs: 25/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0020
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0090
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1343, RMSE: 0.3665, MAE: 0.3006, R²: -0.6053

============================================================
🔄 Round 16 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.1253, val=0.1215 (↓), lr=0.000004
   ✓ Epoch   2/100: train=0.1233, val=0.1200 (↓), lr=0.000004
   ✓ Epoch   3/100: train=0.1219, val=0.1186 (↓), lr=0.000004
   ✓ Epoch   4/100: train=0.1205, val=0.1173 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.1192, val=0.1160 (↓), lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   ✓ Epoch  11/100: train=0.1132, val=0.1104 (↓), lr=0.000002
   📉 Epoch 17: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.1093, val=0.1067, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1072, val=0.1047, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1053, val=0.1028 (↓), lr=0.000001
   • Epoch  51/100: train=0.1035, val=0.1010, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1018, val=0.0993, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1003, val=0.0978, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0987, val=0.0963, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0973, val=0.0948, patience=3/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_77
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0959, RMSE=0.3097, R²=-0.1646
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.1754
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1155, RMSE: 0.3398, MAE: 0.2825, R²: -0.3807

============================================================
🔄 Round 18 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1047, val=0.1216 (↓), lr=0.000001
   • Epoch   2/100: train=0.1045, val=0.1213, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1043, val=0.1211, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1042, val=0.1209 (↓), lr=0.000001
   • Epoch   5/100: train=0.1040, val=0.1206, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1030, val=0.1193, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1014, val=0.1171, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0998, val=0.1151 (↓), lr=0.000001
   • Epoch  41/100: train=0.0984, val=0.1131, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0970, val=0.1112, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0957, val=0.1094 (↓), lr=0.000001
   • Epoch  71/100: train=0.0944, val=0.1076, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0932, val=0.1058, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0920, val=0.1042, patience=3/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_77
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3017, R²=-0.1185
   Val:   Loss=0.1027, RMSE=0.3205, R²=-0.2602
============================================================


============================================================
🔄 Round 19 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0973, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0971, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0970, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0968, val=0.0953, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0967, val=0.0952 (↓), lr=0.000001
   • Epoch  11/100: train=0.0958, val=0.0944, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0943, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  31/100: train=0.0930, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0917, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.0905, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  61/100: train=0.0894, val=0.0888, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0884, val=0.0879, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0874, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0866, val=0.0864, patience=7/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_77
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0532
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0351
============================================================


============================================================
🔄 Round 20 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.0863, val=0.0881, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0856, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0849, val=0.0867, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0843, val=0.0861, patience=8/15, lr=0.000001
   • Epoch  61/100: train=0.0839, val=0.0856, patience=9/15, lr=0.000001
   • Epoch  71/100: train=0.0834, val=0.0852, patience=8/15, lr=0.000001
   • Epoch  81/100: train=0.0831, val=0.0848, patience=5/15, lr=0.000001
   • Epoch  91/100: train=0.0828, val=0.0846, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 20 Summary - Client client_77
   Epochs: 91/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0203
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0196
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2590, R²: -0.0344

============================================================
🔄 Round 21 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 21 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0242
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0172
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2569, R²: -0.0079

============================================================
🔄 Round 24 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 24 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0068
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0080
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2567, R²: -0.0058

============================================================
🔄 Round 25 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 25 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0048
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0173
============================================================


============================================================
🔄 Round 26 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 26 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0030
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0162
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2565, R²: -0.0037

============================================================
🔄 Round 28 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 28 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0023
   Val:   Loss=0.0953, RMSE=0.3086, R²=-0.0136
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2565, R²: -0.0030

============================================================
🔄 Round 30 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 30 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0050
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0020
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2563, R²: -0.0017

============================================================
🔄 Round 32 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 32 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0109
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0482
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2563, R²: -0.0014

============================================================
🔄 Round 34 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 34 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0059
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0077
============================================================


============================================================
🔄 Round 35 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 35 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0051
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0002
============================================================


============================================================
🔄 Round 36 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 36 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0033
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0226
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2562, R²: -0.0006

============================================================
🔄 Round 38 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 38 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0039
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0039
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2562, R²: 0.0000

============================================================
🔄 Round 41 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 41 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0039
   Val:   Loss=0.0699, RMSE=0.2643, R²=-0.0039
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2562, R²: 0.0001

============================================================
🔄 Round 42 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 42 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0038
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0049
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2562, R²: 0.0003

📊 Round 42 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2561, R²: 0.0005

📊 Round 42 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2561, R²: 0.0004

📊 Round 42 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2561, R²: 0.0004

============================================================
🔄 Round 47 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 47 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0035
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0055
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2561, R²: 0.0006

📊 Round 47 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2561, R²: 0.0007

============================================================
🔄 Round 50 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 50 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0053
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0071
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2561, R²: 0.0008

📊 Round 50 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2561, R²: 0.0009

============================================================
🔄 Round 53 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 53 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0039
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0087
============================================================


============================================================
🔄 Round 54 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 54 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0037
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0047
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2561, R²: 0.0008

============================================================
🔄 Round 57 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 57 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0031
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0111
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2561, R²: 0.0009

📊 Round 57 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2561, R²: 0.0010

============================================================
🔄 Round 64 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 64 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0043
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0035
============================================================


============================================================
🔄 Round 65 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 65 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0028
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0086
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2560, R²: 0.0012

============================================================
🔄 Round 72 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 72 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0034
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0084
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2560, R²: 0.0016

============================================================
🔄 Round 73 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 73 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0027
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0065
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2560, R²: 0.0016

============================================================
🔄 Round 75 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 75 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0032
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0050
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2560, R²: 0.0017

============================================================
🔄 Round 76 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 76 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0024
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0123
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2560, R²: 0.0019

============================================================
🔄 Round 83 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 83 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0060
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0052
============================================================


============================================================
🔄 Round 84 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 84 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0026
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0109
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2560, R²: 0.0019

📊 Round 84 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2560, R²: 0.0019

📊 Round 84 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2560, R²: 0.0018

📊 Round 84 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2560, R²: 0.0019

============================================================
🔄 Round 88 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 88 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0048
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0013
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2560, R²: 0.0020

============================================================
🔄 Round 90 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 90 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0035
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0029
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2560, R²: 0.0020

============================================================
🔄 Round 91 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 91 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0022
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0088
============================================================


============================================================
🔄 Round 93 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 93 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0049
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0015
============================================================


============================================================
🔄 Round 94 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 94 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0033
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0056
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2559, R²: 0.0022

============================================================
🔄 Round 96 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 96 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0026
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0185
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2559, R²: 0.0022

📊 Round 96 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2559, R²: 0.0022

============================================================
🔄 Round 101 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 101 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0050
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0026
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2559, R²: 0.0023

📊 Round 101 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2559, R²: 0.0024

============================================================
🔄 Round 104 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 104 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0020
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0088
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0024

============================================================
🔄 Round 107 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 107 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0048
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0221
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0024

📊 Round 107 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

============================================================
🔄 Round 111 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 111 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0044
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0228
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0026

============================================================
🔄 Round 112 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 112 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0048
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0034
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

📊 Round 112 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

============================================================
🔄 Round 114 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 114 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0017
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0151
============================================================


============================================================
🔄 Round 115 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 115 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0035
   Val:   Loss=0.0736, RMSE=0.2714, R²=-0.0036
============================================================


============================================================
🔄 Round 117 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 117 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0038
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0016
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0024

============================================================
🔄 Round 119 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 119 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0029
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0139
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

📊 Round 119 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

============================================================
🔄 Round 122 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 122 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0042
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0032
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0026

📊 Round 122 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

============================================================
🔄 Round 124 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 124 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0022
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0083
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

📊 Round 124 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0026

============================================================
🔄 Round 129 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 129 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0043
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0194
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0026

📊 Round 129 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0026

============================================================
🔄 Round 132 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 132 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0032
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0095
============================================================


============================================================
🔄 Round 135 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 135 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0036
   Val:   Loss=0.0712, RMSE=0.2668, R²=-0.0163
============================================================


============================================================
🔄 Round 137 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 137 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0039
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0012
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2558, R²: 0.0028

============================================================
🔄 Round 141 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 141 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0045
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0171
============================================================


============================================================
🔄 Round 142 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 142 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0049
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0023
============================================================


============================================================
🔄 Round 144 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 144 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0040
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0017
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0026

============================================================
🔄 Round 145 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 145 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0057
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0042
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

============================================================
🔄 Round 147 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 147 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0039
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0052
============================================================


============================================================
🔄 Round 148 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 148 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0054
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0201
============================================================


============================================================
🔄 Round 149 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 149 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0046
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0076
============================================================


============================================================
🔄 Round 152 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 152 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0028
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0128
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0024

============================================================
🔄 Round 155 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 155 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0038
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0001
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

============================================================
🔄 Round 159 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 159 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0035
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0043
============================================================


============================================================
🔄 Round 164 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 164 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0038
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0024
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0026

📊 Round 164 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0027

============================================================
🔄 Round 171 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 171 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0033
   Val:   Loss=0.0847, RMSE=0.2909, R²=-0.0069
============================================================


============================================================
🔄 Round 172 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 172 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0036
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0047
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2558, R²: 0.0027

============================================================
🔄 Round 173 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 173 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0034
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0176
============================================================


============================================================
🔄 Round 174 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 174 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0039
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0015
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0027

============================================================
🔄 Round 175 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 175 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0060
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0044
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2558, R²: 0.0027

📊 Round 175 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0027

============================================================
🔄 Round 179 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 179 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0037
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0092
============================================================


============================================================
🔄 Round 182 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 182 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0030
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0058
============================================================


============================================================
🔄 Round 184 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 184 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0030
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0035
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0027

============================================================
🔄 Round 186 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 186 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0023
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0098
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0026

📊 Round 186 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

📊 Round 186 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

============================================================
🔄 Round 190 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 190 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0026
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0052
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0026

============================================================
🔄 Round 192 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 192 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0051
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0038
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0026

📊 Round 192 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0027

============================================================
🔄 Round 195 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 195 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0029
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0036
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2558, R²: 0.0027

📊 Round 195 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

📊 Round 195 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

📊 Round 195 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0026

============================================================
🔄 Round 202 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 202 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0035
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0026
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0026

============================================================
🔄 Round 204 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 204 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0039
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0002
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0026

📊 Round 204 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0026

📊 Round 204 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0026

📊 Round 204 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2559, R²: 0.0026

============================================================
🔄 Round 208 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 208 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0051
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0035
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2559, R²: 0.0025

============================================================
🔄 Round 209 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 209 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0031
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0027
============================================================


❌ Client client_77 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
