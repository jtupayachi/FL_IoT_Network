[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b65bbd-2425-41e3-9eac-0b25ca62cbfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd2accc5-34a4-48c8-b330-08f1cb0865d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a196074c-364d-4bf5-8d5f-2e93113dca8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a11e61-35af-4cc3-ba74-7dd362f93006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff0184a-7cb4-4bb3-80f2-65ee6e8f9d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55e0d270-82e1-497e-ad88-be884be83860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc272ac5-e066-4f12-ac82-689fbf3d7fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fba56a6b-fecb-43fd-a1fc-c9239f560e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3bfa0f-3dd2-4bc0-a4b8-fd5ff4b8ebab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46f0461c-aa4a-4d59-8e4d-146d07378ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b1ad795-f94a-4107-96e7-d7b08948e6b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06521caf-7785-449c-b6cd-40bb63de853e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3102e9eb-36ee-43c8-b339-ea1b6dfe62e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08532a0f-2844-4269-834e-cc20692a2690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fdbe170-4012-4398-9417-1c452fbf592a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818a95c2-3ba8-4e60-8581-31bee54d626a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98b31669-a404-480f-bdfb-2a95c5adc5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a1d20f6-290d-4fe5-ac64-f2a347483d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca8d727d-326a-4790-83de-001871055a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 144d14c7-4245-4f97-8e20-fe79ddd27d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73378ca-024e-4923-8326-959c5336abc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fda710c4-2f63-4a87-9dea-0872e9c7d5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3da0ded1-8059-4e9e-81d9-1629521bcfcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f57a12-c8f7-44ef-90eb-6923988b22ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f44ac6b-a727-429e-9b21-3f2d39ba8c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f99275b-699d-4319-bd97-bd26150191cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c74db1a-a78d-4643-8b2f-519556111758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5009356b-c63f-4f46-9ee0-16d5afe11a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9242bd3-7d32-4952-9083-af40f34e36c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e8f4cc1-476c-4f15-89c9-3bb9ac70b39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fcf4845-1dde-41f1-96cc-fd1943dba20f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a3c9343-6124-45bf-9783-119ac7faee8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ee9a32-fd23-4d5c-b6ed-5d08453ce636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22734d0d-bde6-43f1-8012-74242e6758ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c799083-cb02-49ff-bf67-2ee505b2e0c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891e7b8d-b14b-49ae-a003-cba4f3513381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 931bfb11-5f14-4cee-af6b-d0be41513d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 712a0b64-0635-4d3e-af93-fd445974044a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4666e42-5290-4c05-8b8d-89164b1c4a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc154cc5-82ef-4bce-916a-25c47a306b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e786fb8d-03f5-47fa-996e-9a97c20bc604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34aa40b8-949c-4740-86d8-9fae2acb6556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92929d0d-3c4e-4fc1-b37e-c5f0d1e805e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aee0ad7-77be-40d1-ad73-324a2cbbcf68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8101c721-707f-4fb5-b7ca-9bba5ade137d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 325016c8-46d1-476d-9c7b-af845e8235d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5647b271-359d-4e37-9ef6-716accf94512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 990cd102-12c6-43f3-93a0-4ab8ef756fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11b02fab-f7e7-42ab-8805-c0665220ed69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f710bad5-4142-4c31-b6bd-31276e2d6c7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c59645f-4af1-4582-b682-ffe1724db5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c53e6066-a965-495c-a271-b461a91e1c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aa6efdc-33ee-4e2a-a9b0-2df323ba10d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 389216c1-4793-444f-86c9-8a42003acef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613e8f92-5f8e-43be-942e-49b98cd12e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b89c1ead-e679-4272-ad0e-85902ef663b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a34df0e-5902-4435-b02c-dc57caff9c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30abe02b-f925-4c09-b08e-4954945cb824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f35e2ab4-0d49-4956-90f5-f89063b7bf8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 071c7aba-8665-42ce-89c8-3eef2b98933d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3453073-5cf4-4cc7-b14f-39596a0743da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afcb6b57-5288-4073-9255-2205cc39562b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96b428ca-2e48-41dd-ba28-1e6aa5705330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1808f97e-c8bb-4636-8a26-1f959c363f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb4a0970-d32a-4052-a06d-4d05a69caedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef9832bf-b41d-4e97-89ce-b0f0c19693ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbd01581-a57b-4051-96c2-c21edc3072d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4de84ab6-ec83-4a4d-a354-7582c2e5af2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20546446-f7e9-4401-9886-93a2eb908cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77bc8234-9ce9-4e4c-872b-5ef1d5eff656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ede796a-b9bf-4043-a839-1c619898ab22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 519fe411-624d-422f-a374-65af04293631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e49c75c9-1b4b-4cb1-83a5-82682bb095fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8cf2a28-90db-4b35-948a-d7817a31061f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9728f2b-b274-4e27-b37d-56a499fa08e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58d28794-6233-4a8c-8e44-aa72c9f7ee34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d224791-ed7a-4fed-ac9c-324fd60cdb2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b68e408-7d88-48f7-b730-28a389fa4f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c568434-6f57-47e4-9cf9-309f3c620b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0a796d-a65c-4587-90b0-8a470d431d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49f1c9b-d877-4ea2-8f6f-4173ee07fd49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce5ba3b-7397-4779-a9e1-0bb8404f980a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7317ffff-4c34-487a-9ad0-7f1a9577af4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab6db74e-eeb9-440f-80e4-cc0a334cae81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc38c9ec-ea1f-4564-b0de-82a1de9d9792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b42bf09a-5b2f-480b-9eb5-a28034178b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9ddf43-cd06-4a82-99c5-06e03097a95a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7acf8e83-fc2e-483f-8346-b400a3ca5e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 738ba6b6-de1b-4d7b-b533-75a5931e2587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11b0b6b0-55be-40d5-82b4-e62f1e690667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a7ec6b9-41cd-49c8-943c-76b73cf486ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc57aaa7-f2a2-420e-be53-4735d72a8f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb9aa95c-8230-48f4-85fe-a9a36c236135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37711bf5-93a5-4848-87cf-71a1504863c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00bd9977-8e49-4470-8201-5b8b447bdcb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fcce61c-0545-4474-a34b-41760d670bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8489dcb2-c67a-4888-ab2c-e0c6f77b1b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a3071a5-02ec-46b3-b3ef-7d7535693912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f9c9a5-6045-42f7-b9ea-771fed55e053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3345b46e-2bbb-466f-a630-63eaea03bb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d61fa0f-ff60-4de5-8881-80b76fafc809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b1162d-93cd-4633-bddc-f2190f72e1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c1cffe0-763b-427d-8b1f-228a99937462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d23ec28-164e-4317-b182-a88416f5d313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 114c5356-50cd-41fa-bb8f-31264c718fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e02e31e9-7d0d-4663-b1ba-e1af338f34d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf8578c-e5b0-4f12-a843-733aff63413c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ccb1bda-20f3-4590-9242-604095738f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791a97a2-df07-4f2a-9f99-6761e18437de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e1e61b1-192c-48b0-ab60-4241aaf61c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04d455cc-0932-41e1-ae74-96cf1f22141e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b23ae807-d2c5-40b7-80f1-2286d0c6c392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 067ca2e9-027f-45c6-9aa1-d80bf5e3a491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 657b7cd2-c54b-4552-89b7-b47e1b90e7ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 746f1e30-c059-4366-a4ec-425054f5ceb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d3965ac-5725-436b-b36f-dd931e7e166f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfbcf4ec-5f97-4bd4-965f-f8347ca8c71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b61910e8-f4c7-4512-ae1b-cb90204e3e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f8b3de-ae0d-4995-bc85-10f82d76b161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e994deb-6839-434f-aaf9-73f39f11e138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 697c9bf6-5c26-4ec1-8dff-78f6c303cbf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60aca5ed-0da1-4207-b23b-fa4436f9cf36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03909149-4708-44d0-9eaf-54ef1f3fa655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 533747e3-9461-4b7d-abcc-70d61e943013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 269681ab-5317-4aea-9b8c-a12a9c94b12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3fde27a-7697-4108-b1de-43d7caaa506e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e889404-2c8f-4a3d-87bf-e824ac9f3545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b78c6ae6-8182-4260-b7aa-b3ecca652d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56596eac-2c77-4828-96fa-034517140a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eca7cc9-4a71-4dc6-81b8-5ad1dd5b0481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c0c15f8-0390-4059-8b21-53728c2f3156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1328e8-9ba3-4865-98c8-46006ea53d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af97fa8f-7992-40b8-9e20-2f9fe4e9aed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 905aad39-c72b-4831-b2cc-54e75e33d962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c64833aa-ebb7-4106-ae38-8b8934187eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3432e08-a1c7-4fbe-97c6-e67df5fe6c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 150b55ec-ee1e-4026-b5cc-7d91f740f5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e40c9dbf-25c7-4157-af45-e41dd8f73b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 949bb7a7-5fc0-4795-8ec7-d3c1f795f9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bcdaa45-bd19-47de-b3ea-4fe8cc5beb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b38d8a6-d838-4002-aab8-c56f707aa3cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1d64a63-880b-4976-81f2-fe051ea7f022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ede66a5-fb0c-4441-839d-0911e8f4bcac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfd71654-2c4c-4f6b-8418-c759673f448b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3def5f3f-6466-48cd-9685-813a31f112aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c817252b-ad99-4a97-9c12-ea74e1bb5694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec0ef3b5-8dd4-4277-91bc-859f8eab6c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a00531b-e123-4234-b305-28bb458680af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0b0920-c5df-4f11-a4ec-c77200c520a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f442a9eb-d4f8-43a2-a61b-4b15063b1c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2922dbee-b13d-46c6-a00c-0638cf0ea954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73159e8e-1f60-4088-a7df-4aa5f4b42e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a04b524-21f7-4e4a-93da-d1a7332f7495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90e6d983-9fac-49d5-9bfd-69b489181338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc54f868-ac40-4810-80b9-2cb4535e9564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0ddc180-d410-4252-9303-300ab2e663ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fe52fb5-0b54-492b-8725-b40f2fa93e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1601c803-2e92-4ed1-b29b-bf7ec03cf52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8ffe4d0-879c-4247-ade4-9d4c8add64ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2785ac2-98eb-431f-9ce2-c87a3c39bea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ea4a9b-3b7c-4974-9560-25f5b182e6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1cf851f-ba04-40e0-83e6-9d22a71e5d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56882b45-6e2a-4208-a4b0-79fbb04214ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 447430d0-43b7-4662-b500-253aa1051f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d905f52b-5930-4170-a3ba-3a483dddd522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6e5f9f3-193d-45cb-9780-45eca57cebd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b030b734-6e05-43cc-913b-c0fe6b3f44cd
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_78
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/test_labels.txt

📊 Raw data loaded:
   Train: X=(512, 24), y=(512,)
   Test:  X=(129, 24), y=(129,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 503 samples, 5 features
   Test:  120 samples, 5 features
✅ Client client_78 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 9 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1160, val=0.0891 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0887, val=0.0777 (↓), lr=0.001000
   • Epoch   3/100: train=0.0839, val=0.0773, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0834, val=0.0764 (↓), lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0770, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0816, val=0.0779, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 9 Summary - Client client_78
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0142
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0089
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1704, RMSE: 0.4128, MAE: 0.3421, R²: -1.0436

============================================================
🔄 Round 11 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1425, val=0.1397 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1034, val=0.1017 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0804, val=0.0927 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0802, val=0.0920 (↓), lr=0.000250
   • Epoch   5/100: train=0.0787, val=0.0923, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0784, val=0.0918, patience=7/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 11 Summary - Client client_78
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0032
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0116
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1662, RMSE: 0.4077, MAE: 0.3382, R²: -0.9937

============================================================
🔄 Round 12 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1503, val=0.1586 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1371, val=0.1437 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1230, val=0.1301 (↓), lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   ✓ Epoch   4/100: train=0.1106, val=0.1181 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1021, val=0.1128 (↓), lr=0.000031
   ✓ Epoch  11/100: train=0.0825, val=0.0941 (↓), lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016
   📉 Epoch 20: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0801, val=0.0919, patience=3/15, lr=0.000008
   📉 Epoch 28: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0800, val=0.0918, patience=13/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 12 Summary - Client client_78
   Epochs: 33/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0063
   Val:   Loss=0.0921, RMSE=0.3034, R²=0.0012
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1611, RMSE: 0.4014, MAE: 0.3334, R²: -0.9321

============================================================
🔄 Round 13 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1522, val=0.1471 (↓), lr=0.000004
   ✓ Epoch   2/100: train=0.1514, val=0.1460 (↓), lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   ✓ Epoch   3/100: train=0.1503, val=0.1449 (↓), lr=0.000002
   ✓ Epoch   4/100: train=0.1495, val=0.1444 (↓), lr=0.000002
   ✓ Epoch   5/100: train=0.1490, val=0.1439 (↓), lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.1463, val=0.1411, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1442, val=0.1390 (↓), lr=0.000001
   • Epoch  31/100: train=0.1424, val=0.1372, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1408, val=0.1355, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1392, val=0.1339 (↓), lr=0.000001
   • Epoch  61/100: train=0.1377, val=0.1323, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1363, val=0.1308 (↓), lr=0.000001
   • Epoch  81/100: train=0.1348, val=0.1293, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1334, val=0.1279 (↓), lr=0.000001

============================================================
📊 Round 13 Summary - Client client_78
   Epochs: 100/100
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.1319, RMSE=0.3631, R²=-0.5622
   Val:   Loss=0.1265, RMSE=0.3557, R²=-0.6679
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1453, RMSE: 0.3812, MAE: 0.3188, R²: -0.7427

📊 Round 13 Test Metrics:
   Loss: 0.1403, RMSE: 0.3746, MAE: 0.3144, R²: -0.6830

============================================================
🔄 Round 16 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1353, val=0.1042 (↓), lr=0.000001
   • Epoch   2/100: train=0.1352, val=0.1040, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1350, val=0.1039, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1349, val=0.1038, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1347, val=0.1036 (↓), lr=0.000001
   • Epoch  11/100: train=0.1339, val=0.1029, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1324, val=0.1016 (↓), lr=0.000001
   • Epoch  31/100: train=0.1310, val=0.1003, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.1296, val=0.0991, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.1282, val=0.0979, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.1268, val=0.0966, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.1254, val=0.0954, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.1240, val=0.0942, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.1226, val=0.0931, patience=2/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_78
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1233, RMSE=0.3511, R²=-0.4196
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.4053
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1079, RMSE: 0.3285, MAE: 0.2823, R²: -0.2945

============================================================
🔄 Round 19 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0937, val=0.1272 (↓), lr=0.000001
   • Epoch   2/100: train=0.0936, val=0.1271, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0935, val=0.1270, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0934, val=0.1268, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0933, val=0.1267 (↓), lr=0.000001
   • Epoch  11/100: train=0.0928, val=0.1259, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0920, val=0.1246 (↓), lr=0.000001
   • Epoch  31/100: train=0.0912, val=0.1233, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0904, val=0.1219 (↓), lr=0.000001
   • Epoch  51/100: train=0.0896, val=0.1206, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0889, val=0.1193 (↓), lr=0.000001
   • Epoch  71/100: train=0.0881, val=0.1181, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0874, val=0.1168 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.0867, val=0.1156 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_78
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2933, R²=-0.0723
   Val:   Loss=0.1145, RMSE=0.3384, R²=-0.3090
============================================================


============================================================
🔄 Round 21 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 21 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=-0.0224
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0415
============================================================


============================================================
🔄 Round 22 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0836, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0842, val=0.0832, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 22 Summary - Client client_78
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0003
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0628
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2572, R²: -0.0382

============================================================
🔄 Round 24 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 24 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0087
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0085
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2560, R²: -0.0263

============================================================
🔄 Round 27 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 27 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0013
   Val:   Loss=0.0935, RMSE=0.3057, R²=0.0003
============================================================


============================================================
🔄 Round 28 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 28 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0031
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0108
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2558, R²: -0.0250

📊 Round 28 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2557, R²: -0.0240

============================================================
🔄 Round 33 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 33 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0030
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0021
============================================================


============================================================
🔄 Round 34 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 34 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0020
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0077
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2554, R²: -0.0216

============================================================
🔄 Round 35 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 35 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0041
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0047
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2554, R²: -0.0212

============================================================
🔄 Round 39 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 39 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0010
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0075
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2552, R²: -0.0199

📊 Round 39 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2551, R²: -0.0191

📊 Round 39 Test Metrics:
   Loss: 0.0849, RMSE: 0.2915, MAE: 0.2551, R²: -0.0187

============================================================
🔄 Round 46 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 46 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0026
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0028
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2551, R²: -0.0186

============================================================
🔄 Round 47 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 47 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0081
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0111
============================================================


============================================================
🔄 Round 48 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 48 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0021
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0030
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2550, R²: -0.0182

============================================================
🔄 Round 50 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 50 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0043
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0060
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2550, R²: -0.0178

============================================================
🔄 Round 52 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.1030 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.1030, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.1030, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.1030, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.1030, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.1030, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1030)

============================================================
📊 Round 52 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0087
   Val:   Loss=0.1030, RMSE=0.3210, R²=-0.0102
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2550, R²: -0.0178

📊 Round 52 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2550, R²: -0.0178

============================================================
🔄 Round 61 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 61 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0054
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0022
============================================================


============================================================
🔄 Round 62 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 62 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0033
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0041
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2549, R²: -0.0169

📊 Round 62 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2549, R²: -0.0169

📊 Round 62 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2549, R²: -0.0167

============================================================
🔄 Round 68 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 68 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0001
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0043
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2549, R²: -0.0167

============================================================
🔄 Round 69 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 69 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0087
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0233
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2548, R²: -0.0166

============================================================
🔄 Round 71 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 71 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0092
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0531
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2548, R²: -0.0162

📊 Round 71 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2548, R²: -0.0161

============================================================
🔄 Round 73 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 73 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0073
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0210
============================================================


============================================================
🔄 Round 77 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 77 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0006
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0141
============================================================


============================================================
🔄 Round 79 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 79 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0019
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0068
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2547, R²: -0.0153

============================================================
🔄 Round 82 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 82 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0045
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0057
============================================================


============================================================
🔄 Round 84 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 84 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0062
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0051
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2547, R²: -0.0152

============================================================
🔄 Round 85 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 85 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0043
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0064
============================================================


============================================================
🔄 Round 86 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 86 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0078
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0042
============================================================


============================================================
🔄 Round 88 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 88 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0006
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0104
============================================================


============================================================
🔄 Round 89 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 89 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0043
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0096
============================================================


============================================================
🔄 Round 90 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 90 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0034
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0150
============================================================


============================================================
🔄 Round 91 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 91 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0102
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0199
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2546, R²: -0.0145

============================================================
🔄 Round 93 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 93 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0068
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0136
============================================================


============================================================
🔄 Round 94 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 94 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0067
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0046
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2546, R²: -0.0143

============================================================
🔄 Round 95 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 95 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0099
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0142
============================================================


============================================================
🔄 Round 96 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 96 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0026
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0154
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2546, R²: -0.0143

============================================================
🔄 Round 101 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 101 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0009
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0223
============================================================


============================================================
🔄 Round 103 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 103 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0051
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0033
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2545, R²: -0.0136

============================================================
🔄 Round 108 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 108 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0079
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0039
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2544, R²: -0.0134

============================================================
🔄 Round 109 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 109 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0044
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0129
============================================================


============================================================
🔄 Round 110 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 110 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0094
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0093
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2544, R²: -0.0132

============================================================
🔄 Round 111 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0997 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0997, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0997, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0997, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0997, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0997)

============================================================
📊 Round 111 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0068
   Val:   Loss=0.0997, RMSE=0.3157, R²=-0.0016
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2544, R²: -0.0133

📊 Round 111 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2544, R²: -0.0133

============================================================
🔄 Round 119 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 119 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0067
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0019
============================================================


============================================================
🔄 Round 120 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 120 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0014
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0148
============================================================


============================================================
🔄 Round 121 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 121 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0037
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0007
============================================================


============================================================
🔄 Round 124 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 124 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0005
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0022
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2544, R²: -0.0129

============================================================
🔄 Round 126 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 126 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0033
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0124
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2544, R²: -0.0127

📊 Round 126 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2544, R²: -0.0128

============================================================
🔄 Round 128 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 128 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0039
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0036
============================================================


============================================================
🔄 Round 129 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 129 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0047
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0072
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2544, R²: -0.0126

============================================================
🔄 Round 130 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 130 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0054
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0039
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2544, R²: -0.0127

============================================================
🔄 Round 131 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 131 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0002
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0216
============================================================


============================================================
🔄 Round 132 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 132 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0043
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0008
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2543, R²: -0.0126

============================================================
🔄 Round 133 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 133 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0061
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0060
============================================================


============================================================
🔄 Round 135 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 135 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0006
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0096
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2543, R²: -0.0124

============================================================
🔄 Round 136 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 136 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0080
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0024
============================================================


============================================================
🔄 Round 137 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 137 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0048
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0023
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2543, R²: -0.0121

📊 Round 137 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2543, R²: -0.0120

============================================================
🔄 Round 141 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 141 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0084
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0060
============================================================


============================================================
🔄 Round 142 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 142 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0059
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0004
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2543, R²: -0.0122

============================================================
🔄 Round 143 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 143 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0068
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0022
============================================================


============================================================
🔄 Round 144 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 144 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0088
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0223
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2543, R²: -0.0124

📊 Round 144 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2544, R²: -0.0126

📊 Round 144 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2543, R²: -0.0125

============================================================
🔄 Round 150 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 150 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0041
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0126
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2544, R²: -0.0126

📊 Round 150 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2543, R²: -0.0125

============================================================
🔄 Round 154 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 154 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0071
   Val:   Loss=0.0894, RMSE=0.2991, R²=0.0016
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2543, R²: -0.0125

============================================================
🔄 Round 155 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 155 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0120
   Val:   Loss=0.0986, RMSE=0.3139, R²=-0.0654
============================================================


============================================================
🔄 Round 156 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 156 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0072
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0007
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2543, R²: -0.0123

============================================================
🔄 Round 158 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 158 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0030
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0172
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2543, R²: -0.0122

📊 Round 158 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2543, R²: -0.0121

📊 Round 158 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2543, R²: -0.0122

============================================================
🔄 Round 163 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 163 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0076
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0010
============================================================


============================================================
🔄 Round 164 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 164 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0023
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0195
============================================================


============================================================
🔄 Round 166 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 166 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0079
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0015
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2542, R²: -0.0118

============================================================
🔄 Round 168 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 168 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0078
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0003
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2542, R²: -0.0117

📊 Round 168 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0115

============================================================
🔄 Round 171 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0999, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0999, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0999, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0999, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 171 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0079
   Val:   Loss=0.0999, RMSE=0.3160, R²=0.0003
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0114

============================================================
🔄 Round 173 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 173 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0033
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0095
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0114

📊 Round 173 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0114

📊 Round 173 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0115

============================================================
🔄 Round 177 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0660, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0660, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 177 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0044
   Val:   Loss=0.0660, RMSE=0.2569, R²=0.0134
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0115

📊 Round 177 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0114

============================================================
🔄 Round 179 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 179 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0053
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0008
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0115

============================================================
🔄 Round 180 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 180 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0052
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0096
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0114

📊 Round 180 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0113

============================================================
🔄 Round 183 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 183 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0071
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0020
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0114

📊 Round 183 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0114

📊 Round 183 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0111

============================================================
🔄 Round 194 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 194 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0081
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0046
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0110

============================================================
🔄 Round 195 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 195 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0045
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0085
============================================================


============================================================
🔄 Round 196 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 196 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0027
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0052
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0112

📊 Round 196 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0114

📊 Round 196 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0113

============================================================
🔄 Round 199 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 199 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0042
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0042
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0113

============================================================
🔄 Round 201 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 201 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0062
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0042
============================================================


============================================================
🔄 Round 202 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 202 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0104
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0215
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0111

📊 Round 202 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0111

============================================================
🔄 Round 206 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 206 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0059
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0067
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2542, R²: -0.0110

============================================================
🔄 Round 209 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 209 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0119
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0622
============================================================


❌ Client client_78 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
