[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5af6e8a0-d8ed-4e4c-9a4c-904ee7c39eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc21309b-4748-4cc9-b57d-b80e3f90ed0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b4cf7d3-c543-4c9a-9a30-3eb48915220e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0028d1e-8b7e-4de1-a660-dea2d110636d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11d51920-c77a-432c-8f75-5ad3714bc65c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7625c0d-6f55-4292-8c22-f4b6aef0c2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db10a6c7-6bce-470e-b4c8-efa3ea37850c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b6848c5-56e7-4a8a-a4b3-ce84d5167386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6187b1a2-6118-41d5-8045-0acebeb5f299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d877401b-b4e6-4c0a-86c1-e84f5bae6c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9df5522-f727-4115-8d20-93cc67448a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a86b93a7-bdd2-4e12-b2a2-da61a7af0868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f52ef141-e1d0-4375-9985-f0972d7e36f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d10b50db-2742-4e29-8f72-6590fe7f6edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da13312a-e7a1-42da-b1f5-d2a7eb56b932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 997d83f9-acf0-40f9-86f4-631a686f8a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0118338c-d683-412e-9005-6ecd6082469d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5063139a-53be-431d-8cb4-d8573598f548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bbccc26-d4c1-4c13-ac32-b9b33b788b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 612d32ac-8c1d-480f-8ee6-0a4bf4cb39d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60b241c3-09b0-4c4e-9255-65bf1cb127f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bf2c7c4-7f17-4609-978e-5f9cca766f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55cd4f95-8994-4d71-9318-813ced109f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 515d5d56-a3e0-4a49-92b4-b1fbcfc33508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4db1a9b4-3438-4ada-bae1-59c278a122fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 782904c0-1f6b-4106-972d-0d33756c4c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54cb8085-f9f1-4d12-b08e-fffe723df502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 334eb369-631c-4753-bbd1-bf20d7ed500b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f99e624-45a8-4d8c-81f9-823ad0a832da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23f2145b-48a7-463f-8336-cd4f3303f751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcdf8e36-12a6-460b-9865-1f2ef7d77d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14bac537-6b2f-4714-b871-77f60c57aa38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27132f31-aa3d-491d-b265-4dd59123a7bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89bce485-3ade-4341-bda4-8cc213cbe171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 272c990b-c622-456f-8a1b-6b1dffd60269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 876e7548-51cc-424d-b249-8d9e8aac9c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4e02da4-2619-41bf-b779-aeeba907e772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06470eaf-3312-429f-b760-52191682e290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0813ad6-9c41-4745-887a-1508703858ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 593a7259-57b8-4c40-8e34-1a9a4db556df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c62d738a-f12a-4aa3-9787-0c83f0f16d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3796077-5f5f-4374-8694-1a71758fb59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92f8094b-16bc-47ac-b6e2-324a6400fcf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0fb5284-2cda-4bd7-a7dd-51f763206a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6673f46b-791c-42a9-9eed-ae9ade9607b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 325e0101-27d5-4286-92a6-60e716ba826e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3461bd31-b626-4e3a-be02-f833fadaf4ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1615776-2e60-4405-8144-f22530163637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2064483-6bde-4a1a-918f-cc25fc1470b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f76077-a6f6-4f16-b6b3-d0e53d6897dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e04dc069-6124-49e9-99ca-d939617f164a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea19575e-ed50-477a-8e7f-65dc5b055780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd7bbe03-a9f1-4858-bc63-59538825a792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14ebb502-d101-4ece-916b-9cc8f295409b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 279f6a5f-ea1a-4507-9ca0-2fb1bc4cd753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ff20d3-45e2-4a4c-bab1-639f18c89f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6600c338-192b-40ce-ad3a-655f54855d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8399673a-f9a9-4edd-a508-011875808ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d23ca9b-ce34-4833-9bc0-67df49d1c5eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 850956ac-bc72-421c-8174-e5e26cddbcf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e9520bb-0b75-4ac3-9d54-70064b11c804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4aec554-365f-43a3-8004-164e1b4d3f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27674b93-0178-4eab-8751-0deda7f66069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3e8925-1685-4a3d-8dcd-c8d2f6de61fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fc275f1-1e4d-4954-9014-2ffe560cf87a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de42454-1d31-4be1-a11e-645b27b40874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed552759-15c1-450c-bb84-b740eea81f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83ac0e36-7fa6-42c6-8471-3c75e82d461c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 668004b3-7001-4192-8eb1-1c9a4d8682eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c988f4-6fe0-41f9-85ad-690873ca21e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b3c7c76-c572-43d8-bc61-6de0a8bc61b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c90a321-797b-451c-a7e6-5cec26d42eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ecaa154-2032-456f-b517-d753a23a3600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2532bd4-d0a3-4d66-885a-302c180ac9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 317701c9-76be-4f1f-a45a-dc8f329ad388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dac6b9f-d6b2-404d-b26e-a9827ad98c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0adafbde-5ccf-4122-8910-003b981bb124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a6341d-124b-4cc0-ae88-b1b235b010b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c04c51e0-9ba7-436c-ab7d-a517a8a48db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6cdeeb2-bb3c-4e6f-be49-7a0afd7b1033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fc00a67-085c-4318-9035-4b1c245190d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3bf6e79-876a-4528-86ee-fe3932a35dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded59216-9fb3-4982-b24a-61894dd5d7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b769d77-a2a4-4ef2-867e-33168028b4f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b66255-c3e8-4506-aca0-a7baddbd3d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d296444-e272-4720-b0ce-494e3f56459f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d180465c-b75f-4c5f-9a1d-22b512fba7bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dbb6469-c5e7-40dd-a87f-565be32ab9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93d7f344-ffd6-4f99-8ac3-1442e312c363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d97c4fb-f814-4428-a01d-dc981a692d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51492b50-a745-4ab3-b69b-51d93f6f17b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fec0b459-b5fd-43df-8a6c-7c9a0f694e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a60f5c83-0292-4681-b1fb-56e55bb01482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d88d4d5c-4b76-40ae-8258-06ec3932ee63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 720008d5-47e2-41b1-873a-8d4631c58271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e0274ea-91f1-46ec-8b39-039c04a13407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b428bba-09c1-4d34-accc-7b8749b57391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62481e2f-77e8-4dfb-bb04-0890d4579c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6df29de-9207-46d6-852a-d0be716b66b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35ca7fcb-9820-4b8d-a617-4e92ff81a8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4348283-dbd1-41fd-a89a-7fd8c20116c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12ea905f-dc26-45ff-9c67-f7d12ea2cd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67d86a1b-89d9-4813-a955-89a037af2c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a5b5bee-7b1b-488c-96aa-e7e11e0c1d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a3c705a-f133-43e6-9739-56154c3e4de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9975efc-6a4f-4493-bdae-e6133f692fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef51ddae-4c5a-4423-a363-0a8e94e86601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 254077df-b715-4ce6-b285-99322cf18a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d658471b-5cc9-4278-9d51-a652ca754786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 525ec684-61ed-4dd0-8538-ea87b0df314e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0161e198-b7c9-4528-9897-13adb881a3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cefebfdd-d1ac-4d31-b26b-59f13ed07d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76151237-eb4c-4745-b0ae-7037b81074cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3c35cfb-7d0d-4285-a54f-aef9ea3c33c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a80916-e375-4207-9a55-f2de9f8ea588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 765b6b65-093c-4c66-b340-627b6bb04b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33ae9d5-5df4-4008-a70e-c9d3f751f591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ae297b2-d30e-4bae-ac9e-4fe4f2992307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4a54a89-a2ac-4fe1-ad62-e95ebaa9328c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb9a95f-b57d-4063-8635-a16174b6015d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de6f3047-c48c-49f4-88db-8accff471953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e059d0ec-07fa-4f27-8476-5f04fe648365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beb9ce30-a3f2-48a2-8c73-9b06f70e8a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e1de4d-d251-4166-b4fb-fcabdfe6a181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d90e49d2-8925-495e-9a98-1aa2b89ac150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17c8a99f-cb1a-4d1b-b9a8-1c4e06552930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10e1264a-5532-4a19-b30b-0d43eef76645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9ca5b9f-45cf-4ad3-973d-90afabe3d95a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4093a78f-6fc6-4623-8ed0-419ff61e153b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0460b68-d415-4907-96c7-79bda5881bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d05bba0-7034-444e-8ddc-cc09a221ac82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80772172-969a-4403-bd86-94d521f06e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f2a715-5ffe-41b3-bd43-9af3d40b3aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb98a173-1a6d-4847-b37a-50b6757b57a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8998c7ab-7d29-4add-96e6-08441ab036af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bace4c9-9311-410c-a2ac-cf9fc5dabffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1226bec3-f53d-4b31-959a-af5873324775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e0a3ba-b7b8-44c5-9406-5a5563fc1d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad69158b-0660-4369-b4b0-a43c36dc4a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd40b5b5-5728-4f6a-a03b-8e99d44c8e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f3104b4-8c77-4973-955f-b6ddde790453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57f7d88c-6a51-436d-b73d-164d16d8ccb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d170361b-0d91-4bbb-9dda-496143a393da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e69f5511-2fa3-4438-8d7b-6c70b9d63195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ba4b8e6-e23c-4d23-b016-16704e227e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e8d120d-499b-4403-9308-7d999dd3ef2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6189d89d-ae1d-4850-b122-e25acf6dccb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49096440-ce7e-4a56-b0a2-07b3bdaf4653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 088fc1aa-1af8-42a3-b2b2-dcd86046868b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e519b7f4-a8b9-4c67-b18a-6b821929ac3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7713df3e-6e74-427a-a0b3-67114b793252
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_79
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/test_labels.txt

📊 Raw data loaded:
   Train: X=(1288, 24), y=(1288,)
   Test:  X=(322, 24), y=(322,)

⚠️  Limiting training data: 1288 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  313 samples, 5 features
✅ Client client_79 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 9 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1062, val=0.0891 (↓), lr=0.001000
   • Epoch   2/100: train=0.0814, val=0.0907, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0816, val=0.0890, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0812, val=0.0886 (↓), lr=0.001000
   • Epoch   5/100: train=0.0809, val=0.0887, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0802, val=0.0887, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 9 Summary - Client client_79
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0213
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0327
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.1633, RMSE: 0.4041, MAE: 0.3262, R²: -0.9749

============================================================
🔄 Round 12 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1314, val=0.0905 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0846, val=0.0864 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0831, val=0.0838 (↓), lr=0.000250
   • Epoch   4/100: train=0.0823, val=0.0840, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0824, val=0.0836, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0819, val=0.0837, patience=8/15, lr=0.000250
   📉 Epoch 14: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 12 Summary - Client client_79
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0034
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0011
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1478, RMSE: 0.3844, MAE: 0.3100, R²: -0.7874

============================================================
🔄 Round 13 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1375, val=0.1286 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0956, val=0.0927 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0815, val=0.0887 (↓), lr=0.000125
   📉 Epoch 4: LR reduced 0.000125 → 0.000063
   • Epoch   4/100: train=0.0822, val=0.0887, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0815, val=0.0888, patience=2/15, lr=0.000063
   • Epoch  11/100: train=0.0811, val=0.0886, patience=8/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 13 Summary - Client client_79
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0022
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0272
============================================================


============================================================
🔄 Round 14 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1485, val=0.1365 (↓), lr=0.000031
   📉 Epoch 2: LR reduced 0.000031 → 0.000016
   ✓ Epoch   2/100: train=0.1343, val=0.1224 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1237, val=0.1164 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1178, val=0.1111 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1125, val=0.1062 (↓), lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0912, val=0.0879 (↓), lr=0.000008
   • Epoch  21/100: train=0.0847, val=0.0827, patience=1/15, lr=0.000008
   • Epoch  31/100: train=0.0833, val=0.0820, patience=8/15, lr=0.000008
   📉 Epoch 38: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 14 Summary - Client client_79
   Epochs: 38/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0149
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0068
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0971, RMSE: 0.3116, MAE: 0.2588, R²: -0.1744

📊 Round 14 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2479, R²: -0.0056

============================================================
🔄 Round 22 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0821 (↓), lr=0.000004
   • Epoch   2/100: train=0.0852, val=0.0819, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0850, val=0.0818, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0849, val=0.0816, patience=3/15, lr=0.000004
   ✓ Epoch   5/100: train=0.0847, val=0.0815 (↓), lr=0.000004
   ✓ Epoch  11/100: train=0.0842, val=0.0810 (↓), lr=0.000004
   • Epoch  21/100: train=0.0838, val=0.0806, patience=10/15, lr=0.000004
   • Epoch  31/100: train=0.0837, val=0.0804, patience=6/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 22 Summary - Client client_79
   Epochs: 40/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0035
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0040
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2479, R²: -0.0011

📊 Round 22 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2480, R²: -0.0008

============================================================
🔄 Round 28 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0826 (↓), lr=0.000004
   • Epoch   2/100: train=0.0839, val=0.0825, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0838, val=0.0825, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0837, val=0.0825, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0836, val=0.0825, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0835, val=0.0824, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 28 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0103
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0111
============================================================


============================================================
🔄 Round 32 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 32 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0102
   Val:   Loss=0.0766, RMSE=0.2769, R²=-0.0069
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2481, R²: -0.0003

============================================================
🔄 Round 33 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 33 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0072
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0179
============================================================


============================================================
🔄 Round 34 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 34 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0082
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0117
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2481, R²: -0.0004

============================================================
🔄 Round 36 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 36 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0075
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0228
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2481, R²: -0.0004

============================================================
🔄 Round 37 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 37 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0104
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0084
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2481, R²: -0.0004

============================================================
🔄 Round 39 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 39 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0060
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0327
============================================================


============================================================
🔄 Round 41 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 41 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0080
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0094
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2482, R²: -0.0005

📊 Round 41 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2482, R²: -0.0005

============================================================
🔄 Round 43 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 43 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0095
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0014
============================================================


============================================================
🔄 Round 46 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 46 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0070
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0107
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2482, R²: -0.0005

============================================================
🔄 Round 49 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 49 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0101
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0028
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2482, R²: -0.0006

📊 Round 49 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2482, R²: -0.0006

============================================================
🔄 Round 55 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 55 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0081
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0070
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2482, R²: -0.0006

📊 Round 55 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2482, R²: -0.0005

📊 Round 55 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2482, R²: -0.0005

============================================================
🔄 Round 61 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 61 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0116
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0126
============================================================


============================================================
🔄 Round 64 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 64 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0085
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0036
============================================================


============================================================
🔄 Round 65 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 65 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0088
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0019
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0006

📊 Round 65 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2482, R²: -0.0006

📊 Round 65 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2482, R²: -0.0006

📊 Round 65 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2482, R²: -0.0006

============================================================
🔄 Round 70 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 70 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0080
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0036
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0006

============================================================
🔄 Round 72 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 72 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0073
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0070
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0007

============================================================
🔄 Round 73 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 73 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0084
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0024
============================================================


============================================================
🔄 Round 75 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 75 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0061
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0107
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0008

============================================================
🔄 Round 78 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 78 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0066
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0093
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0008

============================================================
🔄 Round 80 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 80 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0073
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0054
============================================================


============================================================
🔄 Round 82 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 82 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0044
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0209
============================================================


============================================================
🔄 Round 83 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 83 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0062
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0147
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0008

📊 Round 83 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0007

📊 Round 83 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0008

📊 Round 83 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0007

📊 Round 83 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0007

============================================================
🔄 Round 88 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 88 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0067
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0076
============================================================


============================================================
🔄 Round 89 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 89 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0068
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0109
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0008

============================================================
🔄 Round 90 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 90 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0056
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0119
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0008

============================================================
🔄 Round 91 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 91 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0063
   Val:   Loss=0.0983, RMSE=0.3136, R²=-0.0084
============================================================


============================================================
🔄 Round 94 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 94 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0084
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0204
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2484, R²: -0.0009

============================================================
🔄 Round 96 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 96 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0079
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0008
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

============================================================
🔄 Round 97 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 97 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0051
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0237
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0007

============================================================
🔄 Round 99 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 99 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0058
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0099
============================================================


============================================================
🔄 Round 100 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 100 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0050
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0129
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

📊 Round 100 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

📊 Round 100 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

📊 Round 100 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0009

============================================================
🔄 Round 105 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 105 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0083
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0006
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

============================================================
🔄 Round 107 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 107 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0079
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0041
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2484, R²: -0.0009

============================================================
🔄 Round 108 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 108 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0060
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0110
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2484, R²: -0.0009

📊 Round 108 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2484, R²: -0.0009

============================================================
🔄 Round 112 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 112 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0099
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0103
============================================================


============================================================
🔄 Round 113 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 113 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0053
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0145
============================================================


============================================================
🔄 Round 114 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 114 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0066
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0052
============================================================


============================================================
🔄 Round 116 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 116 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0091
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0013
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

📊 Round 116 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

============================================================
🔄 Round 122 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 122 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0050
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0120
============================================================


============================================================
🔄 Round 124 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 124 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0083
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0007
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

============================================================
🔄 Round 125 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 125 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0089
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0008
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

============================================================
🔄 Round 126 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 126 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0083
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0016
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

============================================================
🔄 Round 127 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 127 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0085
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0067
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

📊 Round 127 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

============================================================
🔄 Round 133 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 133 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0054
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0137
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

============================================================
🔄 Round 134 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 134 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0043
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0167
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0008

============================================================
🔄 Round 136 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 136 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0081
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0001
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2484, R²: -0.0009

============================================================
🔄 Round 139 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 139 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0070
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0045
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2484, R²: -0.0009

============================================================
🔄 Round 145 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 145 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0054
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0111
============================================================


============================================================
🔄 Round 146 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 146 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0039
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0189
============================================================


============================================================
🔄 Round 147 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 147 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0063
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0078
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0006

📊 Round 147 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0005

📊 Round 147 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0005

📊 Round 147 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0005

============================================================
🔄 Round 155 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 155 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0072
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0294
============================================================


============================================================
🔄 Round 156 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 156 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0071
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0080
============================================================


============================================================
🔄 Round 158 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 158 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0056
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0097
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0006

============================================================
🔄 Round 162 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 162 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0094
   Val:   Loss=0.0980, RMSE=0.3131, R²=-0.0223
============================================================


============================================================
🔄 Round 163 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 163 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0070
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0090
============================================================


============================================================
🔄 Round 166 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 166 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0064
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0063
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0006

📊 Round 166 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0007

============================================================
🔄 Round 172 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 172 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0075
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0034
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0007

📊 Round 172 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0006

============================================================
🔄 Round 178 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 178 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0067
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0300
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0005

📊 Round 178 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0006

============================================================
🔄 Round 181 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 181 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0051
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0125
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0006

📊 Round 181 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0004

📊 Round 181 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0005

============================================================
🔄 Round 192 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 192 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0047
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0127
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0005

📊 Round 192 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0006

📊 Round 192 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0006

============================================================
🔄 Round 196 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 196 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0049
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0115
============================================================


============================================================
🔄 Round 197 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 197 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0062
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0057
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0004

============================================================
🔄 Round 198 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 198 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0056
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0539
============================================================


============================================================
🔄 Round 199 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 199 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0062
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0068
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0004

📊 Round 199 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0004

📊 Round 199 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2484, R²: -0.0005

============================================================
🔄 Round 204 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 204 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0050
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0106
============================================================


============================================================
🔄 Round 205 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 205 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0078
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0037
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2483, R²: -0.0004

============================================================
🔄 Round 207 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 207 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0095
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0113
============================================================


============================================================
🔄 Round 211 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 211 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0050
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0108
============================================================


❌ Client client_79 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
