[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a40bbbc-c0fc-4c98-a91a-0271e7544898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6de044e1-bafb-41fb-adc2-3bdbe987af21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9b7a98a-3899-4003-9eac-761ef42aa3b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a87ff2db-eb9b-45f3-b532-4a0cfb1329ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b267ab08-a18c-432d-851b-d7cfae68343b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dd4ea4a-61b6-4580-9cd0-f8e9c576281e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 807616df-60a4-494b-9af3-2a239edb618e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aed8c864-ec90-4b29-9a31-5fcd9388aa26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 704d05be-a4ff-45e2-845b-85950b8e7b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f37e654-c296-42ed-ab81-ffad468b683e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc9af740-923e-48d9-90e8-a595da15fe6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caf45801-0f0a-404c-a8fe-61818624c0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6c26b6a-6586-45c4-b5c6-0b66c1b33cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e74b78c0-33d6-4e6e-92ed-e308ae69947c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ece40e67-298f-42c6-808b-527f7f89ba3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f816597-4ebf-4447-b2ab-ddb4c651f616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f70d57e5-f134-4140-ba82-cca3fc7d8892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2476b207-a9eb-465f-aa37-5f8d021961aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c3c87ee-aee5-4c23-bfb1-5546ca63708e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8285a2f-d079-4c36-9445-b99276586d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ad55568-6451-4561-9b61-5dd47edb9fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52963446-204b-4ac0-85d7-492d96a5f873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 330932ac-15ce-4424-8d2f-788d198198f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad1bd8c-7e85-4d90-9076-4566b7042d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74e5ee38-4ea6-42bc-b6d5-f23b9445d978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0932c8e-4573-4543-81f7-479b76bdc0ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac1af5c8-f9f0-420e-ab50-7667c9f419a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86bea9f9-e57d-450b-b8e0-4beda2f38735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3be5979e-f5d0-4dc1-b56f-33483ffb6eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bf14ada-f79f-489a-9928-ac582810557c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3015b209-1e9a-4188-a3fe-e9cd357cad96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed11767-53dd-4cd6-b333-6fa914b57c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f7d3e2a-e692-4641-8799-59d26e76496a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cca8d22-627b-43b9-a2dd-e6f43cc9b738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 216597da-4ad0-472f-963c-daa94d92c8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ad95044-a8d6-4cc2-86c2-5feaa9dfce9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d876298-f9d7-4791-8ffb-d7dfb2fa2df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 693de123-806d-4d0f-9d14-fc0f5d015155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 894752c1-a6de-429e-beb2-e4bbee638e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5f66c4e-5d5a-4720-afe6-dfa06b055796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 827f1e1d-f08d-4736-8892-aa3f73c7b718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdec29b3-ec7b-4e5f-9bdc-d3fb0a17e39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da586f23-c455-405c-a6e3-bfcaa062fa78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a778ea61-13f8-4e03-9929-1dbd4320d805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ced6998b-4b2e-4a9c-a372-f4e8b9b16dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76b4d85a-aeae-4432-8c2a-6736412d4b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5fc6ec0-1487-4f9c-93f7-c7709db99bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16fcd265-b4ac-406e-a129-83d7b9af3e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d695060c-e227-41b5-9b5f-d5afa2576ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 233d2047-568e-4aac-8da7-90f2ad1e5df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46de1087-bba6-431c-a42a-388d2c2b9925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de2a6f54-64c8-4a63-b99f-697e151d12b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26861bca-4c70-434b-ad40-c33de5073aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ce6f6c-f3dd-4ec8-9417-9e605399c7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82a69711-54b0-4f04-afb2-65baceadc364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7779234-b692-4444-bac6-73c6a49ef3e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82924c04-2946-4a92-b927-b9bbbbfcdb5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca43ac6-568f-49e6-b10e-fa9f13ab2aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff9f7208-c201-46a5-9492-2c15c21ff471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca3c421c-f481-41a2-aa10-7e775144e5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17a02031-faea-4f5d-b107-272204b41c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 100d25c7-7a35-43d2-b50f-8a65c5396b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e1133ec-62e4-4ff0-bbb6-9dfefcc6b287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 847e1005-ae83-4262-a010-687417d0b364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34e621f0-6417-43c7-9a79-f7bcac79233e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7e170d4-c925-4823-834d-333622ee09cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12fec859-831b-4d31-b698-ec4c19791da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d5f210-54c3-4430-922a-186fd59c1c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e861e8d-d8ea-4a15-89a3-a52609d87dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89b3a3e0-350a-4ed7-b81f-09166c93fd1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c15733f1-4fd3-4295-b026-7f454272529a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aea3de39-3f1b-44a9-897f-8cbafcf23110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b488cb-c42e-46cc-86a8-f8946237f60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 198bad8f-4c8f-4687-b544-0a2603267951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c81f9f2-1b68-44d8-9eb5-f30fd7977a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50d415bf-a30d-486c-b05c-26b9798d3118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf154e88-94c2-427c-8329-4ea6e2f1a95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613ad368-fee7-43d0-835d-1f1194b6145f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f886765-2753-40a0-8845-c44d83ef2005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 225a7bfd-a767-4c90-a2c2-29f99736de5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a22ccc51-b61b-46e0-b69b-aea7efaae4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cb8356c-c938-4c68-b7b2-d43bfaa7cc3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee32faa3-7189-449e-8ac7-2efc1e790d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c5e83f-804d-4743-92f2-1e0165ee52be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba9b77c2-8940-4b46-9ecb-4d54e6154827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82421f34-0855-4681-8c7c-414f810d5522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2f5b69b-58c8-492c-b337-ec2280080f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aed0a4f-c346-4a49-90ba-a4604bef1080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f836d669-594b-4808-88b9-91e73fe03783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25953aa4-332b-4cd1-8646-836640345b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d16cdfba-c4da-4ea1-bb3e-32c77014a6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6420b626-7392-4c4f-937a-1440299f17b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7833538e-c5b5-4c72-9245-ffd8cda93450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76a7dded-4e20-40c5-9679-ac0390560285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd574593-c64a-4097-a905-518a65a63874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1321581a-20ad-4424-be6e-a045524e8944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34c3efc6-2ce6-46ac-be76-8c8a595bdd47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4187f321-ceb4-4b09-9781-e839afc83b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 206fe87a-5f41-4aae-88d8-c339a9b1187c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6998f9a3-540b-4d9a-a8cf-89ba9cdf3833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5a6a857-67dd-42ba-a9d6-b3c9bae1888e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ac7ccb-c460-40df-a3fb-acef1d727b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88e12de8-96a3-4d34-a1b1-6a8ac1f76465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4be5aaa-a778-4b87-b041-2a6d26bfefa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f24c2ae-b644-44c5-866f-6f262dae4359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bf37e58-7746-4c99-9d94-5098f622ec8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9f209b8-0a72-4653-99a9-ed6f76ee02be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79422538-f1c1-471a-aeab-92fadceb016f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27b283ac-90af-4577-91dd-80613530de91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95bf721a-2d0b-4f18-97c7-3d275c886c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2307535a-2b37-4031-b3b0-bcc5f296f3fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb189f39-3692-4b0d-a36a-a3f6bdbd66ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b9db7e-22be-4f13-b667-ada7f2840f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca01a8f4-0ac8-4df1-9f3a-69827416435c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7d8e452-33fd-461d-84a4-b4fd685668e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6513743c-9b1e-4414-b5ca-b597c4bb628d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 603e33aa-6753-4a38-b5ba-34411c4a08f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fa08a3f-bb88-4452-91b4-262627b499c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a1eec5c-f55a-4596-a857-769e0bd76e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2229ef35-3485-4308-b8b1-810ce13cf165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 192b3f1c-ea87-4ac9-9426-01ae8484d1ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66fb786-21e6-4312-aa77-452f7bb0af00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818d540d-3bc6-4b64-a296-97f95f691efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76877140-55a6-4e13-b865-23a33403e6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c7c8ff0-53de-4155-b14f-6bfdbc36b5d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b58e893-d48d-4412-8098-a95132a2fcef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f65ad4d-4fc0-47a0-9e8e-0a8543983a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eedb9824-f4c7-4a66-bc95-4ee233a3d86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 614f3834-68a5-403f-b519-67621edc4dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f34698-53f1-40fd-9310-5dfd85e44716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d9ad32d-6d9f-4742-8430-effc60e27580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a189a85e-937e-429b-a080-75979ccd9578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73bd1fea-1583-467f-a8e3-bf2a671953fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb10e31a-65eb-45e9-930b-5cecb7ecd736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 499e759a-1283-4642-856d-82792e8ba66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab6cca41-4a55-464b-9e18-563ef7acd679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5c6b356-287e-41ca-bc24-646ab06ee3f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a005700-4536-4ab4-ab4e-abd6b821e23e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9edb227-0f11-4295-bda8-e4d895088c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d40be02-e57d-4950-b9cd-af6117e8c08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75102294-d279-45dc-91c1-abb488357384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15b40ca5-04e2-4730-9d54-f3aaa0191cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e402829f-c17e-4efe-bb05-1ed0da19be18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aeb917a-8098-45d2-ae4a-e01ff6612d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ccb1ad4-3650-49b6-b94b-2215b16de434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a22a5c5e-3df7-4c2b-a800-9f5b810aef92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50046e51-8f54-4b71-ad80-ceed9ae14db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95923819-c40e-4f45-b47e-9efba2d07294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 457b0680-04c3-4718-b7b3-49ae3cc1af76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90c598c0-c373-42b7-9dea-6af25ddc8a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e3351a3-4def-4a99-a06b-912fb4549efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44bb5c96-9cf5-4487-98b8-241f8025e6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0968d97-e28a-49ff-afe6-16ae882154b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f8a19e-cfdf-44e3-ba21-fa925d0774a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07843da2-2884-4aee-af1b-07463c2627a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32b67706-fdc4-40c8-8440-6e502fc9073e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0943118-a31c-4773-90e6-610370cf2344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc5337fd-1654-4c82-9fe3-92eb6c308452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca39c081-cf2a-456a-955d-27e4414b881e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40154e51-209a-4fb5-b1e2-f5fe83e5227e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dee5a59-3118-49ba-b402-de7401e837ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c38641ad-6789-4920-8425-5a817a485500
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_80
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/test_labels.txt

📊 Raw data loaded:
   Train: X=(1172, 24), y=(1172,)
   Test:  X=(294, 24), y=(294,)

⚠️  Limiting training data: 1172 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  285 samples, 5 features
✅ Client client_80 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 10 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1029, val=0.0928 (↓), lr=0.001000
   • Epoch   2/100: train=0.0825, val=0.0932, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0813, val=0.0927, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0810, val=0.0927, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0808, val=0.0926, patience=4/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0782, val=0.0896 (↓), lr=0.001000
   • Epoch  21/100: train=0.0616, val=0.0849, patience=4/15, lr=0.001000
   📉 Epoch 25: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0558, val=0.0896, patience=14/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 10 Summary - Client client_80
   Epochs: 32/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0652, RMSE=0.2554, R²=0.1986
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.1043
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1653, RMSE: 0.4065, MAE: 0.3312, R²: -1.1003

============================================================
🔄 Round 12 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1182, val=0.0820 (↓), lr=0.000500
   • Epoch   2/100: train=0.0876, val=0.0845, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0850, val=0.0819, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0842, val=0.0822, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0841, val=0.0819, patience=4/15, lr=0.000500
   • Epoch  11/100: train=0.0838, val=0.0817, patience=10/15, lr=0.000500
   • Epoch  21/100: train=0.0830, val=0.0810, patience=6/15, lr=0.000500
   • Epoch  31/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000500
   ✓ Epoch  41/100: train=0.0772, val=0.0747 (↓), lr=0.000500
   ✓ Epoch  51/100: train=0.0692, val=0.0661 (↓), lr=0.000500
   ✓ Epoch  61/100: train=0.0659, val=0.0636 (↓), lr=0.000500
   • Epoch  71/100: train=0.0635, val=0.0623, patience=2/15, lr=0.000500
   📉 Epoch 80: LR reduced 0.000500 → 0.000250
   • Epoch  81/100: train=0.0603, val=0.0631, patience=12/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0623)

============================================================
📊 Round 12 Summary - Client client_80
   Epochs: 84/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0631, RMSE=0.2511, R²=0.2496
   Val:   Loss=0.0623, RMSE=0.2496, R²=0.2402
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1552, RMSE: 0.3940, MAE: 0.3213, R²: -0.9727

============================================================
🔄 Round 13 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1265, val=0.0800 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0876, val=0.0764 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0861, val=0.0746 (↓), lr=0.000250
   📉 Epoch 4: LR reduced 0.000250 → 0.000125
   • Epoch   4/100: train=0.0856, val=0.0749, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0855, val=0.0748, patience=2/15, lr=0.000125
   • Epoch  11/100: train=0.0853, val=0.0749, patience=8/15, lr=0.000125
   📉 Epoch 12: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 13 Summary - Client client_80
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0004
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0052
============================================================


============================================================
🔄 Round 15 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1290, val=0.1112 (↓), lr=0.000063
   📉 Epoch 2: LR reduced 0.000063 → 0.000031
   ✓ Epoch   2/100: train=0.1088, val=0.0923 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.0962, val=0.0858 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.0908, val=0.0817 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.0876, val=0.0794 (↓), lr=0.000031
   📉 Epoch 10: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0850, val=0.0778, patience=2/15, lr=0.000016
   📉 Epoch 18: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0849, val=0.0778, patience=12/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 15 Summary - Client client_80
   Epochs: 24/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0006
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0070
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1335, RMSE: 0.3654, MAE: 0.2989, R²: -0.6963

📊 Round 15 Test Metrics:
   Loss: 0.1004, RMSE: 0.3169, MAE: 0.2662, R²: -0.2762

============================================================
🔄 Round 20 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0856 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   ✓ Epoch   2/100: train=0.0907, val=0.0847 (↓), lr=0.000004
   • Epoch   3/100: train=0.0898, val=0.0843, patience=1/15, lr=0.000004
   ✓ Epoch   4/100: train=0.0893, val=0.0840 (↓), lr=0.000004
   • Epoch   5/100: train=0.0888, val=0.0836, patience=1/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0867, val=0.0823, patience=3/15, lr=0.000002
   📉 Epoch 18: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0857, val=0.0818, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0853, val=0.0816, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 20 Summary - Client client_80
   Epochs: 39/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0155
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0022
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2491, R²: -0.0498

============================================================
🔄 Round 23 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 23 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0077
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0009
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2455, R²: -0.0173

============================================================
🔄 Round 25 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 25 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0033
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0041
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2445, R²: -0.0098

📊 Round 25 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2444, R²: -0.0089

============================================================
🔄 Round 32 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 32 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0002
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0048
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2443, R²: -0.0086

📊 Round 32 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2443, R²: -0.0084

============================================================
🔄 Round 34 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 34 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0062
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0094
============================================================


============================================================
🔄 Round 35 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 35 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0036
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0007
============================================================


============================================================
🔄 Round 38 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 38 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0022
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0029
============================================================


============================================================
🔄 Round 40 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 40 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0000
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0036
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2440, R²: -0.0065

============================================================
🔄 Round 43 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 43 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0010
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0029
============================================================


============================================================
🔄 Round 45 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 45 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0033
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0136
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2439, R²: -0.0056

============================================================
🔄 Round 48 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 48 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0001
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0016
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2438, R²: -0.0053

============================================================
🔄 Round 53 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 53 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0013
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0010
============================================================


============================================================
🔄 Round 55 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 55 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0002
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0025
============================================================


============================================================
🔄 Round 57 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 57 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0004
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0016
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2438, R²: -0.0054

📊 Round 57 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2438, R²: -0.0052

============================================================
🔄 Round 60 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 60 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0008
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0072
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2438, R²: -0.0051

============================================================
🔄 Round 67 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 67 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0005
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0036
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2437, R²: -0.0047

============================================================
🔄 Round 68 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 68 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0017
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0063
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2437, R²: -0.0047

============================================================
🔄 Round 70 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 70 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0002
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0102
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2437, R²: -0.0042

📊 Round 70 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2436, R²: -0.0041

============================================================
🔄 Round 74 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 74 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0000
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0005
============================================================


============================================================
🔄 Round 76 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 76 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0003
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0063
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2436, R²: -0.0039

📊 Round 76 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2436, R²: -0.0037

============================================================
🔄 Round 79 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 79 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0012
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0110
============================================================


============================================================
🔄 Round 83 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 83 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0001
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0022
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2436, R²: -0.0036

📊 Round 83 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2436, R²: -0.0037

============================================================
🔄 Round 86 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 86 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0009
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0017
============================================================


============================================================
🔄 Round 87 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 87 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0004
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0005
============================================================


============================================================
🔄 Round 89 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 89 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0002
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0029
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2435, R²: -0.0035

============================================================
🔄 Round 90 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 90 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0010
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0040
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2435, R²: -0.0035

============================================================
🔄 Round 91 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 91 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0014
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0055
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2435, R²: -0.0034

============================================================
🔄 Round 92 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 92 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0001
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0019
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2435, R²: -0.0033

📊 Round 92 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2435, R²: -0.0031

============================================================
🔄 Round 97 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 97 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0003
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0085
============================================================


============================================================
🔄 Round 98 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 98 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0009
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0108
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2435, R²: -0.0032

📊 Round 98 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2435, R²: -0.0031

============================================================
🔄 Round 103 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 103 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0010
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0016
============================================================


============================================================
🔄 Round 104 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 104 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0007
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0074
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0029

============================================================
🔄 Round 105 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 105 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0010
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0054
============================================================


============================================================
🔄 Round 107 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 107 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0005
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0167
============================================================


============================================================
🔄 Round 108 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 108 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0005
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0004
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0027

============================================================
🔄 Round 109 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 109 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0015
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0059
============================================================


============================================================
🔄 Round 112 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 112 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0002
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0025
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0026

============================================================
🔄 Round 115 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 115 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0003
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0047
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0028

============================================================
🔄 Round 118 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 118 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0013
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0001
============================================================


============================================================
🔄 Round 119 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 119 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0013
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0034
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0026

📊 Round 119 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0026

📊 Round 119 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0026

============================================================
🔄 Round 125 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 125 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0021
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0106
============================================================


============================================================
🔄 Round 127 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 127 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0015
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0058
============================================================


============================================================
🔄 Round 128 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 128 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0005
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0055
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0025

============================================================
🔄 Round 129 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 129 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0004
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0077
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0024

============================================================
🔄 Round 133 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 133 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0004
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0074
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0023

📊 Round 133 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0023

============================================================
🔄 Round 137 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 137 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0006
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0000
============================================================


============================================================
🔄 Round 139 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 139 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0018
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0074
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0021

============================================================
🔄 Round 140 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 140 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0007
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0056
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0023

============================================================
🔄 Round 142 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 142 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0000
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0042
============================================================


============================================================
🔄 Round 143 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 143 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0005
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0014
============================================================


============================================================
🔄 Round 145 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 145 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0018
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0037
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0025

📊 Round 145 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0025

📊 Round 145 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0026

============================================================
🔄 Round 150 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 150 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0010
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0005
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0027

============================================================
🔄 Round 152 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 152 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0000
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0041
============================================================


============================================================
🔄 Round 153 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 153 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0007
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0017
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0027

📊 Round 153 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0027

📊 Round 153 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0026

============================================================
🔄 Round 156 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 156 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0004
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0022
============================================================


============================================================
🔄 Round 157 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 157 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0002
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0214
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0026

============================================================
🔄 Round 159 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 159 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0001
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0011
============================================================


============================================================
🔄 Round 160 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 160 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0012
   Val:   Loss=0.0945, RMSE=0.3075, R²=0.0072
============================================================


============================================================
🔄 Round 161 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 161 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0004
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0017
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2434, R²: -0.0025

============================================================
🔄 Round 162 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 162 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0014
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0096
============================================================


============================================================
🔄 Round 163 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 163 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0015
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0041
============================================================


============================================================
🔄 Round 165 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 165 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0007
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0015
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0023

============================================================
🔄 Round 167 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 167 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0007
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0040
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0023

============================================================
🔄 Round 169 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 169 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0011
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0020
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0020

============================================================
🔄 Round 174 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 174 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0002
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0003
============================================================


============================================================
🔄 Round 175 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 175 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0013
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0042
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0022

============================================================
🔄 Round 177 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 177 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2909, R²=0.0002
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0005
============================================================


============================================================
🔄 Round 178 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 178 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0018
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0037
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0021

============================================================
🔄 Round 179 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 179 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0006
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0006
============================================================


============================================================
🔄 Round 180 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 180 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0003
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0036
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0022

============================================================
🔄 Round 182 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 182 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0024
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0070
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0022

============================================================
🔄 Round 184 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 184 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0004
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0017
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0022

============================================================
🔄 Round 185 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 185 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0009
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0001
============================================================


============================================================
🔄 Round 187 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 187 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0030
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0216
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2433, R²: -0.0023

============================================================
🔄 Round 189 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 189 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0002
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0079
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0023

📊 Round 189 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0022

📊 Round 189 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0021

📊 Round 189 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0021

============================================================
🔄 Round 195 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 195 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0002
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0001
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0020

📊 Round 195 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0022

📊 Round 195 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2433, R²: -0.0023

📊 Round 195 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0023

============================================================
🔄 Round 201 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 201 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0008
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0093
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0022

============================================================
🔄 Round 202 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 202 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0008
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0005
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0021

📊 Round 202 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0021

============================================================
🔄 Round 204 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 204 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0014
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0014
============================================================


============================================================
🔄 Round 205 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 205 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0002
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0012
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0021

📊 Round 205 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0023

📊 Round 205 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2433, R²: -0.0022

============================================================
🔄 Round 210 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 210 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0012
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0004
============================================================


============================================================
🔄 Round 211 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 211 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0009
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0009
============================================================


❌ Client client_80 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
