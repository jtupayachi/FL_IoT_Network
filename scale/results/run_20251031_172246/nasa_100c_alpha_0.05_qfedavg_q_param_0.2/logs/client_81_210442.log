[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b216a19-bfb8-4fec-af20-92218dd55bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 360ae0d2-f233-4c5c-8d47-dcc949dc10f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d080fe25-d043-4615-a0f8-71659c1b5eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c710174f-c674-4191-916b-60684077a38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52d64238-e497-4c77-be6e-e170a34d23f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c28ead3b-ed17-4483-820d-b0437a8c3810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b3532b2-3c39-4afc-a7b7-d30fcad52ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3dc4a22-ae0a-41e4-99e0-a57eef6e220a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23fa0c2f-8698-484e-b144-5e7a76a1be35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e448bff-5e34-4946-be8c-33afeec0f2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f08e528-f886-41d7-8306-f7172bc2d3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bed96792-820f-4eaa-b097-8258d133f7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e508999-d9c5-4381-9d8a-5c914be04e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfefdb1f-44ba-4400-af88-2847794d95bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e0ddd26-ff35-4784-9135-426fd5a3f46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 698a5ae5-1499-49e8-9357-96ca2f026945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b2f0d06-acce-4c61-9fe7-ebdc81946be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 821eb9f2-836f-43e1-8461-8f9993466bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda4489c-b2f2-4094-9298-865ccbca4fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8941e9b-fc5b-4b2f-977a-083cfee3a3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb8088ca-d470-450a-a243-dedba272c929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc9103f-929f-4460-918b-b532913f4b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c114bc1-63b4-4f8f-b1d7-5916300503c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b8210f9-fc49-4b34-9d13-a2d35d1e15ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b306b9a-22fb-44fe-b1bd-cde9ac055631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4949c01a-e9e4-4508-aa89-4026cf853cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 062bf507-7c1c-4194-9e71-d70179ebec63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11bd9e1c-a210-4a7d-985c-677515ab4f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e79da28-1e11-4c50-9190-e175896b8b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d495f270-daa3-4a65-b826-23362427e3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4f2026d-6628-4bab-8d71-467598d7d5c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cc14005-95b8-43c2-99a3-de15107b1140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86bb83e8-83bb-4c0d-83f9-049b288109e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baaee47a-2280-4650-8eec-99b622d29d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3aba7a8-46bc-44d7-88f4-fac041bb88c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fc741f3-a389-4268-8419-0f652f8f27a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e062de16-89ae-487f-ae66-d44d65646912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 322d4bf9-bebb-4d52-bc3a-4cf8f595c213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1cb247c-f479-44ff-b32a-dab421e3d177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89360441-80f6-48fa-8430-27b1f5f55c96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f83eab76-96e2-42af-b9dc-9f189c3e8ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7dfd42f-5d9e-4284-a568-e2d52e8e0e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a7a6c16-d1da-4ef6-b855-4f8a0eba4d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d993384-2692-4587-bb80-f5778c256b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc8b98b-9c9e-4b12-9493-bce3590db6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb62bb3b-0c52-4038-a21f-284a38ed3294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12b2bdb2-56eb-4ca1-9411-ce2a06a50af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f3b5493-1b3b-46bd-8636-e6fb3bb72602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1241913-f5f0-4508-8da0-153ea883b034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c08449f-93d7-473b-8c40-155b25c1a280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e008499b-4dd8-4fdd-86dc-2663aa9d2b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93a50f83-67e4-40e7-bb25-107ef1ba8570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 606f7237-9045-4d09-aeeb-e7113055860f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97001023-15b2-44ae-8dc2-e746385a8c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9142aafc-31ed-4498-8696-1a5c9f23bb2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cf39b0b-fbd2-4d4d-bd29-c8b0d6786e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d0df62-8e04-4bbb-82a2-2de30deec9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5595ae3-5379-46e4-a248-70b5257466e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fadf8578-0aea-4556-bf4b-c5260da449f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff7f4ec6-efb4-4f49-bd86-141875e8ef33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dfee037-c6f2-4632-8aed-b449cd19d846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3c7c523-3cc6-4ce8-9f80-c2f63e338674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfbe44be-2415-415a-8cce-44a4c6b39cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31cd51b7-95bf-449e-83ed-b536d328f262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2570a384-1139-421c-adaf-2c1e876ba662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae25fc0-7081-4492-9544-1ffdd5ad0003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06665567-a3aa-4777-b480-b5be30561cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 833aadeb-f91a-4c9d-a33b-b8ef65fbd117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3691c46d-3b2d-4293-866d-0cc057ca795b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aaebb0a-d149-4c99-8abd-0d1208f319a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f6ffd8-d761-4c81-8bec-8c480b77ff4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 542d37d1-be21-4369-81b6-f8288b511acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4be46de-5101-4678-ac49-f70d00f15172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb3446f5-6ca3-467c-97db-6f4f156f4d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 274f4420-eb44-47a1-b2cb-fee985fa787c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7de4f1a-52a5-4b4e-9ed0-8ade117f7b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20eb344c-56f5-4c30-9773-b0e6124bbd7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7beb3638-8346-4834-a823-b7109016de4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1500cff2-2e83-4a5d-a0a8-c04fe8324f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b1110e4-b5f2-4e25-b4fb-8efe148a8125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98022f96-77e3-4aa0-838c-7cc54738d0d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 412bc43a-2a20-4e27-ac8b-8db2f9fd4650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd62b03-6e27-418f-a0ad-c266abe9be0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3013ab5e-6e92-4925-8c9d-2a4e125852de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f82db4f3-5bdd-425c-997b-0e9ff19664b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f30b529-480e-415d-99e1-d44e92fa170b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5e7be53-77bc-4d98-88a4-9abb215c52a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc58e308-a804-4039-9b12-d6af3f454a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9bf623f-22cb-4107-ab93-2811bbe53d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e7703c2-00b9-4578-b5cf-de4fc7df3558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc73e8ee-0ef3-4a57-9561-6ffb55b6e02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29bcca02-ac53-4345-b2ee-7090db6170b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ffe0a4a-3135-4c60-b534-97a3cf5adf44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d019cacc-147d-4d6a-836f-eb45ada28727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b23b8992-1753-4e2c-a32f-6176aca4370b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e908d12-ded0-42a7-85a4-351f2967d7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ed684a-0bde-40cb-ac71-a9071f86bf7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dcfa5ef-9f81-4932-9d54-449d358e3220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c8616e6-b67d-49fa-b571-b3ed29f2eb9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e902787f-6157-4a25-87c9-f34990acaf1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fa6d358-fc8a-4b20-92e8-fcf23374f62c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 661066d1-1be7-4582-8cfe-7773a59f94cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1be484a-9a52-43ed-919e-63892a011c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8b62715-3c0c-4971-80ab-763d8a659d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88239cf1-3231-4ef8-890a-a17198e0282b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67e8dcf1-dc54-4d8b-99d0-3f5eb3401a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db03a55d-b1fa-4d4a-835b-de7646328bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5c650aa-35eb-44b1-a792-406a3b640062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ebe5704-4433-42a6-8261-3caa036c1504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81288bed-7601-49a5-b55e-87e561ada165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51520ccc-0d06-4c3b-8e0a-084111b5c19b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efb973ea-5b8c-40b3-a82c-59fe098570a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5bf785a-3477-4cb6-9ea6-0065f48dd0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e3c77cb-51d3-479d-a1a2-574c32f06574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a17c9f5-dfee-4952-8f4b-c82b74b4db3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b4dae11-2f67-411e-8da4-d44b9846155f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7171c77a-8708-4a3d-8b67-ac1fcf89e14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 402213c9-4182-4c8d-a426-ae3d0fa17936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3094305-427c-4746-a7ef-15efad65f4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eae89488-e132-4358-b2b5-b506b38810c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d71437c9-b76a-4e9a-9277-b303f477845d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c95ff4-623c-43c1-a465-72d78ea77f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df4a08a1-f737-4a71-8a02-13748e1b4ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7f2d5f-8fae-4630-85ab-c84ae0ce6aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc86d4ab-afd4-4958-9622-8c5431cb5192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c6c3b89-a889-45e3-bf84-fee0ec0e149a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c185c421-d6d1-49df-9a53-2d9aec83f726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef68c7e-ae55-4135-a572-700e5d884392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e582c2e-67a7-4ec3-943b-3e7f221b2019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf370f79-6f38-4951-aeb3-abe6b87959ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3d3806a-7ed6-4b39-8ce3-630442113d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33d44804-4747-475c-ba02-a3c789d9aae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20facf7c-f9ab-4137-a008-68c036c82127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d6cafa-2a39-4d24-98c7-85b720791842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1023f4d1-21a0-4b80-a10d-00a31be1ad12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6204723a-5c7a-4b41-9b4c-de8cbb16a0ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97e858c3-682b-4800-865d-818b474c505c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22dcd77d-7ffa-490e-b305-413d31a22152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3436970-ac6b-405e-9a55-ee03e6bce2eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 646eca78-c639-4121-8513-da039fbd637f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4b8e746-20b2-4998-a506-cfd7ec3d03eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31cece39-d86f-4e45-a670-53c19229815c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c65b1dc-b06a-4897-aaed-a267a287260f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4488fd6e-678a-4714-a2f4-eb2e06a90a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5c5e9cd-5f04-4b41-9316-636edef20cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e45a5b86-8b8d-44fa-beac-4f69c824f183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40fdf40d-dfc0-4cd4-901c-247a96e321ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f44460f7-9b5f-4fa6-a2dd-978dda4711e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f0edfc3-91d3-454c-931f-772b93db7aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36000c0e-8ad3-4847-852d-4f64ea0beb95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6284fd-a309-40df-9988-3baf8cecbde5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74681533-d87c-4428-9200-5d6e9b528efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 806bca7a-f874-43c2-b48c-ca7c8a52b2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24557736-bea6-46d9-898d-acd7d78dca56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c56a4d-6e86-4aef-a6e8-30a378c35a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388c8e30-3518-421e-8012-b2e636572e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41be0a58-fcd0-46b3-bb7e-9a9453d6be56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6eddff6-bbe5-486b-819e-83e204af6ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0500d4a0-34d4-42ca-98b0-630d405f69e5
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_81
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/test_labels.txt

📊 Raw data loaded:
   Train: X=(1208, 24), y=(1208,)
   Test:  X=(303, 24), y=(303,)

⚠️  Limiting training data: 1208 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  294 samples, 5 features
✅ Client client_81 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 9 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1034, val=0.0768 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0849, val=0.0759 (↓), lr=0.001000
   • Epoch   3/100: train=0.0823, val=0.0770, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0821, val=0.0775, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0820, val=0.0779, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0804, val=0.0809, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 9 Summary - Client client_81
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0045
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0012
============================================================


============================================================
🔄 Round 10 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1310, val=0.1098 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0863, val=0.0839 (↓), lr=0.000250
   • Epoch   3/100: train=0.0803, val=0.0865, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0803, val=0.0859, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0802, val=0.0860, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0795, val=0.0862, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 10 Summary - Client client_81
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0015
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0091
============================================================


============================================================
🔄 Round 11 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1513, val=0.1268 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1271, val=0.1064 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1067, val=0.0915 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0918, val=0.0826 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0837, val=0.0801 (↓), lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0810, val=0.0806, patience=6/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 11 Summary - Client client_81
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0014
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0133
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1504, RMSE: 0.3878, MAE: 0.3117, R²: -0.8097

============================================================
🔄 Round 12 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1485, val=0.1556 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.1422, val=0.1487 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1374, val=0.1455 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1345, val=0.1425 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1318, val=0.1397 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1182, val=0.1262 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.1099, val=0.1176, patience=1/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.1067, val=0.1142, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1047, val=0.1121 (↓), lr=0.000001
   • Epoch  51/100: train=0.1028, val=0.1101, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1010, val=0.1081, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.0992, val=0.1062 (↓), lr=0.000001
   • Epoch  81/100: train=0.0976, val=0.1044, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0960, val=0.1027, patience=2/15, lr=0.000001

============================================================
📊 Round 12 Summary - Client client_81
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0946, RMSE=0.3075, R²=-0.1662
   Val:   Loss=0.1012, RMSE=0.3180, R²=-0.2040
============================================================


============================================================
🔄 Round 13 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1444, val=0.1588 (↓), lr=0.000001
   • Epoch   2/100: train=0.1441, val=0.1584, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1437, val=0.1580 (↓), lr=0.000001
   • Epoch   4/100: train=0.1434, val=0.1576, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1431, val=0.1573 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1413, val=0.1553 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1387, val=0.1524 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1363, val=0.1497 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1340, val=0.1471 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.1317, val=0.1446 (↓), lr=0.000001
   • Epoch  61/100: train=0.1296, val=0.1422, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1274, val=0.1398, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1253, val=0.1374 (↓), lr=0.000001
   • Epoch  91/100: train=0.1232, val=0.1350, patience=1/15, lr=0.000001

============================================================
📊 Round 13 Summary - Client client_81
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1209, RMSE=0.3478, R²=-0.4778
   Val:   Loss=0.1329, RMSE=0.3645, R²=-0.6509
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1298, RMSE: 0.3603, MAE: 0.2918, R²: -0.5625

============================================================
🔄 Round 16 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1262, val=0.1294 (↓), lr=0.000001
   • Epoch   2/100: train=0.1259, val=0.1291, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1257, val=0.1289, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1255, val=0.1287 (↓), lr=0.000001
   • Epoch   5/100: train=0.1252, val=0.1284, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1239, val=0.1270, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1217, val=0.1248, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1195, val=0.1225 (↓), lr=0.000001
   • Epoch  41/100: train=0.1174, val=0.1203, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1153, val=0.1181, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1132, val=0.1160 (↓), lr=0.000001
   • Epoch  71/100: train=0.1112, val=0.1139, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1092, val=0.1118, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1072, val=0.1098 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_81
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1047, RMSE=0.3235, R²=-0.2851
   Val:   Loss=0.1080, RMSE=0.3287, R²=-0.3055
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1212, RMSE: 0.3481, MAE: 0.2841, R²: -0.4584

============================================================
🔄 Round 17 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1219, val=0.1237 (↓), lr=0.000001
   • Epoch   2/100: train=0.1217, val=0.1234, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1215, val=0.1232, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1213, val=0.1230 (↓), lr=0.000001
   • Epoch   5/100: train=0.1210, val=0.1228, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1198, val=0.1215, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1177, val=0.1194, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1156, val=0.1172 (↓), lr=0.000001
   • Epoch  41/100: train=0.1136, val=0.1152, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1116, val=0.1131, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1097, val=0.1111 (↓), lr=0.000001
   • Epoch  71/100: train=0.1078, val=0.1091, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1059, val=0.1072, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1041, val=0.1053 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_81
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1021, RMSE=0.3196, R²=-0.2470
   Val:   Loss=0.1036, RMSE=0.3219, R²=-0.2823
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0963, RMSE: 0.3103, MAE: 0.2609, R²: -0.1593

📊 Round 17 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2515, R²: -0.0117

============================================================
🔄 Round 22 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 22 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0007
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0175
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2521, R²: -0.0027

📊 Round 22 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2522, R²: -0.0026

============================================================
🔄 Round 26 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 26 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0010
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0063
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2524, R²: -0.0026

============================================================
🔄 Round 28 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 28 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0022
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0077
============================================================


============================================================
🔄 Round 29 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 29 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0002
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0144
============================================================


============================================================
🔄 Round 30 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 30 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0003
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0049
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2526, R²: -0.0030

📊 Round 30 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2527, R²: -0.0030

============================================================
🔄 Round 33 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 33 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0018
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0140
============================================================


============================================================
🔄 Round 35 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 35 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0005
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0010
============================================================


============================================================
🔄 Round 36 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 36 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0021
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0099
============================================================


============================================================
🔄 Round 37 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 37 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0012
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0017
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2528, R²: -0.0033

📊 Round 37 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2528, R²: -0.0035

============================================================
🔄 Round 40 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 40 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0001
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0070
============================================================


============================================================
🔄 Round 46 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 46 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0015
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0036
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2529, R²: -0.0038

============================================================
🔄 Round 48 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 48 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0028
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0040
============================================================


============================================================
🔄 Round 52 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 52 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0005
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0081
============================================================


============================================================
🔄 Round 53 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 53 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0002
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0300
============================================================


============================================================
🔄 Round 56 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 56 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0021
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0004
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2530, R²: -0.0039

============================================================
🔄 Round 57 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 57 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0005
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0047
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2529, R²: -0.0039

============================================================
🔄 Round 59 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 59 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0060
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0020
============================================================


============================================================
🔄 Round 60 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 60 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0009
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0103
============================================================


============================================================
🔄 Round 61 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 61 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0010
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0122
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2530, R²: -0.0040

============================================================
🔄 Round 64 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 64 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0001
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0045
============================================================


============================================================
🔄 Round 65 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 65 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0018
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0067
============================================================


============================================================
🔄 Round 67 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 67 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0023
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0056
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2530, R²: -0.0042

📊 Round 67 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2530, R²: -0.0041

📊 Round 67 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2530, R²: -0.0042

============================================================
🔄 Round 70 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 70 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0011
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0104
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2531, R²: -0.0043

📊 Round 70 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2531, R²: -0.0043

============================================================
🔄 Round 72 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 72 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0022
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0055
============================================================


============================================================
🔄 Round 73 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 73 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0022
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0054
============================================================


============================================================
🔄 Round 74 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 74 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0042
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0096
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2531, R²: -0.0045

============================================================
🔄 Round 77 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 77 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0017
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0048
============================================================


============================================================
🔄 Round 81 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 81 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0024
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0040
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2531, R²: -0.0046

📊 Round 81 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2531, R²: -0.0046

============================================================
🔄 Round 86 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 86 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0013
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0003
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2531, R²: -0.0045

============================================================
🔄 Round 87 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 87 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0015
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0034
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2531, R²: -0.0046

============================================================
🔄 Round 89 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 89 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0013
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0116
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2532, R²: -0.0047

============================================================
🔄 Round 91 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 91 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0021
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0017
============================================================


============================================================
🔄 Round 94 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 94 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0013
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0021
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2532, R²: -0.0049

============================================================
🔄 Round 98 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 98 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0025
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0011
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2532, R²: -0.0049

============================================================
🔄 Round 102 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 102 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0008
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0229
============================================================


============================================================
🔄 Round 103 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 103 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0011
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0035
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2532, R²: -0.0050

📊 Round 103 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0050

============================================================
🔄 Round 105 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 105 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0018
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0226
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0051

📊 Round 105 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0052

============================================================
🔄 Round 112 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 112 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0005
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0326
============================================================


============================================================
🔄 Round 113 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 113 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0018
   Val:   Loss=0.0975, RMSE=0.3123, R²=-0.0144
============================================================


============================================================
🔄 Round 114 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 114 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0054
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0124
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0051

============================================================
🔄 Round 115 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 115 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0025
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0021
============================================================


============================================================
🔄 Round 118 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 118 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0013
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0037
============================================================


============================================================
🔄 Round 119 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 119 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0015
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0408
============================================================


============================================================
🔄 Round 120 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 120 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0014
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0186
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0052

📊 Round 120 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0052

============================================================
🔄 Round 123 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 123 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0002
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0143
============================================================


============================================================
🔄 Round 128 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 128 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0016
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0062
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

============================================================
🔄 Round 129 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 129 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0009
   Val:   Loss=0.0778, RMSE=0.2788, R²=-0.0077
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

============================================================
🔄 Round 130 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 130 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0022
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0000
============================================================


============================================================
🔄 Round 132 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 132 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0021
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0006
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

📊 Round 132 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

📊 Round 132 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

============================================================
🔄 Round 137 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 137 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0004
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0237
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0054

📊 Round 137 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0055

📊 Round 137 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0055

📊 Round 137 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0054

📊 Round 137 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

📊 Round 137 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

============================================================
🔄 Round 145 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 145 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0004
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0152
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0052

============================================================
🔄 Round 147 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 147 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0059
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0351
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0052

📊 Round 147 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0051

============================================================
🔄 Round 149 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 149 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0002
   Val:   Loss=0.0755, RMSE=0.2749, R²=-0.0157
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0051

📊 Round 149 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0051

============================================================
🔄 Round 153 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 153 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0043
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0063
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0051

📊 Round 153 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0051

============================================================
🔄 Round 155 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 155 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0039
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0051
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0052

📊 Round 155 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0052

============================================================
🔄 Round 158 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 158 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0055
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0019
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0052

📊 Round 158 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0052

📊 Round 158 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0052

📊 Round 158 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0052

============================================================
🔄 Round 163 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 163 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0024
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0003
============================================================


============================================================
🔄 Round 164 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 164 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0025
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0001
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

📊 Round 164 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

============================================================
🔄 Round 167 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 167 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0025
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0029
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0054

============================================================
🔄 Round 168 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 168 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0022
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0041
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0054

============================================================
🔄 Round 172 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 172 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0059
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0045
============================================================


============================================================
🔄 Round 173 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 173 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0023
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0068
============================================================


============================================================
🔄 Round 174 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 174 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0046
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0029
============================================================


============================================================
🔄 Round 175 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 175 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0011
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0274
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0055

📊 Round 175 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0054

📊 Round 175 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0054

============================================================
🔄 Round 178 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 178 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0016
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0076
============================================================


============================================================
🔄 Round 179 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 179 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0052
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0103
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0054

============================================================
🔄 Round 184 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 184 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0049
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0032
============================================================


============================================================
🔄 Round 186 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 186 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0007
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0165
============================================================


============================================================
🔄 Round 189 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 189 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0018
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0109
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0054

📊 Round 189 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0054

============================================================
🔄 Round 192 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 192 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0022
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0524
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0055

📊 Round 192 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0055

============================================================
🔄 Round 195 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 195 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0043
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0034
============================================================


============================================================
🔄 Round 196 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 196 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0009
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0081
============================================================


============================================================
🔄 Round 197 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 197 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0033
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0544
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

📊 Round 197 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

📊 Round 197 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0055

============================================================
🔄 Round 208 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 208 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0054
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0185
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2533, R²: -0.0053

📊 Round 208 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2534, R²: -0.0054

============================================================
🔄 Round 210 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 210 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0019
   Val:   Loss=0.0673, RMSE=0.2595, R²=-0.0250
============================================================


❌ Client client_81 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
