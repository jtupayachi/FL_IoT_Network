[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fad694df-2c72-4a52-a729-0b5eee9a5563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64a5d18-dfbc-4736-9768-070b1b5a7c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ef0d9ed-08c2-44d1-9689-e10f04da9ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04c36e3c-db4b-4390-ac54-8b22db954023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22079613-98ca-4466-9893-0cbba8f265be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e337ecc-4004-4f19-8fbe-19410285c448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17fc8c34-813e-4329-9b22-a1435057b1c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cac53f6-90e9-4b17-b2fa-8ecceab8b0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cb61967-b3cf-477a-9066-5e6b1ecfe91c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97e125d-8c79-4ecb-abd5-55db7f22694d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22e676aa-77b6-4f97-b64a-f631daf32fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb9632d3-5d09-43c4-b4ae-b7d1ab2909e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e018e8d9-c50a-4fb2-8668-0db443d7e3f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1bd7dba-dd19-43ca-afef-0dd11cf7908c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c59fa0b-d1a6-4bdd-a932-8b93dc6eb38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1002658-3679-4f35-8c6d-f9972bb0fa49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3431f870-8387-45fe-aa4d-eaa151dee12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f56203-aec8-439f-a62b-cc105bb177f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32de500b-1b0f-4960-99fe-db733b3e2cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c7d8860-6151-457c-ac03-1675fb0761bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 898d574d-79b6-475d-adb4-971b0292b43f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ce07536-e6de-4767-b92d-47d460210f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3918df35-60b2-4202-85cb-954511ce6724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6372666b-0153-4695-9a80-a3aec54c4355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bd0a3e9-304a-4651-b33b-b15be3c59fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78d45db0-2453-432c-b5f3-5fe04cda1300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c66d852-df6e-420d-a440-79969fc1640e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce939233-b087-4fab-b5cd-bab0eb4a351b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ccdd8f4-8e4e-4b6e-a41b-8174157fbb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a15f9b0-fe3a-42ab-b83c-1b5cb57d28d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52e56f00-41a9-4bd6-9c94-d3813ccfdaba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d0dbf0a-2c42-449f-b168-dc969bb9bd92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d2e18f7-14f9-4184-955d-18f6bc1e608b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9301797d-509c-4685-9baa-21ec020360df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56fa69de-21ff-4749-9a6f-532591e2dd4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27005074-2dc1-448b-8d9b-1a1ec452fdbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7a9ef64-47ff-4a6a-b27f-3e5320ef2c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d045b78c-31db-42dc-b11d-c1aa12bc014a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2013a3e6-17c4-4c0a-b4b6-3acb36373fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d56e3c3c-878c-41f3-b8bf-fe152d2b05e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90b3490e-17ec-46ec-abed-b79699dc24c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8220ae01-4782-4026-897a-9e20ede417c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3294a581-9d6f-4d4f-ae78-5e8fd610898c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57603e5b-f04e-4f1a-8791-881b4721213b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f41ba2e-d1e2-446b-b256-dbbabcc427df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72bd1289-a2ca-456c-a4e1-08ab8dfaebac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fed064a-f1f0-4039-a5c0-1c5f04d55ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72a3c74-941b-471f-b585-6a48307aba4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9eb1c56-048e-4d07-8afa-2c68a7242b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f977fc52-a578-4d1d-b262-83965cff5380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c272d4-1493-41ec-a2b0-f26a2b548634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a6124ff-1906-44a8-ad93-1c27e23a0524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a44ec5ea-9f7c-4a1b-a5e5-76a956d17a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5c16ff-4bb9-48db-bc0d-2af807d0ba95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11fe79c2-1a5e-4124-adad-4e64002da4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 304a2764-1638-479f-bb75-99effd78b5c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 236df85f-bce7-4b9e-b6a5-8466b2751322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa80bebd-0a05-41cd-adf7-9e1c4b8a5e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2704581-1063-46f4-94c6-5dd432ef8388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e1bfa1c-a3e8-45a1-8098-b9478918b4b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d685174-e758-4ad8-9151-9deebb4e13ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a9dee54-f908-4fa8-bd7b-87e7ae60fc51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bfcb22c-125c-4760-a681-6cd04ecd8d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545d2383-53f9-4002-8a27-2a9406cd52ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e19e4a55-9690-4e6c-94f3-c55d08a89a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 988ef22a-a39b-4e94-89b6-23e6ef462fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23ed5da-23cd-4b9c-9790-994792bb8b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d26504a4-ecb3-4119-9cab-1227ac35abfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b456662-2af5-4a08-97d3-cfaa054eba37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e248caca-b82e-455a-8985-2683fcf06527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3f79532-a980-4a95-a633-4b550eebb25c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7124947e-0f2d-4ba5-89a9-e340a6f9a5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b0d457-2e90-4450-a9eb-96c78b5065e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1332b1d-ec14-49f0-94f0-8529c092533a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 066d0932-8111-4e02-ba46-9b01f79bd282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 361712cd-0423-48bd-ab7d-ee519f041198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495ca512-19f0-479e-9977-9ab457dc3b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b36a4acd-32a6-4431-967e-8d3cb45754d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bee36ff-9f55-4d5c-9ea3-f371a9e01f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68cafe9-5b54-44bf-b78e-a0981b23b8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d825f4e3-69b4-4977-950b-8261693fe9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd04c325-a321-4306-a70c-92db5802d2ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e059a5df-7558-4605-bad5-03ab809de4a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5877214f-dfef-40e8-878a-a918ee6a8af3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd6b7711-63c4-4a84-aa84-802b6bf9b849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6429eb87-9387-474c-9ade-54e373be40f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d075a211-9a95-4505-949e-816e9df06183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a2ccf36-208c-42af-b601-aaffd2d9d76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d9118d7-914e-42c4-89a3-64fb9841340b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af38e963-ecad-4fe9-b2a5-51bfc29e3313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 985d48a9-6f30-4afa-bea4-df8384513246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65001770-c54f-42e4-81f7-0d22d23c0cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2beaf26a-005a-412b-8d99-f8d948ba06ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad0e1e9-c848-4905-8117-ab6d0af86ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 415e5477-c9cf-4620-bcf8-9b54a404463c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df0fe46-2752-447f-b5cd-c5cbc7304565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 486369f0-0cf0-4fa4-aa13-de5a63196760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23975403-6a9a-460e-832e-1e52c8a4eca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e89205d3-aa46-4a31-be8f-ac99a7e58c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8514ddc-b561-4c1d-902f-3da0bddbffcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dc9134e-8cb6-468c-b7bd-7fa64a444e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3567e7a9-efa4-44e7-b652-373788a2e168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46199ad9-eb11-48a9-a9a3-8e7242039f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dfb5cb2-e808-43be-8580-1b038052d5cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d30752-b078-4a80-92d6-818b46a34190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5585fa5f-1cd9-4b25-80f3-5a46765a61b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f24005f-96af-4587-815c-49d8f3ac85c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3097e85-cf08-49e7-946b-e8807af85990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f786e958-cfa1-4351-9b9c-4b6d161f756f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe443852-74a6-462f-971c-4c14653f4e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d7db5eb-6304-4235-b27e-18e6a8c75829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c11fa1b4-ae07-430c-a420-9aa1b85e0825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ad96cf-9be3-47aa-b523-115cc0e42d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef9d8ff-2397-4e0a-9b5d-2b8fd4447940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 116f2a36-0180-4db4-8089-a9b8a2fc6c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b65df8-ceaf-48a2-8e6a-ac2fc67e648a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54aca158-57be-4aa7-8de1-007b479348af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fdfaad4-e57b-4f85-a2d9-4c90f339be54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d86e2f89-df8b-41e5-b848-6b13f0277520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0e068df-7c21-4069-a4f6-8e94ff9d2c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a9c29e1-a72c-4f9b-896b-d38838004d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 304e5df1-8a80-4165-9eec-f67e0b9063ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc0ef5e2-38cb-472b-91b3-3b465e4f0fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc4b97fb-93f0-4cb2-8337-8fb80186729a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9eb0d9b-c906-4427-9e3f-2b12ab5af82d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8781e542-cba0-48fd-aeff-34fba32f8d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 074ca60e-7992-4f49-8c33-4a1489dd745a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ff36e1-9327-43bf-9a4f-c6ab0f3ac656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9836c339-da85-4e95-a577-d1607feca8c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f196e6a5-85b5-4f75-89d5-2f8e62cdc015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6258f4e5-4e99-4a21-b8d1-b823a757ebf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14c6dce0-ec71-4182-89e5-f06cbcf3333c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de0e1349-5e04-4e41-b90e-e8b92dce2195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99fe5108-ffd5-47b6-8fd8-24f16a2f169c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f36847e-9594-4317-a6ed-a3337b95e262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab35da83-1b34-4b0c-aafa-01dbb3a385f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35da0d70-df3f-4d4b-8c02-d8856ee80b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6608a932-e4e0-442f-8159-26f66dec2824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3c29786-23f9-4cb1-8df4-fdda0dec967b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d46ad0e-66ce-4f83-81ac-8d273ef86eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72556c71-b814-4c59-af16-ff6238a1bb7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d3e0af-9265-4f31-a764-25515229cc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6fb13c6-b1b5-4224-a761-be23e3d8cf3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 267e0c26-a2e4-4d4e-b854-19ce2ea94300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c2e1dde-b0be-426e-ae12-61cca238297a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e067b3d8-729e-4a1f-a3db-d9a6155bdde3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea7ad81-a595-4dc4-8ea4-e718997e2d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72d1cc11-9fa6-4fe4-a2a1-0c3bb778c24e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4f44463-0366-43ef-be5b-f88fd33c849d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33703954-2c3e-4fcd-82b8-c651608dade5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5062533f-cc1f-416e-a712-dbe1060a4a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18dc2e1f-8110-42da-bd0a-500e5d9446aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bacd2087-6229-4403-a67b-a45130cc45fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8efbe92-7581-4926-8c5f-ef9811721918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6831e5d-56f1-4d08-a179-a984259fafe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1095d33a-c186-4897-998c-a344a2f69202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 812b78c0-dad0-4446-8b52-d871fdb62e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3a9144e-6db6-4d6b-a269-08044ecbaec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 087ddb19-104d-4b90-813e-2fdbd963fa5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104a368f-f33c-438a-8df5-1af2714dc1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76ba37ce-0f16-4f0f-ab1e-d1ab2f26b951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f65a801-4bd9-4086-904e-bb9df5035c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598f1ae1-b0e2-4782-88c4-9c5feb881b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c44abfe-ce50-4b08-87dd-cc6768708bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeecfc34-2b7e-40b4-977d-c648c1f1feab
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_82
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/test_labels.txt

📊 Raw data loaded:
   Train: X=(1604, 24), y=(1604,)
   Test:  X=(401, 24), y=(401,)

⚠️  Limiting training data: 1604 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  392 samples, 5 features
✅ Client client_82 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1854, RMSE: 0.4306, MAE: 0.3547, R²: -1.1841

============================================================
🔄 Round 10 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1065, val=0.0819 (↓), lr=0.001000
   • Epoch   2/100: train=0.0861, val=0.0828, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0846, val=0.0826, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0846, val=0.0828, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0845, val=0.0830, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0838, val=0.0839, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 10 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0039
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0011
============================================================


============================================================
🔄 Round 11 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1325, val=0.1244 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0920, val=0.0864 (↓), lr=0.000250
   • Epoch   3/100: train=0.0838, val=0.0882, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0831, val=0.0890, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0832, val=0.0882, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0828, val=0.0885, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 11 Summary - Client client_82
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0031
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0215
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1516, RMSE: 0.3894, MAE: 0.3200, R²: -0.7861

📊 Round 11 Test Metrics:
   Loss: 0.1417, RMSE: 0.3764, MAE: 0.3098, R²: -0.6695

============================================================
🔄 Round 17 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1213, val=0.1148 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1052, val=0.0978 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0922, val=0.0873 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0861, val=0.0837 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0847, val=0.0831 (↓), lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0845, val=0.0830, patience=6/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 17 Summary - Client client_82
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0005
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0042
============================================================


============================================================
🔄 Round 18 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1110, val=0.1121 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.1070, val=0.1071 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1038, val=0.1047 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1018, val=0.1025 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1001, val=0.1005 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.0924, val=0.0915 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0889, val=0.0870, patience=2/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0878, val=0.0855, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0873, val=0.0846, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0868, val=0.0839, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0864, val=0.0832, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0861, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0859, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0857, val=0.0818, patience=2/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_82
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0056
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0205
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.1111, RMSE: 0.3332, MAE: 0.2798, R²: -0.3084

📊 Round 18 Test Metrics:
   Loss: 0.0989, RMSE: 0.3144, MAE: 0.2688, R²: -0.1650

============================================================
🔄 Round 20 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0975, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0898, val=0.0973 (↓), lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0971, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0960, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0879, val=0.0945, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0870, val=0.0932, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0863, val=0.0921, patience=1/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0858, val=0.0911 (↓), lr=0.000001
   • Epoch  61/100: train=0.0853, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0849, val=0.0896, patience=7/15, lr=0.000001
   ✓ Epoch  81/100: train=0.0846, val=0.0891 (↓), lr=0.000001
   • Epoch  91/100: train=0.0844, val=0.0886, patience=10/15, lr=0.000001

============================================================
📊 Round 20 Summary - Client client_82
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0052
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0361
============================================================


============================================================
🔄 Round 21 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0778, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0878, val=0.0772, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0876, val=0.0766, patience=6/15, lr=0.000001
   • Epoch  41/100: train=0.0874, val=0.0762, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0873, val=0.0758, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0872, val=0.0755, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 21 Summary - Client client_82
   Epochs: 64/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0048
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0482
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0882, RMSE: 0.2969, MAE: 0.2587, R²: -0.0387

============================================================
🔄 Round 24 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 24 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0061
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0188
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2578, R²: -0.0286

📊 Round 24 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2576, R²: -0.0272

============================================================
🔄 Round 28 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 28 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0062
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0058
============================================================


============================================================
🔄 Round 30 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 30 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0032
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0187
============================================================


============================================================
🔄 Round 31 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 31 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0017
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0153
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2572, R²: -0.0229

============================================================
🔄 Round 34 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 34 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0048
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0017
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2572, R²: -0.0224

📊 Round 34 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2570, R²: -0.0214

============================================================
🔄 Round 37 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 37 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0079
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0022
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2570, R²: -0.0212

============================================================
🔄 Round 42 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 42 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0006
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0088
============================================================


============================================================
🔄 Round 43 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 43 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0001
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0115
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2568, R²: -0.0194

============================================================
🔄 Round 47 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 47 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0014
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0050
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2568, R²: -0.0190

============================================================
🔄 Round 48 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 48 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0032
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0033
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2568, R²: -0.0189

============================================================
🔄 Round 50 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 50 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0015
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0180
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2567, R²: -0.0186

============================================================
🔄 Round 51 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 51 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0017
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0027
============================================================


============================================================
🔄 Round 53 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 53 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0067
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0130
============================================================


============================================================
🔄 Round 54 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 54 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0033
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0023
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2567, R²: -0.0186

============================================================
🔄 Round 57 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 57 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0008
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0078
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2567, R²: -0.0186

============================================================
🔄 Round 58 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 58 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0022
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0002
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2567, R²: -0.0183

📊 Round 58 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2567, R²: -0.0182

============================================================
🔄 Round 61 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 61 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0007
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0093
============================================================


============================================================
🔄 Round 63 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 63 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0009
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0222
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2566, R²: -0.0177

============================================================
🔄 Round 64 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 64 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0049
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0171
============================================================


============================================================
🔄 Round 65 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 65 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0020
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0000
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2566, R²: -0.0174

============================================================
🔄 Round 68 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 68 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0020
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0007
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2566, R²: -0.0175

============================================================
🔄 Round 69 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 69 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0059
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0060
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0863, RMSE: 0.2939, MAE: 0.2566, R²: -0.0174

📊 Round 69 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2566, R²: -0.0171

============================================================
🔄 Round 72 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 72 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0026
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0113
============================================================


============================================================
🔄 Round 74 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 74 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0018
   Val:   Loss=0.0854, RMSE=0.2921, R²=-0.0003
============================================================


============================================================
🔄 Round 75 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 75 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0008
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0208
============================================================


============================================================
🔄 Round 76 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 76 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0013
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0031
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2565, R²: -0.0163

📊 Round 76 Test Metrics:
   Loss: 0.0862, RMSE: 0.2937, MAE: 0.2565, R²: -0.0161

============================================================
🔄 Round 78 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 78 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0013
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0021
============================================================


============================================================
🔄 Round 79 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 79 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0015
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0164
============================================================


============================================================
🔄 Round 80 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 80 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0000
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0086
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0862, RMSE: 0.2937, MAE: 0.2565, R²: -0.0160

============================================================
🔄 Round 83 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 83 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0017
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0150
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2564, R²: -0.0158

============================================================
🔄 Round 84 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 84 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0022
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0015
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2565, R²: -0.0160

📊 Round 84 Test Metrics:
   Loss: 0.0862, RMSE: 0.2937, MAE: 0.2565, R²: -0.0160

============================================================
🔄 Round 89 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 89 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0025
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0042
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2564, R²: -0.0157

============================================================
🔄 Round 90 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 90 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0024
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0003
============================================================


============================================================
🔄 Round 91 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 91 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0007
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0038
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2564, R²: -0.0154

📊 Round 91 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2564, R²: -0.0153

============================================================
🔄 Round 94 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 94 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0027
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0042
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2564, R²: -0.0152

============================================================
🔄 Round 95 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 95 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0027
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0093
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2564, R²: -0.0152

============================================================
🔄 Round 98 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 98 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0024
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0004
============================================================


============================================================
🔄 Round 99 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 99 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0005
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0078
============================================================


============================================================
🔄 Round 100 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 100 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0036
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0040
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2563, R²: -0.0149

============================================================
🔄 Round 102 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 102 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0027
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0015
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2563, R²: -0.0148

============================================================
🔄 Round 103 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 103 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0029
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0059
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2563, R²: -0.0147

============================================================
🔄 Round 106 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 106 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0001
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0083
============================================================


============================================================
🔄 Round 107 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 107 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0007
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0048
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2563, R²: -0.0144

📊 Round 107 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2563, R²: -0.0143

📊 Round 107 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2563, R²: -0.0142

📊 Round 107 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2563, R²: -0.0142

============================================================
🔄 Round 116 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 116 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0052
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0213
============================================================


============================================================
🔄 Round 118 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 118 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0023
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0024
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2563, R²: -0.0143

============================================================
🔄 Round 119 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 119 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0020
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0031
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2563, R²: -0.0143

============================================================
🔄 Round 120 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 120 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0024
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0014
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2563, R²: -0.0142

============================================================
🔄 Round 121 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 121 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0017
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0179
============================================================


============================================================
🔄 Round 123 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 123 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0002
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0052
============================================================


============================================================
🔄 Round 126 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 126 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0007
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0087
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0861, RMSE: 0.2933, MAE: 0.2562, R²: -0.0139

============================================================
🔄 Round 128 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 128 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0002
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0050
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0138

============================================================
🔄 Round 130 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 130 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0007
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0080
============================================================


============================================================
🔄 Round 131 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 131 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0014
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0020
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0138

📊 Round 131 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0137

============================================================
🔄 Round 133 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 133 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0037
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0083
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0136

============================================================
🔄 Round 136 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 136 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0016
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0159
============================================================


============================================================
🔄 Round 138 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 138 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0005
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0071
============================================================


============================================================
🔄 Round 139 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 139 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0027
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0000
============================================================


============================================================
🔄 Round 141 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 141 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0001
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0063
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0135

📊 Round 141 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0136

📊 Round 141 Test Metrics:
   Loss: 0.0861, RMSE: 0.2933, MAE: 0.2562, R²: -0.0139

============================================================
🔄 Round 146 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 146 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0009
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0058
============================================================


============================================================
🔄 Round 147 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 147 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0039
   Val:   Loss=0.0923, RMSE=0.3037, R²=0.0081
============================================================


============================================================
🔄 Round 148 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 148 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0014
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0006
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2562, R²: -0.0139

============================================================
🔄 Round 151 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 151 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0014
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0175
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0137

============================================================
🔄 Round 157 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 157 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0017
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0027
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0136

📊 Round 157 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0136

📊 Round 157 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0136

============================================================
🔄 Round 164 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 164 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0010
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0004
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0134

📊 Round 164 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0133

📊 Round 164 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2562, R²: -0.0132

============================================================
🔄 Round 168 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 168 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0028
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0053
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2562, R²: -0.0132

============================================================
🔄 Round 169 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 169 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0019
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0040
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0131

============================================================
🔄 Round 170 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 170 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0022
   Val:   Loss=0.0951, RMSE=0.3084, R²=0.0028
============================================================


============================================================
🔄 Round 171 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 171 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0007
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0144
============================================================


============================================================
🔄 Round 174 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 174 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0005
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0052
============================================================


============================================================
🔄 Round 175 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 175 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0012
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0097
============================================================


============================================================
🔄 Round 179 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 179 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0034
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0320
============================================================


============================================================
🔄 Round 180 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 180 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0002
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0032
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0130

============================================================
🔄 Round 185 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 185 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0023
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0016
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0129

📊 Round 185 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0131

📊 Round 185 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2562, R²: -0.0132

📊 Round 185 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0130

============================================================
🔄 Round 190 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 190 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0008
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0013
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0130

============================================================
🔄 Round 193 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 193 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0009
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0104
============================================================


============================================================
🔄 Round 194 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 194 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0018
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0052
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0127

============================================================
🔄 Round 196 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 196 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0013
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0143
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2562, R²: -0.0131

============================================================
🔄 Round 199 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 199 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0011
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0140
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0128

============================================================
🔄 Round 203 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 203 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0006
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0003
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0127

============================================================
🔄 Round 206 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 206 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0031
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0012
============================================================


============================================================
🔄 Round 207 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 207 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0013
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0028
============================================================


============================================================
🔄 Round 208 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 208 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0022
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0171
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0128

============================================================
🔄 Round 210 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 210 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0003
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0033
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2561, R²: -0.0128

❌ Client client_82 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
