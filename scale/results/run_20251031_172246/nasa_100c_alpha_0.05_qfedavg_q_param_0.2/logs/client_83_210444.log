[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e12439fc-010a-444a-82e1-578c4ff0c285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab79be8-d20c-4a90-888b-6d8fdf797b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eff0f1ba-0a8c-4a0b-a484-fdb7e66d2c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e51418c0-15a8-4a84-8546-a719a3b94420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d90a8e1-19f0-4c18-a6da-fd9e21f61d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6e7e516-216f-415d-989a-a6d4bd2eff8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 377b4099-0113-4557-b01c-19655d84c8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 080c80b3-274a-48a3-872b-7b2708a26175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c33bdd06-458b-40d6-840d-9674e909d14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37aa0c74-15b0-41ae-af21-3a01ec6ef7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a86210da-a5bb-46c3-89bc-1f8818cfc02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a62f30e-d241-44b9-9186-c82237cda311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da40ee71-77de-4f47-b115-84f6d561159e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9140a0e-ca1d-49fa-8e0e-722b85076b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30af7349-a2bd-4f4c-917d-cf0613bce014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1efba308-43fd-4f3d-9316-29afad9009ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9cd94af-9338-4829-8899-df50e0732a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9edb4b64-1008-4036-942e-1f2d0dbb012b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a10ee0a1-38d8-4edb-96c8-e821da24e8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69358c89-591b-411a-aebe-a79055be77da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed17cc2-87c1-4774-87a6-2bdeec9dd2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7883810d-ae2a-4349-a01f-2bdadc34f1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fa5e16e-952c-4341-b9be-2ac99b53a90e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bc65270-a76d-48a9-95df-2cdd0f193ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b75ee89-f6ee-4885-b6cf-766084dcab62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73db4f87-41ae-47f5-8ea6-e350a6b19277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637bf06a-b0fc-4e21-a545-5991ffbaac93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5da1c6b5-39aa-45d4-aea3-e6f39afd6ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04a9348d-3107-456b-a5dd-12286a6c38f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29d78a79-0480-47eb-b7a5-006dbbeb1207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec795fb5-e528-44fd-a2bc-fddeeac24053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a08cad4-fbe1-4f67-b8a0-b24b242c0361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be69414d-33e9-4489-a101-f3705ff97961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed3e751-b693-4624-a2a1-b3d0cef2e244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2903286-3168-4e5b-bb55-68071c495ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93cc7335-a8f7-4d67-8303-a2a9e6ad03b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f0976b-62aa-42e7-a1d3-f71d28c82942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f43c2eab-40a9-408c-a0b2-861dae648686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 368dc8bf-b585-403b-a988-c7e897120b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed86199a-bafb-44e5-b92d-537e74636b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3df9934e-2d1c-499f-8f66-e4123c2c88e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4f829a6-86c5-4e0c-b7fc-08c1ae75e494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ab9cf38-dbda-47ba-99bf-2016e52f9989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd38a8c4-16cc-4318-959c-9f03da48a977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee2db76-4ee3-4572-9594-822c436049bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e80b9eb8-956e-4050-a6cc-8641c7f9c1c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da8cf128-9395-497a-bb1e-c3915e58553e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c2c5885-c559-4fff-8156-9154a3d497a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3973a9-2502-4064-9983-ed4d1a402f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a1c8ed6-8a26-442b-b524-3335aae10db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b88310b-7cfe-4121-8eaa-7736493f3641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae851ffc-9c6c-4e5a-aa93-57b02d84d3ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b8c7818-6e8e-4975-92ee-9a6bdbdf1e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3bb177e-3582-4279-bb76-0e044ddbd57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee4e750-8cca-4a4c-9054-a08e56724b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2af5afa-0957-4a0f-b690-85eda6b1f31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2af772-3c36-4d7c-9e0c-58805f4a32ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a490b6b5-8f5d-4fe6-ac15-cad2fd34b5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c3ac894-96d9-4426-a3b6-7ccd1bb3aa81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6075399-3f19-4878-a272-10fc696b0063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c9eda6-d218-4a61-ba49-f00f04418c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413ffae7-b7db-49b7-8cb8-8faf2b86eda3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f174ec-c27b-4df4-9bf5-811f48333a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68d3f668-83b2-48f7-8890-8df1ad1a0778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4de9ceeb-b577-4878-a0c4-b9ca3f54e543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a885c9be-05c1-45dc-b172-a1480f1c7f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec78dce-812a-487f-88cf-675b30abdeef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7e5e9a-70c9-42eb-8909-a6c3e38b385d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6ec2ed1-4c91-4388-bbe5-bfc4c10a355c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cad81ca-2507-4df3-ab2c-3eccfb76eb53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5df234-e50a-48af-8466-003ad47f8ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec825dc1-5e53-48c2-842a-6ef983177923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bde80e32-ad17-41fd-9e1b-bb3cbeff566f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ba3bcbc-2677-431f-a9cb-a125f2746aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95690d1c-2273-4dae-9c2d-8e2cd39eaf18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef2a4a8e-c678-4192-8d4a-821d93df53b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1643a59-70cb-4861-b148-8da5de70d7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 038d0bf7-bd6d-4c4f-8dec-9134802cf596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84c35a89-a9ea-4f4e-85ad-444c5a243d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 816d7574-327d-49dd-ae47-efc84a36ce49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c196830c-b77b-440e-b000-71ed3bf1329f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5bc3dfb-d66d-414e-972e-4250467d9f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2366b283-b653-4d3d-936c-5d562902e5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb8e98f2-4861-47d6-bbb3-f46274bf0207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3468d2f-4d2a-40c8-9564-41af00f3ffbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55edd109-82d2-4401-aee9-1743cc812069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76dddfa9-528b-4450-b430-96f10ca83796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 477053ca-4e5a-439c-bd10-db6daca37dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cb8df8b-2743-40e8-a0c7-aa182b698381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c7a961-02f1-447f-8271-89fcd22d0463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 133acede-0592-4258-aa7a-4b72e4835139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f25484e-b22a-407b-b3cc-f1aa4c7004fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68695cf4-583c-49ac-a014-6739677862ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b4fb28-f906-4c18-b2e5-bdf4c81e4992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d42ea46-2d44-42ff-8fe5-b98d5f5ef47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 975b245e-12c7-431c-b8d2-942b8b73661d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc07fe2-e755-45ad-8d4b-7b1efefd82b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 623391d2-e693-44da-9f32-5fbcc28d3277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ac1221-4165-4b08-a155-a5eccba2ae8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05783d4a-878d-4973-992d-7f1a3ea8635a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b24b4460-3d13-41c0-9271-4ae7dce26460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09dc90dd-7391-4dff-b480-4cb0c7630aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5dc10d6-676a-45de-9807-24352e684f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0ac10e4-e7f9-472e-b798-4e82edeeea85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bba6795-8d61-45e4-9e1e-3caf878afa6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5607274-fe2c-469a-a3d0-d4a885c2557b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 656d13be-9796-4542-aafb-c66c84475db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8644b255-996a-437b-87af-398fc4327907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e51a95a-cf77-4c3e-a55b-ad8f7526cdab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4aa89de-c6d1-4668-8807-300ae5741452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b823ae-e311-4869-8b3e-14f68e4cf4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 107e5a94-84cd-4b67-9612-1cf6de75faa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0337bd42-550a-4a68-a1ed-ed910b696c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e995a1d7-e2d9-4bed-bc3c-2ef727d8cb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03a222a0-d332-4b3e-a500-32c3d73e4e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae85531c-f6a3-45cb-ac72-c00fdffe811a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5205d27-822f-4e3b-85c5-c2f98c8169b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae2cdee6-95bc-40c0-b79d-fbd8f441ea35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0599308c-5bac-485f-8409-36453fc0963a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1485a7a-406c-490a-91e4-5674a69abe47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06205e44-7797-40b1-9f2d-cb4bcad9b8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92f1fcca-be45-43b0-bb87-4cf86e045033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5966a1f2-10bf-4eb9-b58b-9ee49d515342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60c6d14c-8cd1-4905-badd-b651b5a978fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba35dd5e-a80e-4934-a599-e86ad85f76d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4dfa3ed-0b49-4af9-9a50-7e530fc175ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e94c01c-ccc9-4f31-ab54-cceb2e96dcbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d5c9297-e949-4344-8b2c-d052e36e2eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c9ac1be-f6bc-4301-bbfc-2824661da230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fdffdb2-4cb7-4ed7-9d35-b425a95c52a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e922c03-466e-41b5-a4ca-e6997378e249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cae757a-8878-4c77-8259-6d4cb6fcc71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b32d34f-6235-4c7d-9ece-3e372d3f3860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75cf2c46-ee00-4a52-b6e9-cad671460d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9e0c2a1-0bf5-464a-b020-0251452e82ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 518c9c3c-595e-42ca-a6ce-763d793c119b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55ec11fd-98df-48c1-bcd3-4564a748e920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc018292-b555-45cc-81c2-e7d44ab714e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 490b6da4-21be-4c77-894b-02bf7cfa8ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05076339-4fbe-4973-966a-033f3c6e3123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad8124fd-ce11-4f30-a1e2-f08ed73979ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24b1f6f4-04f4-4c4e-9822-feadbdb5f022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2614f82f-683b-4e61-b221-94794cda140c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb8f7083-8e9e-4df7-ae62-c7426061b429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e2d8f5f-03ca-4e0f-9620-4537846708ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af6a9148-c199-42ae-9af7-967b34331906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86910d7c-3d62-47de-8643-48dc18cd6fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600eaa48-c1e2-4220-92a5-0df84eef1ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a9e268-85e2-40fd-8680-14ced3fd58f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5728012d-e0c3-4437-a374-0d753d7afcb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3789e8d0-4078-4c5d-b2b4-8d32d24c461f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cfb9583-24be-466c-bc9d-f1801eed9735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12bc8d4d-97cc-4c9f-a963-fd4006097cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9302ad0c-a090-4c1d-bd5e-ec869f8ddc3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 252602e1-5a4b-47c1-8ad1-4650594fd0ac
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_83
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/test_labels.txt

📊 Raw data loaded:
   Train: X=(559, 24), y=(559,)
   Test:  X=(140, 24), y=(140,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 550 samples, 5 features
   Test:  131 samples, 5 features
✅ Client client_83 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1743, RMSE: 0.4175, MAE: 0.3352, R²: -0.9957

============================================================
🔄 Round 12 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1014, val=0.0952 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0822, val=0.0924 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0793, val=0.0910 (↓), lr=0.001000
   • Epoch   4/100: train=0.0789, val=0.0905, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0781, val=0.0901 (↓), lr=0.001000
   • Epoch  11/100: train=0.0743, val=0.0926, patience=6/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 12 Summary - Client client_83
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0300
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0279
============================================================


============================================================
🔄 Round 15 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1144, val=0.1004 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0866, val=0.0803 (↓), lr=0.000250
   • Epoch   3/100: train=0.0832, val=0.0819, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0821, val=0.0828, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0821, val=0.0810, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0810, val=0.0802, patience=9/15, lr=0.000125
   • Epoch  21/100: train=0.0804, val=0.0795, patience=5/15, lr=0.000125
   • Epoch  31/100: train=0.0799, val=0.0790, patience=7/15, lr=0.000125
   • Epoch  41/100: train=0.0792, val=0.0784, patience=6/15, lr=0.000125
   • Epoch  51/100: train=0.0785, val=0.0778, patience=7/15, lr=0.000125
   • Epoch  61/100: train=0.0777, val=0.0772, patience=8/15, lr=0.000125
   • Epoch  71/100: train=0.0768, val=0.0767, patience=9/15, lr=0.000125
   • Epoch  81/100: train=0.0756, val=0.0762, patience=9/15, lr=0.000125
   • Epoch  91/100: train=0.0744, val=0.0760, patience=6/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 15 Summary - Client client_83
   Epochs: 100/100
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0909
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0475
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1353, RMSE: 0.3678, MAE: 0.3021, R²: -0.5487

📊 Round 15 Test Metrics:
   Loss: 0.1309, RMSE: 0.3618, MAE: 0.2986, R²: -0.4985

📊 Round 15 Test Metrics:
   Loss: 0.1155, RMSE: 0.3398, MAE: 0.2859, R²: -0.3222

📊 Round 15 Test Metrics:
   Loss: 0.1028, RMSE: 0.3206, MAE: 0.2747, R²: -0.1770

============================================================
🔄 Round 20 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.0894, val=0.0775 (↓), lr=0.000063
   • Epoch   2/100: train=0.0841, val=0.0816, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0831, val=0.0832, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0826, val=0.0830, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0823, val=0.0828, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0815, val=0.0837, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 20 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0195
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0364
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2620, R²: 0.0014

📊 Round 20 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2618, R²: 0.0067

============================================================
🔄 Round 25 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0825, val=0.0843 (↓), lr=0.000016
   • Epoch   2/100: train=0.0823, val=0.0843, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0822, val=0.0842, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0821, val=0.0842, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0821, val=0.0842, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0818, val=0.0841, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 25 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0103
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0144
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2617, R²: 0.0082

📊 Round 25 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2617, R²: 0.0086

============================================================
🔄 Round 27 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0806, val=0.0917 (↓), lr=0.000004
   • Epoch   2/100: train=0.0806, val=0.0917, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0806, val=0.0917, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0806, val=0.0917, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0805, val=0.0917, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0804, val=0.0918, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 27 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0129
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0114
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2616, R²: 0.0088

============================================================
🔄 Round 29 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0822, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 29 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0110
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0148
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2616, R²: 0.0092

============================================================
🔄 Round 33 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 33 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0135
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0422
============================================================


============================================================
🔄 Round 35 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 35 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0126
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0105
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2616, R²: 0.0094

============================================================
🔄 Round 37 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 37 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0129
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0091
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2616, R²: 0.0094

📊 Round 37 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2616, R²: 0.0095

============================================================
🔄 Round 40 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 40 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0104
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0180
============================================================


============================================================
🔄 Round 41 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 41 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0133
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0046
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2616, R²: 0.0095

============================================================
🔄 Round 42 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 42 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0111
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0164
============================================================


============================================================
🔄 Round 43 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 43 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0103
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0223
============================================================


============================================================
🔄 Round 46 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 46 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0085
   Val:   Loss=0.0714, RMSE=0.2673, R²=-0.0282
============================================================


============================================================
🔄 Round 49 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 49 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0120
   Val:   Loss=0.0716, RMSE=0.2675, R²=-0.0188
============================================================


============================================================
🔄 Round 50 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 50 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0120
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0111
============================================================


============================================================
🔄 Round 51 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 51 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0102
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0194
============================================================


============================================================
🔄 Round 52 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 52 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0128
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0096
============================================================


============================================================
🔄 Round 53 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 53 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0117
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0229
============================================================


============================================================
🔄 Round 54 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 54 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0059
   Val:   Loss=0.0958, RMSE=0.3094, R²=-0.0460
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0096

📊 Round 54 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0096

📊 Round 54 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0096

============================================================
🔄 Round 58 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 58 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0117
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0181
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0096

============================================================
🔄 Round 61 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 61 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0123
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0163
============================================================


============================================================
🔄 Round 62 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 62 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0134
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0065
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0096

============================================================
🔄 Round 65 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 65 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0099
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0195
============================================================


============================================================
🔄 Round 67 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 67 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0068
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0408
============================================================


============================================================
🔄 Round 69 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 69 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0138
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0054
============================================================


============================================================
🔄 Round 71 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 71 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0118
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0131
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0096

============================================================
🔄 Round 72 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 72 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0124
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0156
============================================================


============================================================
🔄 Round 73 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 73 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0111
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0168
============================================================


============================================================
🔄 Round 74 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 74 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0138
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0064
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0096

📊 Round 74 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0096

============================================================
🔄 Round 77 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 77 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0110
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0311
============================================================


============================================================
🔄 Round 79 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 79 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0113
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0227
============================================================


============================================================
🔄 Round 80 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 80 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0142
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0152
============================================================


============================================================
🔄 Round 81 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 81 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0158
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0117
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0096

============================================================
🔄 Round 83 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 83 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0134
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0099
============================================================


============================================================
🔄 Round 84 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 84 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0125
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0293
============================================================


============================================================
🔄 Round 85 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 85 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0141
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0053
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0097

📊 Round 85 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0097

============================================================
🔄 Round 91 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 91 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0125
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0198
============================================================


============================================================
🔄 Round 93 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 93 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0112
   Val:   Loss=0.0965, RMSE=0.3107, R²=-0.0165
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0097

📊 Round 93 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0097

📊 Round 93 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0097

📊 Round 93 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0097

============================================================
🔄 Round 98 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 98 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0143
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0254
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2615, R²: 0.0097

============================================================
🔄 Round 99 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 99 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0114
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0263
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0097

📊 Round 99 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0097

============================================================
🔄 Round 104 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 104 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0113
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0283
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0097

============================================================
🔄 Round 106 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 106 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0152
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0055
============================================================


============================================================
🔄 Round 109 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 109 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0113
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0196
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0097

============================================================
🔄 Round 110 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 110 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0119
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0262
============================================================


============================================================
🔄 Round 112 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 112 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0107
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0213
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0097

============================================================
🔄 Round 114 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 114 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0138
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0089
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0097

============================================================
🔄 Round 115 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 115 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0105
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0231
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0097

📊 Round 115 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0098

============================================================
🔄 Round 118 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 118 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0152
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0085
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0098

============================================================
🔄 Round 121 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 121 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0102
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0449
============================================================


============================================================
🔄 Round 122 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0997 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0997, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0997)

============================================================
📊 Round 122 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0136
   Val:   Loss=0.0997, RMSE=0.3157, R²=-0.0114
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0098

📊 Round 122 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0098

============================================================
🔄 Round 124 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 124 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0147
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0101
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0098

📊 Round 124 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0098

============================================================
🔄 Round 129 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 129 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0109
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0758
============================================================


============================================================
🔄 Round 130 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 130 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0181
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0190
============================================================


============================================================
🔄 Round 131 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 131 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0100
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0340
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0098

📊 Round 131 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0098

📊 Round 131 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0098

============================================================
🔄 Round 139 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 139 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0148
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0061
============================================================


============================================================
🔄 Round 140 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 140 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0139
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0256
============================================================


============================================================
🔄 Round 141 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 141 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0088
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0296
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0098

============================================================
🔄 Round 143 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 143 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0150
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0153
============================================================


============================================================
🔄 Round 144 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 144 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0116
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0196
============================================================


============================================================
🔄 Round 145 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 145 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0105
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0431
============================================================


============================================================
🔄 Round 149 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 149 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0114
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0164
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0099

📊 Round 149 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0098

📊 Round 149 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0099

============================================================
🔄 Round 153 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 153 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0069
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0398
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0099

============================================================
🔄 Round 155 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 155 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0129
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0118
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0099

============================================================
🔄 Round 158 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 158 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0111
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0220
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0099

📊 Round 158 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0099

📊 Round 158 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0099

📊 Round 158 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0099

📊 Round 158 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0099

============================================================
🔄 Round 170 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 170 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0148
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0067
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2614, R²: 0.0099

============================================================
🔄 Round 171 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 171 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0158
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0321
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0099

============================================================
🔄 Round 173 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 173 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0140
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0282
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0099

============================================================
🔄 Round 176 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 176 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0142
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0284
============================================================


============================================================
🔄 Round 181 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 181 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0126
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0206
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0099

📊 Round 181 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0099

============================================================
🔄 Round 183 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 183 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0125
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0129
============================================================


============================================================
🔄 Round 184 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 184 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0093
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0439
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0099

============================================================
🔄 Round 185 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 185 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0119
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0267
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0099

============================================================
🔄 Round 186 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 186 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0149
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0039
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0100

📊 Round 186 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0100

============================================================
🔄 Round 190 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 190 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0158
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0191
============================================================


============================================================
🔄 Round 193 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 193 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0119
   Val:   Loss=0.0682, RMSE=0.2612, R²=-0.0154
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0099

📊 Round 193 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0099

📊 Round 193 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0100

============================================================
🔄 Round 198 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 198 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0114
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0249
============================================================


============================================================
🔄 Round 200 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 200 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0121
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0140
============================================================


============================================================
🔄 Round 201 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 201 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0132
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0096
============================================================


============================================================
🔄 Round 203 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 203 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0121
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0156
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0100

============================================================
🔄 Round 205 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 205 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0111
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0186
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0100

📊 Round 205 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0100

📊 Round 205 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2613, R²: 0.0100

❌ Client client_83 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
