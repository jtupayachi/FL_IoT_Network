[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a45e3f33-728d-44cd-be44-50b9576de35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f020b39a-595d-467b-aa0c-b25804d1d40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f30c7d1d-1eb7-4097-9b0f-67180cc6df07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e77eeb5-7b5a-494b-8612-b1faac5887d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5b16cd4-a702-4430-a56c-afea2786c537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26ec3136-a801-4c52-ae03-54e22395455f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7e4530f-6e0e-4f86-a952-4158c014706a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdf7b2d2-1608-4d01-ba46-8809030b60e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c06561e-0502-4065-abff-034776760400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 574317b8-3490-4044-b4de-02062f045987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6669e62-2863-4d34-b69f-4ec0ce1ed28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f27d358a-dac3-48e3-8930-bb0b3c11c94c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94cbfe0-a77c-4864-bd05-f6019bfc61a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a983995-53a0-418f-b74b-bb228f3f035b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ebaab4b-ec42-4b7c-8f8c-67ac879d0d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71158281-4426-43b9-93da-28418f89537b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e100d0-39e0-480a-b0d2-75cf57715c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b7111bc-22b1-436e-aaac-ae7ec39c72ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed81f45-9ded-497b-bda0-aea7047c1e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb6979d5-dfea-4b15-8868-821286f87705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fcaedb9-fec6-4621-932c-08fd5629f543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c1ce694-cc62-4e32-afd0-2b5abdae210b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 943f21d0-fd04-4741-8b8f-11c13c9509a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb7cd7f-48b9-4876-b917-deff728cfeac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d20bbd-e76f-4c9e-a53d-c8b319a55d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9535305-5913-4f24-a6bd-f1da34609ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8e111e-ce50-41ce-8d09-79b32dd7d03f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 177f291f-41fb-4b47-9eda-edb9675e9c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fa8b941-4fcd-414f-9b27-bafabd96ae17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a920b38-2ec5-4ffd-a26c-025a624ed0db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc295b6f-55fa-4aba-8f8c-565185efb1d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48531a60-5e3e-4026-a663-8d11da637235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dddf6bb-d629-4623-a8b8-0303f793a7d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35f2d6ea-b03f-45c0-bf71-54a8adc7ce6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eaab87f-cc8a-4f95-a629-4ae0d817ba9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885062f4-994f-43bb-a510-a5161726ca6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 949eec5e-f71c-4081-a432-f40eb612d359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 835d4180-79a2-41e8-a345-f8aa97f55eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f54b82c5-2ce2-49bb-82a7-a59a2e0015ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50297593-d808-4965-bf7f-5b1a5a3f1f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f966b2e8-1ce3-46a9-9b8a-b65f65b80b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee911104-0c3e-4904-b0bb-4df71bea2710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b192a4c-7eee-47ca-a744-af668a166af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10fc379d-0130-4392-8399-fd69054e1a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e13f8b0b-ba63-4345-827b-13a01cb6d47b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26cc2773-2112-4c68-9a25-1bff51b04162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f0fdb8d-f898-48b0-bd0b-f9b8d3cdaf17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b44311-82dc-42d4-9171-416ea7333372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a9b07bb-d6c5-4388-bfe8-3c4d5795b7b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87b459cc-efb5-4cd3-9e3f-2127a2f11e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5869827c-8af9-4cbe-a222-dfef0bcdbd83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f38314-79c6-454a-b855-139fde386968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37b60ddc-b601-4207-b7b0-fdc4ad12cae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6eb078f-71e6-4ab4-9284-fa49ef9b487f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 683d8851-b4bf-4382-a7b2-2f6c47b58819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1feec07b-7621-4aec-aadb-8b8d987f3225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8de3af0-68eb-4d19-9862-1bb099a5f39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 021e9e20-4788-4ab4-9931-0ca83b2d1f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9097f663-12ae-4617-a461-ce00432e14f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b89c412-4478-49b8-9443-89e8534c6c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1f21c64-0644-4527-8a65-7aec2245ac06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c74836fb-dc24-40d9-9ca2-02654b6dc712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4abe2b17-17e7-4859-9bf9-8047ce0acba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef80310-e4d1-454f-b69d-dfe5d915149f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe814346-c4d5-45a2-a795-29146642a006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30af74c0-812e-437c-9241-63f91057b8e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd4d6cc1-b944-4f5e-bec0-0aaf4dd42751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8112cfbf-2778-4b06-97c3-15b6ddd59ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c21d1555-d156-4a08-bd1a-51bec9321a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 147a342a-3f24-4fea-a6b6-8c3b96b5b598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a2b6ea2-81f8-42f6-8729-f514cf943e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e79222fa-9b3f-4b83-b379-8c057df61453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1388d53c-487a-4a5c-b7de-6e910c7729c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f492820-9203-4a38-8568-fa1372a05ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 811cb183-7f52-4a02-a805-70739ccc1511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 952628f7-8445-4915-98c9-6439535e9e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11bde378-4d98-44d8-a6ac-04e6de27a4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3b51925-ef50-476e-a9f3-b8f830e833a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 004ad286-1b58-4da6-90ea-b81748ba5705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e3659d7-fea5-4f77-835d-217ed9e8a492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c0a202-e1cf-4e6f-abea-e033350138fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56aef87c-7cbd-4519-a02d-73a4393ba2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d131fb13-a8ac-4c01-a6c4-95eebe7e507c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b4a74d-d4c8-490e-a6fd-37dad727c37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35bda1a8-b8d6-4917-a07e-a19534b25f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d448622f-60c1-49e8-a65b-02d29e9a2987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc8fd2c4-ed81-4002-a438-759faa6d8256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f56a882a-c66b-4fb3-ba07-c02b5c7b63ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a49fc699-b9c7-4489-8d7c-2b1aa0ddb401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23f06eb4-825a-4bbb-a587-4ae7a78003a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a5bbbcf-f3e1-4b7f-b150-67aa366c8aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c853b182-f1a6-4df8-a4a0-16428ccc4e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b847e856-2243-49ca-a2f7-ecc332654586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36db78b4-d5c1-4e1c-a8d2-3babe10fb6a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 000e058f-e619-4f49-9839-e11b7b104fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5954ee03-5100-41fa-bfc9-21cedbad207c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12d0b3d3-1b7b-475d-829d-f824e52e1d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8495c7-89fd-46f1-a1e5-e80fda5154bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79171116-0be6-4f8e-a2b2-36d4c6a80ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc4ee55d-0fa0-4756-aadf-65e41f335030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 789a70cd-5821-4234-bc7c-fcdd8c2f0705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e2b977d-f6d7-4568-958b-b8d9386f286e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f08e14c-2fcb-4732-8573-b89bd880c3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68ada5c-12f5-437a-b1e2-dde778b0b11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98026ee7-18d3-4385-aab7-3243fc3b7da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3968c3db-d8dd-4a24-bf35-423558d24571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f72820ee-a5df-4bee-aee9-0f07a051a9ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abc5dce2-dbef-4453-b267-303e9721af7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 444603fc-d693-4c6e-b8d8-ebbf73245ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 696e0d83-1605-4d38-ac74-e86138081b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c37341d-a51e-4155-9f0e-572b4ee10f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 120436bb-1648-4c15-9cab-7ce00934a8ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08c2e438-b45b-4b79-af20-9e7b01523cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 404307a2-4d92-4256-ad4b-698c960aa429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d11403c-154a-4897-8f40-4970d6690db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a1b3495-183b-4ed7-8ae7-ccd242269434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fda9c554-dac2-451b-9c87-4727d0cf5c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3d523f-05e8-46de-96a8-12b64cab73c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 864cb0e4-2e66-4e0c-be6c-d2f79baa43d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe01af0-182c-4397-a79e-70d3da941958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 386a7a49-01c9-40b9-98e6-aba309da5eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18411921-5d26-4c0f-a30c-422c710ab264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6493743-3d86-4360-a677-5a14db8e12e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec84196f-8e14-4462-802a-f7079e49f290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94b67321-4014-4888-b21b-ef3d1643c6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ae96a22-c04e-4d1e-bf8b-ea179a1a5cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7414a768-9233-4342-8cdf-eed8a37a9654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffee1ea2-6a3a-4630-8650-858134f5ee71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 911355d1-91df-4609-b7b7-ebd95725962d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdd4f4d1-d492-4d56-99b2-e6f0dbc80b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b468f922-8cfa-4aa8-b5e2-ae05ef42605d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3517e303-8b66-4345-b39d-f1fbceb669ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b78847e2-d1bc-4109-8dd3-22142af1eb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f53f91fb-7af5-42bc-b700-bf6f6084d816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4c60c4-2a3c-4982-873e-a3ff0bedaeef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 618246cb-811e-4248-a3d8-90a3b8e8347d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb80276d-e8fa-4a60-b01c-b8fdedc87a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf6e97ae-809b-47ce-b2a5-da7cd67e9ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ab1a63f-2a61-455c-a191-51ba3b2b1d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fbfe448-b592-40b7-a2d9-d3e994523cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 381bffa2-a8ba-4a02-bbd2-ed633abdda38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea361fc-57aa-4daf-9585-bc0de470f0ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db5788da-bcaa-4bf7-af81-db7d1bec1819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb86a855-7ca6-49a5-92bf-5f66bab4eec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ff03fee-e8f9-4ac0-8159-1135146403a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60e5c796-3853-4012-b633-4a0f5e9cd649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc5fdb0-e71f-4b0b-9880-458d737869e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a58bb02-afaf-42b8-a87b-c840e4aeb129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0e6f52-4685-4ee7-b5ff-c0406cf896b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b16788be-d7c8-47b6-9b18-04b8074fb2bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2ca259-e5ff-4030-ba41-876c4ddfd548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8afd3c3e-5e42-4df8-9a0b-10f53db09cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76457401-37ad-41b7-8668-02b184ffd8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 744552f9-ea55-4a0b-ab3f-9f273d5bbbb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c12fe953-39c3-4779-933e-b517736532de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72959448-5f6d-46ef-90fd-8d76dedc7df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c71e4f8-60b4-458c-acf1-99c0814e3251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31cf08c5-3df4-4e8e-a955-2d533f29ab09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14f31f0a-d014-43ec-b56c-10b0a84e3e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45465f31-32f1-4443-9b2a-2a16fc740cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aea9215-e59d-4047-88f0-ba384b7f050f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af91220e-228c-45d5-90dc-06b65355ae37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6629c4a3-39a2-4cd4-9420-d7d69d1fe07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 461b2358-d9e6-42a4-ad13-c9451d0b1c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebdf6f3c-8cf8-43e9-adfa-43d246b4e4e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fd8cea4-7d08-4f7f-9712-34f76ac69403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 788d121c-ea14-4fca-a66a-0e27135b31a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9664a6b-4cdb-434c-94c8-ef1845c2c8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eb798a8-4e49-469a-b3be-c1b092f9c148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d02ada50-ba43-42cd-8106-85b15c2723aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a05b1c7-c946-4cbe-8b91-30196cfe4f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9c36613-b02f-4395-b1e7-28d02f571fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da0ab130-20ee-4c6f-aef1-3dc29ac951d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38671253-f429-4f70-a5b4-cda22962e77a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2f6b340-9fed-4134-b4b3-b5cd0b0f488a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5167f03-2d79-459e-b04d-e2d2f1a5802f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d96c955-44f7-4924-9d16-5ad1a5318375
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_84
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/test_labels.txt

📊 Raw data loaded:
   Train: X=(2020, 24), y=(2020,)
   Test:  X=(506, 24), y=(506,)

⚠️  Limiting training data: 2020 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  497 samples, 5 features
✅ Client client_84 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1630, RMSE: 0.4038, MAE: 0.3310, R²: -1.0704

============================================================
🔄 Round 11 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1004, val=0.0804 (↓), lr=0.001000
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0820, val=0.0822, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0813, val=0.0824, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0812, val=0.0830, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0793, val=0.0840, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 11 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0003
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0058
============================================================


============================================================
🔄 Round 12 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1293, val=0.0867 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0873, val=0.0791 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0832, val=0.0775 (↓), lr=0.000250
   • Epoch   4/100: train=0.0831, val=0.0777, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0828, val=0.0778, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0822, val=0.0784, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 12 Summary - Client client_84
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0003
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0012
============================================================


============================================================
🔄 Round 14 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1363, val=0.1232 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1158, val=0.1050 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0987, val=0.0922 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0873, val=0.0857 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0824, val=0.0845 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0812, val=0.0847, patience=6/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 14 Summary - Client client_84
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0044
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0040
============================================================


============================================================
🔄 Round 16 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1268, val=0.1228 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1220, val=0.1185 (↓), lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   ✓ Epoch   3/100: train=0.1168, val=0.1144 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1131, val=0.1126 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1109, val=0.1109 (↓), lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.0997, val=0.1023 (↓), lr=0.000004
   📉 Epoch 19: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0926, val=0.0976, patience=2/15, lr=0.000002
   📉 Epoch 27: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0902, val=0.0960, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0889, val=0.0951 (↓), lr=0.000001
   • Epoch  51/100: train=0.0876, val=0.0943, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0865, val=0.0936, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.0854, val=0.0930, patience=8/15, lr=0.000001
   • Epoch  81/100: train=0.0845, val=0.0924, patience=9/15, lr=0.000001
   • Epoch  91/100: train=0.0836, val=0.0920, patience=9/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_84
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0468
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0067
============================================================


============================================================
🔄 Round 17 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1269, val=0.1091 (↓), lr=0.000001
   • Epoch   2/100: train=0.1266, val=0.1088, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1262, val=0.1086 (↓), lr=0.000001
   • Epoch   4/100: train=0.1259, val=0.1083, patience=1/15, lr=0.000001
   • Epoch   5/100: train=0.1256, val=0.1081, patience=2/15, lr=0.000001
   • Epoch  11/100: train=0.1238, val=0.1067, patience=2/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1211, val=0.1048 (↓), lr=0.000001
   • Epoch  31/100: train=0.1186, val=0.1030, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1163, val=0.1013, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1141, val=0.0997, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.1120, val=0.0982, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1099, val=0.0968, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.1079, val=0.0954, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1060, val=0.0941, patience=3/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_84
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1046, RMSE=0.3234, R²=-0.2898
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.1297
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1120, RMSE: 0.3346, MAE: 0.2759, R²: -0.4219

📊 Round 17 Test Metrics:
   Loss: 0.0990, RMSE: 0.3147, MAE: 0.2625, R²: -0.2575

============================================================
🔄 Round 20 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0847, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0875, val=0.0841, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0866, val=0.0836, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0858, val=0.0832, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0850, val=0.0828, patience=12/15, lr=0.000001
   • Epoch  61/100: train=0.0844, val=0.0825, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 20 Summary - Client client_84
   Epochs: 68/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0387
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0199
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2451, R²: -0.0440

============================================================
🔄 Round 21 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0867, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0822, val=0.0862, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0820, val=0.0857, patience=11/15, lr=0.000001
   • Epoch  41/100: train=0.0818, val=0.0853, patience=9/15, lr=0.000001
   • Epoch  51/100: train=0.0817, val=0.0850, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 21 Summary - Client client_84
   Epochs: 60/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0038
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0556
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2437, R²: -0.0267

📊 Round 21 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2430, R²: -0.0183

📊 Round 21 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2426, R²: -0.0131

============================================================
🔄 Round 27 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 27 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0053
   Val:   Loss=0.0923, RMSE=0.3039, R²=0.0020
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2423, R²: -0.0099

📊 Round 27 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2423, R²: -0.0090

📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2422, R²: -0.0083

📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2422, R²: -0.0081

============================================================
🔄 Round 34 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 34 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0019
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0041
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2421, R²: -0.0078

📊 Round 34 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2421, R²: -0.0076

============================================================
🔄 Round 36 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 36 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0025
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0047
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2421, R²: -0.0073

============================================================
🔄 Round 37 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 37 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0005
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0190
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2421, R²: -0.0072

============================================================
🔄 Round 38 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 38 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0004
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0200
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2421, R²: -0.0070

============================================================
🔄 Round 40 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 40 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0016
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0078
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2420, R²: -0.0066

📊 Round 40 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0065

📊 Round 40 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2420, R²: -0.0063

============================================================
🔄 Round 43 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 43 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0033
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0052
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2420, R²: -0.0061

📊 Round 43 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2420, R²: -0.0062

============================================================
🔄 Round 46 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 46 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0041
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0031
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2420, R²: -0.0061

============================================================
🔄 Round 47 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 47 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0005
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0178
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2420, R²: -0.0059

============================================================
🔄 Round 49 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 49 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0027
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0045
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2420, R²: -0.0058

============================================================
🔄 Round 50 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 50 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0008
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0068
============================================================


============================================================
🔄 Round 51 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 51 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0027
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0095
============================================================


============================================================
🔄 Round 55 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 55 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0009
   Val:   Loss=0.0792, RMSE=0.2813, R²=-0.0141
============================================================


============================================================
🔄 Round 56 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 56 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0027
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0031
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2419, R²: -0.0057

📊 Round 56 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2419, R²: -0.0055

📊 Round 56 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2419, R²: -0.0054

============================================================
🔄 Round 63 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 63 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0017
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0003
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2419, R²: -0.0052

📊 Round 63 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2419, R²: -0.0052

============================================================
🔄 Round 65 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 65 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0010
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0033
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2419, R²: -0.0052

============================================================
🔄 Round 66 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 66 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0009
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0078
============================================================


============================================================
🔄 Round 67 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 67 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0041
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0025
============================================================


============================================================
🔄 Round 68 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.1025 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.1025, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.1025, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.1025, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.1025, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.1025, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1025)

============================================================
📊 Round 68 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=-0.0005
   Val:   Loss=0.1025, RMSE=0.3201, R²=-0.0152
============================================================


============================================================
🔄 Round 69 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 69 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0003
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0137
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2419, R²: -0.0051

============================================================
🔄 Round 70 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 70 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0020
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0055
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2419, R²: -0.0049

============================================================
🔄 Round 72 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 72 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0006
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0080
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2418, R²: -0.0047

============================================================
🔄 Round 75 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 75 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0019
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0041
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2418, R²: -0.0044

📊 Round 75 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2418, R²: -0.0045

============================================================
🔄 Round 81 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 81 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0011
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0068
============================================================


============================================================
🔄 Round 82 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 82 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0005
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0113
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2418, R²: -0.0043

============================================================
🔄 Round 86 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 86 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0017
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0076
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2418, R²: -0.0044

============================================================
🔄 Round 88 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 88 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0029
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0022
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2418, R²: -0.0043

📊 Round 88 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2418, R²: -0.0042

============================================================
🔄 Round 90 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 90 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0004
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0133
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2418, R²: -0.0042

============================================================
🔄 Round 91 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 91 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0023
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0082
============================================================


============================================================
🔄 Round 93 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 93 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0013
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0008
============================================================


============================================================
🔄 Round 94 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 94 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0029
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0056
============================================================


============================================================
🔄 Round 95 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 95 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0013
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0010
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2418, R²: -0.0041

============================================================
🔄 Round 99 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 99 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0020
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0006
============================================================


============================================================
🔄 Round 100 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 100 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0004
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0077
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2417, R²: -0.0038

📊 Round 100 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2417, R²: -0.0038

============================================================
🔄 Round 103 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 103 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0023
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0187
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2417, R²: -0.0037

============================================================
🔄 Round 105 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 105 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0010
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0049
============================================================


============================================================
🔄 Round 109 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 109 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0013
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0008
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0035

============================================================
🔄 Round 110 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 110 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0043
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0104
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0035

============================================================
🔄 Round 111 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 111 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0011
   Val:   Loss=0.0821, RMSE=0.2864, R²=-0.0045
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0034

============================================================
🔄 Round 113 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 113 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0041
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0062
============================================================


============================================================
🔄 Round 114 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 114 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0008
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0031
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0035

📊 Round 114 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0035

============================================================
🔄 Round 117 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 117 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0007
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0137
============================================================


============================================================
🔄 Round 122 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 122 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0024
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0028
============================================================


============================================================
🔄 Round 123 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 123 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0008
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0050
============================================================


============================================================
🔄 Round 124 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 124 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0016
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0036
============================================================


============================================================
🔄 Round 125 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 125 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0015
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0100
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0033

============================================================
🔄 Round 127 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 127 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0022
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0016
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0033

============================================================
🔄 Round 128 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 128 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0016
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0029
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0033

============================================================
🔄 Round 129 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 129 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0014
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0246
============================================================


============================================================
🔄 Round 130 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 130 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0018
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0058
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0033

============================================================
🔄 Round 131 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 131 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0003
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0198
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0033

============================================================
🔄 Round 133 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 133 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0005
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0082
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0032

============================================================
🔄 Round 134 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 134 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0021
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0024
============================================================


============================================================
🔄 Round 136 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 136 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0021
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0044
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2416, R²: -0.0031

📊 Round 136 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2416, R²: -0.0030

============================================================
🔄 Round 142 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 142 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0006
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0122
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2416, R²: -0.0032

============================================================
🔄 Round 144 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 144 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0022
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0173
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0032

============================================================
🔄 Round 147 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 147 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0007
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0038
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0033

📊 Round 147 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0033

============================================================
🔄 Round 152 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 152 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0003
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0151
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2417, R²: -0.0033

============================================================
🔄 Round 153 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 153 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0001
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0062
============================================================


============================================================
🔄 Round 154 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 154 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0013
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0010
============================================================


============================================================
🔄 Round 155 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 155 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0018
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0109
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2416, R²: -0.0032

============================================================
🔄 Round 158 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 158 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0017
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0013
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2416, R²: -0.0032

📊 Round 158 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2416, R²: -0.0031

============================================================
🔄 Round 162 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 162 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0005
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0083
============================================================


============================================================
🔄 Round 163 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 163 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0025
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0052
============================================================


============================================================
🔄 Round 164 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 164 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0007
   Val:   Loss=0.0707, RMSE=0.2659, R²=-0.0035
============================================================


============================================================
🔄 Round 167 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 167 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0004
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0067
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0030

📊 Round 167 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0030

📊 Round 167 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0029

============================================================
🔄 Round 171 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 171 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0022
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0010
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0028

============================================================
🔄 Round 175 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 175 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0004
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0035
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0028

============================================================
🔄 Round 176 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 176 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0027
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0032
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0028

📊 Round 176 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0029

📊 Round 176 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0029

📊 Round 176 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0029

============================================================
🔄 Round 183 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 183 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0020
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0034
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0028

============================================================
🔄 Round 187 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 187 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0013
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0001
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0029

📊 Round 187 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0029

============================================================
🔄 Round 190 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 190 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0007
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0103
============================================================


============================================================
🔄 Round 191 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 191 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0020
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0023
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0028

📊 Round 191 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0028

============================================================
🔄 Round 193 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 193 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0010
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0026
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0028

📊 Round 193 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0027

============================================================
🔄 Round 195 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 195 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0011
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0038
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0027

============================================================
🔄 Round 197 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 197 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0005
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0045
============================================================


============================================================
🔄 Round 198 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 198 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0010
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0013
============================================================


============================================================
🔄 Round 199 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 199 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0006
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0058
============================================================


============================================================
🔄 Round 201 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 201 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0010
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0038
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0028

📊 Round 201 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0028

📊 Round 201 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0028

============================================================
🔄 Round 206 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 206 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0013
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0191
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2416, R²: -0.0028

============================================================
🔄 Round 207 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 207 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0006
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0030
============================================================


============================================================
🔄 Round 208 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 208 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0005
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0033
============================================================


============================================================
🔄 Round 209 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 209 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0036
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0118
============================================================


============================================================
🔄 Round 210 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 210 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0039
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0110
============================================================


❌ Client client_84 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
