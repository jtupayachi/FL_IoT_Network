[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09ddfc5b-05d5-4944-b727-878ee2376cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c74e1e6-4197-4008-992c-19561fe481f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84efb23c-12f3-42cd-a8c5-a1dd75a7fb79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe8d4d3f-fb99-4ad0-8ac2-7c38499b9fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b838f6-9f62-4384-b84c-4f7874231fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0be3ce-eb8a-4e5c-b5e0-ccf9c863eba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb57647-0a1b-4811-9177-722deed84e4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2100522e-ed8d-4f2e-a12c-bf043e990287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de663ef-f246-407a-9427-19a9de74b446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 083ccbd5-d8af-4541-ac24-7103a4237b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7e0ba4c-a3e8-4570-822f-85d64cfb1146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ce1dcce-60d4-4f04-a053-96237015e572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 893dfdeb-d51c-4dec-bd0d-ba9b7ffb7cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc94aad1-acf6-4ea9-8b94-14560c027b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d551ef9-42d4-465b-b0c9-6fa8cc22a8c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 118d7985-5d4d-4b11-ba20-8dd763836c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb474f7-7c1a-415f-9bb9-a65b18df9dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 801d66bc-6cd5-45ec-a4c6-82f6e58be539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f368cfe-e118-4d18-977d-6259c49d55c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c67bbf-bb90-4fb9-a8ad-6047cd292e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39647ea2-34e6-49df-9ba5-1ab955e13352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 321d6d54-c0fd-44da-b354-06141b96a91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09fd1d15-988b-42bf-badf-71167e1667f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e00782f-6956-4768-883f-07a02299fea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df98df5f-92f9-4414-baa1-591365145263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91263451-63a9-4481-a20a-9e9f35ba21ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7af8a616-ab8a-40ce-bfd2-265ce98fe709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6464e996-c10a-4f1a-a816-65467939ac9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56c6a0e9-6167-4e91-ac65-6a45dd04549e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9965d70d-7619-4a67-86db-cce3f4de3244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de639172-7e98-4ba5-a67a-75ef4b3eb1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9c44e1-4faa-4904-af28-5205053eeead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15c0d47e-79ab-4342-9ef2-abf581869aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 586c33c8-36ed-4233-93c4-11cbc87fb33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8578e107-cd33-4b4c-b07b-a9740e9c3edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81690289-2d45-4b63-a832-ef5c4e926076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1b02130-4e7e-49a6-9100-b2632d22dee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfa55ce0-8da7-40b1-b9b5-40fd0aed67ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b16d72-fe2f-4d30-9877-41a4f7a4e49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24095faf-2fcc-41e8-8db1-831edc5bdc73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 234f2baa-72a5-463b-b93d-6ab9dad6b618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97349a21-e019-4931-a67a-e4fa22f98551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03a2c25d-899c-4d7f-9bb9-d4b5f566aeba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e06358d6-2240-4276-acd4-d6df94baf63e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ab37351-20cd-446f-8839-14cb9540dfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2367cdb3-644e-4d83-8e1d-20a8c86bd29b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 679c8377-6aaa-4319-9839-cb203f2a2e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62685670-d662-4faf-a74e-6895527b09ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de857b05-026b-4768-8e6b-2b98067dec96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e277c24-9313-462e-ae0e-e778e457ea46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfe34f71-0916-4e10-8e39-3edfbe534c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f544436-7aed-47f9-9b08-ce557e3eafbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda0dfed-c8ee-4196-a877-9af1392163aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c391811-0d63-4dec-adf2-1d8caec25b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01181d36-5767-47d6-9b34-c51d163626ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d8cbcb3-1462-44ee-87c9-05ff6c7ce087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd662419-4f63-4ec0-a72d-61611b57f725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c50068cf-9deb-449a-bc59-7644140a4953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4ab835f-3117-4d3b-9120-7acc96b6a911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a714e4bb-c3f8-4feb-94a8-ae43641e5300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9149a91-61bf-44b5-bfb6-fe9abf7872cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4745bf3-3f11-4a4f-a090-3667bd719b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53b6ff9a-5739-41a9-b8da-8dc425a21a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b3ddafb-4039-4211-a561-2dd921b071b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5dedf68-deb5-421b-b90a-902fe6a56b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bae14a09-4527-48da-8423-6ab713af138f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be67cd98-6007-472c-ae45-4f8ade93f378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16fe67e-b774-49bb-9f1d-e78565c53e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bfadf97-20f7-4721-94a4-1b3fef72cd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aaa99e0-9cb3-4835-9081-160bf8677909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d69b0f9-ee94-4585-8b36-e4a615ac8895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d621735-1708-4aa1-a302-6db2389742fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a82edeb-5beb-4c27-833d-faad512851d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a2198ab-9cd6-4ade-a238-0a822221f338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8855eac-0b19-483c-86af-0b4f4a0c13a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 081cf38f-77ac-40fb-bfbd-aa5b6f8be9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b228b87a-98cf-41ff-a666-06b9f0144b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e8e6639-32e3-4aeb-97fc-2db79338ddee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6a90beb-84c6-480d-8fba-f8055f7d77d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 603a3253-df10-4172-ac4a-ef9a5f6b7d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e72a95ff-3018-4b63-a71f-4f84c0dc8915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93dfe2a3-66ed-4607-bf1c-fd683c1ef9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ad43326-26c6-48ed-a4f9-07fc65d04599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8a05224-eb15-4458-bc87-0889d1af1926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 853ef8d1-459a-4d23-8419-aa090e93f5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ded5ab7e-10a9-4081-b9ce-da2268efd922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 864b1d43-62e9-4f67-87c3-778505a026f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a83f9ab5-4a11-418f-8834-ac8c4f2f5a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d0dafcb-b825-4433-ace7-e679c7f15a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08393c86-8d1c-48fb-b109-fd82f899b737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92274161-3626-48ce-984a-66e1abbcb610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e67bdadf-96a0-4efc-bc2c-668b6bcf18ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a734f874-4f96-4b47-9306-f407e81695d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 323bac46-537e-4db2-88c8-452ef8d6374d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91fa19e2-ab9a-4e1c-b792-c1edcb96f13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a0705a-292b-4a13-8080-a474c4f0e204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd1de22b-2ec6-4896-bdb4-d757350f47dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a1e1c6-9ba2-4e04-9efe-5e4bb39686d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c78255-1c8f-40ca-8495-c98bd0564cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6cf0e5-b747-4971-9dc4-0f0fdabe5228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361c2f57-2885-42f4-9138-3e14ec173c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 371d8a44-ffbd-4f50-8073-fdcef413a7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2651bae-f6f1-4d7f-ad2d-e85124e7d158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b530cd25-4a26-4da0-ab55-ef3d1cf7493c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591439ad-1f60-4490-808a-c71176fa91cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7dbf8b4-9930-44a9-b8b6-2406a0a5aa32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44fc7fe1-05f7-4c0b-9a2d-af956e77c1f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82a4270b-421b-48d3-b5a2-e15e58c719ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ff0d1cb-72dc-4ea0-a2fb-8df18c233856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 849b7480-1098-4f7d-a262-caf6a654e5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f4a21a-3d9a-413d-902a-2115c79fc3af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6983fdfa-1fe5-406e-9dfd-46f9db57decb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ee8d02-b687-4465-89f2-1aef59361a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38420aa3-903b-4792-9a93-0c094e854a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ff589c-6226-4056-8381-4742f0921878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89f871e9-a505-437a-9f51-3e6a2fea75a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fde0b4a4-bb57-4930-846f-d3217f9892c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dd145b2-7a5e-46b0-be94-49faf0428972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaec3129-1189-43f6-ab99-10e11f499607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a7d946f-2645-47c0-af07-ed9b950042a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d62e95e-aeca-4fe3-8ef9-8a886b61971b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c31c8d-a47b-442c-905d-0cb82f1fcd7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24fb8253-516e-4be0-8584-5ac923d62540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6504a48f-ef2a-48cb-81ff-26df4805c9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b23a6be-8571-4254-9b08-26d3e659f26b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a9a9d4-4f61-4067-b08c-fcf085d0c591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54bb12c2-ac8b-4896-a09b-2fdb86c96ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d52f4e9-f4d9-453b-8cec-f6a928773469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ba8a34-f5f8-4933-a870-138d7a2da999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5872df85-f78c-4c4e-a665-94da5162717d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f961ad9a-e46a-4ead-ba13-db8411bd438a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8518d934-448c-4d5e-af00-a13f80241b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56f3a479-6ba1-4e45-a5fc-f67b8b94ef0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ecb97f1-5d4b-42db-ba0d-9aae5dd3879b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33f8372c-697c-4e21-aeea-adf7a052a355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a57ccdc8-eb6f-42ea-862e-025497f6dd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 318ca24f-9119-4072-91a5-0dff2022da3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d4bd8e-fb51-4c63-9eca-0b098bb32ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 507ae22b-4309-4b84-baf2-19214de52c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d44d9987-e414-4666-a581-b7f191321940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0bc1d2-e0a5-4bdd-8a2b-68cb49b6dce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459bff38-351f-42b0-ac18-2ff20f929ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 884ae360-9ec5-48a1-82fe-063255f834a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85666387-5002-4105-8af1-5f71732c1b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b981546c-e773-497f-a685-9c631ae62a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b674e7a-7bd9-49f1-a8a8-140ee755f080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad2d472-aa5f-4cff-8b16-2ed268c9fea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e990b9ce-3a3d-4497-840b-6f8fdd3d4792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60be312-e03c-45ff-817c-4b1163bb6302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3955d643-d19d-48eb-81f2-912a40734245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d85f79-1b8d-43bf-83f1-5eff8999d8be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06bda9a5-46f2-40d3-af5f-aacb5c50be53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab888553-657e-4f84-b1ed-e7df2b310ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e76da23b-f58c-46a0-8b33-dfec4e761840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a0dc4f2-ad0a-4cc1-9264-d0da2b274791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198e8833-d595-4a23-b7d8-65dfffe58dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9b9907a-f178-4620-a695-37769efe043b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 102b30cd-692f-4a0d-bbe9-ac39e2cee12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3cf451c-8e03-4eeb-b619-cf3d0ac14b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc21c5a7-babf-41f2-96c9-672d4b3e43a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b36b148-ce21-4c1d-a0df-d7450ffc55c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 344d47cd-1e25-4952-87a1-85d16ad09bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29a9f1ff-394b-4137-a984-1a74f934fde5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d4717e-fc4b-4f0d-ae77-7dcc3417b30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1c5aa8a-e214-4466-90d3-b643a2dcf509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0369b181-8d75-466f-b501-ecebd91423a2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_85
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/test_labels.txt

📊 Raw data loaded:
   Train: X=(1160, 24), y=(1160,)
   Test:  X=(291, 24), y=(291,)

⚠️  Limiting training data: 1160 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  282 samples, 5 features
✅ Client client_85 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 10 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1014, val=0.0778 (↓), lr=0.001000
   • Epoch   2/100: train=0.0847, val=0.0789, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0836, val=0.0774, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0829, val=0.0776, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0827, val=0.0779, patience=4/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0799, val=0.0788, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 10 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0019
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0101
============================================================


============================================================
🔄 Round 11 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.1143, val=0.0850 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0828, val=0.0843 (↓), lr=0.000250
   • Epoch   3/100: train=0.0810, val=0.0844, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0809, val=0.0845, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0809, val=0.0845, patience=3/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0806, val=0.0847, patience=9/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 11 Summary - Client client_85
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0033
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0048
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1602, RMSE: 0.4003, MAE: 0.3236, R²: -0.9636

📊 Round 11 Test Metrics:
   Loss: 0.1549, RMSE: 0.3936, MAE: 0.3182, R²: -0.8984

============================================================
🔄 Round 13 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1358, val=0.1412 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1151, val=0.1183 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0978, val=0.1009 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0865, val=0.0901 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0816, val=0.0860 (↓), lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0805, val=0.0854, patience=5/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0804, val=0.0856, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 13 Summary - Client client_85
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0037
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0030
============================================================


============================================================
🔄 Round 14 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1368, val=0.1478 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1314, val=0.1411 (↓), lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   ✓ Epoch   3/100: train=0.1259, val=0.1348 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1220, val=0.1318 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1196, val=0.1291 (↓), lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1077, val=0.1147 (↓), lr=0.000004
   📉 Epoch 19: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1001, val=0.1060 (↓), lr=0.000002
   📉 Epoch 27: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0974, val=0.1026, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0959, val=0.1007, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0946, val=0.0988 (↓), lr=0.000001
   • Epoch  61/100: train=0.0933, val=0.0970, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0921, val=0.0954, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0910, val=0.0938, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0900, val=0.0923, patience=1/15, lr=0.000001

============================================================
📊 Round 14 Summary - Client client_85
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0715
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.1820
============================================================


============================================================
🔄 Round 16 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1265, val=0.1275 (↓), lr=0.000001
   • Epoch   2/100: train=0.1262, val=0.1272, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1259, val=0.1269 (↓), lr=0.000001
   • Epoch   4/100: train=0.1257, val=0.1266, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1254, val=0.1264 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1238, val=0.1247 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1215, val=0.1223 (↓), lr=0.000001
   • Epoch  31/100: train=0.1193, val=0.1200, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1173, val=0.1178, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1153, val=0.1156 (↓), lr=0.000001
   • Epoch  61/100: train=0.1134, val=0.1136, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1115, val=0.1116, patience=2/15, lr=0.000001
   ✓ Epoch  81/100: train=0.1096, val=0.1096 (↓), lr=0.000001
   • Epoch  91/100: train=0.1079, val=0.1077, patience=1/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_85
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1064, RMSE=0.3262, R²=-0.2831
   Val:   Loss=0.1060, RMSE=0.3256, R²=-0.3548
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1299, RMSE: 0.3604, MAE: 0.2946, R²: -0.5915

============================================================
🔄 Round 17 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1224, val=0.1252 (↓), lr=0.000001
   • Epoch   2/100: train=0.1222, val=0.1250, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1220, val=0.1247, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1218, val=0.1245 (↓), lr=0.000001
   • Epoch   5/100: train=0.1216, val=0.1243, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1203, val=0.1230, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1183, val=0.1209, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1164, val=0.1188 (↓), lr=0.000001
   • Epoch  41/100: train=0.1145, val=0.1168, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1126, val=0.1148, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1107, val=0.1128 (↓), lr=0.000001
   • Epoch  71/100: train=0.1089, val=0.1108, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1071, val=0.1089, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1053, val=0.1070 (↓), lr=0.000001

============================================================
📊 Round 17 Summary - Client client_85
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1038, RMSE=0.3222, R²=-0.2611
   Val:   Loss=0.1054, RMSE=0.3246, R²=-0.3077
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1149, RMSE: 0.3390, MAE: 0.2806, R²: -0.4083

📊 Round 17 Test Metrics:
   Loss: 0.1022, RMSE: 0.3197, MAE: 0.2673, R²: -0.2525

============================================================
🔄 Round 21 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0845, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0825, val=0.0842, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 21 Summary - Client client_85
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0103
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0332
============================================================


============================================================
🔄 Round 22 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 22 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0051
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0377
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2468, R²: -0.0176

============================================================
🔄 Round 24 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 24 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0051
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0037
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2465, R²: -0.0095

============================================================
🔄 Round 27 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 27 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0003
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0044
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2465, R²: -0.0086

📊 Round 27 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2464, R²: -0.0080

📊 Round 27 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2464, R²: -0.0077

📊 Round 27 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2464, R²: -0.0072

📊 Round 27 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2464, R²: -0.0070

============================================================
🔄 Round 33 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 33 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0004
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0071
============================================================


============================================================
🔄 Round 34 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 34 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0003
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0035
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2464, R²: -0.0065

📊 Round 34 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2463, R²: -0.0059

============================================================
🔄 Round 37 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 37 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0004
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0017
============================================================


============================================================
🔄 Round 38 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 38 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0015
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0038
============================================================


============================================================
🔄 Round 40 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 40 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0014
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0051
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2463, R²: -0.0052

📊 Round 40 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2463, R²: -0.0050

============================================================
🔄 Round 42 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 42 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0011
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0010
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2463, R²: -0.0047

============================================================
🔄 Round 45 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 45 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0011
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0057
============================================================


============================================================
🔄 Round 46 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 46 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0004
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0065
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2462, R²: -0.0045

============================================================
🔄 Round 48 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 48 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0010
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0042
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2462, R²: -0.0044

============================================================
🔄 Round 49 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 49 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0012
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0105
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2462, R²: -0.0043

============================================================
🔄 Round 50 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 50 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0007
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0028
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: -0.0042

============================================================
🔄 Round 52 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 52 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0003
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0052
============================================================


============================================================
🔄 Round 53 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 53 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0028
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0054
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: -0.0041

============================================================
🔄 Round 56 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 56 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0018
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0084
============================================================


============================================================
🔄 Round 57 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 57 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0016
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0037
============================================================


============================================================
🔄 Round 58 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 58 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0008
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0016
============================================================


============================================================
🔄 Round 61 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 61 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0020
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0051
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: -0.0038

============================================================
🔄 Round 63 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 63 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0019
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0027
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: -0.0037

============================================================
🔄 Round 64 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 64 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0022
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0042
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: -0.0037

============================================================
🔄 Round 65 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 65 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0002
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0176
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: -0.0037

============================================================
🔄 Round 66 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 66 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0001
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0039
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: -0.0036

============================================================
🔄 Round 69 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 69 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0842, RMSE=0.2903, R²=0.0033
============================================================


============================================================
🔄 Round 70 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 70 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0000
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0234
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: -0.0034

📊 Round 70 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: -0.0033

============================================================
🔄 Round 72 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 72 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0003
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0029
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2462, R²: -0.0032

============================================================
🔄 Round 74 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 74 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0001
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0015
============================================================


============================================================
🔄 Round 75 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 75 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0005
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0083
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: -0.0028

============================================================
🔄 Round 80 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 80 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0010
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0007
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: -0.0028

============================================================
🔄 Round 81 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 81 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0016
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0041
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: -0.0028

============================================================
🔄 Round 82 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 82 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0010
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0021
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2462, R²: -0.0028

============================================================
🔄 Round 86 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 86 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0007
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0028
============================================================


============================================================
🔄 Round 87 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 87 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0000
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0009
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2462, R²: -0.0028

📊 Round 87 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2462, R²: -0.0025

============================================================
🔄 Round 92 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 92 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0026
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0115
============================================================


============================================================
🔄 Round 93 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 93 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0031
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0081
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2462, R²: -0.0024

============================================================
🔄 Round 95 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 95 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0019
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0011
============================================================


============================================================
🔄 Round 97 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 97 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0006
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0112
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2462, R²: -0.0024

============================================================
🔄 Round 99 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 99 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0012
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0300
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2462, R²: -0.0024

============================================================
🔄 Round 100 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 100 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0008
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0001
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: -0.0022

📊 Round 100 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: -0.0022

============================================================
🔄 Round 105 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 105 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0002
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0022
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2461, R²: -0.0021

============================================================
🔄 Round 107 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 107 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0011
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0324
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2461, R²: -0.0020

============================================================
🔄 Round 109 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 109 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0001
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0025
============================================================


============================================================
🔄 Round 112 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 112 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0014
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0003
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2461, R²: -0.0019

============================================================
🔄 Round 117 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 117 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0010
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0007
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2461, R²: -0.0020

============================================================
🔄 Round 118 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 118 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0002
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0057
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2461, R²: -0.0019

📊 Round 118 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2461, R²: -0.0019

============================================================
🔄 Round 120 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 120 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0002
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0013
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2461, R²: -0.0018

============================================================
🔄 Round 124 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 124 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0000
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0059
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2461, R²: -0.0017

============================================================
🔄 Round 129 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 129 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0022
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0100
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2461, R²: -0.0017

============================================================
🔄 Round 130 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 130 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0004
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0089
============================================================


============================================================
🔄 Round 131 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 131 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0015
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0063
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2461, R²: -0.0017

📊 Round 131 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2461, R²: -0.0016

📊 Round 131 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2461, R²: -0.0016

============================================================
🔄 Round 135 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 135 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0006
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0079
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2461, R²: -0.0016

📊 Round 135 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2461, R²: -0.0015

============================================================
🔄 Round 137 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 137 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0005
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0005
============================================================


============================================================
🔄 Round 140 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 140 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0016
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0006
============================================================


============================================================
🔄 Round 141 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 141 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0030
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0092
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2461, R²: -0.0015

============================================================
🔄 Round 142 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 142 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0004
   Val:   Loss=0.0915, RMSE=0.3024, R²=0.0038
============================================================


============================================================
🔄 Round 143 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 143 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0012
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0005
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2461, R²: -0.0016

============================================================
🔄 Round 144 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 144 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0010
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0052
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: -0.0017

📊 Round 144 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: -0.0017

============================================================
🔄 Round 149 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 149 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0004
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0037
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: -0.0017

============================================================
🔄 Round 151 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 151 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0010
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0002
============================================================


============================================================
🔄 Round 155 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 155 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0003
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0151
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: -0.0017

📊 Round 155 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: -0.0017

📊 Round 155 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: -0.0017

📊 Round 155 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: -0.0016

============================================================
🔄 Round 162 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 162 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0006
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0025
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: -0.0016

============================================================
🔄 Round 165 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 165 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0007
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0013
============================================================


============================================================
🔄 Round 168 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 168 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0008
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0219
============================================================


============================================================
🔄 Round 169 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 169 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0022
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0054
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2461, R²: -0.0013

📊 Round 169 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2461, R²: -0.0012

============================================================
🔄 Round 175 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 175 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0005
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0006
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0013

============================================================
🔄 Round 180 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 180 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0010
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0125
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0013

============================================================
🔄 Round 182 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 182 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0009
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0016
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0013

📊 Round 182 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: -0.0014

📊 Round 182 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0013

============================================================
🔄 Round 190 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 190 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0006
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0005
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0013

============================================================
🔄 Round 191 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 191 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0013
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0096
============================================================


============================================================
🔄 Round 192 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 192 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0002
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0005
============================================================


============================================================
🔄 Round 193 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 193 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0008
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0014
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0012

============================================================
🔄 Round 194 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 194 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0011
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0005
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0012

📊 Round 194 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0013

============================================================
🔄 Round 197 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 197 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0027
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0092
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2462, R²: -0.0014

📊 Round 197 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0013

📊 Round 197 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0012

============================================================
🔄 Round 203 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 203 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0008
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0029
============================================================


============================================================
🔄 Round 204 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 204 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0006
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0026
============================================================


============================================================
🔄 Round 205 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 205 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0009
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0014
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0012

📊 Round 205 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2462, R²: -0.0012

============================================================
🔄 Round 211 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 211 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0001
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0010
============================================================


❌ Client client_85 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
