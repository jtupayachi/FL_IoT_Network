[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9891cd-9f19-4bc7-9b48-ef28b349ecc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9443f780-b94a-43b4-ad2b-a926feceef42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a06be19-dbaa-489f-97de-31bc2656911c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5cad3d4-6cd4-4c2e-805a-f9d4368360bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 965c85f0-12bc-4c5a-8085-29265fc09512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85493dc2-ae4d-44ee-8232-99c4127a835b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 910b454c-4bde-480a-a13c-516f28a25d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b8a9bfb-a171-4b60-a139-c2eb012680e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eccb86e-b831-4318-a3b0-a44bd1bd12cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6bfa67-4187-42b7-a118-770bba684c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b072413-e9dd-49ab-9a8d-b924cd099a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e3ce03-839c-4028-925f-7da4f9551d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db4d145-7f85-4419-81e2-f78e4649b321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d48c219f-090c-44fd-b407-d738be5b41f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7e93e11-90ce-4472-9a6a-5cfe6973cda8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f985d49-e327-4a39-bc50-0044938fb605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85ef4cc1-bede-4dfd-94eb-51514b6d6fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88bc2755-0809-4919-99aa-3ff5f2a7d9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17d1b0e5-2320-467f-9792-787a7a35a0f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9432360f-b90e-49f5-bb3e-37f80e12ac20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdb467b5-e8a1-479b-9ce4-818c15cfdde3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02c72cc3-1a2d-4300-8011-4485a3599f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b30c6e1-ab0c-4e5b-96ee-f98a0419acc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f65894e-928e-4554-9c4d-41cdc1977960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00221475-fae8-4726-8399-8b0114fec4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2339689-c796-4cf4-bd1f-95fac388d7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6aba778-a2aa-4ce4-b53d-a457d9929353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff485cf3-fa89-4401-8678-2c25e95b876a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67789edc-49dd-416f-a20b-e4ecf3472ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d936ae4f-4e80-4347-bc69-422f27937545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 475d96a7-c1c8-4d79-af60-69efed2039b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be581a34-6cc3-446f-b7ba-f3d279a3f1ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 702148da-6fe3-49c8-9f4e-60b4dfe942eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4359c3cc-7a26-4a03-99dc-819a09fe0746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5935d9d-1dee-4494-a89a-8beddf6a1c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bc2388d-0290-4014-92ac-6a9a9ea30f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae1fedf7-590d-47b6-8db6-a783ede30913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6188eb55-e76c-4d20-b617-e208d63c40a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02811d11-6a8e-4173-bc4b-855fe50dd0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec842b98-084d-4bf5-a611-a357c86acbcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 363cb45d-04e3-468c-9a3b-e616e703c691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23cc08d0-12b3-4601-aec2-50afaa319357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2cc64d-38dd-494b-9b02-7f4cb80ffc63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd444635-5bed-4fc3-883e-f110b2f69a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f7359ac-3ece-43ed-95b1-173d92a38bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66506afb-b119-44de-b6a0-55a11d1fcf8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b9f1f30-5eca-4d8c-8d3c-4b0e23433a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 945768be-3090-43da-8bcf-6bd6d0c4a3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 005a412d-623e-42c7-8d5c-0b3b78bc693e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25765fcf-41c2-492f-989c-c491074f8b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ade4642c-08eb-4347-815f-3d8c790b5a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b3ffd80-b648-419e-b53a-2042985704ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeb351b1-1821-46d4-86cd-79d94f34d56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61177a4b-7648-495b-8234-531c5ae81769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message addb9c56-d74b-4a46-9332-01938c80a576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec842c24-c6db-40db-8d5d-579bf23c3b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e264ecd8-6cc6-49c8-96c6-b0f3509623fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1a43b29-3e1e-4769-91d7-0746e08aa9aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe9b491c-0cd2-4e80-9ef1-a888472a0b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4170e1d-a7f0-4a46-aff2-40800578f317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1af6d1fa-f9eb-44c8-9ecf-a853c0c772cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74c43b18-8e16-4946-a4cb-b45cf3ad2ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e1b2751-4843-432d-ad79-799920de071c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f04d20ea-30bb-42e5-a7fa-dd4d3c4f9faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65dcb295-574d-49da-aa3c-b8eaf55a9295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7a64f67-712f-44cd-86e2-ac8194821a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2f83aaa-6620-4b31-8e50-4448749f2055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb2b9f9e-e980-4167-bd64-adfce1ebc77b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 768e1139-3a5b-4ae4-9d2b-58f4b8c8b722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1f74509-2813-492d-9eb2-1307d3c1b17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e03f1dd7-2a0b-4317-abb5-0952f3259b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9569a9e3-8d30-402b-bbfd-ac1186bfb932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6b63ec3-95d1-4551-846b-c0ece4254e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2906f3f4-09a1-4675-8457-584bfca5b396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2994de07-5fc4-4a4d-9151-8f23d16b64c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 967d798c-f21d-4e2f-b64f-98fa634a82df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e8ddff9-958f-4e06-85e0-26d4b3f16119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8168684-85f3-428e-8c13-a1c230ec72b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02717f71-a388-4bf6-bd09-bd64f1946f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fef3532c-b26f-42ab-a300-68f7ffa785c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 595b32d3-2e49-49c7-860d-e1c64af945d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a29e269-8972-4a82-8b21-2e91a536cb4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b71dde-70c5-4331-93da-7b2adc986491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f6ec26-5d92-4816-9dbf-b27e7b5e2aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90ea4cfa-ff9a-4ede-8b89-db53866b7970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8279e13f-f8f8-4b2b-ad8b-6a6a25be1956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9789604-d109-4e40-b3da-d46110af776f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7947648a-2271-4757-a183-cc6258fc70eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ef54c97-25d7-4a39-a366-3fbf28b583fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d92f036-eff1-4eb9-b8a6-e8e2d3df0ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18d720ac-e4ce-4526-b7f2-8cd70d75163f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2858eadf-c389-428a-afe0-4a4137bc53e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 664e9506-227e-4881-9f23-c5b4e282c9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cda370c0-5d20-40f1-bac2-5fd1ccb22ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06663578-5777-4942-aded-02bf72b5e4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 811d1bda-a943-4e67-b5f7-40590e2bc16d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 586315c6-2aa5-412a-b73c-207985452b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b03f3c3-2d11-40d3-ad4b-8e4a665da097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e9c0c67-b787-4114-bfe6-0044d061fc26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4163930b-0aa9-4cb9-a4ae-77325187e33c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb0fd352-447b-452b-b702-582150dd236f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3ac8dd4-3f3a-471e-8063-d9ed8f388eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4926cf59-14ef-491b-ba08-d5fbf981afe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 035e0470-6a7e-442a-9797-6f53f763f528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9949155-989c-45ba-836b-649435dba0a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 895323d9-3a8a-4ad8-b911-a1ac55284303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6e7309c-8c20-4d1b-90d2-8d77afd64b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa12b321-05e0-4905-acf1-b12a78bd7b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9a2002-7c21-4a39-b4f4-34c2411f69a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b54fcaf2-5a5e-4e8f-aebf-9b6d23fe4fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b04f5f0-2303-4e92-b974-30d92ed702e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 183b8ad6-e851-4da7-9e13-4f019d1dec83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b665f44c-1d19-4855-a98e-c3bdb1edada5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41d34a58-67e9-4b53-8457-d4d0157fc935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f318b838-8f3c-4431-aaae-0d102df68ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46da4364-2021-4edf-87bc-4b6f6e13bd4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e34b90-ad02-47b2-803c-7f5268218449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1da119d5-a518-4e3e-b7be-7fef05d3e55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 512e5b82-7f7b-4969-8cca-05c430d16e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3775b483-04be-411e-b0ba-727dc8f7b3a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc04e96-de18-48ad-ba4e-ef2f6ed6e10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeea86df-cfe0-4d2b-bb3b-889beb95f5a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7cdd34a-2040-4b1e-9bab-30b699d80930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bccc9b9-b4d6-4043-93fe-528f82f5a85f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49484a51-26ec-4ec0-92cf-9d4daa669929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f710360d-814b-4c75-81a9-a2eba1217af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c7aaeae-3637-4201-970a-68c47cb23c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf3762e5-2e27-4ef4-a0ac-051381308429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3727d00d-ff9b-4458-8db9-39ffca16b278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71164622-e6ec-42f3-8140-834240960ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b316938-da50-448e-abd6-7af61ad83e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78cbc255-514d-491d-83f0-91aba7017aa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 570713f9-5141-41fb-a0b5-3943b3383269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9259d690-7a01-41b4-8202-177fdf302c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd0eb54c-a008-4b0a-8a1d-a8b516903fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 248c96bc-3b6f-4194-8568-65d795b8da90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44f9b2ee-348e-41f8-ad2d-0553c244b107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e0d7a4d-b7a8-4688-83eb-e8bd0a67f892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4e12f95-6eee-4013-958d-df4943aa969b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e9c147-552e-46d3-a7fd-5a4752cb8021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bce20b5e-a63e-44c7-a260-364b2a063928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1316838-0dbe-4835-89c9-54dc258a67dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf64b88-c0a8-4549-8651-ab3bf9e9c107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f35a1c-737d-4238-b210-1428dc58eb0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad14fdbf-dc52-45d0-b65f-de9a7bb27766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa69a032-5ed3-4f64-a95b-ceb40c6fb1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2763c807-d97b-467e-9239-8bec30afc063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90bfd2a3-aac7-406b-ab7e-8fcb4c3267c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 099d5bb2-1814-4510-8615-736c969e77fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd652ab0-c3a2-470e-8b6a-e8f468c762bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2a389f1-e4aa-4867-a639-32f08935cfba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82a81258-b4da-4599-b847-cbcf37256f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db35ff83-f09b-4f39-9d54-6b2af521ea73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35cf0052-fa9b-4a98-b099-b0078e58e38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3927f60a-b050-41df-a767-fa77cc0d1883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbdeca2c-ee0a-4fb5-b1f5-6e94e4ee886f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_86
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/test_labels.txt

📊 Raw data loaded:
   Train: X=(698, 24), y=(698,)
   Test:  X=(175, 24), y=(175,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 689 samples, 5 features
   Test:  166 samples, 5 features
✅ Client client_86 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1739, RMSE: 0.4170, MAE: 0.3379, R²: -1.0823

============================================================
🔄 Round 10 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1056, val=0.0692 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0900, val=0.0686 (↓), lr=0.001000
   • Epoch   3/100: train=0.0887, val=0.0696, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0878, val=0.0692, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0878, val=0.0693, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0863, val=0.0702, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 10 Summary - Client client_86
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0060
   Val:   Loss=0.0686, RMSE=0.2620, R²=-0.0181
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1628, RMSE: 0.4035, MAE: 0.3281, R²: -0.9501

============================================================
🔄 Round 12 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1272, val=0.0970 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0852, val=0.0917 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0835, val=0.0889 (↓), lr=0.000250
   • Epoch   4/100: train=0.0824, val=0.0892, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0823, val=0.0892, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0819, val=0.0894, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 12 Summary - Client client_86
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0040
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0011
============================================================


============================================================
🔄 Round 13 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1419, val=0.1185 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1187, val=0.1008 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1000, val=0.0898 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0885, val=0.0857 (↓), lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0839, val=0.0861, patience=1/15, lr=0.000031
   • Epoch  11/100: train=0.0826, val=0.0866, patience=7/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 13 Summary - Client client_86
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0323
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0027
============================================================


============================================================
🔄 Round 14 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1393, val=0.1369 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.1339, val=0.1302 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1295, val=0.1270 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1268, val=0.1241 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1243, val=0.1214 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1123, val=0.1086 (↓), lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.1052, val=0.1007, patience=1/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.1025, val=0.0977, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1009, val=0.0958 (↓), lr=0.000001
   • Epoch  51/100: train=0.0994, val=0.0940, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0980, val=0.0923, patience=2/15, lr=0.000001
   ✓ Epoch  71/100: train=0.0966, val=0.0908 (↓), lr=0.000001
   • Epoch  81/100: train=0.0954, val=0.0893, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.0942, val=0.0878 (↓), lr=0.000001

============================================================
📊 Round 14 Summary - Client client_86
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0940, RMSE=0.3065, R²=-0.1028
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.1432
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1396, RMSE: 0.3736, MAE: 0.3077, R²: -0.6713

📊 Round 14 Test Metrics:
   Loss: 0.1341, RMSE: 0.3662, MAE: 0.3029, R²: -0.6060

============================================================
🔄 Round 16 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1279, val=0.1157 (↓), lr=0.000001
   • Epoch   2/100: train=0.1276, val=0.1154, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1273, val=0.1150 (↓), lr=0.000001
   • Epoch   4/100: train=0.1270, val=0.1147, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1267, val=0.1144 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1251, val=0.1126 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1228, val=0.1099 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1206, val=0.1074 (↓), lr=0.000001
   • Epoch  41/100: train=0.1186, val=0.1051, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1166, val=0.1028, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1147, val=0.1006 (↓), lr=0.000001
   • Epoch  71/100: train=0.1130, val=0.0985, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1112, val=0.0965, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1096, val=0.0946 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_86
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1083, RMSE=0.3290, R²=-0.2314
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.4377
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1296, RMSE: 0.3600, MAE: 0.2988, R²: -0.5522

============================================================
🔄 Round 18 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1075, val=0.1022 (↓), lr=0.000001
   • Epoch   2/100: train=0.1073, val=0.1021, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1071, val=0.1019, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1069, val=0.1017 (↓), lr=0.000001
   • Epoch   5/100: train=0.1067, val=0.1015, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1055, val=0.1005, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1037, val=0.0990, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.1020, val=0.0975, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1004, val=0.0961, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0989, val=0.0947, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0974, val=0.0935, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0960, val=0.0923, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0947, val=0.0912, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0935, val=0.0902, patience=2/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_86
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0934, RMSE=0.3055, R²=-0.1221
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0695
============================================================


============================================================
🔄 Round 24 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 24 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0072
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0080
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2554, R²: -0.0068

📊 Round 24 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2553, R²: -0.0065

============================================================
🔄 Round 26 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 26 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0053
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0018
============================================================


============================================================
🔄 Round 33 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 33 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0065
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0007
============================================================


============================================================
🔄 Round 34 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 34 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0066
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0031
============================================================


============================================================
🔄 Round 36 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 36 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0060
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0052
============================================================


============================================================
🔄 Round 37 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 37 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0053
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0040
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2551, R²: -0.0060

============================================================
🔄 Round 39 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 39 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0038
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0129
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2550, R²: -0.0060

📊 Round 39 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2550, R²: -0.0060

============================================================
🔄 Round 43 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 43 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0049
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0258
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2550, R²: -0.0060

📊 Round 43 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2550, R²: -0.0060

📊 Round 43 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2550, R²: -0.0060

============================================================
🔄 Round 50 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 50 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0057
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0074
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2550, R²: -0.0060

============================================================
🔄 Round 51 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 51 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0042
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0318
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2550, R²: -0.0060

============================================================
🔄 Round 54 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 54 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0064
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0056
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2550, R²: -0.0061

============================================================
🔄 Round 55 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 55 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0068
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0046
============================================================


============================================================
🔄 Round 56 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 56 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0037
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0258
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2550, R²: -0.0061

📊 Round 56 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2550, R²: -0.0061

============================================================
🔄 Round 62 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 62 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0036
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0167
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2550, R²: -0.0061

📊 Round 62 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2550, R²: -0.0061

============================================================
🔄 Round 65 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 65 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0085
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0002
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0061

📊 Round 65 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0061

📊 Round 65 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0062

============================================================
🔄 Round 70 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 70 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0085
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0001
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0062

============================================================
🔄 Round 71 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 71 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0185
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0532
============================================================


============================================================
🔄 Round 73 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 73 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0034
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0227
============================================================


============================================================
🔄 Round 74 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 74 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0055
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0198
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0062

📊 Round 74 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0062

============================================================
🔄 Round 77 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 77 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0058
   Val:   Loss=0.0831, RMSE=0.2884, R²=-0.0189
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0062

📊 Round 77 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0063

============================================================
🔄 Round 83 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 83 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0044
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0214
============================================================


============================================================
🔄 Round 84 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 84 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0106
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0063
============================================================


============================================================
🔄 Round 86 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 86 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0089
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0063
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0064

📊 Round 86 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0064

📊 Round 86 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0064

📊 Round 86 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0064

📊 Round 86 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0064

============================================================
🔄 Round 92 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 92 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0103
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0045
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0065

📊 Round 92 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0065

============================================================
🔄 Round 96 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 96 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0066
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0119
============================================================


============================================================
🔄 Round 97 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 97 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0089
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0015
============================================================


============================================================
🔄 Round 98 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 98 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0049
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0216
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2549, R²: -0.0066

📊 Round 98 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2549, R²: -0.0066

============================================================
🔄 Round 102 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 102 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0088
   Val:   Loss=0.0973, RMSE=0.3119, R²=-0.0086
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2549, R²: -0.0066

📊 Round 102 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2549, R²: -0.0066

============================================================
🔄 Round 106 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 106 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0042
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0334
============================================================


============================================================
🔄 Round 109 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 109 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0095
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0006
============================================================


============================================================
🔄 Round 112 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 112 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0048
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0222
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2549, R²: -0.0068

============================================================
🔄 Round 113 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 113 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0121
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0026
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2549, R²: -0.0068

============================================================
🔄 Round 116 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 116 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0075
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0070
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0069

============================================================
🔄 Round 118 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 118 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0099
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0062
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0069

📊 Round 118 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0069

📊 Round 118 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0069

📊 Round 118 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0069

📊 Round 118 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0069

============================================================
🔄 Round 123 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 123 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0109
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0015
============================================================


============================================================
🔄 Round 125 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 125 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0097
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0062
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0070

============================================================
🔄 Round 126 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 126 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0061
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0132
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0070

============================================================
🔄 Round 127 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 127 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0064
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0267
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0070

📊 Round 127 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0071

📊 Round 127 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0071

============================================================
🔄 Round 137 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 137 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0098
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0007
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0071

============================================================
🔄 Round 139 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 139 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0095
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0074
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0072

============================================================
🔄 Round 140 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 140 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0121
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0082
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0072

📊 Round 140 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2549, R²: -0.0072

============================================================
🔄 Round 144 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 144 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0047
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0198
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2550, R²: -0.0072

📊 Round 144 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2550, R²: -0.0072

============================================================
🔄 Round 150 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 150 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0138
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0114
============================================================


============================================================
🔄 Round 153 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 153 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0060
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0138
============================================================


============================================================
🔄 Round 154 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 154 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0084
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0050
============================================================


============================================================
🔄 Round 156 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 156 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0100
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0026
============================================================


============================================================
🔄 Round 157 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 157 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0052
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0174
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2550, R²: -0.0073

============================================================
🔄 Round 158 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 158 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0086
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0044
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2550, R²: -0.0073

============================================================
🔄 Round 159 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 159 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0093
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0042
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2550, R²: -0.0074

📊 Round 159 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2550, R²: -0.0074

📊 Round 159 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2550, R²: -0.0074

📊 Round 159 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2550, R²: -0.0074

📊 Round 159 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2550, R²: -0.0074

============================================================
🔄 Round 166 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 166 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0090
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0069
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2550, R²: -0.0075

📊 Round 166 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2550, R²: -0.0075

📊 Round 166 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2550, R²: -0.0075

============================================================
🔄 Round 170 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 170 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0129
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0126
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2550, R²: -0.0075

============================================================
🔄 Round 173 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 173 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0080
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0074
============================================================


============================================================
🔄 Round 174 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 174 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0046
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0381
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2550, R²: -0.0076

📊 Round 174 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2550, R²: -0.0076

============================================================
🔄 Round 177 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 177 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0077
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0075
============================================================


============================================================
🔄 Round 178 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 178 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0105
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0061
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2550, R²: -0.0076

============================================================
🔄 Round 179 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 179 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0069
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0289
============================================================


============================================================
🔄 Round 180 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 180 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0108
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0129
============================================================


============================================================
🔄 Round 181 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 181 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0134
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0147
============================================================


============================================================
🔄 Round 183 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 183 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0049
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0235
============================================================


============================================================
🔄 Round 184 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 184 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0063
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0138
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2550, R²: -0.0076

📊 Round 184 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2550, R²: -0.0077

============================================================
🔄 Round 188 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 188 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0087
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0060
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2550, R²: -0.0077

============================================================
🔄 Round 189 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 189 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0016
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0684
============================================================


============================================================
🔄 Round 190 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 190 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0064
   Val:   Loss=0.0821, RMSE=0.2864, R²=-0.0155
============================================================


============================================================
🔄 Round 191 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 191 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0153
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0119
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2550, R²: -0.0077

============================================================
🔄 Round 195 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 195 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0199
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0154
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2550, R²: -0.0078

📊 Round 195 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2550, R²: -0.0077

============================================================
🔄 Round 198 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 198 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0039
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0246
============================================================


============================================================
🔄 Round 199 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 199 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0095
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0021
============================================================


============================================================
🔄 Round 200 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 200 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0100
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0005
============================================================


============================================================
🔄 Round 202 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 202 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0104
   Val:   Loss=0.0673, RMSE=0.2594, R²=0.0002
============================================================


============================================================
🔄 Round 204 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 204 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0103
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0040
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2550, R²: -0.0078

============================================================
🔄 Round 206 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 206 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0134
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0035
============================================================


❌ Client client_86 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
