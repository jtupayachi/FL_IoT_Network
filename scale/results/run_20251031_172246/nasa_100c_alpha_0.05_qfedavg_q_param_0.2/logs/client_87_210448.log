[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74f6ecec-d988-484b-a2d2-f6aa6827e1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee57ef9c-2757-423a-81ec-98d1899660ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b80f0688-cc68-47f9-ac0c-6b05b1d1b57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31d616d-ffcb-47d1-8574-c93f1009e1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fafff51-8f82-4d0f-81e6-3ad2a92b0179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ce6d8a-3f58-4583-85dd-7d2c484acf7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0047e0f-4b61-41e7-9fd9-229ec8d0fbbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b02103-0462-4694-a867-d05d154d69d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 101366d6-06f8-42b4-8652-58dca17bf6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0c7480b-63dc-4cde-85b9-30b7b7c95a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c1417d-3f16-4eff-9cf6-f9bf5fd479d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 695bd190-cff3-49d0-b36d-c571f4c43b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5884b040-9f47-4659-b8a5-e712f7cd483e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae685469-3328-46d8-a82a-205510760fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d666a8-048e-4815-ae58-91b89b8403fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7351eb24-c515-4b4e-a8dd-aefe28a6196b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7a9e314-f87e-497b-98cd-57f2081d31fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47639135-555c-43db-9ed2-5616ae851757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6446a63-7e21-4d40-9943-80faa2453152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 333cf31e-39f7-4991-b070-a013429784d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08dc7562-822c-494f-8074-9a9858ab71b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd59ee3-0c6c-4a49-aa7e-19b65b054b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dea19f3-5fa2-4aaf-897d-741b30bde2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8495a1f-77cd-48b1-8eb2-3dcd0f9063f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26974ebc-cdb3-4978-a643-89328cd9c563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a8a02e3-b50e-4cdf-ad0d-7758a75f4b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ebf9f05-3433-4f1e-96c3-84c92adb724b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43a4ea4a-16a7-4183-b87a-e250153bb513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 939d7099-ba58-466f-a8e2-4c18bc37adcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a1d60be-c599-4a45-8bc9-0f16442dbdf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ad913f-0323-4b7b-9547-4ca67f9d67ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae49da1a-b1b1-4c39-8cce-1fac6c97251e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab654b64-2861-4c9c-ac88-cd16cafed353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b391576-bce2-4b25-adf3-46cb6625433f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bba791cf-f406-4312-be38-6862a5f3703e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19dac4fe-bf55-4d38-b8c5-1966d0042eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a57804b-e67c-423c-8878-93d1270d13a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c3b8444-42a6-4ff7-b53b-12d549bfd226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c019f3-d986-4506-8547-7272b5040f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b08e2e9-91b5-4516-8092-a73445c63f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e07124f2-b366-47eb-b85c-f24aba362443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8734d0-1f8d-45be-98df-8939deb2b4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 800f9ea3-30d0-48ad-a17d-b03c8d4ede5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ec9a345-058a-4aef-9acc-4595962e5479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb308396-a766-4f1b-9d8e-3796e17d7773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c484a2b-081a-491d-b42d-31258fd9eae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 043d630d-f54c-4fe2-8bcd-f297a5e2dfc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2518abb-9ba5-423b-9946-02c1cbe693f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9549720f-38b0-4657-8735-700fe2462b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692be323-69a5-41b2-a267-8f40701abd39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da82ffc8-401d-471a-8f5c-1569fbef2e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1277d76e-b539-4b51-bc13-a21a06b3b7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b11f267a-f75a-4261-9893-2337d8046807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b38593-8ec6-4c80-b468-9455673a4937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4be7291-516c-43ee-8039-33181ad5cfca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64f2a0c5-09c2-4db8-b5ff-0aad4f3f8119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23747904-c268-49c6-a7d1-dc8c44329d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3001c0ff-2d86-49f2-980c-fb0cf5120065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 506d236f-2c0d-40b6-be54-a2c3838dae33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05371a05-b22d-49f9-9b82-21ae55552e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b400f3dd-989b-4cd8-94b7-4d4623f36592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b098d6-6b52-4057-a378-240956665175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b05983-8de4-40ea-8d3d-474eff7db002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60114311-2c9c-4202-aec6-854775fbab5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf94436-a2df-42dd-9301-85dcb9606fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c848c3ed-fae2-4903-aeb1-6515064b8d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f47d0a4-3652-4f7c-9117-a4b553c6724f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98df97f2-bee9-4fe4-8721-2d173d8c4917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a0ec65d-05e2-499e-99f2-e8cf5f544ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33c3cc5-7b1a-4f15-9db6-5e410e3efcd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693ed05b-e5e0-4991-81ec-79a6fd3568ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b4fe4ea-b0e8-43ec-ba52-c18758e237f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655ae814-1f4a-4916-938f-5f237ef68a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 599fafef-592a-47a9-ae29-20fd50c1bd1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 259322c0-87fc-4188-85dc-a2632c18de8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6527ca2-150c-4ad3-be1e-4a5fd300a018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e91bf24d-87bc-450b-ab35-2cd1448c37ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ff1bf66-3e5c-41f0-aa83-b7f69138f1e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 746b5459-cf68-4961-990d-c4d144f8ff0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2759a417-cc67-411b-bc77-a4087d85292c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d8aeff7-f0ad-4ad3-9f6f-a1b99838c121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3bce280-16f7-42b5-b279-48afe996d49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97e7a15c-e07e-42b4-9fe4-35e0bc9fd6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9918faa2-799a-427b-9164-3d4ce480e283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4636bd-016a-4909-b79d-2bf01d9219ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e96796f8-dc32-44d5-a394-39f46fe75eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649096aa-7af3-45b6-a578-a84303158ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 559c99b2-bae0-463f-8b86-021725b436e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc2d6e7c-6aa8-4c53-9d9d-7b38cad5d246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a210eb2-ff18-4c05-8591-f90cf8047115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7843d671-bde1-4ced-8ef0-72f38c0b5903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e588ab2-d092-4848-9112-e4a6f0121f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41dcf468-6dd8-488f-b0fa-711859fb4fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e0142c3-f4e4-4533-a983-ab1e31f86901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8421179f-f4aa-4628-9358-d055c2a6cd17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d4bf317-868b-41aa-9337-93d2e2baebb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f580b823-38c8-4d02-8b7c-0682b1343ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56adda14-4e7e-44c7-bb05-bc2871b82e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65564a1f-6919-4233-8f1f-020e5d985643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2457a5e3-3c31-4aa9-8a02-27b78341a1e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbab33f-8c18-4261-a098-ccfeea52dd72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a80a4e-770a-4c77-953a-807858afaa63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c434e048-4154-434d-967d-4359f2f1647f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d2f23c-609f-4c0b-a45f-bf687966fc21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c50a31a-25b0-408f-9c56-d94a35b03aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37313b9b-c03d-4712-9d30-0d0547c2af0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c4ab26-8dce-45d4-94f7-c0dcc3d2e7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60bac34-ad66-469d-aeb2-0b81e9fd845c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b93deb2b-fa3d-4adb-96c5-b11ca4dffe56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3702471b-cc54-4f60-8acf-0f88920027e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 196fe3cf-ec5b-4c3a-b21b-0cdff78076cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff08dcb1-c541-496a-9b3a-8911da706ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92dd8b62-11e1-43bd-9252-2859dc4acdd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d0e431-e827-4f9e-b38c-f2937717424e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 601815fa-75ab-430d-a19b-f779b14e614a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee187295-915b-438b-8ade-45d5b145bcb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 326a4f95-ac6a-499a-876c-c022d27ae104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab825aac-e7c5-41db-9e47-be392d53d432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ab6e16-992d-4074-b5a6-f0eb560e7aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9367a6e8-166e-4e66-97ce-b7c73d9d3086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27daef61-4919-43bc-8795-6cf770b5ef8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4008803-eb4c-4bbd-81a9-fbf29e45f45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6d5dbb-a309-4de1-ae60-792ddce7aedc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b74bd1b-62f4-481e-9a24-53fcbbdbe7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb2b724-6def-4306-9432-2f0c0fd16e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 838cf7c7-f963-471f-83b1-6294d37d301c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c21acb49-3f46-4436-a164-e10e9857d599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63910eea-0c92-4334-86fb-18f9449ddea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135b21a2-21e8-4975-a407-c27ee63fc2d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daf0d9fc-7db2-48c4-9ec7-c60e7516dc60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0888984-e7b8-45d3-93b3-e979dddd0fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51fb5b88-2671-4992-9bf1-17180d41fe4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177616aa-9b46-4b37-aac9-987b27d10964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ca089c-c818-4089-8066-f34fc1eef530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 777bcff9-f30c-4036-be1c-7338808c2e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0602e5f8-c46e-4d5d-824e-1a464e49d404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5400c87b-0147-4c97-a210-bd30b1b69a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1949a275-f429-4a11-b1da-a79f6cb03def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffd9b639-a172-4a30-9af9-455be200067e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b45dc4-2ab8-438a-afdd-ad9a27f0adb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1384cb4-4f85-4f95-8c90-0c15f49a4caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f51f435-c743-4e1e-8bc6-4314e8cceeea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfbc85ed-aaaa-42ed-b5d4-acf92f28db38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23fe8fb-eec2-4a4b-ba59-ceb93e18a00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68606771-d295-481b-b9ed-e03d4cd0e030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48ef1571-fb40-4ad0-9b77-a5b4a2330fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a474e659-2d8d-4103-8b10-e0a1cfd7b5fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2db7515c-6c83-4912-b25b-1e9db14f5bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60a43053-6800-46f0-b7a8-6434aca57885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29eccdb8-0939-43ae-a5f5-ce826ba5fa17
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_87
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/test_labels.txt

📊 Raw data loaded:
   Train: X=(1701, 24), y=(1701,)
   Test:  X=(426, 24), y=(426,)

⚠️  Limiting training data: 1701 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  417 samples, 5 features
✅ Client client_87 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1632, RMSE: 0.4039, MAE: 0.3313, R²: -0.9745

📊 Round 0 Test Metrics:
   Loss: 0.1537, RMSE: 0.3920, MAE: 0.3212, R²: -0.8593

============================================================
🔄 Round 14 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0962, val=0.0817 (↓), lr=0.001000
   • Epoch   2/100: train=0.0832, val=0.0830, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0823, val=0.0827, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0817, val=0.0827, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0816, val=0.0829, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0807, val=0.0833, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 14 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0040
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0039
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1290, RMSE: 0.3592, MAE: 0.2957, R²: -0.5615

============================================================
🔄 Round 17 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1105, val=0.0814 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0835, val=0.0801 (↓), lr=0.000250
   • Epoch   3/100: train=0.0827, val=0.0798, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0822, val=0.0803, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0821, val=0.0804, patience=3/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0817, val=0.0808, patience=9/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 17 Summary - Client client_87
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0046
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0134
============================================================


============================================================
🔄 Round 19 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1007, val=0.0805 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0882, val=0.0759 (↓), lr=0.000063
   • Epoch   3/100: train=0.0834, val=0.0770, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0832, val=0.0772, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0832, val=0.0768, patience=3/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0830, val=0.0765, patience=9/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 19 Summary - Client client_87
   Epochs: 17/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0159
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0158
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0921, RMSE: 0.3035, MAE: 0.2591, R²: -0.1146

📊 Round 19 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2506, R²: -0.0149

============================================================
🔄 Round 25 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0885 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0809, val=0.0879 (↓), lr=0.000016
   • Epoch   3/100: train=0.0807, val=0.0874, patience=1/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0806, val=0.0871 (↓), lr=0.000016
   • Epoch   5/100: train=0.0805, val=0.0869, patience=1/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0804, val=0.0866, patience=1/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0803, val=0.0866, patience=11/15, lr=0.000004
   📉 Epoch 23: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 25 Summary - Client client_87
   Epochs: 25/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0013
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0219
============================================================


============================================================
🔄 Round 28 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0814 (↓), lr=0.000002
   • Epoch   2/100: train=0.0829, val=0.0813, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0829, val=0.0813, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0828, val=0.0812, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0828, val=0.0811, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0827, val=0.0809, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0826, val=0.0806, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 28 Summary - Client client_87
   Epochs: 25/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0051
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0399
============================================================


============================================================
🔄 Round 29 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 29 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0094
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0296
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2502, R²: -0.0112

📊 Round 29 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2501, R²: -0.0105

============================================================
🔄 Round 32 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0827, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0823, val=0.0824, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0822, val=0.0822, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 32 Summary - Client client_87
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0052
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0333
============================================================


============================================================
🔄 Round 33 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 33 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0146
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0075
============================================================


============================================================
🔄 Round 34 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 34 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0092
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0166
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2501, R²: -0.0099

============================================================
🔄 Round 39 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 39 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0078
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0195
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2500, R²: -0.0090

============================================================
🔄 Round 40 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 40 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0049
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0361
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2500, R²: -0.0088

📊 Round 40 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2500, R²: -0.0087

📊 Round 40 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2499, R²: -0.0086

📊 Round 40 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2499, R²: -0.0084

📊 Round 40 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2499, R²: -0.0084

============================================================
🔄 Round 45 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 45 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0123
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0022
============================================================


============================================================
🔄 Round 46 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 46 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0077
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0139
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2499, R²: -0.0084

📊 Round 46 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2499, R²: -0.0082

📊 Round 46 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2499, R²: -0.0082

📊 Round 46 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2499, R²: -0.0081

============================================================
🔄 Round 50 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 50 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0057
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0353
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2499, R²: -0.0080

============================================================
🔄 Round 51 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 51 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0103
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0056
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2499, R²: -0.0080

============================================================
🔄 Round 55 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 55 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0111
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0046
============================================================


============================================================
🔄 Round 56 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 56 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0082
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0076
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2499, R²: -0.0078

============================================================
🔄 Round 61 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 61 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0093
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0017
============================================================


============================================================
🔄 Round 64 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 64 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0053
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0300
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2499, R²: -0.0076

📊 Round 64 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2498, R²: -0.0074

============================================================
🔄 Round 69 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 69 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0101
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0003
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2498, R²: -0.0071

============================================================
🔄 Round 74 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 74 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0063
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0104
============================================================


============================================================
🔄 Round 75 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 75 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0074
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0058
============================================================


============================================================
🔄 Round 76 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 76 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0028
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0424
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2498, R²: -0.0069

============================================================
🔄 Round 78 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 78 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0095
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0008
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2498, R²: -0.0068

============================================================
🔄 Round 80 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 80 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0042
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0564
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2498, R²: -0.0067

============================================================
🔄 Round 86 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 86 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0070
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0056
============================================================


============================================================
🔄 Round 87 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 87 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0079
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0040
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2498, R²: -0.0067

============================================================
🔄 Round 88 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 88 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0063
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0078
============================================================


============================================================
🔄 Round 89 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 89 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0087
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0022
============================================================


============================================================
🔄 Round 90 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 90 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0042
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0176
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2498, R²: -0.0065

============================================================
🔄 Round 93 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 93 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0057
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0086
============================================================


============================================================
🔄 Round 95 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 95 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0051
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0173
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2497, R²: -0.0063

============================================================
🔄 Round 96 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 96 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0060
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0086
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2497, R²: -0.0064

============================================================
🔄 Round 99 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 99 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0086
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0038
============================================================


============================================================
🔄 Round 101 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 101 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0083
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0008
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0831, RMSE: 0.2884, MAE: 0.2497, R²: -0.0062

============================================================
🔄 Round 102 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 102 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0057
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0084
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0061

============================================================
🔄 Round 105 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 105 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0055
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0083
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0061

============================================================
🔄 Round 106 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 106 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0068
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0039
============================================================


============================================================
🔄 Round 107 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 107 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0047
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0102
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0059

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0059

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0059

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0058

📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0058

============================================================
🔄 Round 114 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 114 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0082
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0014
============================================================


============================================================
🔄 Round 115 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 115 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0076
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0010
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0058

============================================================
🔄 Round 118 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 118 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0063
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0040
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0057

============================================================
🔄 Round 122 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 122 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0040
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0257
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0057

📊 Round 122 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0057

📊 Round 122 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0057

============================================================
🔄 Round 125 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 125 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0063
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0053
============================================================


============================================================
🔄 Round 126 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 126 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0090
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0030
============================================================


============================================================
🔄 Round 128 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 128 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0074
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0057
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0056

============================================================
🔄 Round 131 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 131 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0044
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0105
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2497, R²: -0.0055

📊 Round 131 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2497, R²: -0.0054

============================================================
🔄 Round 137 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 137 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0066
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0038
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2497, R²: -0.0052

============================================================
🔄 Round 141 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 141 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0034
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0137
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2497, R²: -0.0053

============================================================
🔄 Round 142 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 142 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0032
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0553
============================================================


============================================================
🔄 Round 143 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 143 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0042
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0149
============================================================


============================================================
🔄 Round 147 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 147 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0038
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0134
============================================================


============================================================
🔄 Round 148 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 148 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0049
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0076
============================================================


============================================================
🔄 Round 149 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 149 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0075
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0000
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2497, R²: -0.0054

============================================================
🔄 Round 150 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 150 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0055
   Val:   Loss=0.0918, RMSE=0.3031, R²=-0.0060
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2497, R²: -0.0054

============================================================
🔄 Round 152 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 152 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0059
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0055
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2497, R²: -0.0054

============================================================
🔄 Round 153 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 153 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0057
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0051
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2497, R²: -0.0054

============================================================
🔄 Round 154 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 154 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0172
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0357
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2497, R²: -0.0054

📊 Round 154 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2497, R²: -0.0054

============================================================
🔄 Round 157 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 157 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0062
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0051
============================================================


============================================================
🔄 Round 158 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 158 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0101
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0120
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2497, R²: -0.0053

📊 Round 158 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2497, R²: -0.0052

============================================================
🔄 Round 165 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 165 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0061
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0039
============================================================


============================================================
🔄 Round 166 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 166 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0020
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0424
============================================================


============================================================
🔄 Round 167 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 167 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0067
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0001
============================================================


============================================================
🔄 Round 168 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 168 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0025
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0332
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0050

📊 Round 168 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0049

============================================================
🔄 Round 174 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 174 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0034
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0312
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0049

============================================================
🔄 Round 177 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 177 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0026
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0194
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0049

============================================================
🔄 Round 179 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 179 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0083
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0043
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0049

📊 Round 179 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0049

📊 Round 179 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0049

============================================================
🔄 Round 185 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 185 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0027
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0233
============================================================


============================================================
🔄 Round 186 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 186 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0066
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0001
============================================================


============================================================
🔄 Round 187 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 187 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0087
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0023
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0049

📊 Round 187 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0049

============================================================
🔄 Round 191 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 191 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0013
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0595
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0048

============================================================
🔄 Round 192 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 192 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0071
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0001
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0048

📊 Round 192 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2496, R²: -0.0047

============================================================
🔄 Round 197 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 197 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0061
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0026
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0049

============================================================
🔄 Round 199 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 199 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0013
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0542
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0048

📊 Round 199 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0048

============================================================
🔄 Round 202 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 202 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0076
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0068
============================================================


============================================================
🔄 Round 203 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 203 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0024
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0295
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2496, R²: -0.0047

📊 Round 203 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2496, R²: -0.0048

❌ Client client_87 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
