[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c04d2430-eadc-40b9-9e5f-fade3ac063bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5774be09-ebf7-4290-a66e-cd84744b440a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f256edae-1b54-46e7-ad82-97dce45c7bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb05e007-7e6f-4817-a9a6-2f3d41902516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7317f554-55bd-4c5e-8c34-64037e9b26c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed17597-7914-48db-8e25-2a52220f4a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50a34612-fb6f-479f-be28-2266fb978a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1449c9c3-7655-456f-a339-55bea99c687e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f83e20fb-6040-451f-9c22-fa8773182c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bee7815-4131-4d5a-a419-bdec88428f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 701162bf-bf60-478f-a249-bc78c920ddde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec602ce6-b62f-456c-95c2-578aa708bb4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da60c724-aec4-4249-9fc1-0fbbc853c694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e06812d-478c-4906-8943-f1f8cfb55044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 542d357c-cd6d-4550-bcc0-adc787965f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9912d4d-1103-45b3-aad9-a9bc506ff2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29247404-4863-454b-bd76-8d90bd88073c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce68d684-2cc8-47ca-802b-c8879e398a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c2c0a53-a5a7-42d6-93f2-ea3739f8d489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab008c31-ad06-4b35-83f3-8951a30eb0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ffcf9e8-4792-4eea-9d68-29f7a00a4e79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b61b92d-d3ac-4ea8-a304-6681d73f15d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a68216ed-7b43-4b29-a9ee-2f9ca73888b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e6af1dc-87da-4a17-b38c-bf1ecd6aaeb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 450a82f1-3c5f-4ada-9e3f-9f85a32ea03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed207b2-1209-4f53-9da1-891c7d7fa0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 744d808f-91ed-40d8-b7fe-1a8c46b14059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476c3180-b86d-4ead-be6f-1867c06e48e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3766f32e-ceee-4316-bffa-7b9572915420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe5a942-c320-4602-b4f8-ba5f1e0b4644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b427098-ca32-4785-95e3-84aebf696954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1932b9eb-1bef-4a3b-bfb1-6f2a888b30b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e1cb7a-518d-4fe5-acce-e7538cbf1305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d8eca41-2625-40ca-9494-8831c43cec7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca3aeb14-c533-474b-8689-de286430d6be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0b89ab4-36d5-48e7-913c-e9fa3c8e9a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a82baea-daa2-4c3f-8753-beb4e74f0e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9497945-bb89-40b3-a975-89be4647e6c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73775ab-7c20-4d75-930d-b0f122b33a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab91b3b9-7284-4864-9ad0-20e641e214a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca4751c4-a891-4c67-a96c-302120b3119d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa96a2ec-b06c-496a-ad43-2c5037995ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d8c0881-eff8-4a8b-9542-c63045ceb0e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db01972a-0c16-43c6-9b27-168cff004d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28e7bfd8-0fc5-4c84-8aeb-a12d8d18db39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4affd13f-9a2e-4011-bcca-1bc7b7c60dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 279d2e65-b980-4ee8-9732-99aabd346e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 339a970a-5603-43d6-a53c-6efdf00ebdd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaad41ee-f139-423e-a713-a10fe389a04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aef1d018-fecd-4d3e-b50a-97db6d6f601d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3052fb34-57bf-49ce-a527-835b5b229273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb1676e-1923-422e-9964-e3ffdee89517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5df046ce-5c18-4497-bcd2-889786b94eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03e9ff94-c380-4a40-9a84-840493b5856b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7456e83-f0b9-4c37-b635-766fea4c906a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94ab47ec-af9a-4012-b61e-84dd3cd6f491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5224b843-25d5-4be2-be18-3a3999e553af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1465481c-5497-462e-a9c5-8c27a83ab343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f62d237-fa13-4d38-8464-506fe0160586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 894c6064-835b-4c7a-a449-648622a70bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7399cad5-1700-4302-9b99-94eddd02cddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9e7986d-783c-437a-b744-65ab1d556120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ca2f0e-d4e1-41ac-aa08-395157fb0d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cb62a59-1c54-4ba9-801e-cd7e49e98bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cbc8350-f6a4-428b-ba13-f5254b31fa81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ffdb12e-b6bd-4622-96c8-8c6b93b1bf7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 633b9070-c206-4063-b579-1a9c7bf77347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e39a6ec-26a5-4f37-9c9a-7a6c75c8339d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab3ecfe-d827-4443-a476-5884299c125f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da131e2-3f68-4b59-aeab-4e060f668cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb33d3c9-6a24-4da0-b2be-304c26b8d738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 112c914c-c95d-4494-a554-c0c9c43b86c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f6b094-657b-4619-9e27-7f804c9cad88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e06cce-b8f3-4018-9a3f-10960e242bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d2ad579-0114-4114-ab9e-7843fcb1cdea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68b57750-29c2-4d3c-b7d1-5c929b7b6002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0975fbab-1d2d-4ee0-93e3-65b4e33e03db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e67334d-2c66-4337-b82a-590d89772cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 426d754c-ea13-465d-b73a-009c28219cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df188b48-17df-4d71-b9c9-68bdc164ca59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 703160e1-7da2-4de3-8020-7fa725d8b15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e696c573-785a-42e7-b418-c879235abc05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cee52005-d9bf-4366-bcaf-d5142b15f711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c606d29d-7b65-4814-8877-69739d80691b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a90f096d-f5e9-45aa-b424-d5e366b36381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54707cc9-7a09-4d00-894c-8aa3b4c18a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e809c45-b0aa-4249-8aa3-1179ce87694b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de5faf2-c299-4fa0-ae04-726e4459b00f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b147776-cc08-4a09-8a81-631108c96247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 196d7557-4dcd-40fd-9279-ac961c0fcc30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e15d051d-67b8-4a86-91c5-e877795d25cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0fb7fb2-a194-4037-b7f2-4767e6e0b438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 551eb73b-d9e1-46b8-a9a8-fc266b9331f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b952f34-520d-42f6-b3dd-692b92317425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60ebd033-af7a-4619-a5d0-72a1264d98b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab8c452b-9d35-44de-a9ce-8a014801d749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 507fe3a3-a4a5-426f-aac9-2660ac980c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9595108b-ab10-494a-8a4c-f65e8d1df7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb17b39f-08ba-455a-9dc9-81326d79101b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9b97877-b1a7-4039-aafd-c4ad8775bfc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ac22a8-a867-4290-a2fc-bfb68e543ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0450cb6-06bd-4d17-824b-e3591f655a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e34bd65b-a7a8-405d-9fb7-6b4d1ab66300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2480a406-12e0-4808-8fd2-c9bae6065b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ccaaf09-704e-4fc8-be20-adefe5237462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878febd7-f87c-4590-9733-0cf152084db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1599b82d-c34d-4522-b189-330ffdbb56bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fdb3d84-f54f-4360-817c-d839dfca87bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25953a9a-cbdb-42e2-a63d-f28ec55ce728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6efd43fb-d72e-45f5-bbac-35b9948b1094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95389a68-f8db-476b-a55a-abe785596b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9bd387e-5dd1-4d57-97d5-609307185287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc03f71-97e0-4c92-b4d8-c5f86a0c4b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b97b97e8-50c9-4527-9d25-25a6ec963c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ceb13f0-16d1-4226-900b-f34ceb775d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca8174aa-7076-4cc3-aeec-9f9d0ab96a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c0b42d8-15df-4acc-8e41-ea2998b75895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca6ed0e8-6c64-4fc8-a66e-624d786847fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ef98791-a0dc-405c-a138-595ebec88238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b6d0e09-29b1-416b-9a1a-2058c7232a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 049f5360-29eb-45a0-9f6a-0f514d3092ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 613dad8e-47c5-4c57-a820-225838fba6e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e766aaa-fd6d-478d-b50e-098981ca9cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 097b7b93-0568-4f71-9138-4a6bfc3a22b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1d7e67e-2112-4269-b5b0-ef4b0c3ff8b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47da5bc-3d3d-41d3-bf77-f554c1b188a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 280d76da-0365-4312-8de0-cb84f8cc656a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375912e4-6836-40ca-8156-127b4bfbe18e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ff898d-0cec-443e-b0fa-da7bfbd2c4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0183d446-4a78-4648-aaf0-9ed00cbdc447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a45acf37-c7fc-4f27-b12e-96cdc46f8add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d358fb-5995-4d5f-b032-6c88b168ca71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a846a0f-4159-44b6-8bd5-b2282c1620e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffa95ced-3794-4d13-ac4c-a1c6ceabd290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fb7ccc3-b16f-4651-85e4-51e2a161a221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd7be73-88fd-4070-b503-5b6727df3cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2c7ad6d-65d1-48f2-93f1-7d4a2fbbfbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e80afbdc-16b5-421f-a934-ea87b7402810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1995d5c7-3294-4b50-9c39-eae411ba7dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e6e010e-c03c-427f-99f0-55c2c02be828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47e58b6f-c24f-41ad-a945-425e586625ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98184af4-7ebd-400c-afc8-42cfd701b22b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca3cdd1-5e61-4744-b3ba-7b0c871c8a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc7c2f7c-f24b-4192-a95d-4daf32378e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce3f80e8-e120-4bbd-8a7c-698dc4041b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5599ec8c-57aa-4aa0-9173-eafa1aec20b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1d1713d-7a8c-4f6a-855d-c5b8917ddbdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aeb9361-4cab-43f6-a235-9e0438d60a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e40c282-3dcd-401f-80b0-eecae077b319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ecb05b0-f211-43b6-83b0-f2cfb6ddf86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 365298ff-9229-434c-9409-9e55ef551f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c00d587-77e5-4cff-8e9d-e32de55c993e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 145d3e31-d21e-442c-993e-4a1751f70727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f864969-029d-42b4-b5fe-36d872164b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e3d58a-5d51-420b-9758-d530ba33a3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a82abd7-d68b-49e4-b957-c5737e86f67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95b58aa8-0e04-4335-b62d-30a72a0f4c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7748420e-68b9-4cee-90ee-dddf31decdcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb8fbe96-c137-4d4b-b75a-40f253cf178a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93c6a12e-ae72-47a0-a7fb-9f3d58b8882e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97994f1c-1991-477b-9f13-9578d8540400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dd9d3f9-1422-40eb-9abb-1332976454e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7fec6c4-efc2-4e2c-b7a7-de50151c1adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d766b5e-25a6-46ec-b447-83afd9024930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47a283ae-2546-4b4b-8655-a90b2c199dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e55028ec-39bf-4ec0-8e6a-51cd1293b3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6dff3bf-b0c6-4d46-a943-0ed1f67957fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a37d569-0cbd-44cc-86c0-c445b5177dfc
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_89
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/test_labels.txt

📊 Raw data loaded:
   Train: X=(1393, 24), y=(1393,)
   Test:  X=(349, 24), y=(349,)

⚠️  Limiting training data: 1393 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  340 samples, 5 features
✅ Client client_89 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1568, RMSE: 0.3959, MAE: 0.3196, R²: -0.8373

============================================================
🔄 Round 12 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1011, val=0.0853 (↓), lr=0.001000
   • Epoch   2/100: train=0.0834, val=0.0918, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0813, val=0.0883, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0810, val=0.0884, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0810, val=0.0888, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0801, val=0.0892, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 12 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0018
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0156
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1516, RMSE: 0.3893, MAE: 0.3144, R²: -0.7766

📊 Round 12 Test Metrics:
   Loss: 0.1460, RMSE: 0.3821, MAE: 0.3088, R²: -0.7114

============================================================
🔄 Round 15 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1104, val=0.1007 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0808, val=0.0904 (↓), lr=0.000250
   • Epoch   3/100: train=0.0804, val=0.0920, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0797, val=0.0914, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0797, val=0.0916, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0794, val=0.0918, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 15 Summary - Client client_89
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0175
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0016
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1314, RMSE: 0.3625, MAE: 0.2947, R²: -0.5404

📊 Round 15 Test Metrics:
   Loss: 0.1134, RMSE: 0.3367, MAE: 0.2775, R²: -0.3288

📊 Round 15 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2573, R²: -0.0243

📊 Round 15 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2571, R²: -0.0130

📊 Round 15 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2571, R²: -0.0078

============================================================
🔄 Round 23 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0775 (↓), lr=0.000063
   • Epoch   2/100: train=0.0835, val=0.0774, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0834, val=0.0774, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0833, val=0.0775, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0833, val=0.0776, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0830, val=0.0778, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 23 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0029
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0018
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2571, R²: -0.0063

============================================================
🔄 Round 26 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0829 (↓), lr=0.000016
   • Epoch   2/100: train=0.0823, val=0.0826, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0823, val=0.0825, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0823, val=0.0824, patience=3/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0822, val=0.0823 (↓), lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0821, val=0.0822, patience=6/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 26 Summary - Client client_89
   Epochs: 20/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0001
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0165
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2572, R²: -0.0036

📊 Round 26 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2572, R²: -0.0035

============================================================
🔄 Round 28 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0787 (↓), lr=0.000004
   • Epoch   2/100: train=0.0834, val=0.0786, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0834, val=0.0786, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0833, val=0.0786, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0833, val=0.0786, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0833, val=0.0785, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 28 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0026
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0081
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2572, R²: -0.0033

============================================================
🔄 Round 31 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 31 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0075
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0023
============================================================


============================================================
🔄 Round 32 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 32 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0030
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0039
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0855, RMSE: 0.2925, MAE: 0.2573, R²: -0.0026

============================================================
🔄 Round 35 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 35 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0066
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0010
============================================================


============================================================
🔄 Round 37 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 37 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0034
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0010
============================================================


============================================================
🔄 Round 39 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 39 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0031
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0019
============================================================


============================================================
🔄 Round 40 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 40 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0029
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0005
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2574, R²: -0.0021

============================================================
🔄 Round 42 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 42 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0014
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0047
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2575, R²: -0.0020

============================================================
🔄 Round 43 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 43 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0027
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0001
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2575, R²: -0.0020

============================================================
🔄 Round 44 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 44 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0017
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0237
============================================================


============================================================
🔄 Round 45 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 45 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0017
   Val:   Loss=0.0971, RMSE=0.3115, R²=-0.0025
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2575, R²: -0.0020

============================================================
🔄 Round 46 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 46 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0010
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0062
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2575, R²: -0.0019

============================================================
🔄 Round 48 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 48 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0020
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0024
============================================================


============================================================
🔄 Round 49 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 49 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0019
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0054
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2575, R²: -0.0019

============================================================
🔄 Round 51 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 51 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0006
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0073
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2575, R²: -0.0018

📊 Round 51 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2575, R²: -0.0018

📊 Round 51 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2575, R²: -0.0018

📊 Round 51 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2575, R²: -0.0018

============================================================
🔄 Round 57 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 57 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0037
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0052
============================================================


============================================================
🔄 Round 58 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 58 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0030
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0044
============================================================


============================================================
🔄 Round 59 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 59 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0027
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0106
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0855, RMSE: 0.2923, MAE: 0.2575, R²: -0.0017

============================================================
🔄 Round 61 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 61 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0026
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0014
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0855, RMSE: 0.2923, MAE: 0.2575, R²: -0.0017

============================================================
🔄 Round 65 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 65 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0001
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0081
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0855, RMSE: 0.2923, MAE: 0.2575, R²: -0.0017

📊 Round 65 Test Metrics:
   Loss: 0.0855, RMSE: 0.2923, MAE: 0.2575, R²: -0.0017

📊 Round 65 Test Metrics:
   Loss: 0.0855, RMSE: 0.2923, MAE: 0.2575, R²: -0.0016

📊 Round 65 Test Metrics:
   Loss: 0.0855, RMSE: 0.2923, MAE: 0.2575, R²: -0.0016

============================================================
🔄 Round 71 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 71 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0023
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0011
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0855, RMSE: 0.2923, MAE: 0.2575, R²: -0.0016

📊 Round 71 Test Metrics:
   Loss: 0.0855, RMSE: 0.2923, MAE: 0.2575, R²: -0.0016

📊 Round 71 Test Metrics:
   Loss: 0.0855, RMSE: 0.2923, MAE: 0.2576, R²: -0.0016

📊 Round 71 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0015

📊 Round 71 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0015

📊 Round 71 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0015

📊 Round 71 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0015

============================================================
🔄 Round 81 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 81 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0020
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0015
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0015

============================================================
🔄 Round 84 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 84 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0007
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0029
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0015

📊 Round 84 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0014

📊 Round 84 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0014

============================================================
🔄 Round 90 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 90 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0005
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0110
============================================================


============================================================
🔄 Round 92 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 92 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0020
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0028
============================================================


============================================================
🔄 Round 93 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 93 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0032
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0101
============================================================


============================================================
🔄 Round 95 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 95 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0017
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0019
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0014

📊 Round 95 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0014

============================================================
🔄 Round 97 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 97 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0013
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0052
============================================================


============================================================
🔄 Round 98 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 98 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0031
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0093
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0013

📊 Round 98 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0013

============================================================
🔄 Round 101 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 101 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0027
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0010
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0013

============================================================
🔄 Round 104 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 104 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0003
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0041
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0013

============================================================
🔄 Round 108 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 108 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0028
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0073
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0013

📊 Round 108 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0013

📊 Round 108 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0013

📊 Round 108 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0012

============================================================
🔄 Round 113 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 113 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0003
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0103
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0012

📊 Round 113 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0012

============================================================
🔄 Round 115 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 115 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0009
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0021
============================================================


============================================================
🔄 Round 117 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 117 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0005
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0023
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0012

============================================================
🔄 Round 118 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 118 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0010
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0007
============================================================


============================================================
🔄 Round 120 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 120 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0009
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0046
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0012

============================================================
🔄 Round 121 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 121 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0028
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0187
============================================================


============================================================
🔄 Round 125 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 125 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0001
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0037
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0011

============================================================
🔄 Round 128 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 128 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0009
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0122
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0011

📊 Round 128 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0011

============================================================
🔄 Round 130 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 130 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0013
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0012
============================================================


============================================================
🔄 Round 131 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 131 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0007
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0019
============================================================


============================================================
🔄 Round 132 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 132 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0001
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0051
============================================================


============================================================
🔄 Round 133 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 133 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0001
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0033
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0011

============================================================
🔄 Round 135 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 135 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0009
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0014
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0011

📊 Round 135 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0011

============================================================
🔄 Round 139 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 139 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0015
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0018
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0011

============================================================
🔄 Round 142 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 142 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0007
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0027
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0854, RMSE: 0.2923, MAE: 0.2576, R²: -0.0011

============================================================
🔄 Round 143 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 143 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0010
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0006
============================================================


============================================================
🔄 Round 144 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 144 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0005
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0082
============================================================


============================================================
🔄 Round 145 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 145 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0030
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0094
============================================================


============================================================
🔄 Round 146 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 146 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0003
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0033
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0010

============================================================
🔄 Round 148 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 148 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0005
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0099
============================================================


============================================================
🔄 Round 149 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 149 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0005
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0059
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0010

📊 Round 149 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0010

📊 Round 149 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0010

============================================================
🔄 Round 154 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 154 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0008
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0076
============================================================


============================================================
🔄 Round 155 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 155 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0014
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0049
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0010

📊 Round 155 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0010

============================================================
🔄 Round 160 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 160 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0030
   Val:   Loss=0.0957, RMSE=0.3094, R²=0.0006
============================================================


============================================================
🔄 Round 161 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 161 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0012
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0002
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0010

📊 Round 161 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0009

📊 Round 161 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0009

============================================================
🔄 Round 166 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 166 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0016
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0018
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0009

============================================================
🔄 Round 168 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 168 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0009
   Val:   Loss=0.0696, RMSE=0.2638, R²=-0.0028
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0009

📊 Round 168 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0009

📊 Round 168 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0009

============================================================
🔄 Round 176 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 176 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0023
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0056
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0009

============================================================
🔄 Round 178 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 178 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0017
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0022
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0009

============================================================
🔄 Round 179 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 179 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0004
   Val:   Loss=0.0729, RMSE=0.2701, R²=-0.0079
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0009

============================================================
🔄 Round 181 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 181 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0033
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0221
============================================================


============================================================
🔄 Round 184 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 184 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0006
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0081
============================================================


============================================================
🔄 Round 186 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 186 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0003
   Val:   Loss=0.0691, RMSE=0.2628, R²=-0.0054
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0008

============================================================
🔄 Round 188 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 188 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0007
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0070
============================================================


============================================================
🔄 Round 189 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 189 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0015
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0111
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0008

============================================================
🔄 Round 190 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 190 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0008
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0050
============================================================


============================================================
🔄 Round 191 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 191 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0008
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0013
============================================================


============================================================
🔄 Round 193 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 193 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0016
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0019
============================================================


============================================================
🔄 Round 195 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 195 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0009
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0011
============================================================


============================================================
🔄 Round 197 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 197 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0001
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0231
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0008

============================================================
🔄 Round 198 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 198 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0007
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0096
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0008

============================================================
🔄 Round 201 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 201 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0004
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0055
============================================================


============================================================
🔄 Round 202 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 202 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0005
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0015
============================================================


============================================================
🔄 Round 203 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 203 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0029
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0178
============================================================


============================================================
🔄 Round 204 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 204 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0015
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0020
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0008

📊 Round 204 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0008

============================================================
🔄 Round 209 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 209 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0005
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0211
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2576, R²: -0.0008

============================================================
🔄 Round 210 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 210 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0019
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0011
============================================================


❌ Client client_89 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
