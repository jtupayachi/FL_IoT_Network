[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92581a9a-530b-447b-9587-4c1ca06ad3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb586ec9-8682-4205-86ec-c744cde87016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16904b81-0a87-401c-ba93-7ee816c5c5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff66dff2-c1df-44b6-8235-24d14f61a093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a620a6-9627-4e0e-9bad-e17c0b9f227b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7777809e-287b-4830-abc6-7a6dd5b25d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98e0c30f-19a6-4802-9007-de50d2aec59c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3155fd-5867-4ded-96a2-990310434888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99cd5be4-6747-46f8-bdff-65af3d531188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16036182-99df-454b-b0bc-1785a54c0e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b009b86-649b-49b8-8925-7abc8a4c189d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 988fcfdd-8754-4dc5-8d38-5e3b6206c648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b005bb2f-7444-475d-a7c3-92753c374b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 480989fa-7b0d-4ecd-b1bc-3f312d1c9ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d877d712-7e03-4014-aaf0-a9955ae3eec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c615b4b-ea3f-4bd9-83d7-19d1e90fc2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae429f87-ccf6-4565-9eb2-32d7f8d6c68f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb18fdce-88fa-48f3-8451-5f060f145882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be8e7ca4-7569-46ea-be12-bd336e344edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c2fcafd-5e8b-4b63-af4f-453e936c01a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f996737e-7535-413e-9af4-16c26189e8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567e1906-e33a-4037-a51d-bc47273b5f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0114a91-cad9-4d63-90ab-ae0e99ef83e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03371466-6296-4024-8695-e1da73d3734a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4924139-3b9c-4f04-9a4f-673b985f0b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b80e04b5-b8ab-4d21-89df-76fec7a71643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f549d577-2baf-4791-83bc-6222ad8186a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 437c25b8-7f9a-4573-a5d5-30e2df50d047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d481c09-8cec-460e-a512-1736fd3bcebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3b4f0a8-cf6e-4514-87be-d7010c422441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4159031-5e29-4d9e-b313-9c8fca67f33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49ca28fe-9763-4b30-9724-c372b6e2a5a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2817fdea-c602-48df-b56a-0accc4d022dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea30faf5-4412-40a9-bfbb-2ae60aef63bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2550ac78-ff75-4ee0-8463-e453f8317db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa3354c6-188b-42ab-8d02-ebc8d8185533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 720453e7-b44b-4da9-aaf5-157430a1fc59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 583ddb0b-8966-4776-ac3d-71fb36ba7a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c47e348-8417-4fc7-969e-1f211073abec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8d2e518-d2d8-494a-b01f-694dd74a4575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6b61658-c55d-4e10-a402-219dd1b2d03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4b2b7e2-07a2-4122-a382-5402d4fce84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57540eb1-df9d-4a6c-9f8b-efe912ec920f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43203557-34fe-48d2-9918-1f4e1808f4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c15fe29-1ea6-4011-b51d-7374e6a80ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2925571-15f9-4eef-bab9-15fb3d684b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00bbb824-0b0f-4505-841d-bb854e3e9eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce789ff-87fc-4cbe-b8f4-1d0230efb05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db605f9b-a7aa-4852-ae0d-c836164fb267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05cabead-5fd7-4cb4-9b28-f68590aee78c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d939e0e5-5f42-4225-a864-b8fdb7e18efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ffa1fa5-c7ef-4eeb-a281-3fe30422b197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da80f8a6-ddc4-4832-8800-d4fe3f2f7f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce947e5-d0ce-4365-a225-27f185edcaf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baf9152f-903e-44de-91a9-d704d7c82768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55bd6a32-a613-4cd5-b50a-cf0f7cb16e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d8c23a7-167c-44d0-bce7-c19822051927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a9009ba-d4b4-41f2-b2d0-656bb0cd1cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d87bea9-557b-408a-bd4b-fcfc92bb2262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bd11e7b-68d9-452c-a837-284629863fc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbdd1a0a-5345-4298-9534-d3189f1862f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe008971-40de-40a0-a3de-8a208dc63616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61b9e96-5ddc-4785-be38-d67555aa21ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ccc48ad-ef65-4419-9eaf-f9822b101e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 313b66b7-4a86-427e-9e66-084889e5cfad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcedfcd1-c957-4b3a-9b25-060da057dd5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d76ba4-cfeb-48d0-a7af-1e83606c6e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3346fa8-89b8-4402-b409-53b819d9e15c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3ec5a8e-4abf-4366-a14c-db17696311ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8d2919-6686-4f76-85b0-b774dfcf8a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 411db8df-690e-479b-8ff5-f4fa407e7fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8e62fdb-64d2-47e2-ae7e-c4364ee45eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d07a5ae4-b8b4-493f-9612-49db2fbec81c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27cf6275-84af-49e2-8d13-ea5fe89feaf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23fa1c7-2b01-4d05-b4ce-f0a5832ea845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03bcac9d-98d3-480d-8f89-2566d342082c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c5de2cd-1aa4-4f27-9fbe-9d284ae503e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd1ab538-476c-44a3-8196-8cda050865f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4d96733-a659-4682-bbc9-44001253e588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7214916f-e80b-4854-be9d-4b6440120538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5abceed3-d864-465b-87f0-d60abd5d69d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 610c7ae1-2250-4f6b-bb4a-b13bfa3d80c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f35189f7-a094-42cf-a769-b12304917406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d93797b-a2f2-47de-9eb6-adc3f6e56194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e30b84e-3f9e-43a1-ac20-d3e60aafaa00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d1aa76e-7d3d-48e8-a534-35e6b561ccf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f7f768-f689-45f2-be0a-7081ca8c1133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50140008-383a-4a94-b69e-30aa756b406e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 759b084a-4f0a-408d-8ea9-8c2491392a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e31cae76-1daf-4e2c-a0fe-0c5862701026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 829df692-3760-4685-809e-e5e6e20c2fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e6d26c-e384-4365-bf3e-fd1b0e8811b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf55a9c8-54a3-4c11-9387-d4d1cd5d906e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 527a923a-e3d4-49d6-9449-7176c5ad891b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed3991f-c4a5-44e5-b4f2-fb20e5f88f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d7712e-67a1-4ae2-a07a-4bbce67cdedc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ea22679-92e2-4824-83f9-cabaea2b153d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdf0a678-2f10-418c-aa84-ef6a9f6194ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 843eac97-e0a8-4d62-a61e-81ff7e680a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 001af1fe-cebd-48bd-a793-4d0fb11d65de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83f977c2-024b-43ca-a574-c9aeaff325ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 872434d1-0ece-41cf-a5b1-dad9f67878c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fa247ae-9d89-4ab3-8415-95968335622f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd2e674d-e1d0-4370-836a-bef5ef02ccb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4af01e19-a5ec-4473-ba8e-4ba5e08c3c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c1e341-8782-4901-91d3-63ecd64e49ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2371848-ab4b-4b0e-a0b8-7349ebb3542f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d19c695e-ca50-41c7-bb16-d08e84402262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e80df6f-a741-44e8-81a3-e0abfda86c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bbe2f75-4601-4af6-b718-b2384fb29052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5411525-9d13-41c8-bfb0-8bb342bd4f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39c8289d-9509-4850-8475-caa4235e691e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0eb463a-5729-474f-bb0f-aec0e3d73989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a56e62d-72e3-468e-afbd-ac586d9259d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2a7c926-a82b-401c-88f4-e11012839198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b98595a5-2f48-4f4f-b962-3b3d04dc31c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff3bab0-e198-46d7-8a22-fcfe33ef0d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6c1e8e-1b7a-4e39-992d-a52d5d9054bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e8fc0a4-d25e-4f6c-8989-41061f03b48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de2a93f9-3dd1-4ae7-8f68-a2a4be28654f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65ee4bab-b1d2-4380-a2c9-5dffd0d2ee77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efc09259-682b-4e85-9f3b-00d9136563a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49280250-ff6e-4cc0-b8fd-c6b6a5db5951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7717bea-3588-4bef-a65d-bdfc6e7d1cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2803c06-c618-4c08-929f-bec9b9a0eca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4c7d155-6452-4735-9f76-100e93fc426b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cdb1a0b-f42a-484d-876e-de0e1c097b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 294770ae-49d6-44fa-a09a-f875d0a5b736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4c047e9-b499-4c06-b6b6-431e1605bdf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd3cf77a-d86b-4181-974d-69defd97a7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d002edf0-6477-4ae6-beb5-09d81027b517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc7be165-0639-40bf-b12e-158cdfb348f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a82170f-20c8-46a1-bf73-015ea886df05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c1aca50-56d7-4988-94f8-6eac5a833509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd6be9c-52c9-41fd-8984-5e4e1617b0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d55284a2-65cd-4b98-b63a-44dcd0bae12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4768fdd-d911-4926-8097-feea00f41587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3a297aa-94b3-49ad-b32d-ef7bb422d93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0308155c-6954-41c4-8cec-7f51ccb5c406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ce009e-8181-4b48-85ad-27692360ddd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ab85c5-e2f7-4fc2-95a1-3a69c8a9eda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 109408c9-46be-450a-bb57-671d1d4ae268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c01bd08-8343-4902-9143-bdb130f67b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3289e414-b20f-482d-80bf-513369c90a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2b83706-0644-4540-937c-0843c88fbbff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da71b2da-e580-429f-9045-3dc566c75276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28d9963c-91a5-42e7-9855-86e176a76e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf7f7534-4ef8-4e94-bfc8-f0a7dfed12cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53d18fc9-c726-4646-964a-91a4faff44c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6af25f2c-e1cd-499e-9132-e7c75634c020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd976d03-6b28-4c13-9546-86fc46b62a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 128093c7-b1ae-4acc-ac2b-75f8855d2383
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_90
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/test_labels.txt

📊 Raw data loaded:
   Train: X=(2056, 24), y=(2056,)
   Test:  X=(514, 24), y=(514,)

⚠️  Limiting training data: 2056 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  505 samples, 5 features
✅ Client client_90 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 12 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1037, val=0.0853 (↓), lr=0.001000
   • Epoch   2/100: train=0.0857, val=0.0901, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0855, val=0.0875, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0848, val=0.0871, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0845, val=0.0874, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0835, val=0.0872, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 12 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0036
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0167
============================================================


============================================================
🔄 Round 13 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1377, val=0.0922 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0909, val=0.0872 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0869, val=0.0822 (↓), lr=0.000250
   • Epoch   4/100: train=0.0863, val=0.0826, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0862, val=0.0825, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0857, val=0.0823, patience=8/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 13 Summary - Client client_90
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0012
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0071
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1472, RMSE: 0.3837, MAE: 0.3090, R²: -0.8205

============================================================
🔄 Round 14 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1386, val=0.1280 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1064, val=0.0895 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0898, val=0.0752 (↓), lr=0.000125
   • Epoch   4/100: train=0.0884, val=0.0751, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0881, val=0.0761, patience=2/15, lr=0.000125
   📉 Epoch 10: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0876, val=0.0761, patience=8/15, lr=0.000063
   📉 Epoch 18: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 14 Summary - Client client_90
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0028
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0328
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1320, RMSE: 0.3633, MAE: 0.2934, R²: -0.6319

============================================================
🔄 Round 16 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1351, val=0.1310 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.1239, val=0.1210 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.1128, val=0.1126 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.1035, val=0.1058 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.0958, val=0.1007 (↓), lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0830, val=0.0960, patience=4/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0826, val=0.0965, patience=14/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 16 Summary - Client client_90
   Epochs: 22/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0276
   Val:   Loss=0.0961, RMSE=0.3101, R²=-0.0048
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1129, RMSE: 0.3361, MAE: 0.2739, R²: -0.3965

📊 Round 16 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2519, R²: -0.1133

📊 Round 16 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2460, R²: -0.0144

============================================================
🔄 Round 23 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0868 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0869, val=0.0864, patience=1/15, lr=0.000004
   ✓ Epoch   3/100: train=0.0867, val=0.0863 (↓), lr=0.000004
   • Epoch   4/100: train=0.0866, val=0.0861, patience=1/15, lr=0.000004
   • Epoch   5/100: train=0.0865, val=0.0859, patience=2/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0861, val=0.0853, patience=4/15, lr=0.000002
   📉 Epoch 18: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0860, val=0.0850, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 23 Summary - Client client_90
   Epochs: 29/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0049
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0209
============================================================


============================================================
🔄 Round 24 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0758, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0890, val=0.0755, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 24 Summary - Client client_90
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0124
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0200
============================================================


============================================================
🔄 Round 25 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0967, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0840, val=0.0964 (↓), lr=0.000001
   • Epoch  21/100: train=0.0838, val=0.0960, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0837, val=0.0957, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 25 Summary - Client client_90
   Epochs: 39/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0053
   Val:   Loss=0.0959, RMSE=0.3097, R²=-0.0439
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2458, R²: -0.0071

📊 Round 25 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2457, R²: -0.0065

============================================================
🔄 Round 33 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 33 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0134
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0057
============================================================


============================================================
🔄 Round 35 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 35 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0160
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0020
============================================================


============================================================
🔄 Round 36 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 36 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0100
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0168
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2457, R²: -0.0040

📊 Round 36 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2457, R²: -0.0033

============================================================
🔄 Round 43 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 43 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0051
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0533
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0031

============================================================
🔄 Round 44 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 44 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0075
   Val:   Loss=0.0918, RMSE=0.3031, R²=-0.0185
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0031

============================================================
🔄 Round 48 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 48 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0066
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0274
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0028

============================================================
🔄 Round 49 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0977, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 49 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0144
   Val:   Loss=0.0976, RMSE=0.3125, R²=0.0010
============================================================


============================================================
🔄 Round 52 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 52 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0090
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0096
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2456, R²: -0.0026

============================================================
🔄 Round 53 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 53 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0044
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0562
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2456, R²: -0.0026

============================================================
🔄 Round 55 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 55 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0094
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0085
============================================================


============================================================
🔄 Round 56 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 56 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0100
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0064
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2456, R²: -0.0026

============================================================
🔄 Round 57 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 57 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0073
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0182
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2456, R²: -0.0024

📊 Round 57 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2456, R²: -0.0022

============================================================
🔄 Round 64 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 64 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0104
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0071
============================================================


============================================================
🔄 Round 65 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 65 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0053
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0261
============================================================


============================================================
🔄 Round 67 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 67 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0101
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0028
============================================================


============================================================
🔄 Round 68 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 68 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0111
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0004
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0021

============================================================
🔄 Round 71 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 71 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0059
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0214
============================================================


============================================================
🔄 Round 72 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 72 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0118
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0043
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0018

============================================================
🔄 Round 73 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 73 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0058
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0252
============================================================


============================================================
🔄 Round 74 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 74 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0068
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0156
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0016

============================================================
🔄 Round 77 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 77 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0162
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0176
============================================================


============================================================
🔄 Round 78 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 78 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0060
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0292
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0015

============================================================
🔄 Round 82 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 82 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0069
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0173
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0014

📊 Round 82 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0014

📊 Round 82 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0014

============================================================
🔄 Round 86 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 86 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0132
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0010
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0015

============================================================
🔄 Round 87 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 87 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0052
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0244
============================================================


============================================================
🔄 Round 88 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 88 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0121
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0054
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0013

============================================================
🔄 Round 90 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 90 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0036
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0548
============================================================


============================================================
🔄 Round 92 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 92 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0149
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0158
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2456, R²: -0.0011

📊 Round 92 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2456, R²: -0.0010

📊 Round 92 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2456, R²: -0.0010

============================================================
🔄 Round 96 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 96 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0046
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0197
============================================================


============================================================
🔄 Round 97 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 97 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0121
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0027
============================================================


============================================================
🔄 Round 98 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 98 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0074
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0095
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2456, R²: -0.0011

============================================================
🔄 Round 99 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 99 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0104
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0029
============================================================


============================================================
🔄 Round 100 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 100 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0075
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0061
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2456, R²: -0.0009

============================================================
🔄 Round 103 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 103 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0037
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0253
============================================================


============================================================
🔄 Round 105 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 105 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0077
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0034
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2456, R²: -0.0008

📊 Round 105 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2456, R²: -0.0007

============================================================
🔄 Round 109 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 109 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0072
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0052
============================================================


============================================================
🔄 Round 110 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 110 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0139
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0125
============================================================


============================================================
🔄 Round 111 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 111 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0105
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0041
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2456, R²: -0.0005

📊 Round 111 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2456, R²: -0.0006

============================================================
🔄 Round 114 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 114 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0047
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0186
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2456, R²: -0.0006

📊 Round 114 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2456, R²: -0.0006

============================================================
🔄 Round 118 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 118 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0047
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0456
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2456, R²: -0.0006

📊 Round 118 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2456, R²: -0.0006

============================================================
🔄 Round 120 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 120 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0115
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0073
============================================================


============================================================
🔄 Round 121 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 121 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0064
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0077
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2456, R²: -0.0005

📊 Round 121 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2456, R²: -0.0004

============================================================
🔄 Round 126 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 126 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0082
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0007
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0003

📊 Round 126 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0004

📊 Round 126 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0003

============================================================
🔄 Round 134 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 134 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0118
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0144
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0003

============================================================
🔄 Round 136 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 136 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0056
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0091
============================================================


============================================================
🔄 Round 138 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 138 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0078
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0047
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0001

============================================================
🔄 Round 143 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 143 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0047
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0212
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0003

============================================================
🔄 Round 145 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 145 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=-0.0074
   Val:   Loss=0.0678, RMSE=0.2604, R²=-0.0013
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0003

============================================================
🔄 Round 148 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 148 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0086
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0012
============================================================


============================================================
🔄 Round 150 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 150 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0036
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0242
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0004

============================================================
🔄 Round 154 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 154 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0049
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0204
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0003

📊 Round 154 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0003

============================================================
🔄 Round 157 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 157 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0048
   Val:   Loss=0.0942, RMSE=0.3068, R²=-0.0119
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0003

============================================================
🔄 Round 158 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 158 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0029
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0520
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0002

============================================================
🔄 Round 161 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 161 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0070
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0053
============================================================


============================================================
🔄 Round 162 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 162 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0055
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0103
============================================================


============================================================
🔄 Round 163 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 163 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0085
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0004
============================================================


============================================================
🔄 Round 165 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 165 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0133
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0119
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: -0.0001

============================================================
🔄 Round 167 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 167 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0122
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0114
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2456, R²: -0.0001

📊 Round 167 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: -0.0000

📊 Round 167 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0000

📊 Round 167 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0000

📊 Round 167 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0001

============================================================
🔄 Round 173 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 173 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0073
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0049
============================================================


============================================================
🔄 Round 174 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 174 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0062
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0047
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0001

============================================================
🔄 Round 177 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 177 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0065
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0062
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0001

============================================================
🔄 Round 178 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 178 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0045
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0154
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0001

📊 Round 178 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0000

📊 Round 178 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0001

============================================================
🔄 Round 181 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 181 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0062
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0047
============================================================


============================================================
🔄 Round 183 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 183 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0059
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0068
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0001

============================================================
🔄 Round 185 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 185 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0042
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0186
============================================================


============================================================
🔄 Round 187 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 187 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0036
   Val:   Loss=0.0861, RMSE=0.2933, R²=-0.0232
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0000

============================================================
🔄 Round 188 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 188 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0042
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0170
============================================================


============================================================
🔄 Round 192 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 192 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0048
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0102
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0002

📊 Round 192 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0001

📊 Round 192 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0001

============================================================
🔄 Round 202 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 202 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0037
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0209
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0002

============================================================
🔄 Round 203 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 203 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0073
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0013
============================================================


============================================================
🔄 Round 206 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 206 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0048
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0119
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0002

============================================================
🔄 Round 209 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 209 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0077
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0005
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2455, R²: 0.0002

============================================================
🔄 Round 211 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 211 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0075
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0004
============================================================


❌ Client client_90 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
