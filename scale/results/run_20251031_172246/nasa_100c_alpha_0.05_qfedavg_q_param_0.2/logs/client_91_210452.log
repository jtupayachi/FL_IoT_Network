[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ed8778-c33c-4348-af7e-686eac2f9335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8cfb627-a615-42dc-9a15-30205b0cd671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4761c10-9d0f-4460-9528-a50b2c622cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1f6355d-1160-4787-92d0-1dd5423d1bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2efd92d-41fd-4479-abd3-3f2b9ce2f66a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d0602c-a046-469e-9b61-80d5aa0dd60b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a01b6faf-6013-4b08-8eb4-c11a21c7a613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afccf1ca-1dc5-49b9-86f1-42680085085a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fae1317-d5ca-46b4-ac7d-52aa4683544b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73befd3d-31db-49a1-8784-df091be99846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77ce19da-c004-47b7-84f9-c5f1d21bfa0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5809a834-1fbe-423c-aa5d-a464387ed9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7353fc4-8088-4834-8ba3-8b7dc96f89ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c2a3dee-1749-4192-a47b-53f4bd01dbfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b30af29-70e3-4bbd-9d71-cf016793450b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9468296-315f-48a5-a6a3-77958c473480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ede2da0-e2ee-41bb-9293-578d21a783f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7642fa57-cf50-45ca-838b-028d5e5ea4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3832419-7915-4e61-b591-93ee84406ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fa30eb3-a153-49e5-9be4-73d911425629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc1e782-05bb-4344-b812-8625e28a15d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c1230e-d4de-4a26-8032-a5d2852290da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14dca2da-7ba8-4c53-9a08-5b1f02ba0cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c50460f-c878-4423-8bc1-4829829fd85f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9c9035-2848-46a5-87a0-be9886d3bce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa64fe7-0587-48dc-a161-b5fadde50970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8949d138-3143-454d-b556-800cfb69ed26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dad7073-e940-46ea-8e53-287df691d5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1904a9e3-f81b-4306-b4e5-e164e8fc4444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5da9f330-dc28-44b1-99b5-1e53c1c96ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66aa5e32-ff52-48b4-ac31-9df1004f63bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c69494aa-8ba6-4afa-98c6-13d93249db38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07739342-f4ef-41e5-955c-2d62ca61c2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 713665f3-fabb-4981-abb3-a4179707b17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7ccb6e5-ec95-433c-ad9c-31d251367918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f79cfd9e-7caf-4946-a8b2-a273fe6bed93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1d35fb9-8f8c-4ba2-bd06-e065cb34a934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e70238-dafb-4a22-b08e-0a66bc8d6f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68cbf45a-91ae-40f0-a3ea-2c4076a9ad8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb78a7e2-04d3-4383-8f8a-850328e4b202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74433714-9463-42de-9655-3cc874b40604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1a175a-14a3-44fa-bbdf-5a3186f4962c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae7825c-6a24-45a4-b6f5-31763f58fb27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1caea623-20dd-4325-b1e1-38bb5f7dc56c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee1a0c52-6c11-4e8c-b4fa-8e0bc4ae1897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0a6d8e-2df8-459d-93af-98e7ebcf846b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 546a14d3-ab0f-4873-a765-86902950d0ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd43bcfb-c755-432b-b974-6a66df6d2d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e3b1948-2104-4169-ae14-70f01041a0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 797b9a26-c276-4e75-a087-3e504d63447f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f22a63dd-deb4-4024-8d21-5305e3286776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c902a74f-0980-49c4-989f-d7da758f5dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8440c437-0b63-4a21-a966-bbe34e2528a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fea2faf-2bce-4db0-bfb4-d575d031fb52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 460e2eae-b9b0-4533-b2c4-963984458d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33967450-67f9-450c-85f6-35f41c0c4ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 958f7ae5-b7a8-4d5f-bab9-eb285813e000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db997ab-20d9-45cb-aaae-110aef52d9cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e9a4f37-a3fe-4910-a731-f03d12b33c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f86b79f-e769-43f4-a4de-8d3ba6b0f52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158a0142-0163-437d-84c4-56a105744d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee4f7bb-b2a5-44ac-adec-0fdda518fd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80e74d8a-cf7e-412b-83df-dd9666925f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ae42a2d-d817-422a-81c3-35ede2bb8f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3c71588-f579-4328-aa71-32bfb074626e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96b79fce-98b9-4ad1-8fc9-5efc79b493ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ec203b5-c2c4-4a35-86d5-f784bfb89fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0438941-02c7-465b-9dbb-65a2b3442cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0889ba8-428d-41c3-98b6-759167dbb86e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b683431-4e1d-4a7f-ba36-0ab88ee0871d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14e04fe9-a11b-44c3-80a5-c1794ebd25c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca88bff6-1056-4b04-9bee-41c19481b5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d2216e9-016a-42e2-9792-a5a5e02486d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d014c9b-f7ae-4f23-bba7-ae3269e1c132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 872eaeeb-3246-4f1e-8484-cf8062971022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbdb0584-8fa8-43d2-a69d-ac3392bbd0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 496e6a7f-5517-42c4-b3f5-e31cff27f3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f566432-1d90-4f19-8896-2cd426bd77c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1927a04-22ef-4f77-876c-4bb6ba36123a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28339a28-83b9-447b-9a3c-bdc7a8a1fef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad4c4c93-c84d-4b69-97eb-36144e323a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79c1cbd7-2ae0-408b-b1d7-caa4b1f9c7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1987b2b-249c-41af-97be-7e3cf6a83c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b22058d5-f589-4584-8312-705f1325e171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d92293-f788-4d61-93fd-f0b5c390eb77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06968f40-8f35-4ab2-9465-71793901f16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 821770b9-b08a-4346-b8b8-bb1bfbda7487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17df9d58-089c-4890-b2ce-e7546dded3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d8c42a6-2826-46cd-beaa-3ba0d06b9917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f7ca93f-9b7e-4767-af3b-951cdf4f808c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1492959-abb1-42fc-ad43-cfe7d2b2308e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60436473-2526-4512-8e79-940940f8125f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f0b7940-3a1a-4d42-b4cc-b67c074f0624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e0b5601-6df5-49bb-8076-47da9c4a1f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69190c55-de26-4d56-90b8-0dc197e938cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8da1d514-446d-475a-9369-12d453c577e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e090745c-3e27-41a1-bba7-72e75c85eeda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 042d6fea-b5ba-46b8-98fd-e5b1f2f23e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6804781e-56d9-40a5-9fd8-33747f4dd63c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b47f808-11bc-4421-93f9-db73b3cfbfc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d25ca2-ba99-4bce-ad68-77b08216cc1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d04240d-7585-467a-b27f-b8b03f47eed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8d5ab4-a4ff-4c66-9773-8735a0e6cd64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ccd588-f29d-4d00-99db-7dd6a787270e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 156d81a2-6c7b-4a87-8fda-23a80efb8359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4d95d92-d79a-4218-bdec-f25194c8b6b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74f2fe2a-c1b2-4846-8df0-55d189fbdf07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e45aa592-a9e9-4795-996a-7fc2f3e08763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f991b82-4b57-4405-a397-a01d32b73adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c53bffe-d5fc-40a5-9ed6-f90c5edabcef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3f4f86d-2d5a-4312-bac0-6dee4accafb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d8e3bd-e66c-4f3c-9ed5-748760d2626c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message add11537-b7d5-48e9-9dac-b94427512802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5769773c-4f85-488a-bce3-1e83effe1e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba9827e-3b5e-48c4-924b-1b1cdd0ebc5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65cb1a1d-c3fa-4291-b12a-144333dd1683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88da7827-eda9-4564-b818-c7541176824a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90915886-89ca-4bfd-8c67-6631283bfa73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f3414cd-fe57-4d4f-b0ad-625d054bccc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6b6ecd-e301-4608-bcf1-a6cdc1d6083f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eea87ebf-f784-493a-8bdf-bc0d5f9d32a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c602c06f-65b8-4bf4-b83f-6f954f9d3969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8449fbad-1d40-483f-b00a-ec496041b2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f400041a-d70c-4ec7-af9c-f78244420f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e24b62f0-41cd-4027-bd68-fc459acb82d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ed588e-a625-45d3-ae02-069e921463cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f8317cc-058c-41ed-bec0-173e0639f9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b3df98e-8755-4376-afb0-de7851daba1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac81235d-18b9-42e3-934e-5195a2fdc4f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e01c149b-3593-417d-8393-b994781027a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b278cadf-da5c-4f04-9cd7-6629e96d8be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92f0f3db-5656-4e58-ace2-48036c268d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3d3e5d8-8778-493a-862e-f427268a69e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e2c6425-a1c3-428f-a13a-36da287f8e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc68bd66-6c9e-43f6-ab35-6d9a24d80943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4356ca-b1f7-4fbd-854b-1fe636e9e040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f578f2f-9d4c-4cf3-8269-a57660c44601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b65ec477-2d9f-4822-9747-0e0b391dfda0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8dee907-58d2-4fd9-80f4-86bc394cf119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54ed2a8a-633b-4bd3-a709-7a1a1cf69644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff549c4a-67fe-423e-883e-c9ccd090ba20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 790e8def-495c-4949-80ff-aa0c560db0b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 489c2c6c-1ed0-41ab-bbef-c0e563bcce38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 539a806a-ba64-4315-b44a-4e8454b97f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0d4aa4e-f2f5-4cc4-8d1d-b6467a2ac7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9564ddcf-8f55-4a0d-b020-6c087ebffb3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f5950be-8a59-41e5-8a29-eeeacd2930da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a8f4078-89b6-45df-a6c5-b6e7b2b3b2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b492e2e-fd4e-4a35-8706-8f7f837d24fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28951ed5-61bd-4f82-b5ca-58aa1a83e1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2da9dc98-4b47-4390-b1ab-c8aa11a77f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ef3919-9c36-488b-9471-f3915b20aba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a27750c9-2a97-4c2a-9a95-bfab8e01a16c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85b12cff-b0ad-45df-b68d-8739c8a751e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd5dde63-d153-474e-bc9e-b6c873702290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead6dc8a-68b3-4b6b-a08f-3eaee4dc3652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96109d7f-c294-4527-b996-99233119cc04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d15696c6-cded-4636-a3be-72826a4d6447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b03ad51a-dc68-40ed-ba6a-1cf4398d0bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e36e5007-56e6-4d06-8d2f-c61f1d3105d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66f22cd7-a730-4029-8a09-bf7f3fd1466e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23c7423c-250c-4947-b07d-c8c498642511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 180608c4-c548-4cf6-a788-a3a15399c219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd7a4fe6-d89b-48c5-accd-e2587f46b687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04a6f2da-84af-4525-ac9b-5e51db513345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 764e81fa-582c-450d-8315-aa7ae208acae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc95a64-5374-49f7-827e-0abe82cb1b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e51b9ddf-c30d-49bc-84ff-81177547d52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6401723c-8deb-4f32-ad34-4c0a5694b43b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aa9fb6b-db54-4366-bd9a-db21cbde6173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf674635-34b6-4f73-a10f-6bdfb54ab1db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ba802a5-f8d4-4b20-a838-996fc766e710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba6fb85b-e3af-4cf7-bfcb-bd26278eb938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 087ccd53-96d7-4474-9712-38ddbba5cb2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65d84718-177b-4081-bb0d-5e893dcc0d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2da56d2-7e5e-4f2c-98b2-4b164e778485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b92aa9c-72b0-43bc-8f32-bc6671cf2b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ddaf69e-3bce-4b51-8381-de3d1b447ac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb38f995-af63-40c1-85c5-6716a12fa03b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_91
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/test_labels.txt

📊 Raw data loaded:
   Train: X=(563, 24), y=(563,)
   Test:  X=(141, 24), y=(141,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 554 samples, 5 features
   Test:  132 samples, 5 features
✅ Client client_91 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1721, RMSE: 0.4148, MAE: 0.3357, R²: -1.1873

📊 Round 0 Test Metrics:
   Loss: 0.1660, RMSE: 0.4075, MAE: 0.3293, R²: -1.1105

============================================================
🔄 Round 11 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1060, val=0.1002 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0898, val=0.0870 (↓), lr=0.001000
   • Epoch   3/100: train=0.0830, val=0.0874, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0836, val=0.0864 (↓), lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0870, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0817, val=0.0879, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 11 Summary - Client client_91
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0304
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0211
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1615, RMSE: 0.4019, MAE: 0.3244, R²: -1.0533

📊 Round 11 Test Metrics:
   Loss: 0.1559, RMSE: 0.3949, MAE: 0.3182, R²: -0.9822

============================================================
🔄 Round 13 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1346, val=0.1139 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0948, val=0.0788 (↓), lr=0.000250
   • Epoch   3/100: train=0.0869, val=0.0787, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0853, val=0.0811, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0848, val=0.0809, patience=3/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0836, val=0.0827, patience=9/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 13 Summary - Client client_91
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0089
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0244
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1499, RMSE: 0.3872, MAE: 0.3114, R²: -0.9053

📊 Round 13 Test Metrics:
   Loss: 0.1392, RMSE: 0.3731, MAE: 0.2996, R²: -0.7695

📊 Round 13 Test Metrics:
   Loss: 0.1006, RMSE: 0.3172, MAE: 0.2610, R²: -0.2786

============================================================
🔄 Round 24 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0904 (↓), lr=0.000063
   • Epoch   2/100: train=0.0833, val=0.0908, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0830, val=0.0911, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0829, val=0.0910, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0827, val=0.0909, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0823, val=0.0908, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 24 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0035
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0031
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2426, R²: -0.0115

============================================================
🔄 Round 26 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0801 (↓), lr=0.000016
   • Epoch   2/100: train=0.0864, val=0.0799, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0864, val=0.0797, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0863, val=0.0796 (↓), lr=0.000016
   • Epoch   5/100: train=0.0863, val=0.0794, patience=1/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0862, val=0.0790 (↓), lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0861, val=0.0788, patience=10/15, lr=0.000004
   📉 Epoch 24: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 26 Summary - Client client_91
   Epochs: 26/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0010
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0043
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2425, R²: -0.0106

============================================================
🔄 Round 27 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0852 (↓), lr=0.000002
   • Epoch   2/100: train=0.0853, val=0.0852, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0852, val=0.0852, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0852, val=0.0852, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0852, val=0.0851, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0851, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 27 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0038
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0046
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2425, R²: -0.0103

📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2424, R²: -0.0088

============================================================
🔄 Round 30 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 30 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0072
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0020
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0793, RMSE: 0.2815, MAE: 0.2423, R²: -0.0074

📊 Round 30 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2422, R²: -0.0067

============================================================
🔄 Round 39 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 39 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0020
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0010
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2422, R²: -0.0057

============================================================
🔄 Round 40 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 40 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0001
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0091
============================================================


============================================================
🔄 Round 41 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 41 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0001
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0079
============================================================


============================================================
🔄 Round 42 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 42 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0020
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0002
============================================================


============================================================
🔄 Round 44 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 44 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0018
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0005
============================================================


============================================================
🔄 Round 45 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 45 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0016
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0050
============================================================


============================================================
🔄 Round 47 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 47 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0005
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0395
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: -0.0046

============================================================
🔄 Round 49 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 49 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0027
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0007
============================================================


============================================================
🔄 Round 50 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 50 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0007
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0074
============================================================


============================================================
🔄 Round 51 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 51 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0017
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0002
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: -0.0042

============================================================
🔄 Round 53 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 53 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0003
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0100
============================================================


============================================================
🔄 Round 54 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 54 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0025
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0066
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: -0.0044

============================================================
🔄 Round 55 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 55 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0023
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0038
============================================================


============================================================
🔄 Round 56 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 56 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0022
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0014
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: -0.0044

============================================================
🔄 Round 59 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 59 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0018
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0016
============================================================


============================================================
🔄 Round 60 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 60 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0004
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0037
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: -0.0042

============================================================
🔄 Round 61 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 61 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0003
   Val:   Loss=0.0679, RMSE=0.2605, R²=-0.0085
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: -0.0040

============================================================
🔄 Round 62 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 62 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0002
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0086
============================================================


============================================================
🔄 Round 63 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 63 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0023
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0042
============================================================


============================================================
🔄 Round 64 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 64 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0012
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0035
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2421, R²: -0.0038

============================================================
🔄 Round 67 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 67 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0007
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0283
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2421, R²: -0.0037

📊 Round 67 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2420, R²: -0.0035

============================================================
🔄 Round 72 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 72 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0027
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0061
============================================================


============================================================
🔄 Round 73 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 73 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0003
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0033
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2420, R²: -0.0032

============================================================
🔄 Round 74 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 74 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0006
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0097
============================================================


============================================================
🔄 Round 75 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 75 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0010
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0027
============================================================


============================================================
🔄 Round 76 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 76 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0004
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0218
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2420, R²: -0.0029

============================================================
🔄 Round 78 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 78 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0011
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0007
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2420, R²: -0.0029

📊 Round 78 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2420, R²: -0.0028

📊 Round 78 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2420, R²: -0.0028

============================================================
🔄 Round 81 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 81 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0009
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0212
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2420, R²: -0.0028

============================================================
🔄 Round 83 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 83 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0010
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0075
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2420, R²: -0.0028

📊 Round 83 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2420, R²: -0.0029

============================================================
🔄 Round 88 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 88 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0006
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0374
============================================================


============================================================
🔄 Round 90 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 90 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0001
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0036
============================================================


============================================================
🔄 Round 91 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 91 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0047
   Val:   Loss=0.0897, RMSE=0.2996, R²=0.0149
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2420, R²: -0.0025

============================================================
🔄 Round 93 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 93 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0010
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0099
============================================================


============================================================
🔄 Round 95 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 95 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0022
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0043
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2420, R²: -0.0023

📊 Round 95 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2420, R²: -0.0024

📊 Round 95 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2420, R²: -0.0025

📊 Round 95 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2420, R²: -0.0024

============================================================
🔄 Round 100 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 100 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0007
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0051
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2420, R²: -0.0023

============================================================
🔄 Round 103 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 103 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0015
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0069
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0021

============================================================
🔄 Round 104 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 104 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0006
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0738
============================================================


============================================================
🔄 Round 106 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 106 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0004
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0129
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0021

📊 Round 106 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0020

============================================================
🔄 Round 109 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 109 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0008
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0008
============================================================


============================================================
🔄 Round 110 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 110 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0008
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0026
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0019

============================================================
🔄 Round 111 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 111 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0008
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0072
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0018

📊 Round 111 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0020

📊 Round 111 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0019

📊 Round 111 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0020

============================================================
🔄 Round 115 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 115 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0011
   Val:   Loss=0.0954, RMSE=0.3089, R²=0.0003
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0021

============================================================
🔄 Round 116 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 116 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0012
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0140
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0020

============================================================
🔄 Round 117 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 117 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0012
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0012
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0021

📊 Round 117 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0021

============================================================
🔄 Round 121 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 121 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0007
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0044
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0020

📊 Round 121 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0020

============================================================
🔄 Round 125 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 125 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0015
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0081
============================================================


============================================================
🔄 Round 127 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 127 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0025
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0065
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0019

============================================================
🔄 Round 129 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 129 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0002
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0036
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0019

============================================================
🔄 Round 132 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 132 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0019
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0209
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0018

============================================================
🔄 Round 133 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 133 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0008
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0107
============================================================


============================================================
🔄 Round 134 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 134 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0006
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0002
============================================================


============================================================
🔄 Round 135 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 135 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0023
   Val:   Loss=0.0958, RMSE=0.3095, R²=0.0012
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0017

============================================================
🔄 Round 136 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 136 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0010
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0076
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0016

============================================================
🔄 Round 139 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 139 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0003
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0020
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2419, R²: -0.0015

============================================================
🔄 Round 140 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 140 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0007
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0072
============================================================


============================================================
🔄 Round 141 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 141 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0007
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0014
============================================================


============================================================
🔄 Round 142 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 142 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0006
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0180
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0017

============================================================
🔄 Round 143 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 143 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0020
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0079
============================================================


============================================================
🔄 Round 147 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 147 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0008
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0189
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0020

============================================================
🔄 Round 149 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 149 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0014
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0009
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0021

📊 Round 149 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2420, R²: -0.0023

============================================================
🔄 Round 152 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 152 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0012
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0046
============================================================


============================================================
🔄 Round 153 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 153 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0003
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0087
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2420, R²: -0.0022

============================================================
🔄 Round 155 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 155 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0014
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0040
============================================================


============================================================
🔄 Round 156 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 156 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0010
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0084
============================================================


============================================================
🔄 Round 157 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 157 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0008
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0040
============================================================


============================================================
🔄 Round 158 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 158 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0012
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0160
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0021

============================================================
🔄 Round 159 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 159 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0014
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0023
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0021

============================================================
🔄 Round 160 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 160 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0058
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0176
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0020

============================================================
🔄 Round 161 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 161 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0034
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0182
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0021

📊 Round 161 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0020

============================================================
🔄 Round 167 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 167 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0004
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0075
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0019

📊 Round 167 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0018

============================================================
🔄 Round 169 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 169 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0001
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0015
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0018

============================================================
🔄 Round 170 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 170 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0008
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0000
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0016

📊 Round 170 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0017

============================================================
🔄 Round 175 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 175 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0035
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0113
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0017

============================================================
🔄 Round 177 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 177 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0021
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0126
============================================================


============================================================
🔄 Round 180 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 180 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0003
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0014
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0018

============================================================
🔄 Round 181 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 181 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0012
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0074
============================================================


============================================================
🔄 Round 183 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 183 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0007
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0042
============================================================


============================================================
🔄 Round 185 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 185 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0028
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0309
============================================================


============================================================
🔄 Round 186 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 186 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0005
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0088
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0021

============================================================
🔄 Round 188 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 188 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0055
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0191
============================================================


============================================================
🔄 Round 191 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 191 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2921, R²=-0.0006
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0381
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0019

============================================================
🔄 Round 192 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 192 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0004
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0081
============================================================


============================================================
🔄 Round 194 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 194 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0009
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0024
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0019

============================================================
🔄 Round 197 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 197 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0016
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0055
============================================================


============================================================
🔄 Round 198 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 198 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0004
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0014
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0021

============================================================
🔄 Round 199 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 199 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0010
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0058
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0020

📊 Round 199 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0019

============================================================
🔄 Round 202 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 202 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0011
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0115
============================================================


============================================================
🔄 Round 203 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 203 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0002
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0049
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2420, R²: -0.0018

============================================================
🔄 Round 204 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 204 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0003
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0003
============================================================


============================================================
🔄 Round 208 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 208 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0005
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0168
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2420, R²: -0.0020

============================================================
🔄 Round 211 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 211 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0006
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0070
============================================================


❌ Client client_91 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
