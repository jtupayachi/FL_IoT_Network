[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf5a1c3-63d3-4966-b056-92704b2ff4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 299f7bec-0256-4361-bcac-ea316a8d6660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d308e594-cbde-40d7-b73f-bf4b975127cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 863378b9-caff-4c56-b5b8-39493e36ee4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f35c9bc8-148f-4915-b90c-1b95a83ca4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b87f69-4fe1-4e31-9c97-3093756a7a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd447da0-d349-4fca-a63b-ae001f3a8bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ed7e6e6-c102-4193-80c0-3bb26b111729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfb35401-b98c-4c28-918e-a7fbcd4f5fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b766c525-e600-4997-8d57-94c1301ce18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 102f6d51-14d7-4bb8-8b50-6099c4504315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ef47985-7a61-4516-808d-b7770a22deae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 271f20f6-064b-4f04-970d-8e31975850e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c196d0-436f-46b8-ba9b-8380db617395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7749afb-e572-46bb-8f03-d04818cd007c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de4d63c5-140c-4ad4-b8a4-5c1bac60644f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69b2a927-4a74-42f8-ae54-3c5e830b9e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b016daf-a632-42db-9c8b-ec1ed390b96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69b020e8-b567-4cb2-9586-16fb7f577491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adbfca81-b598-4de9-91dc-235e9daadd0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c62cd431-76bb-4587-983e-20c2c3126e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb5b5fe7-64c8-4d76-9958-64ddadb41734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3bf4025-1ae8-49dd-9c8c-4bfc0cfbd988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbbe76fd-6360-47fa-b388-b3f2f63aee11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb6792d4-f2e0-45e3-ae89-cbb5740f3c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 851c9e5d-2ec4-4cae-89c2-30cb23503dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502887d5-f27d-46b3-b057-d1931b8b7bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 699083c4-53b3-46fc-a250-50a1b70f9206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc174514-2e85-4414-bce1-3f646a507f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40056de8-1370-4250-955a-66f12cc35bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdec76df-a862-4bc4-9a80-b26aa5c5d534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb5e47eb-7a64-4534-b3d1-f5dced003af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c48b479-ada2-4033-8d91-3c007882b85d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a12c951a-7f20-4264-996e-f86c735e05e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5215477-ab6f-48dd-8866-4009eb619276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 494444d8-6ef2-43a0-83e2-98051371a640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d172fc6-2824-42d9-929a-aff97cb4c573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f23e61-1f88-43b7-b876-46de3626603c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39e62755-8950-4475-9d3d-dff6de08b684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 441f1f83-06bb-4336-a36e-9178e26e00ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45bef390-8347-4c48-82f9-a89e4898b99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0975e237-6c28-423a-aa87-989260c63b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60f0bdd-d834-46da-99ed-95672dd6f098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4d4fdb1-8c0d-4618-8ecc-9f0f6ddcb076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70bfb5de-d0f0-4785-85bd-af26f79e7657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 255df591-f074-4e7e-b3b2-fbaa179907db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61bf1092-7ee1-410c-9283-6e803aab9788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4056ce70-321b-475a-b486-72b89e9c520e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0328474c-7236-4062-b374-533701347152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e47aa59-a172-4924-b7ce-14dc9ceb439a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f110f2-2a39-43b8-b731-425689577d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cdb1f86-d4a5-4cd3-b54f-cd02b1eedcfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 202a5cfb-711b-466d-8e6c-4c8b4085f26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d798e6d-efd5-4039-9ca5-f1013b97ac32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eee315ca-f00f-4efa-99c9-4c297884de23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e886ba10-8ffd-42bb-93c8-5aa0b1c0c304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34e17c30-70af-4eed-becf-2b534d43b7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72cbf4b1-b4b6-44d7-b7b8-b3fe95f60734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 568cac4c-d5fe-4061-8a6c-e92edbaea9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beac9a87-f69f-4c75-a714-53a47b3cf0d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ffbf6e9-7108-4171-97ba-0406401a79a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d714bc0-d4de-4ee1-9d31-672b8828fe02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8570a7a-5e06-43bd-8118-222afa58cd03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d899e4df-ee9a-420b-bf1f-e0822d170a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60fb2d5b-a00e-4195-b603-ae1141c91377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11af9291-4127-4d72-a3ed-855252f823c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 362b081d-40a4-40e2-8af1-d7306b698987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17eaf23b-2722-4f4a-8f08-92c266a74c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e0b600d-e06f-42c0-9508-c7ef3289520c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ced4b1b-9f64-4fc8-a69c-6f2b9b7c285f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4812b97-6600-491d-b0fb-7188c75bcb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1f49995-cd21-467c-b6cc-847da0364b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922b66dd-47bf-4a02-9b57-cf492626084c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcd63062-47f5-401c-99fc-4bff2cea3562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f30f261f-2d61-4f3f-b95b-77ef24f79223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bc002c4-7f36-4b0e-a4ee-f83afdbff9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24fb092f-4d1a-4735-bf15-3cb71ddcb26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d21077ff-e6e4-424f-a8ca-f80423419047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 106becfc-5248-4021-b9c2-a0e75b7bc572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9536c44e-6ee9-4bd1-9b64-72f5bba6972c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18b7fc8c-3eeb-486f-b3fd-d1463ec3377a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f206cddf-848b-4a1b-a427-a3a573f923d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da4340cd-eb86-4002-a1d1-93113fa43783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9430ad81-3ff9-402b-9cc0-19c4156d8f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59e09cd-102b-4874-b715-3225746cf7ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6b4c738-867d-41fa-9827-6c99c16809fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 893d1fa9-09b0-4772-8f91-81f8c92dcb91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 910f24c6-fffa-4176-8f72-b8d491dafa3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aae342b-de8f-4075-a505-83c05786764c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c4bf826-7d96-409e-8bbb-247303ccbccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c24bb2c-c3d3-42cb-b8ef-8bcfd8ecd596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f4ff6e-7742-4e73-82af-7b63f3f21cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33a9ba07-d691-4de6-9faf-2a38d38b9587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bc8ae80-3ef6-44e3-a752-84bc027ae931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6691f065-eb8c-4c87-8d58-80bf8688a4e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e37ab272-3f42-4f16-a84c-c4df215160d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 978b0042-549a-4217-a93f-63dd51a75ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec55b672-616b-4c5b-bd6b-06922df542fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8814116a-a181-4be4-979e-35247b8ad22d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0da1ad6-541b-42a3-b338-d7012bc718be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c79043bd-4b22-4001-adf3-2e3597101995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a97708d4-c236-40ca-8579-21595695004b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51d7267b-aaa8-42cd-a341-894ba6467381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9caac73-19d9-4777-96b2-aebf9c119edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d8e4a3d-3cd2-4217-82f3-fbe63c0cdf8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11dfda23-63a2-4a90-8cb5-22b0fca56579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf000441-32bd-4a74-a6f4-4582ad8d7f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1a976fe-85e4-4aed-9ef3-e7044aa77d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9fc2495-bfe8-4aaa-adc1-43556ed1c4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a3c7f4c-a684-4bae-8da5-617690fba284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09032134-e402-475b-9078-1aca95174863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43d830b4-9d86-4478-bb1a-c142b3d99740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613461f3-0425-4a5e-937f-25ea3cc08ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8ea37cb-93b4-48ae-80ee-7720eab6a58a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8221b24b-4823-4ad7-a7fb-1ad067f6c803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 786cd599-6665-4b45-a4df-27ae8f8a4d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbb74888-055d-40fe-a32f-ed69c0e266aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5460f1e-f151-40eb-adb5-b931a2af3590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2889cbb-1b96-4fb9-b794-769ce691b6d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33608f3b-1a9b-40b4-85df-ddf36cd46b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 036b2c56-c5ca-462b-9f86-8623e48da830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93ca3302-9d6f-46ab-8ce4-fbb724b746ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed27f12e-b523-4e93-91eb-87e469b24cf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f985b0a2-47d8-4330-8a88-f3ac6228b783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ffdc850-7423-434f-b6d3-c5a459243069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b95f04e-42a8-4d91-a105-72530b9e4e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 556d369f-a953-4f31-b020-a7529afeb281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1108860c-95e3-439a-835a-f3c48878a724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 962c02a0-e65c-4de3-90c4-01713782d31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 225f3dbb-2e7b-4678-9e34-d5fe61324b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eb4f4a8-b28c-41d7-b5ed-ba92c2ae27aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 421f6874-916e-429a-842e-f5c4a4fe098d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc9fc2e0-fff0-48fc-96a9-13b5714c33a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64713113-9816-40bf-8844-799f2ba6d80e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abeca293-a15f-4342-a194-f5d66af8c280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68af663d-9026-4b8e-986f-298865441235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e884005-ba35-4f14-9038-0671d2155b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7a57293-0d9e-44aa-9881-3956ae1e77ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa8780bc-2529-4f9f-b97f-c15792093206
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_92
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/test_labels.txt

📊 Raw data loaded:
   Train: X=(1170, 24), y=(1170,)
   Test:  X=(293, 24), y=(293,)

⚠️  Limiting training data: 1170 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  284 samples, 5 features
✅ Client client_92 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1501, RMSE: 0.3875, MAE: 0.3151, R²: -0.8910

============================================================
🔄 Round 14 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0923, val=0.0873 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0828, val=0.0849 (↓), lr=0.001000
   • Epoch   3/100: train=0.0827, val=0.0850, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0823, val=0.0851, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0821, val=0.0851, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0811, val=0.0844, patience=9/15, lr=0.001000
   📉 Epoch 19: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0778, val=0.0878, patience=9/15, lr=0.000500
   📉 Epoch 27: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 14 Summary - Client client_92
   Epochs: 27/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0217
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0015
============================================================


============================================================
🔄 Round 18 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0944, val=0.0754 (↓), lr=0.000250
   • Epoch   2/100: train=0.0861, val=0.0778, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0851, val=0.0780, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0848, val=0.0779, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0849, val=0.0783, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0844, val=0.0791, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 18 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0117
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0161
============================================================


============================================================
🔄 Round 19 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0967, val=0.0873 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0863, val=0.0850 (↓), lr=0.000063
   • Epoch   3/100: train=0.0830, val=0.0864, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0827, val=0.0863, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0826, val=0.0860, patience=3/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0824, val=0.0861, patience=9/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 19 Summary - Client client_92
   Epochs: 17/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0082
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0049
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2492, R²: -0.0941

============================================================
🔄 Round 23 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0821 (↓), lr=0.000016
   • Epoch   2/100: train=0.0843, val=0.0818, patience=1/15, lr=0.000016
   ✓ Epoch   3/100: train=0.0841, val=0.0815 (↓), lr=0.000016
   • Epoch   4/100: train=0.0840, val=0.0813, patience=1/15, lr=0.000016
   • Epoch   5/100: train=0.0840, val=0.0812, patience=2/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0838, val=0.0810, patience=8/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 23 Summary - Client client_92
   Epochs: 18/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0040
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0177
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2444, R²: -0.0059

============================================================
🔄 Round 26 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0823 (↓), lr=0.000004
   • Epoch   2/100: train=0.0843, val=0.0823, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0842, val=0.0822, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0842, val=0.0822, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0842, val=0.0822, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 26 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0060
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0049
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2444, R²: -0.0052

============================================================
🔄 Round 29 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 29 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0078
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0057
============================================================


============================================================
🔄 Round 30 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 30 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0045
   Val:   Loss=0.0713, RMSE=0.2671, R²=-0.0055
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2444, R²: -0.0043

📊 Round 30 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: -0.0040

📊 Round 30 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: -0.0039

📊 Round 30 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: -0.0038

============================================================
🔄 Round 34 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 34 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0048
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0022
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: -0.0037

============================================================
🔄 Round 38 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 38 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0018
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0111
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2444, R²: -0.0030

============================================================
🔄 Round 42 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 42 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0005
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0154
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2444, R²: -0.0028

============================================================
🔄 Round 45 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 45 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0034
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0032
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2444, R²: -0.0028

============================================================
🔄 Round 47 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 47 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0042
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0010
============================================================


============================================================
🔄 Round 48 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 48 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0026
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0070
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0027

============================================================
🔄 Round 53 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 53 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0026
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0290
============================================================


============================================================
🔄 Round 54 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 54 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0038
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0014
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0026

📊 Round 54 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0026

============================================================
🔄 Round 57 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 57 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0032
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0052
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0026

📊 Round 57 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0025

📊 Round 57 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0024

============================================================
🔄 Round 62 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 62 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0009
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0204
============================================================


============================================================
🔄 Round 63 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 63 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0028
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0048
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0024

============================================================
🔄 Round 66 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 66 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0031
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0045
============================================================


============================================================
🔄 Round 67 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 67 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0027
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0046
============================================================


============================================================
🔄 Round 68 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 68 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0036
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0008
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0023

============================================================
🔄 Round 73 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 73 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0028
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0022
============================================================


============================================================
🔄 Round 74 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 74 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0026
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0036
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0021

📊 Round 74 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0021

📊 Round 74 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0020

📊 Round 74 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0020

📊 Round 74 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2444, R²: -0.0020

============================================================
🔄 Round 80 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 80 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0020
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0052
============================================================


============================================================
🔄 Round 84 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 84 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0023
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0219
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0796, RMSE: 0.2820, MAE: 0.2444, R²: -0.0020

============================================================
🔄 Round 85 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 85 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0049
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0015
============================================================


============================================================
🔄 Round 88 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 88 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0019
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0044
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2444, R²: -0.0019

============================================================
🔄 Round 91 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 91 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0030
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0020
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2444, R²: -0.0018

============================================================
🔄 Round 93 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 93 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0029
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0001
============================================================


============================================================
🔄 Round 96 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 96 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0024
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0014
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2444, R²: -0.0017

============================================================
🔄 Round 97 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 97 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0019
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0055
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2444, R²: -0.0017

📊 Round 97 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2444, R²: -0.0017

============================================================
🔄 Round 102 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 102 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0020
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0028
============================================================


============================================================
🔄 Round 103 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 103 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0039
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0080
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2444, R²: -0.0016

============================================================
🔄 Round 107 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 107 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0019
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0031
============================================================


============================================================
🔄 Round 109 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 109 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0026
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0014
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2444, R²: -0.0016

============================================================
🔄 Round 110 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 110 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0025
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0003
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2444, R²: -0.0015

============================================================
🔄 Round 113 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 113 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0029
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0007
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0015

============================================================
🔄 Round 115 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 115 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0025
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0138
============================================================


============================================================
🔄 Round 116 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 116 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0029
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0023
============================================================


============================================================
🔄 Round 120 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 120 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0023
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0080
============================================================


============================================================
🔄 Round 123 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 123 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0026
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0049
============================================================


============================================================
🔄 Round 124 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 124 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0007
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0074
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0014

📊 Round 124 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0014

============================================================
🔄 Round 131 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 131 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0028
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0022
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0014

============================================================
🔄 Round 133 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 133 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0022
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0010
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0014

============================================================
🔄 Round 134 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 134 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0026
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0005
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0013

📊 Round 134 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0013

📊 Round 134 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0013

📊 Round 134 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0013

============================================================
🔄 Round 141 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 141 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0021
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0023
============================================================


============================================================
🔄 Round 145 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 145 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0013
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0155
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0013

============================================================
🔄 Round 146 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 146 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0016
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0060
============================================================


============================================================
🔄 Round 147 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 147 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0048
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0100
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0013

============================================================
🔄 Round 150 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 150 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0022
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0074
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0013

📊 Round 150 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2443, R²: -0.0013

============================================================
🔄 Round 154 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 154 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0002
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0094
============================================================


============================================================
🔄 Round 155 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 155 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0016
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0093
============================================================


============================================================
🔄 Round 156 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 156 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0028
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0081
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0012

============================================================
🔄 Round 158 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 158 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0024
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0035
============================================================


============================================================
🔄 Round 159 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 159 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0024
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0004
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0012

📊 Round 159 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0012

============================================================
🔄 Round 164 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 164 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0026
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0017
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0012

📊 Round 164 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0011

============================================================
🔄 Round 167 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 167 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0014
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0065
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0011

============================================================
🔄 Round 168 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 168 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0021
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0205
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0011

============================================================
🔄 Round 171 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 171 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0022
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0013
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0011

============================================================
🔄 Round 172 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 172 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0013
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0042
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0011

============================================================
🔄 Round 174 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 174 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0025
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0211
============================================================


============================================================
🔄 Round 176 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 176 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0012
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0062
============================================================


============================================================
🔄 Round 177 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 177 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0026
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0054
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0010

============================================================
🔄 Round 185 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 185 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0022
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0007
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0010

📊 Round 185 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0010

============================================================
🔄 Round 187 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 187 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0018
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0013
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0010

============================================================
🔄 Round 191 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 191 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0014
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0038
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0010

============================================================
🔄 Round 193 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 193 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0011
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0076
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0010

============================================================
🔄 Round 196 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 196 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0023
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0028
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0010

============================================================
🔄 Round 198 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 198 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0024
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0059
============================================================


============================================================
🔄 Round 199 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 199 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0020
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0004
============================================================


============================================================
🔄 Round 202 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 202 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0008
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0046
============================================================


============================================================
🔄 Round 205 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 205 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0021
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0182
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0009

📊 Round 205 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0009

============================================================
🔄 Round 210 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 210 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0024
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0011
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2443, R²: -0.0009

❌ Client client_92 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
