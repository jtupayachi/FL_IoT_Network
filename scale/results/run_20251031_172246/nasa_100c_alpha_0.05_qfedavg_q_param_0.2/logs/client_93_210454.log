[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6616a942-f288-4917-918f-f53a9563fb82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a8d6b9b-d149-4599-bd96-e731e776b6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65a974b-aa3a-45ad-b7cd-250837fdd62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d7b3766-9e66-45a3-acb1-40ead07ae35c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b06d599-caf3-4b4a-9855-3007c34c74b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 737e5abf-4f22-47bf-9095-bab054235117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 022b2e62-f800-4833-86d3-8f0e8c08be58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9767a89d-ca7f-4fe0-a751-0840f74df369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68c69aa0-71ee-46b8-88ad-43fcc9e7592c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b47d129-9d8d-4409-95a3-e0e1e2f6f2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0919ddc7-208d-4dda-af4b-8058c3c23246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5683c39d-6cb1-4828-8a4a-8ce0a20efe9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d89956-8cbc-49a1-892e-682722a8bbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e77580b-2764-4907-ae5d-79a9d29fc250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c76e3a24-c95a-4f2d-9290-64c7c1bccb63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc194211-6a21-4aaf-bbf7-062db22ee3fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 999d5544-6a3c-43d8-b30c-da10fe70ab1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f6eae36-5966-4c40-b744-cd8fd260e76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bfc37f4-2a90-44d4-92f5-ceed90ad4784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd8dd57-aa02-4b2b-a4ab-86cea168d336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00596b20-4a05-4fb9-a1bb-e6dd4c0ae05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4a6e6f7-ab56-459d-8d53-c489366a270c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73ff4c10-f8c4-4d1f-bd01-0590c6cb8011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77a6f8a8-a18d-4a6e-8d53-0c4386c415f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a769e5e-d95f-4341-a8a7-b489e0e58b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602470a0-5b6f-4476-97d2-cda22e5a8781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0dbb29a-a1d1-4236-8417-78b9aeecf0f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab77816a-d8f7-4de6-a3ec-305e01f44139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17213013-abcf-4425-8b61-956dcb39dd0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b02db803-292e-4492-90ae-681fe8e09bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee731df4-0818-4dd7-8415-c16167e93437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 974e2fb0-4eb6-4863-9277-defb9f3226d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42808b83-ec1e-41bc-b9cf-e626753e3c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 321c3d0e-6381-448e-b1f4-968ac86d72ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4db0b4-303f-476e-a225-6fbcaf613978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f035d844-333e-47ee-b6b9-44a7af9116e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f992752c-6815-40e1-90f8-bedc9ae26528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61944ca0-bd62-4158-9e91-4b8a79a54d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be3fdfb-9662-464e-90ad-6c7f3f104f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7649de6-bb85-43e4-9e79-06c033af7b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ad3a013-7738-4a3e-b09d-01b24636061d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19608c64-775f-4820-b5ac-313095527713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11dbd9a4-6d43-4592-994d-9fea41302748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 989e80dd-0758-4248-a31d-773d7c90c482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 166afdb9-8028-44e1-b02d-d4d382d32995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c119788-402b-4b61-8dbf-9b27dd719cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f53a6b-b93c-40c4-af60-afa313f1f142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82b27892-9f5c-4985-b008-a9ac30aa0934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f063f32-0cf3-41d1-ba70-4d9fbdf20a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba691bcf-4fc8-4fda-8e6e-ffcaef23d5c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91cc2308-0040-40aa-822f-9f360d520976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca76e57-85cf-4e18-9f89-637d790be172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b96e2e9-81d3-4676-bd02-c52a74a10889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f394e0-4c48-44d1-951b-b639ace881dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 796db254-e4ce-4f4c-874c-4d96d5696989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a1c272e-1caa-49df-b849-4dc20a789890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9baa6bed-abbc-4647-9be6-0210315c607d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d20d7e-bab2-4637-b63a-4c734f980403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5ce7890-7726-4b65-9046-92c8074d7bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4119f6b8-4a66-4374-a79e-2971fd244647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7f80e95-8208-40ce-9e43-2d5449b0a2eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3f66be8-4255-4c8b-ae15-183a21ddedff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 673ae00c-45c8-4a61-8963-df7974190b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c12809b7-a694-46b0-a121-97762faa9deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc45ccba-134d-4248-af01-474480dac9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b94e62f9-19d0-4ba3-b021-a0b5f48d5566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bb23197-9823-4c49-bf71-5534711aa3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c9120ca-7989-4ece-947f-4d3627779420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5559f0bb-0e9b-46ee-aab2-2e3046acee55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2655220a-cd35-40e4-ae1b-22cc83008abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ed64683-2de6-413a-9055-1946c498573b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7a376d-2ebf-4f54-a5da-75367cdba89c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e6c4fb6-af33-4ebf-904d-5fdc787ff427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f58e624-06fd-46f0-9084-c699cf35e78b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d7c6d42-20ab-4892-8dcd-a5f50857482c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5132121-a7c9-46b5-935e-e16331bc6693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5a628e8-b8c9-401d-a53e-576b7ea23ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b2e91ea-52d7-495b-aabc-a60b66ab0609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfb5d190-2c57-4eeb-9926-cfc7369696f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f36cb78-f73b-45cd-bdcc-b0b5be127610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28030976-b0fd-4063-8ce7-7859512e2ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ca6ba4-1aa7-495f-a500-1690e0240a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebcaec8c-efe3-4478-8265-647dad2667b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 029d9be8-2a89-4e06-b924-cf804af45ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f463aec1-fea2-4221-a3cf-eb917e24faca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b29525a7-076c-438d-9f9c-648d0b053655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da9d61e4-5cbe-40d4-af48-236bb6479297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94dc22de-c680-4633-8b82-d791b7494cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abe2e0f6-8068-4696-b252-39a12a3f1097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5090d70d-6d9b-416e-b840-4999324977c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e472f756-7403-4d55-a269-af45a37119a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17371760-60cc-46d3-9881-9c4f4a03bbdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 395eba33-1f8d-41ed-b843-a4c6feb6ab7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c986e1-e315-42fb-b117-57a12895bd60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfc6007-f25c-4dde-ac7e-8a52fca1a6db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee6a0c82-ab5c-4fbb-876f-0f981a3bfad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4252a617-c9c6-41e0-9a4d-9dedc0d308ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb468e0c-7499-42f8-ba62-9858f5937c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 045d0adc-894a-45be-8a35-980386e87c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f832d359-bf6a-404f-b103-d4deb9d40d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7fd2b18-4ab0-4c17-b69a-36447c763595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e2ae8bb-cc77-47be-9e17-ac506aedd817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c741e655-8917-49d7-a4d0-8c8b3f788361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c5057d5-e863-4e70-8e02-8ff8c96705c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 509e531b-750e-49ff-9bc7-69bb48b72e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b89963-1a2a-48c8-b34c-bd604cf201dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32abdeaf-2933-4596-994c-f3f2caf697f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd42a013-07a1-4998-b273-8d7e1e470dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f886c3-2300-429a-9ca5-6fae82206e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d32c10c5-1c54-4e44-b29b-f3bf3d43deb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc90d94f-d81b-4ed2-9e8b-88763ca3b804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 545c3079-b15e-4094-865a-555955a44d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94fa9970-be8a-4482-bb57-595f4958c23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16981a22-ca00-4f64-a2f1-5c9ded32b676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5bfe35e-2d01-444d-8ced-bffea9a5c8e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a1232cc-d552-49c7-b757-37463ddce571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffe0aa4f-3be6-4522-b997-21b1574f0bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 775bbec9-6aa4-40ea-a841-f518e84c1071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76965276-f91c-46f7-a910-6d5d7f0afd21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e6310d3-b32e-49d4-b556-672d9f3680a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 291a8445-0e95-49b9-91a6-573288473f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f5e0401-8cac-4b79-8915-197e391b0af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8fb7012-907a-46ca-9214-63ebad04015f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebd21733-a943-46f4-bea9-b9a005ab9886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94add94-45b6-4e42-912b-e90430527f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7353848b-3605-430c-b9ad-2e5a4c3bae86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffa6e741-0a06-47ab-af21-6c9c73774dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef89532-634d-4cc2-9785-10e22f41f8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e543701-299e-40a1-b4dc-9119108c4ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca64f705-59b6-4d5c-b1bb-e263f0ff216b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0c77649-87de-4fb8-8e93-4d44778716db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2fb3949-4cbd-4baf-aa5e-6b14571a3a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbdf0947-533f-4c82-9852-7b25cd6013e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c097c386-2655-4c33-9485-8c4a1a0555c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7fbe49d-3b05-49eb-9eba-3f0b1f526fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 452b93c2-67a7-4f59-a5c2-fec264147bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c64330-8c97-423c-bcc6-46f976dab964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2edbea0-26da-408a-9e74-bd21da6476ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9deefdb6-22a5-4fb4-a173-6863d9948317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 756d491d-ae85-4287-ba06-4450796e474c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49bc6cb6-f5cd-4910-8b95-508caf478ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a512df7-6c52-4fc0-8e99-d5b4a4c331ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2929f003-f0b8-4d03-8b1d-bd332bfbd770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c89f90-8025-4972-8b47-6a828b129f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e908268c-9650-45c9-86bc-01113e8806b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1ea56c8-6e0f-4eb2-b67a-30426b8fabbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e30e721-bc72-43e8-97c3-f42c7bb296d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c06d552e-0669-4675-babe-3b4a71637743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a54b0b-0df9-4a63-801f-2a450760dc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d2b01ef-b024-4202-8676-eb1de051c9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f11d775f-daa7-4cf3-89ba-dd3bae5b36c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e403e53d-d7bd-4c7b-8640-cb2b74745995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0d4f2f9-dc2d-43a2-8365-cee5f231723c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa97bc25-50a9-421e-a646-8b0283df98b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e687327-108d-4132-a6be-96be71ef9930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4789b047-f5c3-41cd-a3f7-21611aa11372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17a82c22-c9a2-4764-a764-0e8af057df27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8709988-c40f-4518-bbbd-dc9eb1195ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e94b4fb-e85a-4366-98d9-01f6213b0703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e40e28a6-968b-4f68-a902-98dd427a5041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb2c37fd-30c0-4d60-b9a2-52e75a0d68fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a3b13bc-8c47-4829-9daf-fa1767a79972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f78c319-7766-49e0-a5b2-a42e9501dcb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a4dfb7-b559-4303-829e-662fb759031c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 279633bc-8053-43c5-b94a-86d622937ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72c95be-3d56-4819-99ca-49b09843d2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74fb9c9c-8354-4fc4-86c9-9cd6d3668edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d708160e-8267-4de4-ae1c-11a448c88eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ffc8e81-22a7-4e5b-bd7a-5ef11047e5b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321a3b29-610e-4718-9dbe-c29a92672204
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_93
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/test_labels.txt

📊 Raw data loaded:
   Train: X=(815, 24), y=(815,)
   Test:  X=(204, 24), y=(204,)

⚠️  Limiting training data: 815 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  195 samples, 5 features
✅ Client client_93 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1603, RMSE: 0.4004, MAE: 0.3245, R²: -1.0154

📊 Round 0 Test Metrics:
   Loss: 0.1561, RMSE: 0.3951, MAE: 0.3197, R²: -0.9623

📊 Round 0 Test Metrics:
   Loss: 0.1509, RMSE: 0.3884, MAE: 0.3139, R²: -0.8964

📊 Round 0 Test Metrics:
   Loss: 0.1351, RMSE: 0.3676, MAE: 0.2965, R²: -0.6987

============================================================
🔄 Round 15 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0963, val=0.0834 (↓), lr=0.001000
   • Epoch   2/100: train=0.0859, val=0.0834, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0852, val=0.0837, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0850, val=0.0838, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0849, val=0.0840, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0843, val=0.0842, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 15 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0097
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0329
============================================================


============================================================
🔄 Round 16 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1109, val=0.0897 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0858, val=0.0890 (↓), lr=0.000250
   • Epoch   3/100: train=0.0838, val=0.0892, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0839, val=0.0890, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0836, val=0.0892, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0833, val=0.0893, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 16 Summary - Client client_93
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0022
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0027
============================================================


============================================================
🔄 Round 17 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1288, val=0.1006 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1087, val=0.0878 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0927, val=0.0832 (↓), lr=0.000063
   • Epoch   4/100: train=0.0856, val=0.0850, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0844, val=0.0863, patience=2/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0843, val=0.0860, patience=8/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 17 Summary - Client client_93
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0351
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0029
============================================================


============================================================
🔄 Round 18 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1162, val=0.1068 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1119, val=0.1022 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1075, val=0.0980 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1035, val=0.0944 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1000, val=0.0911 (↓), lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0900, val=0.0827 (↓), lr=0.000008
   • Epoch  21/100: train=0.0863, val=0.0795, patience=1/15, lr=0.000008
   • Epoch  31/100: train=0.0858, val=0.0792, patience=11/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 18 Summary - Client client_93
   Epochs: 35/100 (early stopped)
   LR: 0.000016 → 0.000008 (1 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0079
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0043
============================================================


============================================================
🔄 Round 19 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1023, val=0.1053 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   ✓ Epoch   2/100: train=0.1006, val=0.1032 (↓), lr=0.000004
   ✓ Epoch   3/100: train=0.0991, val=0.1022 (↓), lr=0.000004
   ✓ Epoch   4/100: train=0.0982, val=0.1012 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.0974, val=0.1003 (↓), lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0933, val=0.0959, patience=1/15, lr=0.000002
   📉 Epoch 18: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0909, val=0.0932, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0898, val=0.0919, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0888, val=0.0907, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0880, val=0.0897, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0872, val=0.0888, patience=5/15, lr=0.000001
   • Epoch  71/100: train=0.0866, val=0.0880, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0861, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0857, val=0.0867, patience=5/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_93
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0138
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0217
============================================================


============================================================
🔄 Round 20 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0937, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0936, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0934, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0932, val=0.0925, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0931, val=0.0924 (↓), lr=0.000001
   • Epoch  11/100: train=0.0922, val=0.0916, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0908, val=0.0905, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0897, val=0.0896 (↓), lr=0.000001
   • Epoch  41/100: train=0.0887, val=0.0888, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0878, val=0.0882, patience=5/15, lr=0.000001
   • Epoch  61/100: train=0.0871, val=0.0877, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.0865, val=0.0872, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0860, val=0.0869, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0856, val=0.0866, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 20 Summary - Client client_93
   Epochs: 95/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0249
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0032
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2469, R²: -0.0494

📊 Round 20 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2469, R²: -0.0253

📊 Round 20 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2470, R²: -0.0203

📊 Round 20 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2471, R²: -0.0188

📊 Round 20 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2471, R²: -0.0178

📊 Round 20 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2471, R²: -0.0176

============================================================
🔄 Round 30 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 30 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0038
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0148
============================================================


============================================================
🔄 Round 31 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 31 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0079
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0003
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2471, R²: -0.0158

📊 Round 31 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2471, R²: -0.0156

============================================================
🔄 Round 33 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 33 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0002
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0329
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2471, R²: -0.0155

📊 Round 33 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2472, R²: -0.0147

============================================================
🔄 Round 38 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 38 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0038
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0052
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2472, R²: -0.0144

============================================================
🔄 Round 40 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 40 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0048
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0001
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2472, R²: -0.0140

============================================================
🔄 Round 42 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 42 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0007
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0128
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2472, R²: -0.0139

📊 Round 42 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2472, R²: -0.0137

============================================================
🔄 Round 45 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 45 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0031
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0029
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2472, R²: -0.0137

============================================================
🔄 Round 46 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 46 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0045
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0028
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2472, R²: -0.0136

============================================================
🔄 Round 47 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 47 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0004
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0306
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2472, R²: -0.0134

📊 Round 47 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2472, R²: -0.0133

============================================================
🔄 Round 50 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 50 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0015
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0335
============================================================


============================================================
🔄 Round 51 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 51 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0021
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0084
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2472, R²: -0.0132

============================================================
🔄 Round 52 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 52 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0030
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0022
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2472, R²: -0.0132

📊 Round 52 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2472, R²: -0.0132

📊 Round 52 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2472, R²: -0.0132

============================================================
🔄 Round 57 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 57 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0042
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0028
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2472, R²: -0.0132

📊 Round 57 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2472, R²: -0.0130

============================================================
🔄 Round 60 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 60 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0006
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0402
============================================================


============================================================
🔄 Round 62 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 62 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0014
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0064
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2472, R²: -0.0126

📊 Round 62 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2472, R²: -0.0127

📊 Round 62 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2472, R²: -0.0125

============================================================
🔄 Round 71 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 71 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0031
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0026
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2472, R²: -0.0124

📊 Round 71 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2472, R²: -0.0121

📊 Round 71 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2472, R²: -0.0120

============================================================
🔄 Round 79 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 79 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0059
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0105
============================================================


============================================================
🔄 Round 80 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 80 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0092
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0002
============================================================


============================================================
🔄 Round 81 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 81 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0010
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0043
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2472, R²: -0.0119

============================================================
🔄 Round 83 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 83 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0055
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0062
============================================================


============================================================
🔄 Round 84 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 84 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0008
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0078
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2472, R²: -0.0119

============================================================
🔄 Round 85 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 85 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0019
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0002
============================================================


============================================================
🔄 Round 86 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 86 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0036
   Val:   Loss=0.0676, RMSE=0.2600, R²=0.0070
============================================================


============================================================
🔄 Round 87 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 87 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0019
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0053
============================================================


============================================================
🔄 Round 88 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 88 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0006
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0091
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2472, R²: -0.0118

============================================================
🔄 Round 89 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 89 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0004
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0179
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2472, R²: -0.0117

📊 Round 89 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2472, R²: -0.0116

📊 Round 89 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2473, R²: -0.0116

============================================================
🔄 Round 94 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 94 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0039
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0052
============================================================


============================================================
🔄 Round 98 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 98 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0028
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0046
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2473, R²: -0.0115

============================================================
🔄 Round 99 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 99 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0040
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0088
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2473, R²: -0.0114

📊 Round 99 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2473, R²: -0.0112

📊 Round 99 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2473, R²: -0.0112

============================================================
🔄 Round 105 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 105 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0056
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0017
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2473, R²: -0.0112

📊 Round 105 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0112

📊 Round 105 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0110

============================================================
🔄 Round 110 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 110 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0020
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0165
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0110

============================================================
🔄 Round 115 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 115 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0002
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0106
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0110

============================================================
🔄 Round 117 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 117 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0008
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0022
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0110

============================================================
🔄 Round 119 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 119 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0003
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0030
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0109

============================================================
🔄 Round 121 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 121 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0085
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0187
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0108

📊 Round 121 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0109

============================================================
🔄 Round 125 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 125 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0029
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0047
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0107

📊 Round 125 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0107

============================================================
🔄 Round 132 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 132 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0008
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0063
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0107

============================================================
🔄 Round 133 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 133 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0020
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0020
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0106

📊 Round 133 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2473, R²: -0.0106

============================================================
🔄 Round 136 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 136 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0015
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0030
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0105

============================================================
🔄 Round 139 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 139 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0018
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0282
============================================================


============================================================
🔄 Round 140 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 140 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0040
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0039
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0105

============================================================
🔄 Round 144 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 144 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0025
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0004
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0105

============================================================
🔄 Round 145 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 145 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0003
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0082
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0106

📊 Round 145 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0105

============================================================
🔄 Round 151 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 151 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0043
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0015
============================================================


============================================================
🔄 Round 153 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 153 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0007
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0034
============================================================


============================================================
🔄 Round 154 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 154 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0002
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0039
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0105

============================================================
🔄 Round 156 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 156 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0027
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0027
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0104

============================================================
🔄 Round 158 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 158 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0022
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0027
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0104

============================================================
🔄 Round 161 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 161 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0019
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0041
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0104

📊 Round 161 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0104

📊 Round 161 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0103

============================================================
🔄 Round 164 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 164 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0045
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0299
============================================================


============================================================
🔄 Round 165 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 165 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0018
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0014
============================================================


============================================================
🔄 Round 166 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 166 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0016
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0181
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0102

============================================================
🔄 Round 167 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 167 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0018
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0001
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0102

📊 Round 167 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0101

============================================================
🔄 Round 169 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 169 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0012
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0082
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0101

============================================================
🔄 Round 171 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 171 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0017
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0039
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0101

📊 Round 171 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0100

============================================================
🔄 Round 174 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 174 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0010
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0081
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0100

📊 Round 174 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0101

============================================================
🔄 Round 177 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 177 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0008
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0012
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0100

============================================================
🔄 Round 178 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 178 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0026
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0023
============================================================


============================================================
🔄 Round 182 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 182 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0013
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0036
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0099

============================================================
🔄 Round 183 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 183 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0009
   Val:   Loss=0.0900, RMSE=0.3001, R²=0.0008
============================================================


============================================================
🔄 Round 184 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 184 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0001
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0051
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0100

============================================================
🔄 Round 186 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 186 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0010
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0057
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0100

📊 Round 186 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0100

============================================================
🔄 Round 188 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 188 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0005
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0053
============================================================


============================================================
🔄 Round 189 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 189 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0025
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0046
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0100

📊 Round 189 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2473, R²: -0.0099

============================================================
🔄 Round 193 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 193 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0016
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0096
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2473, R²: -0.0098

📊 Round 193 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2473, R²: -0.0099

============================================================
🔄 Round 197 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 197 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0006
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0018
============================================================


============================================================
🔄 Round 198 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 198 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0003
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0011
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2473, R²: -0.0099

============================================================
🔄 Round 199 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 199 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0027
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0011
============================================================


============================================================
🔄 Round 201 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 201 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0008
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0060
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2473, R²: -0.0098

📊 Round 201 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2473, R²: -0.0098

📊 Round 201 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2473, R²: -0.0098

📊 Round 201 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2473, R²: -0.0098

============================================================
🔄 Round 206 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 206 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0001
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0583
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2473, R²: -0.0098

============================================================
🔄 Round 207 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 207 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0006
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0000
============================================================


============================================================
🔄 Round 211 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 211 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0003
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0060
============================================================


❌ Client client_93 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
