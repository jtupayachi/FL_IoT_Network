[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9309bf90-3820-488c-808c-6144b10a345f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 378accf6-37e8-4169-9fcc-8cbfe3c8fb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 778b0694-dcac-4e90-916a-8fc876b0741d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13c0347-e365-493b-86c1-d7188e44b0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0b9259-4b72-491b-ae05-5079e584f8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f207873-8b8d-49f1-96a0-b636067fd84e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11296c44-f9ef-4488-ad20-5a124bc5f000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff4db8ef-8bcb-4f2a-a22f-e0bc3bc6bdb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ac286a9-f63c-415f-ad75-141d16be7b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47437ad2-b703-4827-a7be-23f27d5d80fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9b10ae-9ae3-48db-aeec-d2d3eba53cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f611420-1c3f-4fbc-bca0-59977692d3a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd0f6ba6-e545-4f69-8d38-3dc625315931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa86e0d-707e-4371-aea6-d25f54db6722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc2a5fcb-1cc0-4f38-b073-508bfdd5098f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a00c01-b729-4316-b849-9f8969b7d381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81fb9661-3167-4641-ac55-9e110501f201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 277ab17d-7e13-41d2-a6c5-b8606b619286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7647ffcf-cac3-4617-8627-6cda0b87bd44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b8e6915-e705-45f9-96ca-5a1dcb425fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56e0c65e-cd38-4d99-b5c4-02f6d162ad54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1681431-2564-4ffd-ba3d-2ae4a68a421f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 400bb341-e609-47f4-8750-d74f63bfa6bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56376cdb-c44d-42be-bb19-546d580de970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26afc9ed-0f8b-43e5-908a-33e8fe8a2991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60efde3a-94bc-4126-9699-6b09d28b16b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 561aa807-f042-414b-9daf-063699b2cc0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 273d4d8e-0808-40c2-8b8e-68f1a3b5086e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ff7272d-e907-41ed-875b-4caa1c57eff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7e79542-9f96-4852-bd22-b8ba245f51c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99d53111-d314-423b-89ee-f6a4fe2d323a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc65a550-66df-4b95-b5e0-953946f6b92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b6eacf0-3873-482e-8993-fb03b1d562d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c1aff5-909d-4b1a-93a9-e169cac8e388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c112106-e780-4ba3-8217-eed48052fd5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94856df7-a82b-4ab7-ab49-dff738224fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f914b9e-ee7e-465d-bfc3-11f7268993be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6952ab09-ab59-4c24-a7d7-ba49a25ec597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 667a5382-e902-4c6d-98bd-69db4e263389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cac1ed3-1bdc-43f7-810f-edf8bbed22e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d96e8dc-3d69-4d62-9e79-4fb03ac7a739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5222b667-f16a-4881-803f-307dcc269c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b272e42b-37f6-450a-abd7-7badca56690a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6561821a-6ea1-4b0b-90e0-a3db75567bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37725cc6-56ff-49fe-a9f2-8e7f5f3caa76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c2a8e03-3961-4298-a064-b3f30f2e4054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8616b6c9-b342-4e77-85a0-89eee3a1d96d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42e8fa7e-0bf3-49a8-abc5-2b39339ab29d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0ae5a60-ce2a-4d06-ba5d-7f10e6e883a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12e1f473-36ec-4b1e-ae17-1128f788ebe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42516302-25d8-4c16-8505-f711948dbb65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e391bda-c3ab-4d5d-81db-1d861bb10194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fa1815a-7bac-4f5a-934f-42c8b0ee709b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3929cf68-e6ae-404c-9ccb-a3a4594228f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e40b9afe-743e-4339-bedd-4573bf7d894a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f78c517-d891-4c2b-af1e-e6a6f67bb966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 855f8479-fb02-4a5d-86d8-c352e5a7ef8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f65cf150-538a-458b-a72d-a100fca5aba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15eb9622-4a48-4b84-8046-ed96e2f42aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a6c5f20-61ef-4af8-a36a-3b1dd9eb7580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf9f8b73-8da9-4ff9-9060-a3ef49c838c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed35766a-60cf-42fd-b24d-775ed2a91a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b00c333-1c2b-4fea-a17d-07b5198d7d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a31f4ffc-58a4-4dee-bd57-1f83d2e25756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01dba3e9-5cbe-4caf-9141-345587aea09d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81bcaeae-a2fe-467c-927e-8aaf984ba3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7b8d17f-f60b-4fe2-bf98-295f9128c206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4af373be-9457-45ac-bf62-949d6ad64741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a770d18b-e1dc-4b25-9460-5e3d993434d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a69010f-46ca-4b6f-9498-fe877247bb61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32ebc4c1-6c11-4d89-a08d-c899941a0dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e6cd9a-598d-4302-8c58-caa922fa7047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3270d282-20e7-4217-9a23-bfb3c7e35c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83a9c582-a6a4-4a6f-9fc6-21dfce47ead6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e409d299-e227-42e7-b349-195fbe2c7d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b07ea6a9-fa36-42af-950a-4426088cd21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d2c7f64-64fd-4eab-ad00-fa7a4dabd257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cb5bd90-c502-4347-9fdc-f954ececf2cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dcc2e9f-efc6-4599-bd73-c26768595105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba004953-d157-471c-8f21-db5f349c67c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1360d847-3b4a-462b-b633-1c158b1020bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message add55e4f-490a-42dd-b716-8407f812f3f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ede39b-8131-484a-9b25-1ab7cb2ca714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6f74204-372a-4ecc-9fd3-9b8e90f078fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77a7208f-6d24-47d4-894d-4d61d67c6c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e44c0012-5b64-471d-b238-dde106a64fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a07dd969-b545-43ae-985a-5cbcfd5c1986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a07ca24f-89ef-46ca-be08-d557d8eab40e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 304de3a7-798c-4db3-aec8-710b962d4b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b836f7e-2df6-47d5-80a1-6b94189212e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c32b9c5f-820b-4463-8777-d61dcac10e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de2597b4-4d17-4004-a15e-47f68a8aa6b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bf550ed-c5f7-4a04-8db6-e699f87746b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e2e32f8-b96e-4267-8a02-00a32d9a56e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7035d31-901f-41fe-ab42-c4ba0fd37333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63fe2777-3527-4a1b-9ebe-df551792176f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c17d0454-cdb3-41fa-90de-e7040f6eac0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7905034e-afb5-46ca-933c-ccd3585799d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 829341a0-9d11-4c0e-a421-69ed3ff80a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ec7748e-5eb1-42b6-8d99-42b657079783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e51c1deb-191f-4507-8580-6c5a6d45802b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05c254a9-badf-4482-a429-13f073d8a4ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9fbf713-4790-4724-976e-4ae2fdbea430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17585c05-ca83-41e1-b6e7-4f51133677c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 647f8d4a-f7a1-4903-b5f8-8837cb394fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19e83b0d-cd3d-4a63-af38-26721c0d3d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec57baf8-9c6c-4dce-9ff5-c7b7cc1f811c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeff16b0-6198-4bf8-b3db-37def9f8af32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1968ca96-5d4b-4274-a4cd-d718fa0e858a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe580f5b-2382-4a5c-8456-c9d106b02023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbda5904-375d-4d7c-9773-a0fb145a8438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63b0df06-e948-4323-ba5c-328375a1c3d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee9f1bd7-c846-49dd-a728-22278735bb15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 796f101d-14b8-4c95-9ebb-3946bbde6f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9abe0dd-ff33-41dd-99de-b5271640abc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c50ea47-8787-431c-ae4b-76597dedf45e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f553e2e-0640-4623-abf0-9ccfe237823e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8200cc2-5235-4eec-bcb4-324e86bdcf21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 781ddae6-e8f1-4048-b87b-252ec2b52632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62338dd8-36ee-4b6f-a156-160f655eeca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6cef861-4737-4726-af08-df9406bb0b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c99706-6778-4a5a-8a72-ad0ac66c6af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 350dd3d5-5fd5-4a0a-9c04-eb6fc597198c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b874dc8e-eb16-4c99-8b40-bac981050882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d3ad9f3-202f-479e-a385-680de58efd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d3c8dd3-6a2e-4304-9d87-569df6839ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbe4a514-e8b9-4ff6-bfff-a1fcffdc594d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c1dba6-2917-4485-bd20-a7636d72935d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf6db91-25d7-452d-ba30-7d6c09cd4c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6f06a17-87f2-4051-8859-c8b928ebaddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecafd2b2-8b2f-417a-a77b-968e9c780940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e379a9d8-3593-4579-8224-faf6148df16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0654c2d-3368-4200-849c-6f56a314a984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e645eb-c6dc-4eae-8575-7ce9cdfc28fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed233033-9d6b-408a-8900-59b13437ce4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70dbfd11-ca71-4fdc-ad77-19d5dca2dce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c394e7-67b6-4c1c-846f-f62985d34f46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f445391-22ef-4849-ac6f-b73e9ee11f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc69174d-258f-4a8b-9882-14aa2fdf1dbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b35d60d-eedc-4738-ad8a-478eae3bd337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb4af06-916f-4619-b202-30199ce758c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef239ae6-7a7e-4327-9575-fe986e20f5bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e4c8202-c159-4848-8742-34a361a7ccea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8fb0001-1eb3-4d47-a4d0-4c4dbe22d4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5583cc0-d5b3-4ef7-88cc-56f8ae8e41f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d2a807-2925-4e26-a51d-fd571c311c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f515da8-a104-41a8-a948-870312663730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0475db0-0d2a-41f9-a48f-d4e952867150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17d8f5b0-b2df-46c6-bf45-990f3af2491a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d228f21e-267c-4a61-bb85-6c9087883920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cde88a1-2e8b-498f-b6af-3ff66115f009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 570189df-9985-4fc7-b9e2-7d93e0a3a3d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a15c59b8-1606-4559-9763-8050542fe0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eba9ce54-15a9-435e-9dca-19946a0f894a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11117df2-0824-4bc2-aa8d-3e5fcd4145ed
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_94
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/test_labels.txt

📊 Raw data loaded:
   Train: X=(860, 24), y=(860,)
   Test:  X=(215, 24), y=(215,)

⚠️  Limiting training data: 860 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  206 samples, 5 features
✅ Client client_94 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1525, RMSE: 0.3905, MAE: 0.3127, R²: -0.9413

📊 Round 0 Test Metrics:
   Loss: 0.1431, RMSE: 0.3783, MAE: 0.3019, R²: -0.8217

============================================================
🔄 Round 15 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0946, val=0.0879 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0845, val=0.0872 (↓), lr=0.001000
   • Epoch   3/100: train=0.0843, val=0.0879, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0842, val=0.0883, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0840, val=0.0887, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0822, val=0.0909, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 15 Summary - Client client_94
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0077
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0160
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1192, RMSE: 0.3453, MAE: 0.2751, R²: -0.5174

============================================================
🔄 Round 18 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1012, val=0.0835 (↓), lr=0.000250
   • Epoch   2/100: train=0.0863, val=0.0836, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0854, val=0.0835, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0852, val=0.0836, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0851, val=0.0836, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0848, val=0.0836, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 18 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0035
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0041
============================================================


============================================================
🔄 Round 20 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0912 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0853, val=0.0888 (↓), lr=0.000063
   • Epoch   3/100: train=0.0842, val=0.0888, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0841, val=0.0887, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0841, val=0.0887, patience=3/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0839, val=0.0887, patience=9/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 20 Summary - Client client_94
   Epochs: 17/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0013
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0017
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2391, R²: -0.0236

============================================================
🔄 Round 21 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0849 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0869, val=0.0843 (↓), lr=0.000016
   • Epoch   3/100: train=0.0862, val=0.0840, patience=1/15, lr=0.000016
   • Epoch   4/100: train=0.0858, val=0.0839, patience=2/15, lr=0.000016
   • Epoch   5/100: train=0.0856, val=0.0839, patience=3/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0853, val=0.0839, patience=9/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 21 Summary - Client client_94
   Epochs: 17/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0138
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0063
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2389, R²: -0.0128

============================================================
🔄 Round 23 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0831 (↓), lr=0.000004
   • Epoch   2/100: train=0.0865, val=0.0832, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0863, val=0.0833, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0861, val=0.0835, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0859, val=0.0836, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0854, val=0.0841, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 23 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0210
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0036
============================================================


============================================================
🔄 Round 24 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 24 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0140
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0005
============================================================


============================================================
🔄 Round 25 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 25 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0072
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0098
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2392, R²: -0.0052

============================================================
🔄 Round 26 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 26 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0058
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0076
============================================================


============================================================
🔄 Round 34 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 34 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0085
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0063
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2394, R²: -0.0040

📊 Round 34 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2394, R²: -0.0039

📊 Round 34 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2395, R²: -0.0038

============================================================
🔄 Round 38 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 38 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0035
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0022
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2395, R²: -0.0037

📊 Round 38 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2395, R²: -0.0037

============================================================
🔄 Round 42 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 42 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0008
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0360
============================================================


============================================================
🔄 Round 43 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 43 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0050
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0035
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2396, R²: -0.0037

============================================================
🔄 Round 44 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 44 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0033
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0005
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 46 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 46 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0040
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0006
============================================================


============================================================
🔄 Round 48 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 48 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0004
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0204
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 50 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 50 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0020
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0039
============================================================


============================================================
🔄 Round 51 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 51 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0039
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0020
============================================================


============================================================
🔄 Round 52 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 52 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0025
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0008
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 53 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 53 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0027
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0195
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 55 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 55 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0002
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0122
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 56 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 56 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0037
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0021
============================================================


============================================================
🔄 Round 58 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 58 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0025
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0017
============================================================


============================================================
🔄 Round 62 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 62 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0006
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0084
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2397, R²: -0.0035

📊 Round 62 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 65 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 65 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0025
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0007
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2397, R²: -0.0035

📊 Round 65 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2397, R²: -0.0035

📊 Round 65 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2397, R²: -0.0035

📊 Round 65 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 75 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 75 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0009
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0065
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2397, R²: -0.0035

📊 Round 75 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0035

============================================================
🔄 Round 78 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 78 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0018
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0232
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0035

============================================================
🔄 Round 83 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 83 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0018
   Val:   Loss=0.0854, RMSE=0.2921, R²=-0.0018
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0035

============================================================
🔄 Round 84 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 84 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0011
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0029
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0034

============================================================
🔄 Round 88 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 88 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0009
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0062
============================================================


============================================================
🔄 Round 89 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 89 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0016
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0400
============================================================


============================================================
🔄 Round 93 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 93 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0010
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0204
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0035

📊 Round 93 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0034

============================================================
🔄 Round 99 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 99 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0035
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0007
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0034

📊 Round 99 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0034

============================================================
🔄 Round 103 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 103 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0021
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0010
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0034

============================================================
🔄 Round 108 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 108 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0016
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0005
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

============================================================
🔄 Round 109 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 109 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0033
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0030
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

📊 Round 109 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0035

📊 Round 109 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0034

============================================================
🔄 Round 114 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 114 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0011
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0001
============================================================


============================================================
🔄 Round 115 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 115 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0015
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0014
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0034

📊 Round 115 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0034

📊 Round 115 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0034

============================================================
🔄 Round 121 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 121 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0038
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0033
============================================================


============================================================
🔄 Round 122 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 122 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0016
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0018
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0034

📊 Round 122 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

============================================================
🔄 Round 125 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 125 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0006
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0039
============================================================


============================================================
🔄 Round 126 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 126 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0012
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0043
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

============================================================
🔄 Round 127 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 127 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0002
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0092
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

📊 Round 127 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

============================================================
🔄 Round 131 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 131 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0012
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0010
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

📊 Round 131 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

📊 Round 131 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

============================================================
🔄 Round 141 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 141 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0042
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0207
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

📊 Round 141 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

============================================================
🔄 Round 143 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 143 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0008
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0019
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

📊 Round 143 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0034

============================================================
🔄 Round 146 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 146 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0007
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0039
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0033

============================================================
🔄 Round 149 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 149 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0003
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0030
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0033

============================================================
🔄 Round 150 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 150 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0007
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0073
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0033

📊 Round 150 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0033

📊 Round 150 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0033

📊 Round 150 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0033

============================================================
🔄 Round 154 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 154 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0002
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0050
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0033

📊 Round 154 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0033

📊 Round 154 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0033

📊 Round 154 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0033

============================================================
🔄 Round 163 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 163 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0005
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0100
============================================================


============================================================
🔄 Round 164 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 164 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0003
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0037
============================================================


============================================================
🔄 Round 165 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 165 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0029
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0002
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

============================================================
🔄 Round 166 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 166 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0022
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0004
============================================================


============================================================
🔄 Round 168 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 168 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0013
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0021
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

============================================================
🔄 Round 169 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 169 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0018
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0035
============================================================


============================================================
🔄 Round 170 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 170 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0015
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0096
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

📊 Round 170 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

============================================================
🔄 Round 172 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 172 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0024
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0106
============================================================


============================================================
🔄 Round 173 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 173 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0014
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0028
============================================================


============================================================
🔄 Round 175 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 175 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0007
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0125
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

============================================================
🔄 Round 182 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 182 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0007
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0210
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0034

📊 Round 182 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

============================================================
🔄 Round 185 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 185 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0006
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0212
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

============================================================
🔄 Round 188 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 188 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0019
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0007
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

============================================================
🔄 Round 190 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 190 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0046
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0295
============================================================


============================================================
🔄 Round 191 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 191 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0016
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0032
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

============================================================
🔄 Round 192 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 192 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0005
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0034
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

📊 Round 192 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

============================================================
🔄 Round 194 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 194 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0057
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0411
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

📊 Round 194 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2398, R²: -0.0033

📊 Round 194 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

============================================================
🔄 Round 201 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 201 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0014
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0001
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

============================================================
🔄 Round 203 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 203 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0029
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0041
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

📊 Round 203 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

============================================================
🔄 Round 205 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 205 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0010
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0121
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

============================================================
🔄 Round 207 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 207 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0006
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0122
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

📊 Round 207 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

📊 Round 207 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2399, R²: -0.0033

============================================================
🔄 Round 211 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 211 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0008
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0025
============================================================


❌ Client client_94 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
