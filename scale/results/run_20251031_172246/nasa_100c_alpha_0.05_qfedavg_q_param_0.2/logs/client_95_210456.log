[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f406277d-5e01-4e8a-9138-10a3540f0dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0be42107-0ad4-45d6-8261-0266e479cb56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3027d175-1d1f-4670-a380-2c9f144da888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87d5ae8-8d4a-4909-a9c4-233855138e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 889c92b5-dade-43e3-8dcb-303abfc09b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27e1ef4a-3fa7-4702-992b-611b4dba1dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ceb0d3-fa1b-4b45-baec-afbc9d650626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e986411-9811-4c52-9553-84db4dd1221e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f88b563-688d-4077-9f38-584a4d05ca93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d497de86-1673-44ea-8c63-d25955566834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18bd510-be4f-4713-9c2f-b48df23db77e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a1104e6-59a4-4c76-b02b-eaf4c2ffb919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 521c52c6-17e3-430f-9f34-c4c0f6d2da37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 637f775b-2f1a-435b-a069-1d9fdbfc8fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8469062-b819-42e4-9b87-e299e11ef068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34b3c95a-5e96-4d03-9e7b-90c7c0e3dfd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f51769-2a7e-439b-aead-32600479b7b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d59862f1-cfa9-4230-a036-7c80720659e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3752382-cc4c-43dc-8b3e-b3e0441e743f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f411793a-22d6-45f1-a3cf-88eb4f3accf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33267775-2b91-4822-8254-83748e4d1082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 958776ee-1a14-4bbb-b02e-d71c93246ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34046010-8585-4e4f-bebb-2bd81f529879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e84d91b-1c10-4a41-a61e-546f632237fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ba582f-74de-4baf-a633-4450b5ec2978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8702706a-95ad-495b-a538-7ae00f731eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d16235b7-2472-481d-8d24-fde56618c748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcab833c-0945-4f5e-bb76-ec1ed44b8696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b5ae96b-ded8-412f-b4f3-8ede2feba69f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da9a7fc4-85e2-40b3-b628-29ad3f2a0bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eface9f9-707f-4803-9e6e-b2bd0b4475e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3b440c9-dbad-4b2d-967c-36087a4035cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35d5dec2-09ff-4232-a829-22987e5f89bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c057bb7-3af7-4119-bf1a-d73a06053d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95afb3ee-0504-45f4-add3-b7c82ef3fc30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5163e9c-211d-4850-9095-fb0ec44036de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5cf0c19-5c6e-467f-a514-06a77df57923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c64c10f-ad99-440a-bca9-b95abce48a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be0752ef-794c-4e3e-98a1-9a1a990caa2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee43b6ef-b5fb-49cc-8e19-8ddb79fc7016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44f672d4-de17-416b-a6c2-7dc4fa46abfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36dfe1cb-bfe7-49f9-9e13-57457fcd0ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf188951-18ca-431d-855d-ae5df839a0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df4a5e05-8a94-49de-ba8d-b7da9237284c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa7a8c40-6118-4cc0-bfea-b97bf5c2fc01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cfb88c1-0703-4c66-acdc-c54dd4735980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81ae541b-1974-43a3-b925-096dbb091c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16f19c12-0c6a-40e5-825a-e6f128d7fd33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dc0fe75-c708-4b0f-a1d1-80b29b1f803f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64842515-0f50-4d43-9278-5d4dcff525c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7098475a-1714-415a-bc98-d1186e5b62c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15495259-4dda-4952-93a0-618eca5803fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eec11fc9-ce24-4210-bc80-16d132454ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f963125e-61c8-4183-8e06-8aae98905174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32096e92-fb60-446c-b631-b3d05daa3762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be9add3-4bf6-43bc-a0d1-e41dcbba647f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a1f0544-8d95-45cc-b012-d1c0b4c9158a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fbdc6e4-f8c9-4e65-be32-8bafe6e5310b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0332f676-b038-4c6a-a0d5-ee49e88870ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dc5b906-be93-4331-b08c-86c92734a3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b9ca1d-e45e-4bcb-a46d-6c550c567523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b9940da-73b9-421d-b46d-743c49765d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 922cc5a2-5cdf-466d-bee3-d751960c2d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d861b91-61fe-4afc-8c59-1c631eec067b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bfb6347-419d-4f90-8d9b-a4c3dc35584c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 731f5bb6-ebee-471a-a42a-cb853a079925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cc0f091-b025-4772-90b0-9a8efbcd2bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569f1207-9f33-45aa-badd-20a42adeac5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c9f9d51-fe58-4602-be3e-b6db8e7aa5de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa35f6c-9557-4b3c-9104-f326b4729793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec98e49c-b9d4-4570-9bc3-193440a2700d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 046f6e63-bc7e-4485-a41a-dd9d2cceca41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bdc6fb3-235d-4fee-a174-477e58319bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d642d61c-d3ba-4cdb-b7bc-7f4495db7691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd73f1fc-d525-4c25-9588-8557f81a53f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7d949b6-5257-4d36-8b40-d4a09133a5ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e3f002-f6b7-4839-af1d-e625643f141c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80080df8-06a6-4904-aa40-23b63245db17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d8c905-659b-4239-989a-38aa307b697a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80b288b1-e56a-45f6-aeab-bd3c5994b5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9d53b2d-a189-4753-9e14-27734c3474b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e027f2af-b4b3-4aa9-90ce-8a8fbfcaab2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fce1b67-7830-419d-9a74-159ebda98f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a9d6d80-f0e6-498c-9f06-21b7c83f51ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d954b15-4ab1-4393-8a5d-78fb49658a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df4e686d-68bb-4248-b731-be11b694b07e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ef7031-a3c2-4423-9f51-c3233baf4be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b9593b8-db8c-4a2c-a20d-ce3d2888c780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23fae55e-88ca-450d-9a34-80b802cbbcf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5374fc59-dbc5-4b17-a38e-9ca642b8f13e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2554e62e-80c9-4cf1-bdb9-68962a9d8383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d557020-5a12-40b7-b63d-aacb9ce4c2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fe7e2ff-2838-4fac-becc-7f6563e8521b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d982dadd-eb9a-42fe-a191-d029d1de7061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7110c821-6dd4-4994-ae6f-cd406ef401bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef6161d-142f-4bf6-8eca-a17e59f7466e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ce53b8c-f84b-4d9e-a70a-9e76ff0d695e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4708258f-7ead-4054-9649-798e2f8e4d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68fb865c-423e-4643-870f-e787b0a506ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd5620f-4bd5-48d6-965c-9e601b0a251e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf0914e0-38fa-45af-80f7-0c19998fcaf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e00bc6b-03d3-4a6a-aaf8-a46ceb58c88e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bfcdb10-95dd-4d44-b8ca-3033a14c469d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 995f7515-b6b9-430d-acb3-acc32d934faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d67f3bcf-187b-488a-bce5-dd37e677ecb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a611f26d-e6ce-4f99-ac74-95335dee1b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f91d9d7e-02f1-4df7-936b-086a6777f819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 452bfcb5-977c-46c5-926c-58e7faa9caf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74799c04-a37e-4117-b065-915d247a4878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf43695b-bf7d-45c5-8755-22406fb56162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a97b52-3e7f-418b-b883-2e07ec97fa52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bbc2bd8-0d1a-4fe1-8bfe-280bcdb0b8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81760bb0-f913-4433-98e4-0b50a3f46f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1e6ebc8-fd32-47a9-a006-1722fbddfb2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cece2352-ba27-4d34-aae3-64669198a680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5917589-60d1-4dd4-b38c-03faf760fafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0d6bfb9-7bd8-4627-9e47-0f4e9e0e4335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 853cbdda-0107-4007-ba1d-8f19878fd9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af9518ad-d8c8-49b6-8230-3e250cce0f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74112469-b2ca-4762-bd38-608b28de3376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3825ef7d-aa64-45b6-9448-3d5f5639467a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f4556c6-42d6-4bd2-9031-c8efd9bc0104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 582a4d5d-3817-487a-835e-7d0cde0748a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 355b255a-f663-4142-a1bb-9a5cc80491df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 705f037f-7753-4b50-b2de-9b87a2b8de4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08d9474d-d64c-411f-9745-43c50710d728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02b47529-86c8-4f79-aea5-c67137ca7d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1182974-9fd6-49c7-8046-0345c7b8dd94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95ca7baa-bbe5-4ef6-96fb-d5fa9f2e1ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e760779f-e592-4e03-bb96-ddb01ca4c66d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7089066-35e4-46c3-900d-6ea745d0d23d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69b00fe8-614a-4e3c-98f1-29f9211a18c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3904f500-f26d-4394-87dc-eea8be5d2dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b88c59-f3ed-4a8e-a3b8-cb559ff0b2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eb50b23-5b5a-423d-8bb6-e9f9cf8c1d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8aa290e-e171-4029-937d-bdabe30d0f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9437a54-fae7-4871-bff8-f0e93227c292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f72e9d6-4db2-47cd-9c17-acb8e14b5845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ea3f207-5aa8-43ed-babb-fab82bb54c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd9ad0f6-cb54-4fc0-a474-390cb2478e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abc21950-493b-4283-8142-682f55c169cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 874dfdef-595b-424e-9fef-e69868582d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04d1472e-58aa-42ee-a80b-4c43b500c4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58e726ac-9bd9-416d-9e1a-c472da41dbf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e9f24f3-ac31-4e9e-a44e-a62d6f70289e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be966b8-2139-4704-872b-eb39291b2cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2145c0fa-48e1-4e7f-972c-1e18245f7859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb549b8b-239c-4246-a38e-ab2102218917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd6c225b-4a70-4f80-a569-23ef4af9da93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74b34fcf-2886-4cab-9289-bf6037bc0296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec09fc09-1bb2-467c-ac73-4edbfa2e2bdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f30d6649-ddc1-4734-9809-1801b2fbd488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07490606-16d4-4a56-b901-f6271ab33b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9250a913-f956-4247-abf4-3d8e86343e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd4015f0-ef3b-4ae7-ac90-909631e8a3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76df1a6a-9150-4fb2-bdf6-2b4bc33dc6e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db914284-9757-4707-88b8-02b0b98484a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc4731f-1feb-4756-95a0-292aedc08306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56579b40-5e6c-40b7-b90f-53642e5a8ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeebc6af-1dc8-4cde-9537-7fbd8fa82b5d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_95
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/test_labels.txt

📊 Raw data loaded:
   Train: X=(1176, 24), y=(1176,)
   Test:  X=(295, 24), y=(295,)

⚠️  Limiting training data: 1176 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  286 samples, 5 features
✅ Client client_95 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1649, RMSE: 0.4061, MAE: 0.3316, R²: -0.9503

============================================================
🔄 Round 12 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1012, val=0.0773 (↓), lr=0.001000
   • Epoch   2/100: train=0.0832, val=0.0816, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0808, val=0.0787, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0809, val=0.0790, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0794, val=0.0812, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 12 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0048
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0165
============================================================


============================================================
🔄 Round 13 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1262, val=0.0948 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0827, val=0.0891 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0814, val=0.0843 (↓), lr=0.000250
   • Epoch   4/100: train=0.0800, val=0.0845, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0799, val=0.0847, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0797, val=0.0843, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 13 Summary - Client client_95
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0002
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0141
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1496, RMSE: 0.3868, MAE: 0.3166, R²: -0.7699

============================================================
🔄 Round 15 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1195, val=0.1333 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1030, val=0.1135 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0898, val=0.0989 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0823, val=0.0909 (↓), lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   ✓ Epoch   5/100: train=0.0797, val=0.0880 (↓), lr=0.000031
   • Epoch  11/100: train=0.0793, val=0.0874, patience=3/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016
   📉 Epoch 21: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0792, val=0.0874, patience=13/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 15 Summary - Client client_95
   Epochs: 23/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0003
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0249
============================================================


============================================================
🔄 Round 16 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1245, val=0.1262 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1220, val=0.1235 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1193, val=0.1209 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1167, val=0.1185 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1144, val=0.1163 (↓), lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1066, val=0.1095 (↓), lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.1009, val=0.1043, patience=1/15, lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.0988, val=0.1023 (↓), lr=0.000001
   • Epoch  41/100: train=0.0970, val=0.1006, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0954, val=0.0991, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0939, val=0.0976, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0925, val=0.0963, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0911, val=0.0950, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0898, val=0.0938, patience=4/15, lr=0.000001

============================================================
📊 Round 16 Summary - Client client_95
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.1126
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0935
============================================================


============================================================
🔄 Round 19 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0966, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0965, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0963, val=0.0980, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0961, val=0.0978 (↓), lr=0.000001
   • Epoch   5/100: train=0.0959, val=0.0976, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0950, val=0.0967, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0935, val=0.0951, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0920, val=0.0937, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0907, val=0.0924, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0895, val=0.0912, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0884, val=0.0901, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.0873, val=0.0891, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0864, val=0.0881, patience=5/15, lr=0.000001
   • Epoch  91/100: train=0.0855, val=0.0873, patience=3/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_95
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0530
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0507
============================================================


============================================================
🔄 Round 22 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 22 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0178
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0023
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0858, RMSE: 0.2928, MAE: 0.2530, R²: -0.0144

📊 Round 22 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2528, R²: -0.0120

📊 Round 22 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2527, R²: -0.0100

============================================================
🔄 Round 27 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 27 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0040
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0185
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2526, R²: -0.0079

📊 Round 27 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2526, R²: -0.0074

📊 Round 27 Test Metrics:
   Loss: 0.0851, RMSE: 0.2918, MAE: 0.2526, R²: -0.0069

📊 Round 27 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2526, R²: -0.0067

============================================================
🔄 Round 31 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 31 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0027
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0107
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2526, R²: -0.0063

============================================================
🔄 Round 34 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 34 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=-0.0024
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0085
============================================================


============================================================
🔄 Round 35 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 35 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0051
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0024
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2525, R²: -0.0053

============================================================
🔄 Round 37 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 37 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0051
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0028
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2525, R²: -0.0052

============================================================
🔄 Round 39 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 39 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0027
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0277
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2525, R²: -0.0049

📊 Round 39 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2525, R²: -0.0047

============================================================
🔄 Round 42 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 42 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=-0.0036
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0018
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2525, R²: -0.0046

============================================================
🔄 Round 44 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 44 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0039
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0001
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2525, R²: -0.0042

📊 Round 44 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2525, R²: -0.0042

============================================================
🔄 Round 50 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 50 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0011
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0100
============================================================


============================================================
🔄 Round 52 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 52 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0039
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0127
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2525, R²: -0.0040

============================================================
🔄 Round 53 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 53 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0008
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0159
============================================================


============================================================
🔄 Round 54 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 54 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0011
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0105
============================================================


============================================================
🔄 Round 55 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 55 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0012
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0175
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2525, R²: -0.0040

============================================================
🔄 Round 59 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 59 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0058
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0047
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2525, R²: -0.0039

============================================================
🔄 Round 63 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 63 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0054
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0054
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2525, R²: -0.0038

============================================================
🔄 Round 66 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 66 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0021
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0045
============================================================


============================================================
🔄 Round 67 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 67 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0031
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0061
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2525, R²: -0.0037

============================================================
🔄 Round 70 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 70 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0022
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0039
============================================================


============================================================
🔄 Round 76 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 76 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0029
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0040
============================================================


============================================================
🔄 Round 77 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 77 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0038
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0046
============================================================


============================================================
🔄 Round 78 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 78 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0015
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0094
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0032

============================================================
🔄 Round 82 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 82 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0045
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0058
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0031

📊 Round 82 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0031

============================================================
🔄 Round 84 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 84 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0001
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0131
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0032

============================================================
🔄 Round 86 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 86 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0034
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0017
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0031

📊 Round 86 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0031

============================================================
🔄 Round 91 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 91 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0077
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0039
============================================================


============================================================
🔄 Round 92 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 92 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0031
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0016
============================================================


============================================================
🔄 Round 93 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 93 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0024
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0021
============================================================


============================================================
🔄 Round 95 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 95 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0023
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0027
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0029

📊 Round 95 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0030

============================================================
🔄 Round 99 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 99 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0028
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0034
============================================================


============================================================
🔄 Round 100 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 100 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0008
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0097
============================================================


============================================================
🔄 Round 101 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 101 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0050
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0098
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0028

============================================================
🔄 Round 102 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 102 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0012
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0090
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0028

============================================================
🔄 Round 103 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 103 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0043
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0094
============================================================


============================================================
🔄 Round 105 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 105 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0005
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0119
============================================================


============================================================
🔄 Round 107 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 107 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0024
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0014
============================================================


============================================================
🔄 Round 108 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 108 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0058
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0213
============================================================


============================================================
🔄 Round 109 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 109 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0043
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0047
============================================================


============================================================
🔄 Round 111 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 111 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0016
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0055
============================================================


============================================================
🔄 Round 112 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 112 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0051
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0084
============================================================


============================================================
🔄 Round 113 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 113 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0029
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0123
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0027

============================================================
🔄 Round 117 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 117 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0029
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0006
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0027

============================================================
🔄 Round 118 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 118 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0029
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0004
============================================================


============================================================
🔄 Round 119 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 119 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0034
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0152
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0027

📊 Round 119 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0027

============================================================
🔄 Round 123 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 123 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0020
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0161
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0026

============================================================
🔄 Round 125 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 125 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0028
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0031
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0026

============================================================
🔄 Round 126 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 126 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0008
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0082
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0026

============================================================
🔄 Round 130 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 130 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0038
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0038
============================================================


============================================================
🔄 Round 131 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 131 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0025
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0523
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0026

============================================================
🔄 Round 133 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 133 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0010
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0072
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

============================================================
🔄 Round 138 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 138 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0015
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0067
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2525, R²: -0.0024

============================================================
🔄 Round 140 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 140 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0021
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0036
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2525, R²: -0.0024

============================================================
🔄 Round 141 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 141 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0022
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0017
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

📊 Round 141 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0026

============================================================
🔄 Round 145 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 145 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0031
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0166
============================================================


============================================================
🔄 Round 146 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 146 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0039
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0273
============================================================


============================================================
🔄 Round 147 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 147 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0019
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0031
============================================================


============================================================
🔄 Round 149 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 149 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0076
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0263
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0027

============================================================
🔄 Round 150 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 150 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0022
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0032
============================================================


============================================================
🔄 Round 151 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 151 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0034
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0058
============================================================


============================================================
🔄 Round 152 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 152 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0014
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0046
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0027

============================================================
🔄 Round 153 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 153 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0025
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0003
============================================================


============================================================
🔄 Round 154 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 154 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0048
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0027
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0027

📊 Round 154 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0027

============================================================
🔄 Round 159 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 159 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0021
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0058
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0026

============================================================
🔄 Round 160 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 160 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0034
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0007
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0026

============================================================
🔄 Round 162 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 162 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0009
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0122
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2525, R²: -0.0027

============================================================
🔄 Round 166 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 166 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0028
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0091
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0024

============================================================
🔄 Round 171 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 171 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0046
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0144
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2525, R²: -0.0024

============================================================
🔄 Round 172 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 172 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0045
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0038
============================================================


============================================================
🔄 Round 173 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 173 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0005
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0084
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2525, R²: -0.0024

============================================================
🔄 Round 174 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 174 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0035
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0041
============================================================


============================================================
🔄 Round 176 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 176 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0026
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0071
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

📊 Round 176 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

============================================================
🔄 Round 179 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 179 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0008
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0167
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

============================================================
🔄 Round 180 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 180 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0021
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0027
============================================================


============================================================
🔄 Round 181 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 181 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0011
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0065
============================================================


============================================================
🔄 Round 183 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 183 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0033
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0036
============================================================


============================================================
🔄 Round 184 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 184 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0013
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0089
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0026

============================================================
🔄 Round 188 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 188 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0018
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0064
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0026

============================================================
🔄 Round 189 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 189 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0035
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0023
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

============================================================
🔄 Round 191 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 191 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0006
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0091
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

📊 Round 191 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

============================================================
🔄 Round 194 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 194 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0024
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0162
============================================================


============================================================
🔄 Round 195 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 195 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0019
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0034
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2525, R²: -0.0024

============================================================
🔄 Round 196 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 196 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0036
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0028
============================================================


============================================================
🔄 Round 199 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 199 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0030
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0023
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0026

============================================================
🔄 Round 200 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 200 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0020
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0027
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

============================================================
🔄 Round 202 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 202 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0037
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0172
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

📊 Round 202 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

============================================================
🔄 Round 210 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 210 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0051
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0073
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2525, R²: -0.0025

❌ Client client_95 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
