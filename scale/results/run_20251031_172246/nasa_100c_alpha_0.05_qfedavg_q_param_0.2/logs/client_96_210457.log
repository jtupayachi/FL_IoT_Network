[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da567137-937a-4f93-b553-cd07c615e1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b272094-c595-4ffa-add4-f3f30f3b21fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b0cc1db-dda3-4044-9a2f-7f9a1c1587ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92e490f1-f2f4-4537-aaae-a615432297ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa99d02-e486-4d98-bbf9-dc89ce7d090c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4ef3c5d-0126-4610-989e-be6648d8df7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 083c9b73-649e-4a0e-b391-951316873051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8278cbb1-7964-497a-aa01-946a9b29a078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6139155e-acbb-4df1-9de0-2a7243dcfec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81b77d7c-8fd7-4909-8ffb-0ccdaa6b1606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0d49663-74c5-44ed-96e2-b84b0e8a35dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d21d7591-7ebf-4f42-b970-a6876785f556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 087843c7-2d0a-47e5-8e09-5830c22ed6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4e5a787-18fb-41e1-b5c9-e3678bc8bb8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90d72cd4-0487-4385-a5bd-3c9809f6605f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b18bd31-a503-484e-b689-ed29c28c819a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7665cc6a-8323-4702-90a4-b97b6646715b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f806af7-4906-4c53-a951-564e5c91ecf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f1a03af-1977-48a3-bdb1-1afa96f42409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5ebac6d-ef5b-462d-84d8-44c97daded27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 263ad030-6974-4c31-b520-74048665c9dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3ee5c1f-959d-435d-a87c-8cfcd57c6b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7edb5a6-1a12-4901-9342-49192f2389b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a57aafe5-620c-4671-8d2d-7fd767142dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a49ff445-5660-4428-84f5-53bb55d1a00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98f06e35-36ff-43cc-b41c-e9f367d571ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1186f62c-02e0-4ed1-8717-57ab30c22500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e8dbd47-8aab-4a79-89b2-ef8cdc0de3f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f26e49e7-3398-413c-a41a-78b4804370a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb17ae1b-96fb-424b-9bf3-cce740c28a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d413e26b-4d63-4625-acdd-100e81724843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cc8b330-4c58-4f8e-ac63-1c1277b115ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b33899d-a48d-416c-abdf-5cda21c839f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f98607a5-a066-4d1f-8e7b-431dfe262e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9fe7b13-80a4-457e-acc2-e03e513724d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f2a7df1-4edf-4b40-a53c-453e55ef739f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3223d4d1-befb-4ae3-a200-57da19251db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e05accd-4e64-46c6-8125-30160d0b9d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87cdc70c-b35b-4b90-9f93-1c08d542bee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6786552-912a-48b4-bac3-111885ea4b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9550cf0e-3bc5-43d4-8f45-aeaf8344facb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73e3e330-41f2-4b0a-b7bf-4813805c10f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45dd5c8e-62b7-4d47-b37a-be750f8829c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 926b7dd5-ea08-486a-8b6b-5223bf961b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19ca5a78-9f20-47b0-b565-73c36f589ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ca916cc-8a86-4e1e-af34-ed1989f8314c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa97e870-178f-4274-8a9c-513d84e8d7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5cf83fb-9fb4-4234-87a6-34684807b424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ef7d57-30b3-42e2-a9ae-4b316e45926e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7e33521-0545-44ca-a58f-9ec84fffedef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2607a587-29ee-4882-81ab-c65152210437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 043c6d1d-3fb4-4221-8222-e3525d7310ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b580d72-12d8-4aff-a142-accef7c8d724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b43ce2ef-1759-4ddc-8506-c334082ebb97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb1a691a-3ef9-49f6-8b3c-c72c1071d6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aff1c317-7270-455a-86c7-6b0618674bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0565810c-e60f-408b-99b2-cad9ce1dc79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c70fca5a-9d34-4bc4-8619-a30a231ece4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39c70772-94ba-4af4-880c-c06b0a32111f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54080159-18fd-4046-97c4-3f17e939e2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff10337-d84d-4f6d-92be-14afc03b3246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 438465a9-9ab3-48b2-842e-800213e7dc6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 563eb453-b566-4f43-956c-71aebb734f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad513cb5-cf18-4a1a-90c5-6754d65516d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f46ef27-138c-41a4-96e2-e4695b560a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cacfab5-9072-4dcc-94cf-398324b71cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a330a4e4-4d31-4e20-89d4-ebec0101b0a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90219530-2127-4e16-9679-0398b59a41e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f03fee0-7db1-4184-ae1e-b088dd548f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67961f20-6ee5-431c-a77e-2e45fb2d8bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0249040-c732-4b72-8be4-4e11103b0d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d3a26d2-7379-4f86-8fa0-04a6be1ee184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31b91d15-5874-4ffe-a284-e224b3474efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0e58bf-de9f-49bd-a2d5-8ca50b68ac76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6d3afc3-19eb-4d89-a5d8-6c32c6fe78ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7280ac9-adda-4429-accb-a547be800470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9005293e-ec23-424b-b821-22453acc84fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a0ddcf-14fe-406d-8559-f289e091fc2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3792ec98-84d4-420f-bb45-abe7b9649dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e75b80c-60aa-4adb-b23f-02fda9feca05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a197b796-21ee-4703-a8c8-5665ad07fedd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2790d52-e378-4f3f-8137-74436f2bcc70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdf49644-c537-4f2c-8e91-2640cd225f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92d73363-a212-47a7-bcc1-f4256547ee12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4762d2ed-c723-421b-bebc-dbf1493e81bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9fe362c-9385-47ca-ac7e-e761b3a6ae88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b532d6-0632-4452-aa57-d1a7148df082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f967d5-1f77-41ae-af22-0b8d298da48d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45417f51-bcf2-44d0-8f7b-d8d856c1449f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b7c4c38-cf5f-4ec6-9204-e5f519513668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e7acf60-66d2-4e92-8b20-e60e68b7e0fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba3db3db-b976-4879-a4f0-eb25daef30a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3e56de8-b4c2-40a7-b3f8-34d9cb0f56c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac86428-c174-4e01-8dfa-c17e6246130c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdd4afc2-cf0a-4b57-b025-f96be2912ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 723bb2ed-a25f-4050-a19b-6bbc929f6e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027326c6-ad72-48d7-9004-2efc37c02c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49121232-5766-4c8d-97a1-f2b793c6de45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53287ab9-85af-4738-90a7-c891b19dd610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 890af14c-d25a-48a2-8a44-404bcd82c1c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e13f783a-f3bc-4bef-a737-c7d3e90f6169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7df50b-6dd0-4678-8127-11d50b679ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a20aa7c0-18b6-448b-bcde-ba55ab37b2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46dc6e94-38e6-4cb7-8c50-7d20c79fe7a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b7d07c6-b860-4faa-a8e7-13d5cfe5438e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01acb791-afd1-48cf-bfec-939c70e62505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9001c575-c801-4170-aff0-8d17a31ad611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23fbc3a-3578-41d5-9168-91032a5e2594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3d65a1f-6847-42be-a687-0f98ff14fc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e432c29-3943-485e-99ba-3bd87e5206fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a349d3d8-6d46-45e9-aea7-ccf8a6e55c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0491d011-1b4f-49cd-b6e5-39252a80442f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25b8a7f6-6772-4453-a6db-cc8124bd90ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ba5b1c-f764-40d9-9d2d-e418e3b21b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb88903c-fbb8-4fad-98d4-d4b4bf13b3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a22328-33cf-46b3-a691-a7b9e3c6266d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07d4d50-9a90-4b66-baae-adb96efa35de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f4df0e7-3ab5-4b36-8b5e-fd5fb9469afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a55ae09-8414-4743-9982-950aeee9cd28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2381cf7d-e9cc-404f-92f4-8f5d03de5df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68705c70-ac4a-4d08-87f3-b05c6f744b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19a17e9f-939f-4873-9f65-27a2f19f8858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 411792fc-6eeb-45cd-86d2-11e983d1fcb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7fe61db-692d-4250-a8ea-0d2daec930ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b545be19-696c-41bd-88ff-b11c1156268c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39731833-db54-483a-b87b-e87b22ffec1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 123265c5-b88a-4f09-bc3b-2a75823e2917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00487753-5106-44b8-bf09-6a75989cd6cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78e1b73e-cf75-45a7-a381-5939a6a2376f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b4671b4-bfcd-4b3f-83ae-19da0c5e07ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2ac2c76-9752-4294-afcf-cba1ddf8a4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 331e2d81-b74e-4bb4-a1c2-f0cacde3abf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b16ea599-9b62-416b-b7c2-ed4614c0a0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd23fc6-e5d5-44e6-84cb-6fda6b54adb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95504b45-a34d-4f0f-b435-6089f969bf0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c71fa8d-1512-439e-8709-1d82a8e26334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81f925e8-b168-4493-8b79-c46266dc1c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e2fe20-75ac-4384-b331-aaa910e295d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a705f033-de84-4745-bd9f-223c1c28e126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fcd685f-24e7-42b7-b0fd-0c57f0d1bbac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cd938b9-66e9-48fe-b472-512897fd402f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f312dc39-a439-4c55-b526-c37275f83e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c78f90-1e70-47e3-acfc-84c81d52d58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58ffd82a-ce42-4ace-8c94-a9c9ebbb6231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e930c3a-065e-4ba7-90de-ae7fe101bde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 672316ec-b676-45cd-b213-841a02a0eec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1d52ca-6493-4928-a310-c40f662d045f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18e0d72d-4bd5-456c-b6da-1bd1339c9773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5b4e2fb-3414-4fc7-af57-6bc3ed10f586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1188a3af-a71c-44df-ae37-01aab97c8b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4e58b8f-15d3-4b41-918f-1c4890e73e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0ac625-dd0f-4681-8e3d-0f2dd114ba92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb7d5324-10cd-4823-aaf5-773c52f36deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ea4f5e-6b75-4e91-a839-1716ce52f683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 919e0e3a-5d73-474e-b105-ea86ea082a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d780030f-ee64-4b4d-a9b1-57e9700a3d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b1ddf2-c2bf-4060-aae1-07239078c0a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7441d204-6b03-4c42-bda3-85cd63d225b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b14183e0-f536-4e62-878a-edf7bedc9f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7edce97-1cd7-4c23-b666-9d082625d082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7bbb48d-8b69-4a5f-aec6-1a21a7d15fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d5e4927-3245-40b7-98c1-a38c74c60895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebb04e54-4652-4337-81a9-b3cee088ee76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3002dd15-8c4e-43dd-8508-3f7a01468485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e260d67d-7f62-4648-b186-46ca90abdf28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708973fc-077e-4719-ab5f-7069a8fd626e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00247575-dbfd-4805-8a4e-a2cad382a5b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69553174-3666-4d46-8c71-cf8f3c69b95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5235c42a-b333-41fa-84e6-fb72e38700bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bf2f0db-4003-4569-961d-8388757b3bd2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_96
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/test_labels.txt

📊 Raw data loaded:
   Train: X=(1516, 24), y=(1516,)
   Test:  X=(379, 24), y=(379,)

⚠️  Limiting training data: 1516 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  370 samples, 5 features
✅ Client client_96 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1694, RMSE: 0.4116, MAE: 0.3347, R²: -1.0874

============================================================
🔄 Round 13 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0952, val=0.0937 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0828, val=0.0898 (↓), lr=0.001000
   • Epoch   3/100: train=0.0823, val=0.0903, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0819, val=0.0910, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0815, val=0.0910, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0796, val=0.0921, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 13 Summary - Client client_96
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0005
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0120
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.1460, RMSE: 0.3821, MAE: 0.3105, R²: -0.7996

============================================================
🔄 Round 15 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1137, val=0.0871 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0859, val=0.0839 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0853, val=0.0834 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0849, val=0.0827 (↓), lr=0.000250
   • Epoch   5/100: train=0.0847, val=0.0826, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0843, val=0.0819, patience=3/15, lr=0.000250
   • Epoch  21/100: train=0.0838, val=0.0813, patience=6/15, lr=0.000250
   ✓ Epoch  31/100: train=0.0833, val=0.0806 (↓), lr=0.000250
   • Epoch  41/100: train=0.0827, val=0.0798, patience=3/15, lr=0.000250
   • Epoch  51/100: train=0.0818, val=0.0787, patience=2/15, lr=0.000250
   • Epoch  61/100: train=0.0805, val=0.0776, patience=2/15, lr=0.000250
   • Epoch  71/100: train=0.0785, val=0.0763, patience=3/15, lr=0.000250
   • Epoch  81/100: train=0.0757, val=0.0754, patience=2/15, lr=0.000250
   📉 Epoch 87: LR reduced 0.000250 → 0.000125
   • Epoch  91/100: train=0.0723, val=0.0762, patience=12/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 15 Summary - Client client_96
   Epochs: 94/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.1085
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0810
============================================================


============================================================
🔄 Round 16 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.1218, val=0.1021 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1007, val=0.0917 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0900, val=0.0865 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0848, val=0.0856 (↓), lr=0.000063
   • Epoch   5/100: train=0.0833, val=0.0861, patience=1/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0826, val=0.0867, patience=7/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 16 Summary - Client client_96
   Epochs: 19/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0056
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0008
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1360, RMSE: 0.3687, MAE: 0.3005, R²: -0.6756

📊 Round 16 Test Metrics:
   Loss: 0.1194, RMSE: 0.3456, MAE: 0.2848, R²: -0.4717

📊 Round 16 Test Metrics:
   Loss: 0.0932, RMSE: 0.3053, MAE: 0.2593, R²: -0.1490

📊 Round 16 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2523, R²: -0.0573

============================================================
🔄 Round 22 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0797 (↓), lr=0.000016
   • Epoch   2/100: train=0.0857, val=0.0794, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0855, val=0.0792, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0854, val=0.0791 (↓), lr=0.000016
   • Epoch   5/100: train=0.0853, val=0.0790, patience=1/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0852, val=0.0789, patience=7/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 22 Summary - Client client_96
   Epochs: 19/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0019
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0104
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2503, R²: -0.0260

📊 Round 22 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2500, R²: -0.0225

============================================================
🔄 Round 24 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0831 (↓), lr=0.000004
   • Epoch   2/100: train=0.0844, val=0.0831, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0844, val=0.0831, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0844, val=0.0831, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0843, val=0.0831, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0843, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 24 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0040
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0192
============================================================


============================================================
🔄 Round 25 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 25 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0024
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0087
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2496, R²: -0.0175

============================================================
🔄 Round 26 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 26 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0054
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0049
============================================================


============================================================
🔄 Round 27 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 27 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0023
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0041
============================================================


============================================================
🔄 Round 28 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 28 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0038
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0039
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2493, R²: -0.0141

============================================================
🔄 Round 31 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 31 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0050
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0217
============================================================


============================================================
🔄 Round 32 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 32 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0057
   Val:   Loss=0.0980, RMSE=0.3131, R²=-0.0095
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2492, R²: -0.0132

============================================================
🔄 Round 36 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 36 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0019
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0286
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2491, R²: -0.0118

📊 Round 36 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2491, R²: -0.0116

📊 Round 36 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2491, R²: -0.0114

============================================================
🔄 Round 39 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 39 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0022
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0001
============================================================


============================================================
🔄 Round 40 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 40 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0022
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0006
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2490, R²: -0.0107

📊 Round 40 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2490, R²: -0.0105

============================================================
🔄 Round 43 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 43 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0010
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0056
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2489, R²: -0.0103

============================================================
🔄 Round 46 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 46 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0029
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0010
============================================================


============================================================
🔄 Round 47 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 47 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0009
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0096
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2489, R²: -0.0099

============================================================
🔄 Round 48 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 48 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0025
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0025
============================================================


============================================================
🔄 Round 49 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 49 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0020
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0005
============================================================


============================================================
🔄 Round 50 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 50 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0017
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0019
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2489, R²: -0.0095

📊 Round 50 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2489, R²: -0.0097

============================================================
🔄 Round 59 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 59 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0028
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0035
============================================================


============================================================
🔄 Round 62 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 62 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0010
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0046
============================================================


============================================================
🔄 Round 63 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 63 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0031
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0005
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2488, R²: -0.0091

📊 Round 63 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2488, R²: -0.0090

📊 Round 63 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2488, R²: -0.0090

============================================================
🔄 Round 68 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 68 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0008
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0042
============================================================


============================================================
🔄 Round 70 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 70 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0020
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0011
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2488, R²: -0.0087

============================================================
🔄 Round 73 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 73 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0012
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0028
============================================================


============================================================
🔄 Round 75 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 75 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0013
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0104
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2488, R²: -0.0081

============================================================
🔄 Round 78 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 78 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0023
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0016
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2488, R²: -0.0081

📊 Round 78 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2487, R²: -0.0079

📊 Round 78 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2487, R²: -0.0080

============================================================
🔄 Round 82 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 82 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0025
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0094
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2487, R²: -0.0079

============================================================
🔄 Round 83 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 83 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0004
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0198
============================================================


============================================================
🔄 Round 85 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 85 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0031
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0055
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2487, R²: -0.0079

============================================================
🔄 Round 89 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 89 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0014
   Val:   Loss=0.0736, RMSE=0.2714, R²=-0.0028
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2487, R²: -0.0078

📊 Round 89 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2487, R²: -0.0077

============================================================
🔄 Round 91 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 91 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0012
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0052
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2487, R²: -0.0076

📊 Round 91 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2487, R²: -0.0076

📊 Round 91 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2487, R²: -0.0075

============================================================
🔄 Round 94 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 94 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0024
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0101
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0074

📊 Round 94 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0075

============================================================
🔄 Round 97 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 97 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0021
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0022
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2487, R²: -0.0077

============================================================
🔄 Round 98 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 98 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0011
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0079
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2487, R²: -0.0076

📊 Round 98 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2487, R²: -0.0075

📊 Round 98 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0074

📊 Round 98 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0072

============================================================
🔄 Round 105 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 105 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0023
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0014
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0072

📊 Round 105 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0072

📊 Round 105 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0070

============================================================
🔄 Round 109 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 109 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0028
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0004
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0069

============================================================
🔄 Round 110 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 110 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0026
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0018
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0069

============================================================
🔄 Round 111 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 111 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0022
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0029
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0070

============================================================
🔄 Round 117 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 117 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0003
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0068
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0072

📊 Round 117 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0071

============================================================
🔄 Round 119 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 119 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0002
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0089
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0069

============================================================
🔄 Round 123 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 123 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0021
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0007
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0070

============================================================
🔄 Round 125 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 125 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0034
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0084
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0068

============================================================
🔄 Round 129 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 129 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0027
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0017
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0068

============================================================
🔄 Round 132 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 132 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0002
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0189
============================================================


============================================================
🔄 Round 133 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 133 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0020
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0006
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0067

============================================================
🔄 Round 135 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 135 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0017
   Val:   Loss=0.0679, RMSE=0.2606, R²=-0.0015
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0067

============================================================
🔄 Round 136 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 136 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0015
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0031
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0066

============================================================
🔄 Round 137 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 137 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0021
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0269
============================================================


============================================================
🔄 Round 138 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 138 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0003
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0155
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0066

============================================================
🔄 Round 141 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 141 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0033
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0053
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0066

📊 Round 141 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0069

📊 Round 141 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0071

============================================================
🔄 Round 146 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 146 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0040
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0214
============================================================


============================================================
🔄 Round 147 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 147 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0016
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0108
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0070

============================================================
🔄 Round 148 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 148 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0012
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0051
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0072

============================================================
🔄 Round 149 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 149 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0022
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0071
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0071

============================================================
🔄 Round 151 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 151 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0035
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0155
============================================================


============================================================
🔄 Round 152 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 152 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0028
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0233
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0073

============================================================
🔄 Round 154 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 154 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0010
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0064
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0072

============================================================
🔄 Round 157 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 157 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0025
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0024
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0072

📊 Round 157 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0071

============================================================
🔄 Round 160 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 160 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0032
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0184
============================================================


============================================================
🔄 Round 161 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 161 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0017
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0029
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0071

📊 Round 161 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0072

============================================================
🔄 Round 164 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 164 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0001
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0236
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0071

📊 Round 164 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0070

============================================================
🔄 Round 166 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 166 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0006
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0054
============================================================


============================================================
🔄 Round 167 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 167 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0002
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0160
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0069

============================================================
🔄 Round 168 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 168 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0048
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0054
============================================================


============================================================
🔄 Round 170 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 170 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0009
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0056
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0067

📊 Round 170 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0066

============================================================
🔄 Round 175 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 175 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0013
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0166
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0069

📊 Round 175 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0069

============================================================
🔄 Round 180 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 180 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0015
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0050
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0068

============================================================
🔄 Round 182 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 182 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0017
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0073
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0067

============================================================
🔄 Round 183 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 183 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0008
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0049
============================================================


============================================================
🔄 Round 185 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 185 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0027
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0164
============================================================


============================================================
🔄 Round 186 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 186 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0005
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0102
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0071

📊 Round 186 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0071

📊 Round 186 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0070

============================================================
🔄 Round 190 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 190 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0011
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0032
============================================================


============================================================
🔄 Round 193 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 193 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0021
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0106
============================================================


============================================================
🔄 Round 195 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 195 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0009
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0158
============================================================


============================================================
🔄 Round 196 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 196 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0021
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0011
============================================================


============================================================
🔄 Round 198 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 198 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0041
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0021
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0071

📊 Round 198 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0070

📊 Round 198 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2486, R²: -0.0068

============================================================
🔄 Round 204 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 204 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0018
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0004
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0070

============================================================
🔄 Round 205 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 205 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0005
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0116
============================================================


============================================================
🔄 Round 206 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 206 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0016
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0119
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2487, R²: -0.0071

============================================================
🔄 Round 210 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 210 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0023
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0016
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2487, R²: -0.0070

❌ Client client_96 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
