[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4724c2c9-0dea-407c-a940-54ab99573af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4074e8a-da78-477a-be96-d4de1b611b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 646c90c0-217e-4eff-9a05-147f4d819b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6124933-7be2-464c-9908-f2f346afd3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06c8d090-015c-4cdf-92c2-4e64e54ed245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2056b951-08e3-4d79-b54c-801424c15c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f41adb0d-dcf2-40fe-bfb7-e311181ef895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed74fbc8-60f0-460c-a318-8934eec11841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec34939d-6428-4ec1-8cf3-09f4e34033b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36bd1766-3f8b-4cb8-b816-1f70100688f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aed1f9a7-8c3a-438a-b62c-861e4a3f9f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14717dd-3f4f-4cab-b159-cb48bef3ab9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cbd6ce1-ddca-4bf4-b699-36bec0bcc396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec6c9ecf-66cc-42fd-a27e-f23ab1cbb430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c8f924c-34ce-4e36-905e-000c52ca7566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cea708c-e00b-4be3-a6fe-86a8effc0f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c109b4b7-c61e-406e-905b-c8adacfe0228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13e2c530-87ec-4c45-88d4-ab189ba572f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c78419f-6489-4d32-ad28-e5745bfe8ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182b90ac-732e-4948-a020-5c5cee0b720c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7efd033d-4af8-4d00-a3fb-6ee85403fe97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08208c87-3d15-4507-80c4-75f8317888b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc3b912b-b866-4707-a92b-f77490120611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c1c1a11-fd6c-4c24-8b8e-07fcde643951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cfbb654-2146-40f6-a054-5a988fa26d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99611c06-0313-4a38-8e8c-4221e7413bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4fd185a-c2d7-45ba-bc40-f024dfbab328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d98d5659-3887-47a1-8f28-4c41a6104ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abaf479e-b8f1-4cee-81d2-b763be7d6f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 450b9fb9-8cd1-422d-8033-1dc0a1ec021b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 216549e5-29d4-4f81-875a-0addc237de27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c597dff5-0dd2-44fc-85e1-78c6acc18de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 848f5c9b-4254-4998-b5e6-f0c3ab0c7381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b441e66d-677a-4645-82d1-5ea177c41577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74e9da60-44d6-483f-8ee2-4ffe35948c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36656059-9d81-4a3b-8854-2154878f1025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e21cf686-dc73-4719-9db6-7101004249ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92f3b2b9-9d67-4a36-a824-95ff7b8453be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message accbfe41-b055-4ee3-85e9-cb9ba1397779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0538289d-65e1-4041-a109-ecc68cc1fa9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ca7194-72d9-4dff-8f57-4618eb713127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5a847ef-d240-47c0-b6e8-40d35cbbe1b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4a7c694-cafd-4241-a327-e95d21ca3dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81c1e875-904e-48b2-9ce5-4620967a8578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d3f320-73aa-4cbe-9116-bd6f41cb9a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 914ec800-cb03-4654-89c7-1d67a6928fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89876594-f446-4e0b-95e9-496798b2aa4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cc24453-f1f1-4d51-aacb-92f18f6463aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57f70fa3-0390-4338-a484-71ef73ed8b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37150d97-58ae-49ea-ad7b-02a7a831a85e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf1c62a8-5e68-4fa8-b98b-4c8071a9c5f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb5a3f4f-b687-48bf-ab03-a023afc02c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abb9271f-d6cd-494f-81b6-805a191f44ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5748d1d-b24b-4c30-aeae-3514e4c9e4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae386b85-928a-4499-901a-67f2f4a4f087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1456c50c-75af-4e5a-9682-c70a8d29e487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67231b15-c562-42aa-8eca-1c438cdcff09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f0e8c7b-cbf0-4934-8c2a-11138650b9eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15d51cff-67e4-460c-8bf3-5317f9644baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb2eb911-3287-4a13-a1bc-cba37c14e5a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6107c19-0ae9-4ae3-b983-0359ecfe10a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c64f90a-c938-4baa-a821-3ee6b10a8cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd3ef7fc-92e6-40bb-8e4f-c73a57a93417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0873d14e-5539-44f6-9831-0b970c06c224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 698b5219-32fa-4cfb-9e43-a03d9d1caac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1e4c64c-289f-41d6-9099-9617ea481b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02d8ef77-9d6a-4e78-a5c3-d4745e593bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a97a457-4c6f-4a23-82ef-a6087a1161b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95103e7a-e333-44f0-be39-b2bbf8c95095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3da66922-ddd0-4f92-859e-c50e70766554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c4c908-a5b0-41d0-9d4d-ce3a0120f6a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c69d2d7-9467-4568-a240-cccc70c43bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd204a2e-4e6b-47d7-bfb1-0341a9588e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcaf45b2-ffe4-4d1e-909a-b0301e2f31f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3c48d00-981f-4124-9f48-77d4687a9a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d76c63e-fa9f-40d8-b591-5587765cd9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac72fc2-3118-424f-98da-790ad277d2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc80d89f-3539-48a8-a2e5-631b0980e8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bac7cb2-07ca-493c-a906-020677a2f7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be671dbc-962f-423f-906e-738d2ef5e498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a573df-1c34-4bd6-bedb-46ab121d654a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b7ebce-67a6-4b44-b9f1-a617b07ce8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae03f1b0-cb7e-4f73-9d9c-8a14d1c1c0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22743725-0747-4f40-b6b7-da3ab4e8c289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6190fba-f933-4396-9677-a5cc088e94d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b798e0e-4830-444a-8f42-d6d4617ad63d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62943382-47b1-4e38-8bb9-f4a0b2a40d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 908f6a1d-85e3-450e-aae2-7f878047ea44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba10ac93-42c2-4d55-813e-1b3324a0e299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f300cb24-53cf-474b-acf7-c0d8c0863990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01b7c6ff-26bc-40b0-b39b-34adf4fc78dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e477333-6601-4e14-b88e-7f8987619e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bdb0e63-dc8a-4741-b6b4-8cf81456f836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fd7fbd3-a347-4d33-bba0-8047440d397a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad9c9bde-1289-4a1c-8a39-679ec3c0d870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91077138-2cba-47d7-941a-70d6cf618cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf0cf89-aaf2-45c3-99bd-121ae6cd9aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73dfe818-9173-428d-9f92-dc010ddaea64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca4137a8-65aa-4215-8e6e-cdc97c983d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 245fd62c-1554-454d-8cad-c1bf70ac04d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5515c65d-2e36-42ce-80a0-2668b1873b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 859e0c7d-29cd-482f-a54b-54a4a3e5df8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf27693f-61f8-487f-98fd-3534d29b755b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a8c280-b0fb-4b82-b179-67ca1007f128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96114ee-090f-4b51-b869-84702c196a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d5f6d86-a7ea-4527-ab37-f30430e137d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf753890-b9bf-4a00-a304-40f6324738fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c8f360c-3b06-4694-86e2-a1f17217324d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aab2a023-7541-4bd8-aace-9029d8ae4ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 276fabb5-914d-4462-8d41-bb294f06a0c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0866674-6cb5-4d4f-aa0d-2e21ead64a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b10207c3-deb6-4184-8c1e-e129e7e04c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a68fabc-9941-449f-ab6b-fab4fede921f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fee76478-9e5d-45da-80f6-4641138617bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e0151bb-78c9-45c3-8458-71c488e1154b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f888f04d-d247-4579-a932-08704a9f30a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4e869ea-fb81-43af-81b7-502cd92e4895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d0e8e4c-4f3b-404e-aa41-0be8d529c8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39d13649-1240-40d8-b8be-429a6068019e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 351930d2-1f4c-4d6e-bdb0-60a5d8ed6417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8bd603e-b382-492a-8f2c-5e1e754bc150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe22fda-95f2-409c-bb2e-9242149522a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6881d67f-ad5a-4e29-8735-f4255c6bcc45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6da69e91-a25c-421d-be25-2628e19873e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 810744ce-139b-4261-a6fa-594956128207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 403d6067-07f7-43ca-8a55-219c41be0681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 641d954a-c414-437f-9a89-5dfee0e73f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6af9ffcd-6c45-4f2c-a875-cf9abe2ad079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c166452c-ecb1-47aa-9641-3644d7f810d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a09de141-70cd-4398-a79b-278d6a146ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e02b23c-d63f-4e80-9d87-466de5838800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a13e5d83-33b1-4536-b636-822418d504ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff786357-e0f7-4598-812a-f674cfa83070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5df3f8-77f5-4731-bc35-ac5f690e28ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7756004-85e6-4e43-84d0-45409923e6b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc07a70-8efd-45d8-a80f-16859048691f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bda7307-ae73-4286-8b43-3d77ebab3025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfadcf4c-e930-418b-9746-09e2a75a08ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8cf59ae-a219-46c2-92c5-051d44982410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4570b3ad-2801-4480-a713-fb382310c647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6282b087-6dbe-44bd-b8dd-b27de8b4445a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b12c3d98-315e-4f89-aa38-104fd10af24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08f0d5e1-3680-459a-8ac2-718ad0bbb6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 390ca638-9168-4908-b79f-28465f2692aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c01ae499-36d1-41ad-b6b6-c6e6f46e7617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e3c8827-4ab2-4c9f-b38a-7f455a1d3d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f772f02-48fd-46c6-a273-379f11f1ae4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0acbdeef-37d8-417c-85b8-9ae06ff862e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d73e255-4a52-48bb-959f-c71ef7bb26ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52083f56-ec70-498e-b6f0-22be6d25bae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b42fdc91-5fdd-4658-b638-0d9b46164977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71811f6-c819-42d7-855f-8ea182b67a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde22c7e-7abc-4d02-951d-7db21d55563f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8b8cfe2-a708-460e-8cc6-0c991f3cf4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebb17b08-55cc-4a90-b474-f191bed811e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb5176d4-2d82-4a81-a6ac-c2ede9a7ec69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a7c0fc2-fce5-480c-a49c-b72db2963c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6df53461-fa5c-4a43-9f8a-2da26b6c3ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3c3657-6fe9-4932-83dc-873222acd892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d8993e8-482d-4f6d-929e-7a66d8f35443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f954efc-dcc7-482c-baf3-f41a37a66886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d941a1db-fe89-4802-b63e-94a848cc7313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f89c06-3766-436d-9b1d-1d9469868706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de3bc41c-6243-4ee5-8b7a-144991e81b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83708212-af0a-42f9-bd8b-919c854bd3f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa58547-e83b-4aef-890f-7402d65a2bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f92ed762-dfe4-4317-8778-d7621ca5fd89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f92d30c0-2d10-4387-8934-0c0af3e54198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f46b21dc-d97b-4d06-867c-8359cb0276bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1fad2f5-eba6-4d88-9962-9a509de8ef5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dea145c-384b-49a5-8955-244a610ddebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff0e5e9-f6b5-4bb0-8279-fabfe72c4ccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 918310d3-ae76-4011-aa5d-2762d258b31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd3627a-e8e3-4dde-af01-49a3bb7a6a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc4ad40d-78de-4871-9d48-dfe5065ff29a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_97
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_97/test_labels.txt

📊 Raw data loaded:
   Train: X=(1124, 24), y=(1124,)
   Test:  X=(282, 24), y=(282,)

⚠️  Limiting training data: 1124 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  273 samples, 5 features
✅ Client client_97 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 11 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1062, val=0.0784 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0853, val=0.0778 (↓), lr=0.001000
   • Epoch   3/100: train=0.0835, val=0.0785, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0833, val=0.0787, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0832, val=0.0789, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0824, val=0.0796, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 11 Summary - Client client_97
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0017
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0051
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1487, RMSE: 0.3857, MAE: 0.3115, R²: -0.8411

============================================================
🔄 Round 14 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1239, val=0.0980 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0840, val=0.0852 (↓), lr=0.000250
   • Epoch   3/100: train=0.0822, val=0.0856, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0816, val=0.0850, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0815, val=0.0852, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0811, val=0.0856, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 14 Summary - Client client_97
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0119
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0118
============================================================


============================================================
🔄 Round 15 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1323, val=0.1231 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1108, val=0.1012 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0937, val=0.0865 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0849, val=0.0809 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0828, val=0.0801 (↓), lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0825, val=0.0802, patience=6/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 15 Summary - Client client_97
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0057
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0041
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.1102, RMSE: 0.3319, MAE: 0.2734, R²: -0.3637

============================================================
🔄 Round 18 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1164, val=0.1069 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   ✓ Epoch   2/100: train=0.1111, val=0.1026 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1068, val=0.1006 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1042, val=0.0989 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1018, val=0.0973 (↓), lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0910, val=0.0911, patience=1/15, lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0859, val=0.0889, patience=2/15, lr=0.000002
   📉 Epoch 26: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0844, val=0.0884, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0836, val=0.0882, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 18 Summary - Client client_97
   Epochs: 41/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0457
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0007
============================================================


============================================================
🔄 Round 19 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1048, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.1046, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1043, val=0.0950, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1041, val=0.0948 (↓), lr=0.000001
   • Epoch   5/100: train=0.1038, val=0.0946, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1023, val=0.0934, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1002, val=0.0915, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0982, val=0.0899, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0965, val=0.0884 (↓), lr=0.000001
   • Epoch  51/100: train=0.0948, val=0.0870, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0933, val=0.0858, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0919, val=0.0847, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0907, val=0.0837, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0895, val=0.0828, patience=1/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_97
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0613
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0350
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2544, R²: -0.0988

📊 Round 19 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2494, R²: -0.0190

============================================================
🔄 Round 22 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0841, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0839, val=0.0837, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0836, val=0.0834, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 22 Summary - Client client_97
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0089
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0173
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2490, R²: -0.0108

📊 Round 22 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2489, R²: -0.0091

📊 Round 22 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2489, R²: -0.0081

📊 Round 22 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2488, R²: -0.0066

📊 Round 22 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2488, R²: -0.0065

============================================================
🔄 Round 31 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 31 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0071
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0003
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2488, R²: -0.0061

📊 Round 31 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2488, R²: -0.0060

============================================================
🔄 Round 36 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 36 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0050
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0012
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2488, R²: -0.0055

============================================================
🔄 Round 37 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 37 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0032
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0051
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2488, R²: -0.0054

📊 Round 37 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2488, R²: -0.0053

============================================================
🔄 Round 39 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 39 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0081
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0096
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2488, R²: -0.0052

============================================================
🔄 Round 40 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 40 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0103
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0073
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2488, R²: -0.0051

📊 Round 40 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2488, R²: -0.0050

📊 Round 40 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2488, R²: -0.0049

📊 Round 40 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2488, R²: -0.0049

============================================================
🔄 Round 45 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 45 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0013
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0104
============================================================


============================================================
🔄 Round 46 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 46 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0014
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0315
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2488, R²: -0.0049

📊 Round 46 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2488, R²: -0.0048

📊 Round 46 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2488, R²: -0.0047

============================================================
🔄 Round 51 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 51 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0037
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0008
============================================================


============================================================
🔄 Round 52 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 52 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0016
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0041
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2488, R²: -0.0046

📊 Round 52 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2488, R²: -0.0046

============================================================
🔄 Round 55 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 55 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0035
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0031
============================================================


============================================================
🔄 Round 56 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 56 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0012
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0155
============================================================


============================================================
🔄 Round 58 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 58 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0008
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0172
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2488, R²: -0.0046

📊 Round 58 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2488, R²: -0.0045

📊 Round 58 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2488, R²: -0.0046

============================================================
🔄 Round 61 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 61 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0091
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0055
============================================================


============================================================
🔄 Round 62 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 62 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0040
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0083
============================================================


============================================================
🔄 Round 65 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 65 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0002
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0209
============================================================


============================================================
🔄 Round 66 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 66 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0001
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0089
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2488, R²: -0.0044

============================================================
🔄 Round 67 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 67 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0037
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0058
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2488, R²: -0.0044

============================================================
🔄 Round 69 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 69 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0070
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0069
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0043

============================================================
🔄 Round 73 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 73 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0037
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0284
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0042

============================================================
🔄 Round 75 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 75 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0013
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0210
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0041

📊 Round 75 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0040

📊 Round 75 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0040

📊 Round 75 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0040

============================================================
🔄 Round 84 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 84 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0034
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0348
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0040

📊 Round 84 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0040

============================================================
🔄 Round 87 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 87 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0074
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0005
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0040

📊 Round 87 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0040

============================================================
🔄 Round 89 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 89 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0017
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0046
============================================================


============================================================
🔄 Round 90 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 90 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0029
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0234
============================================================


============================================================
🔄 Round 92 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 92 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0014
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0166
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0039

📊 Round 92 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0039

📊 Round 92 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0039

============================================================
🔄 Round 97 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 97 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0000
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0018
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0039

============================================================
🔄 Round 102 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 102 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0005
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0029
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0038

📊 Round 102 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2488, R²: -0.0038

📊 Round 102 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0038

📊 Round 102 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0038

📊 Round 102 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0037

============================================================
🔄 Round 108 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 108 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0009
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0026
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0037

📊 Round 108 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0037

============================================================
🔄 Round 112 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 112 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0018
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0053
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0037

📊 Round 112 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0037

============================================================
🔄 Round 115 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 115 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0036
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0256
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0037

============================================================
🔄 Round 118 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 118 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0005
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0006
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0037

============================================================
🔄 Round 120 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 120 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0004
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0005
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0037

============================================================
🔄 Round 121 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 121 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0021
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0084
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0037

============================================================
🔄 Round 123 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 123 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0041
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0301
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0037

============================================================
🔄 Round 125 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 125 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0027
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0031
============================================================


============================================================
🔄 Round 126 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 126 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0006
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0046
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0036

============================================================
🔄 Round 128 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 128 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0015
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0050
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0036

📊 Round 128 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0036

============================================================
🔄 Round 131 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 131 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0004
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0023
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0036

============================================================
🔄 Round 134 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 134 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0013
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0024
============================================================


============================================================
🔄 Round 135 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 135 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0030
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0174
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

============================================================
🔄 Round 137 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 137 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0029
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0129
============================================================


============================================================
🔄 Round 138 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 138 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0024
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0077
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

============================================================
🔄 Round 139 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 139 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0009
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0061
============================================================


============================================================
🔄 Round 141 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 141 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0010
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0080
============================================================


============================================================
🔄 Round 142 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 142 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0011
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0020
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

============================================================
🔄 Round 143 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 143 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0029
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0183
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0036

📊 Round 143 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0036

📊 Round 143 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0036

============================================================
🔄 Round 147 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 147 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0007
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0045
============================================================


============================================================
🔄 Round 148 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 148 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0032
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0108
============================================================


============================================================
🔄 Round 149 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 149 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0027
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0110
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0036

============================================================
🔄 Round 150 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 150 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0022
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0108
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2489, R²: -0.0036

📊 Round 150 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0036

============================================================
🔄 Round 155 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 155 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0045
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0668
============================================================


============================================================
🔄 Round 157 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 157 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0032
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0174
============================================================


============================================================
🔄 Round 158 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 158 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0004
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0006
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0036

📊 Round 158 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

============================================================
🔄 Round 161 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 161 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0021
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0062
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0036

============================================================
🔄 Round 162 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 162 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0034
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0102
============================================================


============================================================
🔄 Round 163 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 163 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0027
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0125
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

📊 Round 163 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

============================================================
🔄 Round 165 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 165 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0035
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0191
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

📊 Round 165 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

============================================================
🔄 Round 170 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 170 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0050
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0138
============================================================


============================================================
🔄 Round 172 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 172 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0015
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0101
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0034

============================================================
🔄 Round 173 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 173 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0020
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0201
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0034

============================================================
🔄 Round 174 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 174 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0021
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0162
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0034

📊 Round 174 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

📊 Round 174 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

============================================================
🔄 Round 178 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 178 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0009
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0030
============================================================


============================================================
🔄 Round 179 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 179 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0012
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0033
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0034

============================================================
🔄 Round 182 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 182 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0007
   Val:   Loss=0.0871, RMSE=0.2950, R²=-0.0083
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0034

============================================================
🔄 Round 185 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 185 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0034
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0324
============================================================


============================================================
🔄 Round 188 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 188 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0001
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0034
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

============================================================
🔄 Round 189 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 189 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0093
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0049
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

📊 Round 189 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

============================================================
🔄 Round 192 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 192 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0019
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0006
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0034

📊 Round 192 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0034

============================================================
🔄 Round 194 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 194 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0015
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0048
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0034

============================================================
🔄 Round 196 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 196 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0031
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0172
============================================================


============================================================
🔄 Round 197 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 197 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0031
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0182
============================================================


============================================================
🔄 Round 198 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 198 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0007
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0011
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0035

============================================================
🔄 Round 199 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 199 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0002
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0013
============================================================


============================================================
🔄 Round 201 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 201 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0023
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0016
============================================================


============================================================
🔄 Round 203 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 203 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0009
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0011
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0034

============================================================
🔄 Round 208 - Client client_97
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 208 Summary - Client client_97
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0024
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0065
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2489, R²: -0.0034

❌ Client client_97 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_status:14, grpc_message:"Socket closed"}"
>
