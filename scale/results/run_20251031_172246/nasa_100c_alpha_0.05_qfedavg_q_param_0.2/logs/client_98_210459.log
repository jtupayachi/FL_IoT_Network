[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 331cfa46-badb-4547-bde4-db21e9befa1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a38526b-bfa2-4ae8-8bfe-02830afcb26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d132be9e-0c2f-4639-bc1a-990fb9a63c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8207ddf5-d0f6-4b2b-965c-cd8a4cb6d022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce1dcf02-0b89-4a01-84bf-d2c70c9ece5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbe1c28-4316-4680-bf21-c2238dbe956d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8a4b14e-a6a3-4349-b828-008137279b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daac372b-d205-419e-a260-39f5d08a6147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cce006b5-7632-4c1f-aba8-e7477eaee1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1add1e9b-ae96-4b17-9505-cdb177c55b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e62667f-d053-4b9c-82b2-69bc60f34417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 480c7d18-654c-41eb-95da-f9ecfe7e0fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7d39133-c78d-4d90-abfd-97403289120e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e0ee7c3-500a-4ad4-a8b5-8a77ffcc9d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10d41597-4737-4eec-9bfa-4b257b76d790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f207c065-c2d5-40c0-bc9d-1eb21356dc0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78a0a202-00ee-4420-afab-aa17465c8f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f34630f-d53e-4714-9c81-eab6778e3c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d029a4-5c23-4f4c-b68a-19e814421729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bdeaafc-30e6-4110-9a6a-3d95ec722c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a9a221-a42b-4139-bb21-f492669cd290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e74ba2e-e0d8-45b1-96d1-78edd57cfa56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a108d886-7b8c-4286-ae6c-355ebfd53fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b18761f-3a68-450c-bb52-3077e5b8713c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a50f8e-c82b-40b5-8f68-86eb087ea624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10bf2dc-a1e6-4f38-9ac2-c8f4de13edd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 810e9eca-b3f8-476b-a53d-2c6707a39e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b473630-7816-4fb9-b392-67feddca1d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message accb81da-75b8-4ea3-9ddd-48b2fb7c4990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 084995f1-3705-4838-a3ab-9677d248594f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3e0770c-b8ec-4d81-917e-d8c9b2fd1682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d25ae8e-8782-463a-aba7-39c80569305f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3adb39c-aafe-438f-90db-eca9cbb515fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f43d6a8-9191-4b5c-8861-502262256afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1361036f-603e-48de-b273-1eb91f120123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4191e7ca-b836-4327-8c26-2a3c7df42c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f13698a-b48b-4cb5-b374-cbc95706bfeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2457995a-0177-4278-9ae4-688b9ddf7f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3416f059-a283-4c43-92d4-1ee667abfc98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fe4fd07-bae9-4896-a71d-f41911801a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb60ca62-bc95-4551-859c-6520f78d817b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd5e879e-37ee-4936-85e6-5fa71dcc20bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81f7d76-ca94-4430-ba52-f190a02caaa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4695cee4-ff38-4cba-854d-c2e5e8a57849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be58bf30-3be1-4f0a-b915-1f0026efc4f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 311c4e81-2591-49e0-a68e-bf5022087dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8a660bd-075a-46b2-93f8-492e57b45914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a8e558-2349-43b9-beed-d74d0fd976d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 710e51b9-79b7-42e8-88b5-01cc60591741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5bcde03-2bd7-412f-bf37-ae8d560d7e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12a7990a-8970-4e3b-aeea-ddadad2fbc4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac9096c0-26a7-4b04-b5a2-dc9176137167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6efd472d-7a4e-4e14-87b2-f89dca7c9785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e3dc794-4c0a-4ba0-ad8d-05fdba56a93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a830a9ee-428d-444e-ace1-643fd3e91414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f4fa41f-7b92-44ad-bbbf-df2571a072d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18ab0202-2908-4587-aed2-49e6cbe8ff82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f0b254-91bf-4b14-a699-89768dc9f8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1964f41-8188-4998-8828-3b69ab7eed94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2f6c726-1dda-4d50-ac18-a7e503832256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31b3d47b-74c0-496c-b838-3f7fab1cfc4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bace5daa-3f13-4dc0-b4db-d626a3d3470b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7c0692e-3e97-400e-a6d2-d26fc2521e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e239f073-5300-450c-a6be-8b12e7b7cb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff390ed8-64ef-44d8-a84e-ebf1a02d3196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec4cc7c-d733-4796-8581-9be2bd523aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd77f1a0-878a-48ec-9789-595fd11f84ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8e50b20-6ef6-4669-ba43-cd45739ddc60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c9a2ee7-5f54-44d5-ad32-22db76011f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 093799be-f700-498e-84ad-4234e1d22456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4557628f-abbf-4967-b572-6beb3a4f7a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d68611-42c8-4c05-95ea-0f1fcc83902d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98bcd2c3-08f5-4343-bd7c-7d324bb1c1f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73942916-db22-4214-9388-dd91c2605c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 286f39e4-44b3-46f4-8945-42548784ddd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 672bc9cd-0515-40c4-9d68-a2006e8e532d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39b18841-388f-4c40-960f-28bbbb92ba97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19df6c0d-1327-4d6b-b23a-72173d0c4bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8067ffb5-ec35-4f7b-b9e6-0d77977b9d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 140de46b-e811-420e-ae14-9ff442f4adcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a1158f2-cf20-4f4a-b367-eac0a3c386e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0bcf7cc-ef5f-411c-aac4-e8c32af7cc7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e724cfdf-e8fb-41a9-a2e4-6b620945b86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c05d49ca-bf40-4903-b9d8-99024bf45bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7922223a-b3d5-40a0-8175-4ab43c70cf79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3692bee-deb4-4e47-b254-2eaf47c892d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb0eea5e-f1fe-41a0-889b-0a1cb4b6659d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e54cfa7c-d89c-408b-817e-64b367e83546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfc07619-a38c-4354-8e8d-a76cdf044efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 083b2069-66b6-4a27-9251-6803fb707574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 547439e8-40d5-46d1-becd-1b5438c0e907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d5910ef-6a48-4c0a-8934-03f72a5b934a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e959b8-e96c-4ce0-9ed9-dddfb1a89323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34d69416-af19-4407-9cc7-f5f2888e7cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b21c9442-33be-4bb0-85a3-b155f8dc7323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52731371-0e95-4962-a5f3-6026a263f413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84e9ee25-c7cf-474d-8ff9-dbf59ad86c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b3ed33-dec7-407f-868d-4b8867ea5725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf716af4-6733-4e96-8615-980a098d3723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b479bce-4cc7-46a6-93fc-570035b9170a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9fb1f81-116e-4df2-ad4b-69815fa75c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dadef51a-a53b-4956-92fd-1592d4515762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e805daf0-d466-4b6c-8982-aa8c4ee9617f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c33fb3d-874f-4381-be12-eed2a956797b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 835dd7e1-c3e9-46a0-b149-02adf38d9182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2657f71-96e3-47e9-9273-4305fdaa25e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e79b6977-c8b8-4571-b97f-401010d8b47b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29333202-aab6-4e23-996d-85fdf0d89d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b00a5b9c-dec9-4cc8-bf59-85b42119c5d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 691d531a-fb81-45d5-b07d-ae95b0d75cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd45f4a9-893a-4290-8a9f-d4effcff9b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dbc9741-cf5f-46c0-aa12-f674033e9f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3418ab3e-86bf-48a2-9c77-fadaf96c6ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9f2806a-ad08-40c8-acb7-aac1046d39ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e72099-f31b-4342-82a8-57ec635e6b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b86097-ab3d-459c-bc29-b114389cfd0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc915ad-0687-49e7-a72a-e7844d5b15af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2a1bac6-4b08-4eda-854b-a66e76687e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17d1fbb7-f473-49ff-bfe0-4c34b044a24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e4d7e3b-ee40-4222-85be-5fc6ebb34a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ea4237-f13c-47e7-9687-89120de95d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcfb27aa-b4c8-478c-ad28-6babd6162cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18159f22-0efa-4d07-b5f4-645dc38c5b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530fb006-9d5d-4213-aa43-42efa500d839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4066c38a-3e9b-4b91-9a23-642fb06a75fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d19090d8-a369-4a98-9583-ca1e3b6e9e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf0771b-8d88-4318-81c2-6beca4adeb47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06822ee3-98b5-460f-b8aa-ed165e8881a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 766e62eb-2251-4283-84ee-2e01247ba79d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d70b60-e30d-4bdd-b4ca-087424ba1ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f0519ef-a49c-4dd5-ab65-1954f8076f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 976f44b5-b6f0-413e-ae3e-d2df3261dd82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec1ca22-c458-483e-93d0-e5dc0d3cc237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44891367-149c-4273-86fe-02454235021f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1817f752-cf4e-4be0-b102-e2523c5db7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8810b341-5a46-494d-9d83-5f3b16a9443f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 117ffb70-d1ad-4331-b493-ad90b0cb4dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8657b2a-7893-40f4-8282-4b13e1c156da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b20ea143-5e6e-4da7-b6bf-0413d51f3e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 333046c6-4c06-4a38-8120-b9dc6c543f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b60b04ea-8160-4c22-888c-c3a065ad0371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6296ee57-a736-471b-aca6-09779deaaad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ae04bd8-6c01-4a63-8546-9c942c092da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad457e6-0417-4504-8482-fb26cf3787a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac65b278-d5bd-4591-b160-c101c816f9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84819481-c3d2-492f-9656-a1d4592c3a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87364f35-510c-4a1d-9e26-26781e973e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07fa0bdf-1bf1-4128-a4a8-e62b827fe44a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_98
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/test_labels.txt

📊 Raw data loaded:
   Train: X=(1000, 24), y=(1000,)
   Test:  X=(251, 24), y=(251,)

⚠️  Limiting training data: 1000 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  242 samples, 5 features
✅ Client client_98 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1642, RMSE: 0.4052, MAE: 0.3353, R²: -1.1716

============================================================
🔄 Round 11 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1032, val=0.0786 (↓), lr=0.001000
   • Epoch   2/100: train=0.0895, val=0.0809, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0866, val=0.0787, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0859, val=0.0788, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0860, val=0.0791, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0835, val=0.0790, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 11 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0002
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0111
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.1597, RMSE: 0.3996, MAE: 0.3303, R²: -1.1120

📊 Round 11 Test Metrics:
   Loss: 0.1480, RMSE: 0.3847, MAE: 0.3171, R²: -0.9579

============================================================
🔄 Round 14 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1207, val=0.0888 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0864, val=0.0811 (↓), lr=0.000250
   • Epoch   3/100: train=0.0869, val=0.0809, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0857, val=0.0803 (↓), lr=0.000250
   • Epoch   5/100: train=0.0860, val=0.0803, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0855, val=0.0802, patience=7/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 14 Summary - Client client_98
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0018
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0040
============================================================


============================================================
🔄 Round 17 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1210, val=0.1050 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1026, val=0.0888 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0900, val=0.0812 (↓), lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   ✓ Epoch   4/100: train=0.0859, val=0.0801 (↓), lr=0.000031
   • Epoch   5/100: train=0.0858, val=0.0801, patience=1/15, lr=0.000031
   • Epoch  11/100: train=0.0857, val=0.0803, patience=7/15, lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 17 Summary - Client client_98
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0009
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0081
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.1119, RMSE: 0.3346, MAE: 0.2764, R²: -0.4806

📊 Round 17 Test Metrics:
   Loss: 0.0985, RMSE: 0.3139, MAE: 0.2615, R²: -0.3032

📊 Round 17 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2495, R²: -0.1548

============================================================
🔄 Round 20 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0921, val=0.0869 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.0908, val=0.0858 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.0900, val=0.0849 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.0892, val=0.0842 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.0886, val=0.0835 (↓), lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.0867, val=0.0815 (↓), lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0862, val=0.0809, patience=4/15, lr=0.000002
   📉 Epoch 25: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0861, val=0.0807, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 20 Summary - Client client_98
   Epochs: 32/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0018
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0142
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2385, R²: -0.0316

============================================================
🔄 Round 23 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 23 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0106
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0045
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2381, R²: -0.0278

📊 Round 23 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2375, R²: -0.0225

📊 Round 23 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2373, R²: -0.0209

============================================================
🔄 Round 31 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 31 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0013
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0192
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0770, RMSE: 0.2774, MAE: 0.2369, R²: -0.0180

============================================================
🔄 Round 34 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 34 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0005
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0197
============================================================


============================================================
🔄 Round 35 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 35 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0040
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0067
============================================================


============================================================
🔄 Round 36 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 36 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0018
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0077
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2367, R²: -0.0162

📊 Round 36 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2367, R²: -0.0159

============================================================
🔄 Round 39 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 39 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0005
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0072
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2366, R²: -0.0152

📊 Round 39 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2366, R²: -0.0151

============================================================
🔄 Round 44 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 44 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0034
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0084
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2366, R²: -0.0146

📊 Round 44 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2366, R²: -0.0144

============================================================
🔄 Round 48 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 48 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0039
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0026
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2365, R²: -0.0141

============================================================
🔄 Round 50 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 50 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0009
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0490
============================================================


============================================================
🔄 Round 51 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 51 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0016
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0068
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0766, RMSE: 0.2769, MAE: 0.2365, R²: -0.0138

============================================================
🔄 Round 52 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 52 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0010
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0003
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2365, R²: -0.0138

============================================================
🔄 Round 54 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 54 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0006
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0031
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2365, R²: -0.0139

📊 Round 54 Test Metrics:
   Loss: 0.0766, RMSE: 0.2769, MAE: 0.2365, R²: -0.0138

============================================================
🔄 Round 57 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 57 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0009
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0021
============================================================


============================================================
🔄 Round 58 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 58 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0000
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0022
============================================================


============================================================
🔄 Round 60 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 60 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0011
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0035
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0766, RMSE: 0.2768, MAE: 0.2365, R²: -0.0135

📊 Round 60 Test Metrics:
   Loss: 0.0766, RMSE: 0.2768, MAE: 0.2364, R²: -0.0131

============================================================
🔄 Round 66 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 66 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0028
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0252
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2364, R²: -0.0128

============================================================
🔄 Round 69 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 69 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0038
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0132
============================================================


============================================================
🔄 Round 72 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 72 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0007
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0047
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0765, RMSE: 0.2767, MAE: 0.2363, R²: -0.0124

============================================================
🔄 Round 75 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 75 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0012
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0044
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2363, R²: -0.0121

📊 Round 75 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2363, R²: -0.0119

============================================================
🔄 Round 77 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 77 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0018
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0031
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2363, R²: -0.0117

📊 Round 77 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2363, R²: -0.0119

============================================================
🔄 Round 79 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 79 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0032
   Val:   Loss=0.0897, RMSE=0.2996, R²=0.0092
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2363, R²: -0.0118

📊 Round 79 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2363, R²: -0.0117

📊 Round 79 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2363, R²: -0.0116

============================================================
🔄 Round 86 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 86 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0008
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0029
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2363, R²: -0.0117

📊 Round 86 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2363, R²: -0.0116

============================================================
🔄 Round 88 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 88 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0004
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0103
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2363, R²: -0.0114

============================================================
🔄 Round 93 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 93 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0007
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0114
============================================================


============================================================
🔄 Round 94 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 94 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0008
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0044
============================================================


============================================================
🔄 Round 95 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 95 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0005
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0036
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2362, R²: -0.0111

============================================================
🔄 Round 100 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 100 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0021
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0012
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2362, R²: -0.0107

============================================================
🔄 Round 102 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 102 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0000
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0264
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2362, R²: -0.0106

============================================================
🔄 Round 104 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 104 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0015
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0048
============================================================


============================================================
🔄 Round 105 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 105 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0020
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0125
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2362, R²: -0.0105

============================================================
🔄 Round 106 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 106 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0031
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0141
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2362, R²: -0.0104

============================================================
🔄 Round 107 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 107 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0050
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0083
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2362, R²: -0.0102

============================================================
🔄 Round 109 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 109 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0005
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0122
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2362, R²: -0.0102

============================================================
🔄 Round 110 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 110 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0009
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0023
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2361, R²: -0.0100

============================================================
🔄 Round 116 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 116 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0014
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0033
============================================================


============================================================
🔄 Round 117 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 117 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0028
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0128
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2362, R²: -0.0102

📊 Round 117 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2361, R²: -0.0101

📊 Round 117 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2361, R²: -0.0101

============================================================
🔄 Round 120 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 120 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0014
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0273
============================================================


============================================================
🔄 Round 121 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 121 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0008
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0039
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2361, R²: -0.0099

📊 Round 121 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2361, R²: -0.0100

============================================================
🔄 Round 124 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 124 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0002
   Val:   Loss=0.0940, RMSE=0.3067, R²=-0.0074
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2361, R²: -0.0097

============================================================
🔄 Round 127 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 127 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0003
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0003
============================================================


============================================================
🔄 Round 128 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 128 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0002
   Val:   Loss=0.0954, RMSE=0.3089, R²=0.0024
============================================================


============================================================
🔄 Round 130 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 130 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0009
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0078
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2361, R²: -0.0097

============================================================
🔄 Round 131 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 131 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0014
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0063
============================================================


============================================================
🔄 Round 132 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 132 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0015
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0013
============================================================


============================================================
🔄 Round 134 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 134 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0016
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0069
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2361, R²: -0.0094

📊 Round 134 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0093

📊 Round 134 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0093

============================================================
🔄 Round 139 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.1009 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.1009, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.1009, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.1009, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.1009, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.1010, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1009)

============================================================
📊 Round 139 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0038
   Val:   Loss=0.1009, RMSE=0.3176, R²=-0.0230
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0092

📊 Round 139 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0092

📊 Round 139 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2361, R²: -0.0094

📊 Round 139 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2361, R²: -0.0095

📊 Round 139 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2361, R²: -0.0096

📊 Round 139 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2361, R²: -0.0095

============================================================
🔄 Round 151 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 151 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0010
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0063
============================================================


============================================================
🔄 Round 153 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 153 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0003
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0022
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2361, R²: -0.0095

📊 Round 153 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2361, R²: -0.0094

📊 Round 153 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2361, R²: -0.0094

============================================================
🔄 Round 163 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 163 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0003
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0013
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0093

============================================================
🔄 Round 164 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 164 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0001
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0017
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0092

📊 Round 164 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0091

📊 Round 164 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0089

============================================================
🔄 Round 169 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 169 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0012
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0123
============================================================


============================================================
🔄 Round 170 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 170 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0038
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0131
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0088

============================================================
🔄 Round 172 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 172 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0007
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0046
============================================================


============================================================
🔄 Round 173 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 173 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0000
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0018
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0087

📊 Round 173 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0088

============================================================
🔄 Round 177 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 177 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0010
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0069
============================================================


============================================================
🔄 Round 178 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 178 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0002
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0007
============================================================


============================================================
🔄 Round 180 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 180 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0031
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0137
============================================================


============================================================
🔄 Round 182 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 182 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0004
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0052
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2360, R²: -0.0086

📊 Round 182 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0088

============================================================
🔄 Round 187 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 187 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0011
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0073
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0089

============================================================
🔄 Round 190 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 190 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0003
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0136
============================================================


============================================================
🔄 Round 192 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 192 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0011
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0024
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0763, RMSE: 0.2761, MAE: 0.2360, R²: -0.0085

============================================================
🔄 Round 196 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 196 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0006
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0002
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0088

============================================================
🔄 Round 198 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 198 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0011
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0009
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2361, R²: -0.0087

============================================================
🔄 Round 200 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 200 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0014
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0400
============================================================


============================================================
🔄 Round 202 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.1012 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.1012, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.1012, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.1012, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.1012, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.1012, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1012)

============================================================
📊 Round 202 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0032
   Val:   Loss=0.1012, RMSE=0.3181, R²=-0.0112
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2360, R²: -0.0084

📊 Round 202 Test Metrics:
   Loss: 0.0763, RMSE: 0.2761, MAE: 0.2360, R²: -0.0086

============================================================
🔄 Round 207 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 207 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0018
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0144
============================================================


❌ Client client_98 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
