[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fa75650-1084-4804-91bf-d6f2ca5f9af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e5d405-6987-47f6-b749-19411b5fbd30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b725aa63-db43-4975-ae7d-0afb30072e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cee0cb32-742f-478b-aa86-93cdcd649d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 556f9ded-f742-4ad2-aaf2-8614417b993d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5515aa81-e104-437f-a495-f8e116854741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e3e8dbb-7ee1-4e70-995d-66dadac8c491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb28867a-d277-41e9-abc7-f70f34a7f983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56d0a309-4fa6-445f-a8da-d1110e33170f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ecf9e14-ea0b-44dd-b859-b623d4833d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c76a081-2fbd-4bda-b3aa-b4d68b462ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdfc8a59-385f-481a-af48-dd57d24e95ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d541b38b-f9da-4f6d-913f-2d2f8834c4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bcaeff3-fb92-48bf-8867-18d2827dacd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40837262-5323-48ca-9e60-a9eee7199f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 246a1068-2d9b-4ea9-b014-e4e49c59d996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39a12db9-8afa-4cfe-8105-0e8808593677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5111e923-6584-4ba0-a668-12d8cbd5c186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9f29143-2a4c-471e-b341-038354efb96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4accdf7a-a55b-4059-a3fa-1621247196f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d50eec80-5f1b-4408-b03c-df47bff5e13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2439a784-b1a6-4e2e-bde8-36e201cfff37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2136480f-2c60-485d-8c31-41026fcfba8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec363857-782b-41e4-88e2-ceaeda9811bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a531fc0-3314-4105-86bf-f55cd25b687c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7c26fc5-4c3f-41b0-b432-8c6427cbd985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e3f970-9cdc-4698-ab3d-6cedbddf0373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1280c371-76d9-4919-bf99-9050fdcf4b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d6d9a70-b1ba-4bcc-87eb-c5079faab65a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2d7ca53-6eac-4dc5-b7b5-9e950e61e9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3174e8c2-dead-4c41-bf0f-f39afb94e94e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4098f822-a32a-4280-97fd-2e52e58db236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f43826a-b95e-4bab-867b-6733e859d03e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d10b5bc-2ba4-4fe1-8ed0-99bf75074839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb40f342-3631-4be3-941b-467c76cefed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ec80cf-fed3-477f-b134-bd5ebf69d940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4994aa6-e4ab-4de9-94e6-ec1852b992a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee98c5c7-696f-4d82-8b12-ed7105c1c297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29491d9e-eeb5-4288-8c21-23d568b2ab8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed321f25-fb6e-479b-b53c-168698019f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 495ca88c-86ad-40d4-81d8-1023a45a5dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c780025a-db9a-4843-bb8d-a817231e6ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 622f3487-779d-403a-9adf-5f3647762e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944d2177-f9b6-43af-8a0d-a2d7b83db146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 201adf46-f547-409e-b68f-ae200e6951c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f87fcbb-ea4b-46de-acae-b1c96be75980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0866329a-089f-4d2b-91d2-54f802c4f665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86b07123-c1c4-4abe-a884-66b3b155edaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c89b0271-0813-499a-a154-e3cf1299acb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0397eaa-78e5-4aa5-8705-7aee015912a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f03da47c-ec69-4550-b837-17eca5cb78f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce5ce68-22ed-49c7-886a-bc70f89ef4fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 852abb4e-0c43-4802-852b-7f6504d32d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cb41062-235f-4c7c-9aef-d49ed22c1d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4823a07-6da5-4dba-9336-ed5a74d37e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf09a777-0152-41ef-825f-d436c75e6f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 539d9cfc-6e1d-41f4-931e-e1cf15be1c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a38e8e93-4265-41ce-81f0-1775292f0ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca4f5001-97bc-4d71-be45-e375c7584e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc004fc-d792-4c7f-bf64-e829ad4dcb78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db127e6b-436a-48a7-a7d8-89cbf5da5b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 118d9890-6c27-4d7c-b61d-1800b5b8e3d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bd5da7d-3ed5-447a-bc94-3086cad6931e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73cee66-6e2d-42c9-983a-1b2182cf87b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43962024-9ae0-4d01-adff-f1a037a7797a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 541c2009-bcb3-49d0-8b2e-492caa59b798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cdf3a33-46e9-40d4-a1d6-055ff23081de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4d0144d-fefa-4952-968a-4f4cc165502d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71f1bbb6-5290-431d-8f99-97020874dbc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 686ca16f-b5de-422f-a905-de3c762c225c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc9c12de-e468-45b0-904f-f318d6396b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d2da4a-540c-4b5f-9f2f-491d113bac40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45534abc-ab94-4827-8457-d4a9f46c9381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c46f549-5c39-49e6-b1e7-9583ffb3db9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 841fd74e-ef39-4bcd-a200-94923853b8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad8a06d1-280a-4847-9fda-9956979f6655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2eb2e19-4b12-4be5-88e9-d3e0017d7c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e472b2dd-df17-4aaa-911b-4d67656b7f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0480515-fc0f-4d86-9b60-3cb32dddcea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda3b783-da8b-4deb-a5d3-d80725fd5798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547c4701-0ac9-474d-9449-9e9967614873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdb6499f-ba5a-413d-80b4-fb2055d9fdb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e25c1a89-8ca0-4743-ba7b-78e981162829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9338efb7-4ad7-4c2f-bfcd-0f2625685327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4393e62-02f9-42a2-9cdd-56c3e9a5e68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c89c82-4703-4936-a0da-c79c9569076f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e8ced90-d643-42c3-94d2-e6f11f9538d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f4dbf02-66b7-4896-9a91-15b72da4f692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 712c713b-4634-4615-97f3-8346b31e3dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9add1448-5e45-44da-b503-3f28f5552fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8d6a9f4-301b-4c69-b8a6-32566c33028a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7112b5b-c637-40b2-a648-0f91dc144eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf62c7e-5100-45bf-83cb-d7a7427da2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c98bfad6-04e9-445f-8656-eaba40623693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0498f14d-ce76-43d8-8db7-1f6568ac778f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b1ca34c-91b6-4ed8-b082-4131587180c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 880de0ed-43d1-4570-8233-17de1c150e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98199bd4-0b44-4f3f-8d97-7be27ec81e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98288f7f-6f49-44a3-ab27-4fd0cff37f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 672cde62-19f2-438b-b32e-d95072e80041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 076a2247-c129-4d87-a2e0-5e9aa66dbcda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f74b45af-8608-402b-ae40-b0def71f773a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd4c67f2-86c9-4473-bb75-57f2b0eced61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 188aba8b-b353-4d27-aadf-4877e0c197bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3efc55e-8cc1-4137-b29b-81dcc5ab7b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01f1477b-aea5-4fce-be6c-486f23af53ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 238f2246-322c-4b11-9e84-5145fba8847c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e167a77-4fe5-4951-8820-eb0f801bc5f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b15e44-68d6-403b-ba42-c066ef8c59ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d70aa43c-ab5a-46dd-a6dc-ed57a4ccfec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb680e77-a08e-43d9-8aa9-4f37f1890fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 134137a9-4898-4298-833f-5060aa317f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d360418c-04b2-49ef-bd20-887c2e38ba50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7043d099-25a2-4225-bdd7-6b186ef2fdd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 551baa21-7e94-47a3-9a12-57e38f6c7206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d811db5-13a8-4ed3-b2cf-e8133464dc83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcf4ea03-fdb9-41f4-971b-fe07e0901db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba9f6f5c-530b-433d-be54-eee3a595a4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5ba437e-bd90-4a62-bbc6-08328ad9ac7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9468e0ca-dfd4-4da1-ac96-45469307cd2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 936f50d2-70e7-4edd-8a26-b7ec686c03b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a077fd73-2c1a-4256-b460-34c852d7a8e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdc6c9b0-6e7e-423a-a031-7f4f7e3e1499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d12a96aa-276c-4bf3-9758-dd4a1b48593a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2d773e1-bbb6-4e36-8723-a52ec4d6443a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4961947d-d050-4ba7-a8c2-faf2d343181e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5839cee1-b730-4e83-a715-e7de9b98c52e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17359d7e-f792-4a62-87c6-a01d03c70155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e55cfe-9a5e-43fe-9830-9bdf74975bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1fc7847-eb5c-42ed-a260-39e6ca19fe69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 214c2ef7-12d9-426a-98a4-d212217f5f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04249699-c2a7-48c8-862a-ffb3a6f0be7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 423aff1f-4a10-45ee-bcb5-65be35733ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a12830-9ef0-447a-a370-4b5c0425ba43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f87cdd5-5172-4da6-b87a-7d8db8aec294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee6e3bb3-d5f0-4d93-817a-e0626092c157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a74d95-3710-484e-b22c-e4c3d7612806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62462043-b093-4179-a610-5c063d0e2dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95a3363c-fb09-4576-b096-38a563794f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab81e4a2-0c6d-4e4b-ba76-746b0aa51747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88b33e43-aaa3-4293-b32a-aee33e5dd053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a3bd0c6-6358-4ee4-9c53-5bc8e1def6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 359a07f3-11f8-4791-92ba-3d0f42474bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f004f86-7eaa-4ad5-a904-ad6f90b7c2ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd80db6e-6f77-4891-a6b4-8c9d1a9afdc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 482de0fc-3a80-4f3c-9cbf-b63768e1f62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5ff0a49-f5ab-4cfd-96a6-22fe6ea506f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04a22c98-1bd6-42e0-9b75-d1d3d6f9d575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e203940-98d6-477b-8619-537c44456fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c4924f-e250-4e8d-bf34-ca32f625ddb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b9bece7-5222-4459-8879-157d91d95677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b62b90a-2047-4aff-996e-f2390b088bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5253c114-12f0-4fc7-8a42-eba54d20349a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d085039a-c0f4-4136-8b0b-44bd2521ef7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a90a83-7148-4ba5-9ad1-0074f50c5134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b51b468-148e-4115-991a-02a346f5db37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9898dcf6-07dc-43ff-b6a2-e22bb34bb691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 267947ac-d4e1-44fc-b94d-006cad61751d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8d717a1-1738-4153-ac9a-8d5ab7b3ff83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cdf300f-0950-4302-a9da-5cd5333027d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62224b16-9576-435e-b41b-bce269b6326d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54cc3d2-4a71-40b2-9cbe-34be6b48e805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9fc200f-c1f7-4d71-961c-3c5a4cab3eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d91cbe89-a566-4031-9ead-9db03fc8050d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a27ec26-5d71-4ca2-9162-f383ea84651d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c2be0a6-6a4d-487e-b8f2-a2a41eaea7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93099cda-ba5a-428f-ac72-f54858bca9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4cb1b0b-8336-433e-af80-6085b1774619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87c25ab0-2368-41ff-a5ae-67368ab2b8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 995483da-b135-450c-9b45-b99996eb781c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11a9508f-e640-45f1-8d1e-ad4ce5427f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3764edb7-a7d9-465a-b5c4-9d86c317844b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a245b1ad-3e10-4f8f-a3d2-b553744ad409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bef93534-117e-4694-a921-4dc253961654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7022cab-2630-4725-85b9-a0a6510f1fee
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_99
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_99/test_labels.txt

📊 Raw data loaded:
   Train: X=(339, 24), y=(339,)
   Test:  X=(85, 24), y=(85,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 330 samples, 5 features
   Test:  76 samples, 5 features
✅ Client client_99 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 12 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1258, val=0.0835 (↓), lr=0.001000
   • Epoch   2/100: train=0.0883, val=0.0906, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0858, val=0.0846, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0821, val=0.0878, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0824, val=0.0897, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0810, val=0.0906, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 12 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0017
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0044
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.1287, RMSE: 0.3587, MAE: 0.2776, R²: -0.4919

============================================================
🔄 Round 14 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1438, val=0.1260 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1255, val=0.1098 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.1066, val=0.0974 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0918, val=0.0916 (↓), lr=0.000250
   • Epoch   5/100: train=0.0841, val=0.0927, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0804, val=0.0926, patience=7/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 14 Summary - Client client_99
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0551
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0015
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.1204, RMSE: 0.3470, MAE: 0.2695, R²: -0.3958

============================================================
🔄 Round 15 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1414, val=0.1436 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1371, val=0.1371 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1313, val=0.1300 (↓), lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   ✓ Epoch   4/100: train=0.1253, val=0.1230 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1209, val=0.1197 (↓), lr=0.000031
   ✓ Epoch  11/100: train=0.1063, val=0.1021 (↓), lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016
   📉 Epoch 20: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0963, val=0.0902, patience=1/15, lr=0.000008
   📉 Epoch 28: LR reduced 0.000008 → 0.000004
   ✓ Epoch  31/100: train=0.0935, val=0.0865 (↓), lr=0.000004
   📉 Epoch 36: LR reduced 0.000004 → 0.000002
   • Epoch  41/100: train=0.0925, val=0.0851, patience=3/15, lr=0.000002
   📉 Epoch 44: LR reduced 0.000002 → 0.000001
   • Epoch  51/100: train=0.0921, val=0.0845, patience=7/15, lr=0.000001
   • Epoch  61/100: train=0.0918, val=0.0840, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.0915, val=0.0835, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0912, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0909, val=0.0826, patience=2/15, lr=0.000001

============================================================
📊 Round 15 Summary - Client client_99
   Epochs: 100/100
   LR: 0.000063 → 0.000001 (6 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0279
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.1274
============================================================


============================================================
🔄 Round 17 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1335, val=0.1247 (↓), lr=0.000001
   • Epoch   2/100: train=0.1334, val=0.1246, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1332, val=0.1245, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1330, val=0.1243, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1329, val=0.1242 (↓), lr=0.000001
   • Epoch  11/100: train=0.1319, val=0.1234, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.1304, val=0.1222, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.1291, val=0.1210, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.1278, val=0.1200, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.1266, val=0.1190, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.1254, val=0.1180, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1242, val=0.1171, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.1231, val=0.1161, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.1220, val=0.1152, patience=1/15, lr=0.000001

============================================================
📊 Round 17 Summary - Client client_99
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1212, RMSE=0.3481, R²=-0.4741
   Val:   Loss=0.1144, RMSE=0.3383, R²=-0.3457
============================================================


============================================================
🔄 Round 18 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1110, val=0.1198 (↓), lr=0.000001
   • Epoch   2/100: train=0.1109, val=0.1198, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1108, val=0.1197, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1107, val=0.1196, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.1107, val=0.1195, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.1102, val=0.1190, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.1094, val=0.1182, patience=6/15, lr=0.000001
   • Epoch  31/100: train=0.1085, val=0.1174, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.1077, val=0.1166, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.1070, val=0.1158, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1062, val=0.1151, patience=4/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1054, val=0.1143 (↓), lr=0.000001
   • Epoch  81/100: train=0.1046, val=0.1135, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.1039, val=0.1128, patience=6/15, lr=0.000001

============================================================
📊 Round 18 Summary - Client client_99
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1073, RMSE=0.3275, R²=-0.3174
   Val:   Loss=0.1121, RMSE=0.3348, R²=-0.2637
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0923, RMSE: 0.3038, MAE: 0.2506, R²: -0.0699

============================================================
🔄 Round 19 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1012, val=0.1046 (↓), lr=0.000001
   • Epoch   2/100: train=0.1012, val=0.1045, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1011, val=0.1045, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1010, val=0.1044, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.1009, val=0.1044, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.1005, val=0.1040, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0997, val=0.1033, patience=4/15, lr=0.000001
   • Epoch  31/100: train=0.0989, val=0.1027, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0981, val=0.1021, patience=6/15, lr=0.000001
   • Epoch  51/100: train=0.0974, val=0.1015, patience=7/15, lr=0.000001
   • Epoch  61/100: train=0.0966, val=0.1009, patience=8/15, lr=0.000001
   ✓ Epoch  71/100: train=0.0959, val=0.1004 (↓), lr=0.000001
   ✓ Epoch  81/100: train=0.0952, val=0.0998 (↓), lr=0.000001
   ✓ Epoch  91/100: train=0.0945, val=0.0993 (↓), lr=0.000001

============================================================
📊 Round 19 Summary - Client client_99
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0960, RMSE=0.3098, R²=-0.1854
   Val:   Loss=0.0988, RMSE=0.3143, R²=-0.0990
============================================================


============================================================
🔄 Round 20 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.1145 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.1144, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.1143, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.1142, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.1141, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.1136, patience=4/15, lr=0.000001
   • Epoch  21/100: train=0.0901, val=0.1126, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0897, val=0.1118 (↓), lr=0.000001
   • Epoch  41/100: train=0.0893, val=0.1109, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.0889, val=0.1100, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0886, val=0.1091 (↓), lr=0.000001
   • Epoch  71/100: train=0.0882, val=0.1083, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0879, val=0.1074, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0876, val=0.1066, patience=5/15, lr=0.000001

============================================================
📊 Round 20 Summary - Client client_99
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0332
   Val:   Loss=0.1059, RMSE=0.3254, R²=-0.4255
============================================================


============================================================
🔄 Round 21 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0907, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0850, val=0.0902, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0846, val=0.0898, patience=7/15, lr=0.000001
   • Epoch  41/100: train=0.0843, val=0.0894, patience=4/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0840, val=0.0891 (↓), lr=0.000001
   • Epoch  61/100: train=0.0837, val=0.0887, patience=10/15, lr=0.000001
   • Epoch  71/100: train=0.0835, val=0.0884, patience=5/15, lr=0.000001
   • Epoch  81/100: train=0.0832, val=0.0881, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 21 Summary - Client client_99
   Epochs: 81/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0217
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0541
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2526, R²: 0.0461

============================================================
🔄 Round 22 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 22 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0282
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0645
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2537, R²: 0.0452

📊 Round 22 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2542, R²: 0.0445

📊 Round 22 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2546, R²: 0.0434

============================================================
🔄 Round 25 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 25 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0168
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0273
============================================================


============================================================
🔄 Round 27 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 27 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0137
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0252
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2556, R²: 0.0404

============================================================
🔄 Round 30 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 30 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0129
   Val:   Loss=0.0966, RMSE=0.3108, R²=-0.0223
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2558, R²: 0.0396

📊 Round 30 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2560, R²: 0.0392

📊 Round 30 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2560, R²: 0.0389

============================================================
🔄 Round 39 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 39 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0039
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.2046
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2562, R²: 0.0385

📊 Round 39 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2562, R²: 0.0383

============================================================
🔄 Round 43 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 43 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0117
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0173
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2563, R²: 0.0379

============================================================
🔄 Round 44 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 44 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0075
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0544
============================================================


============================================================
🔄 Round 45 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 45 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0076
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0422
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2564, R²: 0.0375

📊 Round 45 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2564, R²: 0.0374

============================================================
🔄 Round 50 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 50 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0163
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0044
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2565, R²: 0.0373

📊 Round 50 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2565, R²: 0.0372

============================================================
🔄 Round 53 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 53 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0153
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0012
============================================================


============================================================
🔄 Round 54 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 54 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0138
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0028
============================================================


============================================================
🔄 Round 55 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 55 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0101
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0179
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2565, R²: 0.0370

============================================================
🔄 Round 56 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 56 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0135
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0016
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2565, R²: 0.0370

============================================================
🔄 Round 57 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 57 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0152
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0013
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2566, R²: 0.0367

📊 Round 57 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2566, R²: 0.0366

============================================================
🔄 Round 60 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 60 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0249
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0273
============================================================


============================================================
🔄 Round 61 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 61 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0042
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0540
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2566, R²: 0.0365

============================================================
🔄 Round 62 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 62 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0053
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0318
============================================================


============================================================
🔄 Round 65 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 65 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0046
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0465
============================================================


============================================================
🔄 Round 66 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 66 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0082
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0183
============================================================


============================================================
🔄 Round 69 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 69 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0224
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0460
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2568, R²: 0.0359

📊 Round 69 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2568, R²: 0.0357

📊 Round 69 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2568, R²: 0.0355

============================================================
🔄 Round 73 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 73 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0014
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.1002
============================================================


============================================================
🔄 Round 74 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 74 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0168
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0014
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2569, R²: 0.0352

📊 Round 74 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2570, R²: 0.0350

📊 Round 74 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2570, R²: 0.0348

============================================================
🔄 Round 82 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 82 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0139
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0028
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2570, R²: 0.0346

📊 Round 82 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2570, R²: 0.0346

📊 Round 82 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2570, R²: 0.0345

============================================================
🔄 Round 88 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 88 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0207
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0160
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2571, R²: 0.0343

============================================================
🔄 Round 89 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 89 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0011
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.1248
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2571, R²: 0.0342

📊 Round 89 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2571, R²: 0.0341

📊 Round 89 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2571, R²: 0.0340

📊 Round 89 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2572, R²: 0.0338

📊 Round 89 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2572, R²: 0.0336

📊 Round 89 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2572, R²: 0.0336

============================================================
🔄 Round 97 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 97 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0082
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0116
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2572, R²: 0.0336

============================================================
🔄 Round 98 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 98 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0089
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0145
============================================================


============================================================
🔄 Round 99 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 99 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0032
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0395
============================================================


============================================================
🔄 Round 100 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0642 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0642, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0642, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0642, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0642, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0641, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0642)

============================================================
📊 Round 100 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0090
   Val:   Loss=0.0642, RMSE=0.2533, R²=-0.0074
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2573, R²: 0.0333

============================================================
🔄 Round 101 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 101 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0055
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0585
============================================================


============================================================
🔄 Round 104 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 104 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0097
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0042
============================================================


============================================================
🔄 Round 106 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0656 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0656, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0656, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0656, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0656, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0657, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0656)

============================================================
📊 Round 106 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0095
   Val:   Loss=0.0656, RMSE=0.2562, R²=-0.0189
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2574, R²: 0.0324

============================================================
🔄 Round 112 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 112 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0034
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0263
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2574, R²: 0.0324

============================================================
🔄 Round 113 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 113 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0070
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0171
============================================================


============================================================
🔄 Round 114 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 114 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0085
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0064
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2575, R²: 0.0322

📊 Round 114 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2575, R²: 0.0321

📊 Round 114 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2575, R²: 0.0320

============================================================
🔄 Round 120 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0997 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0997, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0997, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0997, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0997)

============================================================
📊 Round 120 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0054
   Val:   Loss=0.0997, RMSE=0.3158, R²=-0.0655
============================================================


============================================================
🔄 Round 122 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 122 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0083
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0122
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2576, R²: 0.0317

============================================================
🔄 Round 124 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 124 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0022
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0432
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2576, R²: 0.0316

📊 Round 124 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2576, R²: 0.0314

============================================================
🔄 Round 128 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 128 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0064
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0534
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2576, R²: 0.0313

📊 Round 128 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2576, R²: 0.0313

============================================================
🔄 Round 130 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 130 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0072
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0121
============================================================


============================================================
🔄 Round 132 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 132 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0080
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0102
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2577, R²: 0.0311

📊 Round 132 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2577, R²: 0.0310

============================================================
🔄 Round 135 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 135 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0069
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.0113
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2577, R²: 0.0308

📊 Round 135 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2577, R²: 0.0308

📊 Round 135 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2577, R²: 0.0307

============================================================
🔄 Round 139 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 139 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0068
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0188
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2578, R²: 0.0306

============================================================
🔄 Round 140 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 140 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0141
   Val:   Loss=0.0712, RMSE=0.2669, R²=-0.0309
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2578, R²: 0.0305

============================================================
🔄 Round 141 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 141 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0124
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0000
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2577, R²: 0.0307

============================================================
🔄 Round 142 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 142 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0082
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0050
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2577, R²: 0.0307

📊 Round 142 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2577, R²: 0.0307

============================================================
🔄 Round 148 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 148 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0055
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0172
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2577, R²: 0.0305

📊 Round 148 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2577, R²: 0.0305

============================================================
🔄 Round 151 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0998, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0998, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0997, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 151 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0028
   Val:   Loss=0.0999, RMSE=0.3160, R²=-0.0748
============================================================


============================================================
🔄 Round 153 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 153 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0142
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0086
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2577, R²: 0.0303

============================================================
🔄 Round 154 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 154 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0068
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0123
============================================================


============================================================
🔄 Round 155 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 155 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0061
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0141
============================================================


============================================================
🔄 Round 156 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 156 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0062
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0242
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2578, R²: 0.0301

📊 Round 156 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2578, R²: 0.0300

============================================================
🔄 Round 158 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 158 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0077
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0074
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2578, R²: 0.0299

============================================================
🔄 Round 160 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 160 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0138
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0083
============================================================


============================================================
🔄 Round 161 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 161 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0115
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0018
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2578, R²: 0.0298

============================================================
🔄 Round 162 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 162 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0107
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0017
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2579, R²: 0.0296

============================================================
🔄 Round 165 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 165 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0063
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0120
============================================================


============================================================
🔄 Round 167 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 167 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0063
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0367
============================================================


============================================================
🔄 Round 168 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 168 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0139
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0078
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2579, R²: 0.0293

📊 Round 168 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2580, R²: 0.0291

============================================================
🔄 Round 171 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 171 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0015
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0359
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2580, R²: 0.0290

============================================================
🔄 Round 172 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 172 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0051
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0309
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2580, R²: 0.0289

📊 Round 172 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2580, R²: 0.0289

📊 Round 172 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2580, R²: 0.0288

============================================================
🔄 Round 176 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 176 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0019
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0567
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2580, R²: 0.0289

============================================================
🔄 Round 177 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 177 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0021
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0268
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2580, R²: 0.0288

============================================================
🔄 Round 179 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 179 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0054
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0177
============================================================


============================================================
🔄 Round 180 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 180 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0123
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0153
============================================================


============================================================
🔄 Round 181 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 181 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0112
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0035
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2580, R²: 0.0286

📊 Round 181 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2580, R²: 0.0286

============================================================
🔄 Round 185 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.1025 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.1025, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.1025, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.1025, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.1025, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.1026, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1025)

============================================================
📊 Round 185 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0144
   Val:   Loss=0.1025, RMSE=0.3201, R²=-0.0056
============================================================


============================================================
🔄 Round 188 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.1073 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.1073, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.1073, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.1073, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.1073, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.1073, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1073)

============================================================
📊 Round 188 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0085
   Val:   Loss=0.1073, RMSE=0.3276, R²=-0.0034
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2581, R²: 0.0284

📊 Round 188 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2581, R²: 0.0283

📊 Round 188 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2581, R²: 0.0282

============================================================
🔄 Round 191 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 191 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0117
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0172
============================================================


============================================================
🔄 Round 193 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 193 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0120
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0047
============================================================


============================================================
🔄 Round 194 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 194 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0084
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0121
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2581, R²: 0.0280

============================================================
🔄 Round 195 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0990, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0990, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0990, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0990, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0990, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 195 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0092
   Val:   Loss=0.0990, RMSE=0.3146, R²=-0.0000
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2581, R²: 0.0279

📊 Round 195 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2581, R²: 0.0280

============================================================
🔄 Round 198 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 198 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0072
   Val:   Loss=0.0701, RMSE=0.2647, R²=-0.0076
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2581, R²: 0.0281

============================================================
🔄 Round 199 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 199 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0138
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0039
============================================================


============================================================
🔄 Round 200 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 200 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0082
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0025
============================================================


============================================================
🔄 Round 202 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 202 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0101
   Val:   Loss=0.0709, RMSE=0.2664, R²=0.0060
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2582, R²: 0.0278

============================================================
🔄 Round 206 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 206 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0071
   Val:   Loss=0.0707, RMSE=0.2659, R²=-0.0070
============================================================


============================================================
🔄 Round 207 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 207 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0096
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0130
============================================================


============================================================
🔄 Round 210 - Client client_99
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 210 Summary - Client client_99
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0076
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0055
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2582, R²: 0.0275

❌ Client client_99 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
