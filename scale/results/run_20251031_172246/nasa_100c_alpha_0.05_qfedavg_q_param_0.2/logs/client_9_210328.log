[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd413c01-390c-4c31-971a-727e2f15751e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb2815c2-9baa-44d3-baee-961bc65daf9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b37f450-0648-4de2-9c2f-cf8016eb64a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a5f376a-bf04-4ec9-8c03-1148df1b2326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eab84617-1cdc-42c8-8f77-4fb347815391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c80e34c6-8291-4d57-8b8c-9e5e243c19bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c34747f5-a22c-4cf6-a1e8-c57dd65c101f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 146d322a-a0ef-44c7-9041-c6ac055ff1f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ce95c91-0585-4e9e-9a16-4f6c26c24c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10545021-97cb-4a7d-98fb-6c1363858f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87688042-6496-4161-b66f-31c8e2f322bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 501fa94c-650d-4160-8a69-e68eac011247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 960155cf-2e81-4736-a09d-4ce20d96199c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c4e077-51b9-4b45-857a-0ffea844e804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55bb7c4b-b2ab-4efe-928b-f6272dc1b823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9d9f2ff-99d4-42f6-8152-4b3b240d7d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc2baf24-fb78-423e-896d-cf8ea6600897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2fe75e8-7c78-4b77-973f-204a6cb2b942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2045b967-d6b8-4fe0-864f-f56af1a6274e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6575133-be5d-4015-92bc-4e5eaa4c0cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f2a5e3-07d9-4fb1-b6f6-6ed3749d7b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c16a435-d104-433f-9db2-7ff327ab5fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f1a6fac-0af3-4e18-95fd-c70eb2d649c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5013a4ab-6f02-4bb8-bf1c-c920765de5d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92455a23-83a6-4b2c-ae86-ecb6ea1fde67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19c42af3-2c1b-41e4-9cc5-c682da873988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd3b4e79-0602-4ad1-bfc0-841629e41fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43930324-284b-4650-9b46-38176dc02e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a78c63c-fbf1-4cba-a89d-b3dcbea38787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 325f2e66-4076-43cb-82e7-8fdcc55df674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3106b40f-1bb1-47ea-a71a-2e230d7be7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f8e6907-a031-4459-b480-28ac496c6953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78fc7ef0-d396-4bb6-a32a-7c50e623455e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eba19666-a14c-4916-9944-ee9e31f27d51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5d28e2-8c50-4486-85f6-7a56a0bcd710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee317f67-4def-4d90-8c57-5243b818e0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 519c0d2b-bd3c-4e82-a043-90907f2bf2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e93c1a4-e3d9-4b51-9dd2-bc951a29382a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c45e0449-bfb5-47a8-8db0-dfffdd23a605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e65e4d40-1d4f-45fa-94cf-719f078349e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee3b2bf-9bf4-4d23-be5a-f7f1bd7f4a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf69846e-a318-4ae8-a11d-f9322ac9c279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0025ffab-5b77-42ae-a692-fae58f55db0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fee33fe9-7f18-4c9a-a672-f2560d34f5e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b59b33f-c077-45d2-a0a3-466c9d593989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 300ae62a-bd2d-470c-a411-f31832c0a152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f380cd5b-9791-4fbb-84f7-6e68a76ac8b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b00c5b-5b6e-40b8-934c-9c937f774606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7573717-f403-4208-affd-fef158ca1dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8da71f91-65ab-47e5-82fc-00e5a397f6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f21667a1-8ea9-4aaf-bb9c-73a7564646af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d89d21d-e954-4d48-9fd9-cfc9de9177d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0434a9-370b-45be-a497-2da3d6d89c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1fb6bb9-eccc-4c92-8216-5bacce51347a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 204eb6a6-e6ec-4c0b-b4b0-be98504d5d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a7f88d-8d4a-43b1-9135-933f5d276714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eac622a-5c9c-44b3-8a4d-4d6a445d662d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bddce04-296c-4f98-a46f-5c0eaf95f762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98402718-3e80-4365-a613-7888de6ce2a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c3f8e3-0881-40be-94bd-ec3af06c8ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e741bde-3f94-46d7-a567-1ca64dc86a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3a5ec2-9da0-432d-b2ff-f207f2218f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a53c27f-ca35-4042-902e-4d82ad0b2a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fceb44b-9e51-4188-b496-81abd1d45d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe1b5c59-8e98-4860-9076-161fa49acf13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85c8795c-45c2-4de1-b3e1-5f878da9a802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098a2ac3-c402-4c6a-ade0-dfd3cf36a179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e987d049-7e69-403e-b3e3-fc003805e6be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26db18a2-755a-43d0-831b-a057bf0226c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94492414-1078-4c7b-b49e-2f2a0b27500e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57586d03-7aff-4961-b216-28c8420d264f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08dd559f-b035-4fdf-8c6e-c06b33a5060b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf7c4968-444a-4b48-bb61-7759776c9bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66181018-be67-49d7-aa05-3572546346e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9136054-9695-4450-9d1b-2445c5f9cce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5c716fd-09ca-41bd-94fb-3af839addb0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3afe37b-68f9-4c94-ac73-0f7f613ab4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42b7d44c-8635-447d-8451-fff1cd060b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0868a01-ee31-40d3-b0fe-3c17ae932c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb6f01ec-9b90-4015-9411-2fe0b1144ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600bcb5d-81c2-40e1-9346-0bf5996f32e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ebe3dd0-0252-4a04-99e1-c1525197c361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 203e81ac-0463-40c2-b3da-2dfb89abbb03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 118dc00b-8745-4690-9299-8936431fbb9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd1b2833-b781-42f2-91e8-f908e00d5854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a302731-74b5-49de-92e2-87006d653af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19473e5e-26d2-4dfd-a77f-69d56df75e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 887d76c7-58be-4744-958d-fee9f0666a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e89d96c0-50d8-4600-9192-ca7c193ff96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd3f8b6f-e0f5-4f92-aaeb-c3a8caa5f652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4e466ce-9eee-42e0-8939-7976ff650d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2ce3eea-1bfc-466f-ab63-7878a11ec543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fed4347a-3f6e-44e4-9bab-1e6dbfdba636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7741862-68f0-4a86-bd79-9f1169a6f20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5f3f5d2-32aa-443d-a5a7-ff1e5292e6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d25b7ec-379f-4abb-b971-57179be802a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 122f0dfd-a67f-450d-a20e-efdc6a4a64c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a1c50a-ab9b-4e5d-b7d4-24972b810601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41829f26-795c-4875-b1bf-0044fbd8fb34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90b63036-9ae6-4e06-a30e-4b405c8b0d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8e55f22-eaef-4380-b9a4-146fb77d3b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73594625-4abb-42f5-b33d-2d756dfa0676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98fe484a-0eff-4449-8fb3-4ada78000df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edc5ee9a-27ae-4112-a59d-105a2e5f9aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68236912-3395-45dc-9bed-b636bbb9c6a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ce74963-9c7d-4921-a82a-4dffa42444db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adbcbaab-79cb-41ff-a18d-30baa9ba92e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d693939-ccce-4549-b890-7b54cf77f80f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4198f0d-6e4d-4fbd-a117-b1b43d828f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab3784d-c337-47bb-89d8-6b91ea2a125d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8da2ec9-1d0b-4685-82ce-bd2b232d6dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9acc0adf-2a35-423a-8176-c7d0e6761a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2bff4e9-6d99-4c22-85a3-7a530e13dab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd2f380-1432-4952-9f40-2ead458bc4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef3b405e-24fd-45e8-82b1-98ce2ce47c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f949e9a7-851c-405a-a9d0-d692c2eee678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef27eaf-551d-4202-a45e-08453df50381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b014d4c-6df8-4d8c-9ce9-dbce38100906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcab1704-9df6-4b3f-89d7-2b521be68568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad652faa-aaa8-4f6f-b2eb-5ec5f1a4170f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eee89be7-88aa-4bf3-8bab-a98cdfb34b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84cb0431-72e6-437e-b830-2b78f0410058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d2799ff-2d03-4d9b-96b3-b52f53193967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e6e425f-5ce7-4520-90ea-4bfc986b584e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c7fe470-d4a5-437d-afa6-916c630c6646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80b9f05e-a3fb-47e1-b720-c4976e047cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c023903d-aacb-41c7-a1e1-4fe828881380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ecb70e-5bdd-42ed-88b7-d8104290acb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c3e7e32-e037-490d-b7c0-bfabf3880994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 714a063a-3081-4ae5-8887-80e9ea2f2556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dfdf110-7424-489a-843f-f5be3b65e5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d61b98-5de0-4f6a-8ab3-65bb034814f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 840dd160-f612-4506-ba5e-42ddd4f63fb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d526d0-f904-43d1-b7a8-68538e2b00da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1560410d-1444-4772-bc9d-2332ad1cc236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f2bdb25-b63b-4079-804a-18d406a732c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7977cca7-01cc-4f7a-9cbe-2cbc448729f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3c34e83-08ab-42f8-a4c1-c750373d58cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c775419b-c8f0-44a6-9891-c1c6c96d5bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ace88e-49ac-490c-989d-36940d624341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44f9a346-d087-4f22-be13-7da021bcfb8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 592c67b6-6688-4f42-83eb-1f2d31021090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f8fc4cb-07cd-4550-a54c-84959449c617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40fa8146-ee6b-4b2d-b8b8-bc5c202ab4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83b7c2fe-e92b-4f0d-95d3-6524e2878c96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c59a045-7c55-44cc-9842-308c7fbd7d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8f2c796-6871-4757-90c3-64e62683ee32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9907721d-1678-45c4-9e1b-cbae6abf65cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23c1a6d-2934-42b4-9602-0b6eff44048b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53b25a29-f005-4fae-a7fc-b071927b5b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb1ab5d7-8942-4b43-b5ea-cd9626d4afcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2eec8ad-36e5-41ae-abd4-0ee17dfc1ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7642ceb7-57be-41d0-aa44-bc7b7640d92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93f02aef-1a20-4299-9064-f3fcf91c1e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61902254-4c4e-4571-ae5a-fc93365c5946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3ab3d7c-68f8-44b0-a06b-78f26a6c4a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cad982c-b736-4d28-9020-f19aed8073a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe39011-8743-49aa-af4f-bf976187afc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ecd600-d872-47eb-958d-0b3b82fe7ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e648a0d3-4f46-417e-b727-1c25d6b1a8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49c7b6cf-8935-45f3-88e0-8d4f4df49d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d897dc5-8dce-4ab8-9c4d-47f1280e35aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb08cea4-46c9-4a26-a56e-cf6458555fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41509156-1a8b-4d3b-a04d-6e58ba298421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6edd8c66-e536-4e14-91e8-9a11d61f273b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30412bf7-2e0d-456f-b12d-81a869e54002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1529c1a5-4e93-4e0b-9652-76b96a258339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b4a56c9-0869-4e1e-8f70-5787e687e321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c10a53-17d3-4414-8d96-80db2b63e5eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7d5d8cb-c7a7-4353-ab14-00bc9c16895d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4caccd32-e80f-4772-abea-b9bf853975ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a287ed18-69f9-4130-94cf-2f58230b21b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5702c2a2-b5a9-4b9c-bf37-d96bba4bd0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cdea4be-3b09-40b6-afdb-bb802889d600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 083659de-ad1b-48f7-8051-1b952f302afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda6c09e-a08f-4f0a-8943-e2ccf94dc80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a63b52b1-3ae6-4697-b8bd-f955400768d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b8a4d2-df5c-43bd-9ac3-9f208302c344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f38cae59-0310-4f40-8ce5-76e3c451dfe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 675596c4-362f-492e-8764-a3b00c6caf95
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_9
Server: localhost:8693
Algorithm: QFEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/test_labels.txt

📊 Raw data loaded:
   Train: X=(755, 24), y=(755,)
   Test:  X=(189, 24), y=(189,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 746 samples, 5 features
   Test:  180 samples, 5 features
✅ Client client_9 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1372, val=0.1037 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0909, val=0.0785 (↓), lr=0.001000
   • Epoch   3/100: train=0.0851, val=0.0818, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0859, val=0.0816, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0856, val=0.0816, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0847, val=0.0807, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 1 Summary - Client client_9
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0023
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0069
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.2150, RMSE: 0.4637, MAE: 0.3824, R²: -1.6331

============================================================
🔄 Round 2 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1814, val=0.1556 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1204, val=0.1019 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0845, val=0.0891 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0836, val=0.0884 (↓), lr=0.000250
   • Epoch   5/100: train=0.0821, val=0.0884, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0818, val=0.0886, patience=7/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 2 Summary - Client client_9
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0034
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0029
============================================================


============================================================
🔄 Round 3 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1976, val=0.1926 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1734, val=0.1696 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.1534, val=0.1515 (↓), lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   ✓ Epoch   4/100: train=0.1368, val=0.1354 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.1249, val=0.1278 (↓), lr=0.000031
   ✓ Epoch  11/100: train=0.0893, val=0.0931 (↓), lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016
   📉 Epoch 20: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0826, val=0.0876, patience=2/15, lr=0.000008
   📉 Epoch 28: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0825, val=0.0875, patience=12/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 3 Summary - Client client_9
   Epochs: 34/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0001
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0054
============================================================


============================================================
🔄 Round 4 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1953, val=0.2273 (↓), lr=0.000004
   📉 Epoch 2: LR reduced 0.000004 → 0.000002
   ✓ Epoch   2/100: train=0.1937, val=0.2253 (↓), lr=0.000002
   ✓ Epoch   3/100: train=0.1923, val=0.2244 (↓), lr=0.000002
   ✓ Epoch   4/100: train=0.1915, val=0.2235 (↓), lr=0.000002
   ✓ Epoch   5/100: train=0.1907, val=0.2227 (↓), lr=0.000002
   📉 Epoch 10: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.1867, val=0.2187, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1839, val=0.2156, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.1813, val=0.2129, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.1790, val=0.2103, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1767, val=0.2079, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1745, val=0.2055 (↓), lr=0.000001
   • Epoch  71/100: train=0.1724, val=0.2032, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1703, val=0.2009, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1683, val=0.1987 (↓), lr=0.000001

============================================================
📊 Round 4 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.1658, RMSE=0.4072, R²=-1.0441
   Val:   Loss=0.1967, RMSE=0.4435, R²=-1.0910
============================================================


============================================================
🔄 Round 7 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1818, val=0.1806 (↓), lr=0.000001
   • Epoch   2/100: train=0.1815, val=0.1803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1813, val=0.1801, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1811, val=0.1799 (↓), lr=0.000001
   • Epoch   5/100: train=0.1808, val=0.1796, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1795, val=0.1782, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1772, val=0.1759, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1750, val=0.1736 (↓), lr=0.000001
   • Epoch  41/100: train=0.1729, val=0.1713, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1708, val=0.1691, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1687, val=0.1669 (↓), lr=0.000001
   • Epoch  71/100: train=0.1666, val=0.1647, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1645, val=0.1625, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1625, val=0.1603 (↓), lr=0.000001

============================================================
📊 Round 7 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1612, RMSE=0.4015, R²=-0.8680
   Val:   Loss=0.1584, RMSE=0.3980, R²=-1.1424
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.1743, RMSE: 0.4175, MAE: 0.3399, R²: -1.1343

============================================================
🔄 Round 10 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1647, val=0.1869 (↓), lr=0.000001
   • Epoch   2/100: train=0.1645, val=0.1867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1643, val=0.1865, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1641, val=0.1863 (↓), lr=0.000001
   • Epoch   5/100: train=0.1638, val=0.1860, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1626, val=0.1846, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1606, val=0.1823, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1586, val=0.1801 (↓), lr=0.000001
   • Epoch  41/100: train=0.1566, val=0.1778, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1546, val=0.1755, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1526, val=0.1733 (↓), lr=0.000001
   • Epoch  71/100: train=0.1506, val=0.1710, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1486, val=0.1687, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1466, val=0.1665 (↓), lr=0.000001

============================================================
📊 Round 10 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1446, RMSE=0.3803, R²=-0.7285
   Val:   Loss=0.1644, RMSE=0.4055, R²=-0.9707
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.1648, RMSE: 0.4059, MAE: 0.3298, R²: -1.0176

📊 Round 10 Test Metrics:
   Loss: 0.1553, RMSE: 0.3940, MAE: 0.3197, R²: -0.9012

📊 Round 10 Test Metrics:
   Loss: 0.1344, RMSE: 0.3666, MAE: 0.2976, R²: -0.6455

============================================================
🔄 Round 16 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1372, val=0.1215 (↓), lr=0.000001
   • Epoch   2/100: train=0.1370, val=0.1213, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1367, val=0.1212, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1365, val=0.1210 (↓), lr=0.000001
   • Epoch   5/100: train=0.1363, val=0.1208, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1351, val=0.1196, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1330, val=0.1178, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1309, val=0.1159 (↓), lr=0.000001
   • Epoch  41/100: train=0.1289, val=0.1141, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1269, val=0.1122, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1248, val=0.1104 (↓), lr=0.000001
   • Epoch  71/100: train=0.1228, val=0.1086, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1208, val=0.1068, patience=2/15, lr=0.000001
   ✓ Epoch  91/100: train=0.1188, val=0.1051 (↓), lr=0.000001

============================================================
📊 Round 16 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1164, RMSE=0.3411, R²=-0.3698
   Val:   Loss=0.1035, RMSE=0.3217, R²=-0.3097
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.1027, RMSE: 0.3205, MAE: 0.2649, R²: -0.2575

============================================================
🔄 Round 19 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1009, val=0.1105 (↓), lr=0.000001
   • Epoch   2/100: train=0.1008, val=0.1104, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1006, val=0.1102, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1005, val=0.1100 (↓), lr=0.000001
   • Epoch   5/100: train=0.1003, val=0.1098, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0996, val=0.1088, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0983, val=0.1071, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0970, val=0.1054 (↓), lr=0.000001
   • Epoch  41/100: train=0.0958, val=0.1037, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0946, val=0.1021, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.0935, val=0.1005, patience=3/15, lr=0.000001
   • Epoch  71/100: train=0.0924, val=0.0990, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.0914, val=0.0975, patience=3/15, lr=0.000001
   • Epoch  91/100: train=0.0904, val=0.0961, patience=1/15, lr=0.000001

============================================================
📊 Round 19 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0676
   Val:   Loss=0.0950, RMSE=0.3081, R²=-0.1619
============================================================


============================================================
🔄 Round 20 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0995, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0994, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0903, val=0.0986 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.0893, val=0.0975 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.0884, val=0.0964 (↓), lr=0.000001
   • Epoch  41/100: train=0.0875, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.0868, val=0.0946, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0861, val=0.0938, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.0855, val=0.0931, patience=2/15, lr=0.000001
   • Epoch  81/100: train=0.0850, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0845, val=0.0919, patience=5/15, lr=0.000001

============================================================
📊 Round 20 Summary - Client client_9
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0157
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0353
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2488, R²: -0.0297

============================================================
🔄 Round 22 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 22 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0345
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0052
============================================================


============================================================
🔄 Round 24 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 24 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0163
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0137
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2478, R²: -0.0146

============================================================
🔄 Round 25 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 25 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0158
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0041
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2477, R²: -0.0115

📊 Round 25 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2477, R²: -0.0108

============================================================
🔄 Round 30 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 30 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0172
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0014
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2476, R²: -0.0097

============================================================
🔄 Round 31 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 31 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0076
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0153
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: -0.0092

📊 Round 31 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2476, R²: -0.0084

📊 Round 31 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2476, R²: -0.0081

============================================================
🔄 Round 36 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 36 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0066
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0077
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2476, R²: -0.0077

============================================================
🔄 Round 37 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 37 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0039
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0355
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2476, R²: -0.0076

============================================================
🔄 Round 38 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 38 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0071
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0046
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2476, R²: -0.0069

📊 Round 38 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2476, R²: -0.0068

============================================================
🔄 Round 42 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 42 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0093
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0011
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2475, R²: -0.0064

============================================================
🔄 Round 46 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 46 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0120
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0093
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2475, R²: -0.0063

============================================================
🔄 Round 47 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 47 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0079
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0010
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2475, R²: -0.0061

============================================================
🔄 Round 50 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 50 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0047
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0081
============================================================


============================================================
🔄 Round 51 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 51 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0041
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0377
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2475, R²: -0.0057

============================================================
🔄 Round 53 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 53 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0095
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0067
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2475, R²: -0.0058

============================================================
🔄 Round 55 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 55 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0057
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0085
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2475, R²: -0.0057

📊 Round 55 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2475, R²: -0.0058

============================================================
🔄 Round 58 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 58 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0015
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0614
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2476, R²: -0.0056

============================================================
🔄 Round 61 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 61 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0027
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0243
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2476, R²: -0.0054

============================================================
🔄 Round 62 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 62 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0065
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0008
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2476, R²: -0.0053

📊 Round 62 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2475, R²: -0.0052

📊 Round 62 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2476, R²: -0.0052

============================================================
🔄 Round 66 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 66 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0093
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0028
============================================================


============================================================
🔄 Round 67 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 67 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0006
   Val:   Loss=0.0980, RMSE=0.3130, R²=-0.0356
============================================================


============================================================
🔄 Round 69 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 69 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0031
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0260
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2476, R²: -0.0050

============================================================
🔄 Round 71 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 71 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0051
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0033
============================================================


============================================================
🔄 Round 72 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 72 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0034
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0153
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2476, R²: -0.0046

============================================================
🔄 Round 74 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 74 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0009
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0509
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2476, R²: -0.0045

============================================================
🔄 Round 75 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 75 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0016
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0220
============================================================


============================================================
🔄 Round 76 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 76 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0030
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0488
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2476, R²: -0.0043

============================================================
🔄 Round 77 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 77 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0099
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0034
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2476, R²: -0.0042

============================================================
🔄 Round 81 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 81 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0057
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0004
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2476, R²: -0.0041

============================================================
🔄 Round 83 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 83 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0029
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0122
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2476, R²: -0.0042

📊 Round 83 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2476, R²: -0.0041

============================================================
🔄 Round 89 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 89 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0057
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0011
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2476, R²: -0.0040

============================================================
🔄 Round 91 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 91 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0079
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0027
============================================================


============================================================
🔄 Round 92 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 92 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0036
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0048
============================================================


============================================================
🔄 Round 93 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 93 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0030
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0087
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2476, R²: -0.0036

📊 Round 93 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2476, R²: -0.0038

============================================================
🔄 Round 98 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 98 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0042
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0026
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2476, R²: -0.0037

============================================================
🔄 Round 99 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 99 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0041
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0084
============================================================


============================================================
🔄 Round 100 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 100 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0011
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0412
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2476, R²: -0.0036

============================================================
🔄 Round 102 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 102 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0046
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0011
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2476, R²: -0.0034

📊 Round 102 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2476, R²: -0.0034

============================================================
🔄 Round 106 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0993 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0993, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0993, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0993, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0993, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0993, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0993)

============================================================
📊 Round 106 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0058
   Val:   Loss=0.0993, RMSE=0.3152, R²=0.0034
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2476, R²: -0.0033

============================================================
🔄 Round 107 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 107 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0016
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0243
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0032

📊 Round 107 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0031

📊 Round 107 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0030

📊 Round 107 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0031

============================================================
🔄 Round 113 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 113 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0047
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0061
============================================================


============================================================
🔄 Round 114 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 114 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0027
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0091
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0032

============================================================
🔄 Round 117 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 117 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0047
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0012
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0032

============================================================
🔄 Round 119 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 119 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0027
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0077
============================================================


============================================================
🔄 Round 120 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 120 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0028
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0069
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0031

📊 Round 120 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0030

============================================================
🔄 Round 123 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 123 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0032
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0034
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0030

============================================================
🔄 Round 125 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 125 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0040
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0030
============================================================


============================================================
🔄 Round 126 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 126 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0026
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0125
============================================================


============================================================
🔄 Round 127 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 127 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0045
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0261
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0029

📊 Round 127 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0029

============================================================
🔄 Round 129 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 129 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0007
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0241
============================================================


============================================================
🔄 Round 131 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 131 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0002
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0178
============================================================


============================================================
🔄 Round 132 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 132 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0052
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0025
============================================================


============================================================
🔄 Round 135 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 135 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0028
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0036
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0027

📊 Round 135 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0027

📊 Round 135 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0026

============================================================
🔄 Round 139 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 139 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0026
   Val:   Loss=0.0721, RMSE=0.2686, R²=-0.0141
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0025

============================================================
🔄 Round 141 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 141 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0016
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0299
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0026

📊 Round 141 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0027

============================================================
🔄 Round 144 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 144 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0043
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0035
============================================================


============================================================
🔄 Round 146 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 146 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0027
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0072
============================================================


============================================================
🔄 Round 147 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 147 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0027
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0052
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0029

📊 Round 147 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0028

📊 Round 147 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0029

============================================================
🔄 Round 154 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 154 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0017
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0082
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0029

============================================================
🔄 Round 155 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 155 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0108
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0179
============================================================


============================================================
🔄 Round 156 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 156 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0011
   Val:   Loss=0.0962, RMSE=0.3101, R²=-0.0170
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0028

============================================================
🔄 Round 158 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 158 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0007
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0237
============================================================


============================================================
🔄 Round 159 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 159 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0020
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0087
============================================================


============================================================
🔄 Round 160 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 160 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0030
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0029
============================================================


============================================================
🔄 Round 161 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 161 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0022
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0402
============================================================


============================================================
🔄 Round 162 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 162 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0024
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0075
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0028

============================================================
🔄 Round 163 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 163 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0058
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0078
============================================================


============================================================
🔄 Round 164 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 164 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0076
   Val:   Loss=0.0944, RMSE=0.3073, R²=0.0038
============================================================


============================================================
🔄 Round 165 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 165 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0028
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0111
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2476, R²: -0.0026

📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0026

📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0025

============================================================
🔄 Round 168 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 168 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0061
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0105
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0024

📊 Round 168 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2476, R²: -0.0023

📊 Round 168 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0023

📊 Round 168 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0024

📊 Round 168 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0024

============================================================
🔄 Round 177 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 177 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0009
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0365
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0023

============================================================
🔄 Round 180 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 180 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0002
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0170
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0024

============================================================
🔄 Round 182 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 182 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0053
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0050
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0023

📊 Round 182 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0024

============================================================
🔄 Round 187 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 187 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0039
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0028
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0025

📊 Round 187 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0024

============================================================
🔄 Round 190 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 190 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0029
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0009
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0024

📊 Round 190 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0023

============================================================
🔄 Round 195 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 195 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0039
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0010
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2477, R²: -0.0022

📊 Round 195 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0023

📊 Round 195 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0024

📊 Round 195 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0023

============================================================
🔄 Round 203 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 203 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0009
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0120
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2477, R²: -0.0022

============================================================
🔄 Round 204 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 204 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0043
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0024
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0024

============================================================
🔄 Round 210 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 210 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0026
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0019
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2477, R²: -0.0023

============================================================
🔄 Round 211 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 211 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0009
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0737
============================================================


❌ Client client_9 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8693 {grpc_message:"Socket closed", grpc_status:14}"
>
