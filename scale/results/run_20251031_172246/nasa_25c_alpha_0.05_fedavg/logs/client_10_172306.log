[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 026df4d3-be30-4aac-9084-53a38e5afb7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93a094f6-42d1-44da-9334-0934d18e05c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18245855-ec44-41ef-9481-12ce045afef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08590656-593b-40dc-8863-7371ceca7136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0a6fa76-2aac-4189-b8a1-0860777df675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffa23eb6-9ba9-4100-b4c8-df0e50bb5cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 143ab02e-65d6-4712-843d-77bc5ea4e09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2ef13f5-fb93-4631-ac3c-f58a5c75e13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb198b1b-eb32-430d-a13c-0d42b4d1e8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f95a54da-8e8c-4574-8ab8-5586014e1239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94d87454-6d0e-4dcd-afbc-171657fe6211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31046634-713f-49ab-b474-ed1943e6b145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eaa05b6-2bab-4f70-8715-8de4a446f1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27279185-2bd0-4dcb-a69f-60d76bcb8daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 341802a8-25c1-46b3-b293-366277e84ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17b3b87d-8eee-4e89-903d-fd1f0b8a9031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b5ae9b6-fc88-415e-b74b-097f3e6fc671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eff17813-9fc6-4a8c-a7be-73b6d210be17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 429b7855-92a0-40a3-abf0-6935c1603e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3192239b-9921-4ffb-a4ea-8ffb95704453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14c662b8-0d69-4173-a5b5-c01edccb5a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d65a7ed9-09e5-45bd-aab7-199959884c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05c9700-ffeb-48b2-b255-f3ee53797b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f421db-d18f-482f-b6c7-225c79758a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b046a28-0c38-4fa4-81a2-b3412cc97bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad7ab8c-e36c-4995-a09b-355ae3ce6224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c9e60d4-f0b6-4176-bed8-d79304d239c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf7b5683-fda1-430d-89ca-77fa06286223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 247e866f-7f7f-422e-8244-a5342fc64e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d92d89-03da-4b4b-999c-cc147af739a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a226db9b-5f06-4a57-b5b2-467847c78717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66ea2801-62b1-4ef2-8dae-f0ba903d7cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0610b139-fd0c-4cb7-b502-d6efa4457e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b617987-8279-40f3-aae7-213804685ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5af4b5f4-b1c1-4295-a2fa-6393347e5ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cfc8f3f-2a99-400f-8667-b0a5b630ad8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51709eaa-f623-4eda-b33b-31ceef929c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 293c345b-f61d-44f9-bced-8307c51a54a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8d256b0-f03f-40cf-870d-f3305aaa0f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e7739ba-f074-42ab-9a98-06b080cd40e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 473687c4-c59e-47e9-82b2-f2c2ac32d333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 568a6df7-c00e-46f6-8d88-a2774ee2df8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a54bf83a-7878-481e-912b-3c5b28f5bad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e98aa68-e92d-4137-9328-66977e251044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47deaa37-65b9-4883-8a4c-628c2c5b9e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e3dd459-e500-49c5-a64a-7436278c674a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bc1c880-a77e-4a9c-811f-89522d1ee8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88ace8cc-5736-4ff4-ace3-a702ea8c05e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d653b99-7c39-451d-b8e1-833181d2b9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 399f1b01-2aee-4749-9b77-5f97d37c3d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b67f99a-aff5-4a41-9b5d-068ddfaa7d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1baa4d99-0696-4eff-b84a-e02c08ec31a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a462a0a-dc46-4ebc-a041-688506bfc5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29bed14f-c2ab-40c0-bdf3-b4d15edf1d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3729dedc-1b48-436a-bb9a-b50143fb2fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c63b414a-3608-4799-9263-67bc0853308a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da083ad-450f-4cf0-ba9f-40db2172a19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e137fe7-1782-46a5-af14-869245a0a29e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc4b037a-42c5-48a0-816a-60fb7f5f0e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fed4622a-4006-42be-82b8-d7040a03f9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4937002-bab4-4587-9d33-264a1936d1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a3d842-ded7-427c-b9cd-87b55943e153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f4c5b96-a5e3-4c95-84d9-082c62c5316e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5073c373-7f8b-404e-abdc-55d2c877e501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1e04667-1ce8-4550-b47d-38428a74c84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a4bf191-fe31-4ceb-8f21-59435d0e49e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa426347-899e-4023-b21e-ad4a7441aad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebbeb3af-32b2-4404-aa78-54aa857cc5ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f8b2a4-ada6-4cc9-842d-f2b2c1a9a02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af895525-92e7-4393-879b-152627a8d475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5211168-5015-49c4-8f88-37a36355e7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d64bfac-411a-477c-b2b0-c73591f16dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a25b2109-ff75-4c72-bed5-a671e02ff4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 326b64d0-55a4-46c6-a623-de505bc7d49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f290e9-1206-43eb-83e5-35d3ff169cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 345bae55-c9ed-4802-9572-d644c96b07bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbcadc5e-cc54-4d5f-b96f-2f2237dfb346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3396dff0-2a9c-4094-9a90-67500378f6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9dbd56d-87e5-4365-aa5c-b10d045ad0b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e3e0119-35ef-4c2a-8503-9a5e6faf76d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10a29729-0e20-491d-a68a-6513e4995c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 072131cb-b77d-4449-b324-c5f14ec2e6ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8105fd58-f140-4532-a68a-1dadc9636e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 031342ef-a5f2-40e3-a003-c63452c2b2af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cf50bfc-dda6-4a50-94a3-aa9e26ccc7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 823bbe00-03a0-4a67-b934-81f73a19c7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dd7114d-5c30-4c2f-9d1b-800bd224348c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75f6b36a-3a20-48ad-9db4-dad9dfd05969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8925e2a9-4a7b-45c0-b418-b08baadce07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b7d49f-c1ed-4e10-b38a-c417d4dc96bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68a6071e-c3ff-4845-9092-67abb22ba5f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 301945fc-e96a-41db-90ac-a203e137b9aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27955097-f75b-4a5c-ae31-111aec02b1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee68216-ddcf-47a2-89ca-249aae4836d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e00b6e1c-32bc-455e-a8e5-291772eca466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b95ad85-a0b4-46a6-ba7c-5ec19ceca19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cd04675-25d9-48f9-b28f-cdee23176478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f7ed60-bf8d-4548-ac18-7e1c9f8588fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d6e2a0-247e-4562-b06f-a0ef2f5630e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4915b090-603a-4ba7-8cce-2992247777db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9cb02af-4c8d-4056-9e81-67847d49f2e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b01809-3e4c-4844-933c-e70e41f73dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 942db582-80e5-4f81-b483-102ef40ca681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efa0570a-e90b-4cb1-a6f2-b499744e7365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b12ac34b-c7d7-45e9-991c-f6d9d4525b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b06e945-f9c5-4ae1-ab5f-63a140240627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 100e8fa3-30e4-4fe4-a343-ad4043e259b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a06254a-89f1-45e9-8434-59eb0fbe5b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db664c8-70dc-413e-afb0-26296d67e3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd15e3a-da69-4d81-9951-98c44bcbdfd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f77fb23-62d0-4568-a2fb-46466ddd6d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5651642-bfb5-47a0-beaf-e3ab81516637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 482e6aea-5059-43ba-af97-8b74eec3f25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3f7490d-047e-4db7-af1e-ec2b7c9587e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fffc1ea-b674-4dfc-86be-ff082a582a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4812b0-354c-4207-b05f-f6bfb40b7655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a3161df-e1ed-4a72-95c7-c4cd71fcb745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 085393af-54f2-4762-8f92-5bb741937378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10b73261-05db-4190-a520-196929e1f48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfb98fab-5182-4ff8-b0ea-bd4c8b1eecae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 023440d4-ac3e-4e61-8b6c-1fdeb1926d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e854962-3a76-4e11-aef8-f74bd4307ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3203597-5bec-46a9-bd26-d3b48b5e39b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 539c2ac6-7f17-4c1a-bbb8-cc73082b1015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fbe5623-991a-4543-b8f0-c6ddf6e7df5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3338646f-149e-46dc-823d-6b37b2b41087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52ebcb6b-e11b-4fae-914a-58fa8cf83253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 062f7412-9ac7-4688-8889-715159c27fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90229a8c-f008-4eb7-b74a-2436c7e35efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eaf6972-9a7e-4a02-805a-74338aafc92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ab433a4-1f8a-4fed-b270-8f3a74bffd06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1081854d-518e-4afc-9dcc-23b706557f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc8cbf3a-b405-4b71-8c16-f9f65f6e55bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90597e6c-90d4-46af-99e0-d907c9ab18eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0674fd33-3192-409d-b2bc-f0d64fc98cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f052206-cb30-4ffc-9db4-28257c2fb185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39e1b662-8b2a-4a0b-b5d6-a018eef5a91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6386e38-031c-4f0f-9b27-f8e889e5dd8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59bc2d20-33db-441a-8ba7-83a36b8fc4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5721151-839a-4ff2-a6d9-5130644df1de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d02709-6e6e-4633-8119-798619758f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c319e8c-9e0f-4e76-9f52-d6e915062752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff497f31-7232-4822-8fa2-032980a33cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8506101a-d354-424d-b687-0719c7fe265b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0bfe17d-fb56-4624-85f7-b51e0ac02115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e0f4be6-2731-4760-afe3-80f749c44514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4256a981-051f-4ae4-a031-fb38b54d626c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bab9cbc-17af-4e0f-95df-a3cbbcbad61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59b7d0ab-c541-4b3e-9846-064ec9bc8641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bffe4e9-d2ce-4fe8-bdd9-bc6bdbcafbf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad10091-8472-42e4-b4d2-d3f4de2e7bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c544c164-eee5-48bf-a60e-284aa2224326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c77ea5-121f-4f44-bce1-6185c313b075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aefca9a9-4d58-4ce6-89ee-00c309bbc0d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50ce7ac7-dd8c-4aa5-9343-ce14c916ed02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2049d1d9-7cee-41c6-8512-dfadd900c354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11487ea-eb13-4fd6-9733-8537836207bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74f44473-1195-4094-b07c-082338ab2b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b055f77-e80e-4ab9-b8d6-910ab515794c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cdef53f-368e-4732-9561-88e5dde4afa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5257f066-b4de-4550-a7b3-bdf3136237b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95554c54-3d1e-460b-b7a2-dbeba4a2be7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bddb534-411c-4faa-9e97-b48e19fe65fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d2d0c38-868a-4801-9c8f-a717e6a14cea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9472103-3f21-45ed-be34-e8e89e60468b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c72841-8caf-4d76-a67c-f66a1d2d9972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 707dc418-d536-4d35-a768-9345ba1234b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc454c1-1073-4627-bd37-aa48e15701a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c00d3ea4-2c20-47af-bc72-7df6b3a6e2ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29981f2e-2e4e-4744-814f-c83d42ef7e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d5807d9-f08c-4cc5-8e62-5ec6199fcc42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c27d7a6b-8828-4e39-95ed-111ff550e10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 633428c4-d7fb-48d4-a6e1-2fd4b119eb52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a61e77d7-7b78-4f63-8ff9-ec6f2cc2bb7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afb87039-84b2-4964-8b32-57b7f3c1a196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff71df5d-d5a6-4a77-bdcf-72ec6a243598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae71fb2-b2be-4c5d-9104-748a3b2da5d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2196b651-cc93-47a5-8279-fcf909ab20ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f67d467-3901-46af-b846-bd176969a437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ea4879d-f908-4fd6-a172-0c548952489f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa7eb098-4de8-462b-b3f4-f4a1c78643ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25b4985b-dc47-4229-ae48-f73c6a16b123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3654c9-b417-4f51-9ce4-e3eb0db0f7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efff7975-508f-4a16-b334-41a75f102345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04d2f1e7-07ee-4cfb-98ae-84b5c042f9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c91f3bbc-8db3-4c32-9676-10f1ac546234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce4ab766-9661-4c48-b9a6-e1012b942ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62c48c91-f766-4d10-9fa7-b349b98418fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6e5ab5a-34bd-4897-ad0e-abfa8fc699eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a34f5b5a-dedd-4dc6-860d-04c2b8b2415f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240093ad-9dc7-4b51-a471-e3884269adea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40617fa9-e47e-412b-8dd3-38a6ef4daafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5bff1d0-ead3-48ca-9314-6eb49aa28467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bea82aa-dd12-4f4e-a8d5-ec9438292cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2470511f-a997-4962-925d-9ecc8e6e070a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6de9cbc-82de-4303-8263-f56e3dbc76ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1631fabe-4cf3-4891-8319-f78d37000fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c50d94fc-1455-4628-9cf6-0188cac598a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 750ab175-4421-44f3-9b41-f9916794db8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1db07c11-0093-4214-a846-369f3798b0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99072665-d991-4547-a7a4-e351ace7869b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c32715d-1d2d-4596-a489-fd2498066ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afd03985-41bb-4a61-bd98-8f3dd0132e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b604fcb-4c2f-4474-8963-90ece3f74dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29b17fc1-0eeb-416c-976f-f707debe0a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b6902f-825f-4146-96ef-795ecd4f2f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1721d7b4-07b6-4d5a-8711-b1b7abe1e9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eaebeab-5877-49da-a5ff-f29ff6163622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c80533da-a605-461f-a317-f153357e2e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcc67080-03ca-4cd8-bdb9-61ce8ae3d6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04a66759-8078-48ca-9ba7-6889eaaf8775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f05b9b4-dc22-413e-9df6-0a5bddd7267b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a68cb77-8410-4d6e-bdb8-9b017f553640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce992f7-d654-40d0-9e38-0e177e160829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da33df1e-8c81-4f07-bd42-2306e25e825e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 001e2220-918e-45b2-8377-4eea1a251894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd0138f6-84fe-4881-b9c5-ddb0f76c51b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569f47a3-8327-484e-94b1-a28ee42e5924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3abbdb5d-2d7c-4108-b397-34371547652b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb06e628-d2a8-49b0-8ce5-3e0593f425fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc71d788-2e6d-4d19-8b06-bde773321786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c499e43-585c-46b6-a772-93c08ae4e27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9919eb34-ae03-48d3-8735-1c69612b1b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d164cf-5d06-418e-8236-f32bbf9f7085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a414f52-02c5-41ed-a71b-9fbfa41f3b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f58841b-9375-45c1-a61e-b525a7b56565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aacfea58-4984-4307-a703-4b9f2b2df39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9449c13-1a5e-468b-bfab-6bac72960d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 228feaf3-327b-4602-9701-3e383e924839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ff108c-7180-4ab8-8f8c-c69c6a247646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c641c20-39aa-405f-a341-e97389f34c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5bed03d-2616-46b1-a0e5-269538a6fdb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b600cc0-b50a-41d1-b3dd-f7f6702173ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ea86359-0b82-44e5-b27b-d327a11551d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c320c6-022e-4851-ba03-4090599d0161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c6d721-ea35-4c4a-b849-7b0455953f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4f10f93-4e67-48b2-a238-ce7e4f0a123c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a5d00e-eca2-4db0-935e-f879f956cb7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c02e3451-8754-491c-acf4-d9266cea3d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bc25f97-76c4-488f-b8b9-43990a0ddbbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e596001-c994-4f20-bd0c-b12ed4b63452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95a336a5-dc97-4adc-ab9e-c57be256fba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e3bb321-95a6-411d-b113-c2d7ddeaa70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 727703bf-8cb4-482e-8d9a-3569d0d9a3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a7b21ac-ae14-488e-af7e-ce03592d7e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65dd0a0e-6df4-42ee-a79a-bb9ade8713cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25d73ccc-2c75-4520-84b2-626c2aec94d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c240de4d-afbf-4086-ac85-fae8fde0ba2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df8fcae-f1d2-435d-8da2-05a463b8ba75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43990374-e6aa-47c6-91de-49079eb3efd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 971a6563-8df2-4337-9e31-132ab190c6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1062568a-637b-4ae4-b275-c39b3743253e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3800f39b-2319-471a-9a63-f128c0f06a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcec84e4-f66a-4b30-a717-f5b4ea06850c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 481beefa-570e-431f-a319-ccef4d8a2a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa0bfd4c-e4c5-4ebe-86f0-4c96ab7e69e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f8d3000-5135-48af-b210-8cdd47e388c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15bbfdb5-a176-4176-80a1-c3eb4e61fc91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdd56556-60b9-413e-9f8f-9b73e9090414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b0ef4a4-c822-4f84-9158-6a9695085a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f258428c-54b8-496e-b986-67515aae5820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8df69795-f5b0-4b0f-8f2e-8bd8639bd67a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fe1040c-9c94-4351-b02a-47ba2637905b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec107096-c663-49aa-80c4-aba2fa15692c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0262fcd-5ba0-4ea7-984b-6c71bb2cc563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5239f35a-b820-4043-a73c-d2cdc1dbf833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f19ac36-3360-4673-a99d-b111d30fa734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af11747d-8f67-44c8-a8a1-6b382111d01a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0271a342-789e-42cb-b63a-cf69fa0ee015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab38c6b9-a9d7-48cb-b2c0-53fe28369368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e5dbae-9c08-4f37-b2c3-d42f9245255a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d047591-4a6e-4d88-be75-462c36843484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b37dac7c-8c64-4bc7-af91-a85f17bf61c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29b5e623-2b9b-491d-8de3-7429351f0e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a24516e5-d2d5-432c-a66d-84eb5fe80bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 749b8bfe-091c-479d-a6c9-49deb752cb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e070596-ab55-4c8e-9a32-7b3bd112ad9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6091435b-e1e4-47b2-afc3-af0b09fedf80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed08c41c-0bf5-427f-899e-87af39243ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa07e901-f7cd-4b72-836f-812a2d003446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbff99f6-def9-47f9-95de-98837945ac06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d03ecb-e389-40b2-9a44-600013e675f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcd4e48d-6279-4906-860e-83b52f3d2f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d1825bb-5a15-4006-9630-bcbfbfc729d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e199225a-e91d-4b51-bac4-950fe1f15036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf3e4218-2d1d-40cb-915a-1874c50ea15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99ef445f-bf82-49a6-888d-21f7484bc4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f204288-d928-4a34-9f7e-712fd1819cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c4f926-39ea-4ced-9b5e-6d60f078df40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38faa9d0-1eba-4547-a04c-3b572d724f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc6e2f56-cb40-411d-970e-f45edf5ed91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f2b5d4b-2167-446a-aaea-328f76946499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 220ffd03-f868-4d3e-a5e8-53ebe77a1649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf3b0d13-72da-4fda-abe9-e4f90af5d54b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb86df1b-0a12-41e2-956e-9dd103edbbe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d54b5e0e-63ac-47a7-b7ee-34f8e5aad9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ace8837-878f-4871-92bd-f31daa7bac59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ff6155-b893-48d9-83da-fbeb1d5e85c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b9e85d-5caa-4c50-a72f-531a390871fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ed2ce65-5f99-4481-ae1a-a91d07654879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 284d59d6-0a10-45fa-9eef-e1631962b0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3af71a3a-8c55-4d93-8bdd-e2e76c3efee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c21640c-ecaf-42ce-9c02-b02dea227622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 811f98dc-df05-4cde-a037-f8a9e24ffa01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 934d3f20-1ea9-4259-8936-964895e4297d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7456b0f-697a-4427-9abf-c4fa2107e8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dda093c4-6753-4b19-a976-b2b563a7ac73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58014569-ea65-4f2a-b109-6af3d3f86ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fac74a65-3c27-4b0a-8f2a-4afe5efe2476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efa92daa-86ac-4859-a488-04a42eadf80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aa68b5c-da21-416a-bbb6-f0cd7f9b065d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92088b66-909b-408d-929c-2da98ea2f3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f76bc35a-52e1-4d3c-9f26-ad47954f4214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cfd6c77-fce6-4361-8373-99aa4a66827a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6d87b2-c7a7-4bbe-8f3c-28a3380d5532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 788ad830-fc88-4ceb-ba19-e8093cf99aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f25570-adb0-41e2-baa2-558f57917aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86601613-0c20-45da-9c96-03afde4e5018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f732849-3543-4751-8e07-4563d08a4ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f4a6d89-579f-450e-9f2f-63ac3013b8ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61d202e1-0bda-4532-9e77-5d9d5e532cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e01ee1a-2b49-4f5b-9661-ca20a9a144cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc35b4e2-b353-4996-9a42-8d495a7dee93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d5df1f-f83e-4862-a61a-7f0d3e92fe01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d6447e6-778c-4d22-8dcd-d3cdb790e829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49600690-e74a-468e-a9da-845d824016f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5abde45-cb1a-4bc1-ad8a-92a55cac8ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82892d8d-4889-4a05-8b74-67c491e21cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 040a5e94-9195-43b3-ab12-852682d9f02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe124083-12f1-4434-b722-052350de56a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39eda96b-c88d-4869-a901-86119ef9f223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9eabc34-0e6e-4080-a6ff-5c66a15bb4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d361e7-aa01-4542-b95e-25296432ea07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b1ddbf-79a5-4176-887d-014e502db0d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbb9bfe9-9db1-4e74-8e2b-c30b611b2d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7baa2c4-f355-4504-989d-b8c80a741ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57bdde86-1acc-4fce-81fd-0b1dd65cad0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23964635-5023-4977-a9de-dd1ee772c158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3af3b29c-e2d2-44aa-909d-6f29e8223f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3de05a40-3644-48bc-84f0-527c970a643f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6323fac5-c967-4d3d-8d9d-062a28a748e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 658dd39b-3a86-4424-8f25-9b45488fbeb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1078deb7-5c18-4c0b-94f3-a9834cf4c946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200818dc-cf9c-435a-aac7-e2c3044cf2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 905b087a-36b2-44cb-b9eb-e619753c2343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1011592e-4f91-49c6-a531-95da6a3b7e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4e17511-fe67-42b9-b5c0-a0b4c3f6ee86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1a7cac-4327-4ba0-a0ca-60f86ffc7297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fac8933-7635-40df-9414-a05c495f2d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c888344a-2330-461d-b054-9d091b4ef932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69080407-d3ca-478a-bdb8-2aa5462e8a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 222cfa12-2c9e-43eb-906c-ebdff1d6041a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 512be47d-afcc-4174-a721-271c8cbd22a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 618d95f2-2c4c-450a-9571-22bba29c9974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f22ccf11-56b9-4d10-9eff-f084c91e0b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b360822-c953-4e7b-acb0-47535992a759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793c5d24-2588-4465-b1de-35471553253c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0be9363b-b5fd-4f65-a519-426394474b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 887189da-94ba-4547-a0a5-8628965ebf25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1e2293d-cab8-466d-947c-61d962a01c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5853992-23df-4620-971e-b0054f29d935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37db9878-4e3b-4245-bf91-ef537dfb0743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe09ded-5aa7-4567-a39c-cf9be6e91bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 666d22d1-6ccf-4134-999c-e0a9da7d5757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77258f97-a9ec-4eb8-b3ff-4834d1a58384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04c6ca8e-dc8f-4a1b-b55c-30e3f6fcaa24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04476217-2a48-49f8-8680-a3078822b7df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b7b30e0-2080-488e-bab2-76b3ad0ade83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36eb1582-7641-4813-ae0d-350798090358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a180d67a-eba6-4b90-b89b-badbad3bbfca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feb77a29-6135-4d09-96ea-b2a8678d04c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a57a96a-948e-4d69-bae9-924a7b27ba82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d789ea4f-89bd-4dca-992c-e9fcb1af1de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96014642-983e-4263-9ac1-bae1a11592aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3561685-d6eb-40fe-aeb4-b120aa66b45c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00faab15-ac0d-4e05-a7bf-2a677b84b276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b22324e-a4ef-4e31-83dd-99ebe7dd709e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d2b7af-3df7-4e33-982e-b7b3bacd99f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07967c50-3aad-4008-ba0e-8c481544aa34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f497717f-31bb-4580-878f-71a18a6946e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74ec1a84-474f-4c91-a265-21e2cf5c4892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68256e0e-de54-407e-b066-21e45a77d913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321a45e7-258c-457e-ae36-debcc9634cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0104d6f2-750c-4041-9881-d25e37aa2d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e66b7e29-08e5-4a29-b005-802b39896a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7976124-a587-498e-b9e3-214bea14ea8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc8cc338-8ba2-457b-914f-d2287ac18092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1adf4242-8a9a-4817-811a-e9448cf58ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239fd51a-d1d7-4bf6-942b-a9b3a274c789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c95402f9-4685-414b-aad9-f41887187fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 975ace6d-7082-4527-9c5c-9abe5ab442f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56fc1709-f7b4-4550-8158-ceb2bcda8151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 939489bd-ea65-41bb-815c-10b2eeb97ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21fd2211-dd0a-4032-b591-eb15fc149c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce8a8f26-2dd8-4ddc-9d16-2879a94c5f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d142b4c0-00b0-46c5-a84c-93b3b0994436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 712980aa-696a-4ff1-bb62-7098f24a8dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 311dacf8-c3bb-4f78-b503-6f342b35a978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd7383fe-793f-4b5e-b48c-f46f76786a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c8b861e-af53-4d21-8546-8c063edc5ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a7495e-0aae-4ef1-8ebb-4df4a7c0a8f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fef00edf-7069-4bdb-a491-32d8ff4bc56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2f8d197-de82-4192-8edc-7bfab4a411d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1cef6cf-8b9a-413e-a48c-a5b333a24086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5032ee7-c4cb-4ed3-9355-cda4e3494c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0a7d06b-3deb-4251-aa32-ce7ef8b017a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34a12b1b-306b-4f77-b36c-30d60fc99ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c16eab4-0513-456c-9ba1-701476895979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4bc93af-9bde-4b6f-bc55-ed8e30a99e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fdfa0ed-c966-4443-96d7-dc6ab208dc6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 852ae319-aab0-4f64-a971-39b7810cc800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376d89d4-38ab-420c-b143-72db2a1a501b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc7471f6-4939-43dd-9ebf-da8bf9a46e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26960d70-bee2-48ed-b5c8-44c5be77128a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85fd071e-4edb-4074-a3b0-912e4290406b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7bc399d-9a94-49a5-a4f1-eadfb797e11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66ed629b-5745-4408-a9df-dfa427afca3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f78fbc9-5646-466c-9821-d04bdc799e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ea7cbb2-1d6b-466c-acb3-c27d845d399a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c25de673-2db4-4f87-825c-06460fb294b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d69bc97c-4bd3-49a1-b56e-265780ff0892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b421919e-516c-4aff-a087-da6ff8ff94ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83b13809-dce9-448b-87fe-afc16500bb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6f8912c-dbcf-4b77-95f0-853e0f6433d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd46f216-161d-4ac1-8636-b0831b85e01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df44d1bb-729d-44e9-b6a0-bf9ee98dc249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 803e5b33-545e-4403-85fd-9f9ec928d73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10573613-d628-4016-8346-75d372277000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb512228-fd69-4ce7-8ff6-bba1271263a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9570249-610a-46f9-bd21-6e55d1a1e76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bde3fb55-86ed-4621-8159-70d3b2ac01db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0bf31b7-487c-4de3-9725-32e0f6f7f65e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3568d62-6dfd-4050-be91-e42469f18b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fc6b1ca-983a-4d71-911e-9f804ec56d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e4c762c-192c-4c8a-8503-ce16155a166b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85866e5e-99b6-4486-bbd0-63e7a1dd0ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68c547f6-5bda-4bd7-b635-d48d1de2887c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f8c059d-0e52-46ca-9b00-3cd9c40869be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 174d4e6b-2b5c-490e-88b4-9c7f52f9cb3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc24e6c4-ad0d-489c-b4bd-11df4b7c7d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f57366e-bb80-4af0-b36a-c3f184349265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be29071d-6fd7-40da-acd5-898828cdef8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b0ec24-ffe2-4589-ac3d-a9ce7c815bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eabd1f45-c60c-42fd-b01d-ca0fee2084d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c8551ec-7468-4c48-b721-eb81a7dced88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2613ece4-8418-4b17-98b8-25a18dfc5a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c45fd54-8f2f-479c-9642-a2b759a2276f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 161c3dd0-7bf9-4d2d-a4c1-36dca9588218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b943d9-3adb-4d8d-a57c-20fd92da05d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 630a800d-12e6-4132-a8da-d8b3311479df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57435a23-8db1-4956-a63a-1680bb636ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e02d9af9-5ac2-4bd2-8dca-1eba54b2c934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6268475e-fb84-43af-9349-f99221d74e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27816c20-a53c-4735-8699-06d88d4c5321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c86b0b9c-e18b-425f-a496-9bcf1243f2a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 879deea1-7f3f-405e-9088-df9434736490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc20ea8d-4f2d-4be2-b622-5b4f99f2750c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3887f39a-877e-40db-a689-d7470cedaca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b93eb3dd-2c51-4e1e-9bef-b9f225b60373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f562e76-f2be-46de-b851-869caf208f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a06479db-12aa-4866-9265-8154c70945c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59d62dc6-e339-4ef2-b775-2a59d70651ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea7b6f5-f54e-4a0b-8e46-f838a18a25ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a8e340-1a16-4612-aab8-96510411c20e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b077009e-84d8-42c3-ab12-d727f20cbb52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7790a3d-f7be-4cb3-9944-a8a79f2d4b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f3214c2-d355-4a21-a356-c4206532ae71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe329336-6333-400b-8ed4-c0c2016855bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 448efcd6-b01d-4aae-a78d-e329d939cddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f093aba-eefc-413a-9e23-a7e6fc32e144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 174bb48a-14bd-4780-bd74-5f4e46bd9bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 574a0044-c78f-4645-a797-fd97c78630ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2307cdea-ec54-44c4-bd01-6afb74ce546c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 219e48cd-2429-4a8f-b9b6-f0da94cec1e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e64ed17d-8b66-46e5-ad06-bdd96121eb4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89df1eb0-8a69-443d-84a7-2a7a607f068a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e570ae-14d2-465d-b4b8-69a05c848a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85e6b0d0-0d7b-4914-851d-41c33580aa72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cda91ae-b7ad-4481-9f4f-484af49ac129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce80679e-cf0e-4675-b21f-3c469762f7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11fda6b5-ca37-425e-8b0d-d9ba51a7803f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8361604e-c73e-409c-9e12-fce104824876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e1146b6-a5f8-4f85-9676-edf4a04fa82b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e652cf3-3877-4116-8ccb-cd916dbaeb47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e75c352-3875-4f88-ac71-d2e421574d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4638e027-8e09-45e4-b6e2-18d822ffd182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66070f47-a1f2-4666-84b6-50c9070704bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe4d738a-5d45-4bc1-8425-8b3a14a02ac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a9c08eb-62cd-449d-89e0-7f97301d5568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb2bdd36-029f-4cf4-9bae-bcabcaf0f211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec63cd7b-a6e6-4f8f-b6cc-b266c9aa0149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3bbb0b4-d6dd-49c3-a599-38b61d14e446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eea1bd5-e3e0-4df7-9b0a-2eaa65fbd785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e4bc217-c4db-4930-8b43-91b8d8f29b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7357c64-766c-463e-a292-a3298b776a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be63a00f-d908-482e-81f7-ca12324d5cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5076b672-04aa-4e9d-9fb6-264f41f5a97d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddfb60bd-7e7b-4f72-a456-49aa934ac8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 549d1bd5-88c1-47e5-b40f-5d5a2d7276d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e02e5364-8dec-4d42-b21d-776572199881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7baa2f21-b8f3-4cbb-9c90-cd44150db8bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba84eab5-3847-473a-98cf-7caf07f3f59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f079ad76-1f2c-4d00-9094-f61a4cd9a6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ae99c2-d2d4-4eb0-a068-1b42ff2c48e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fb8857d-634a-46aa-9856-4915e8b4cfbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7889912-13df-4974-98c6-16af4d87192f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be4aebe-21b1-4002-8bec-f36823e31e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8484b81-fba0-41c7-b668-e93820bb9b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b352365c-aef5-4fa4-a617-17f1abce07cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0ff1add-35d7-49ff-a856-656852f69187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e75c27-e28e-4ed9-b60d-ef12a435442d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b7eded4-0edf-40c5-97d5-f240c5e2c54a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2288ae98-e463-4728-ab2e-1fa16f768d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9990680-3b4e-4c6f-9e40-30c6b71b395f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94864c98-9e17-4522-b4c2-2d87fe9016f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69630a96-0946-48f0-a1e2-9e1dd84d4905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f91cda-b23c-405f-83b9-be0023f0aa60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a300c23d-fa11-4ee0-9ad4-6c3bc872c39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ebf492f-9eca-44bd-91b3-e8cb802d2c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17eda367-01a9-4dcc-948c-93acb1b50abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 870f70fb-5dbc-4220-93bb-498212883259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cfed8a0-c981-47b3-b571-b1bc843aac43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88ea9719-9a9c-41b8-b714-a64ba2a39c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cfc6191-126c-4fb5-9afd-6b1aab9e0eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3b2b7e0-daad-41f1-841c-53ade3ae7c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8332bf1-9edc-4a75-89e9-3d055e68e3d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7866bd1-0473-4cf0-98d8-9d2151620830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ce8b3d-1428-4f12-b315-f1b3c1c755c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc07e4f-2ea9-464d-be90-cafbc96f2576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed6d0fc-dcd2-4225-9a24-aad2c43ce6be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d664e9f-9076-4bd5-bac8-3a91ad8dabcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 083cc3d1-8f6d-470d-85f2-2bcb6443ae85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59e6f627-d7b6-4f03-ad05-85dffbae7c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ec0f58-157d-4d2e-ba52-9b6d15a71761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab7fb1b-6727-41fb-976f-5f913edd01ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8936adee-1872-430e-a093-f6d2d6668609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e0e1bc4-c329-425d-b1c3-7f6b3c71ebca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b81189e1-df01-43ff-95f8-32732b71d18d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41e7b23c-9e23-4618-96ca-46071e13040c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea77d68e-a58f-412d-8e02-b23306371145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5553a3e2-44b6-4c8b-95a9-6d99e5b70afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c72dbc4-a021-44ac-aa37-1cabdc440a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8b77e0-9fb4-440a-af94-9a995822679b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9fd851a-da8f-405a-99a4-b8fd794bace4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f924f9-644d-420a-8b74-8d7298662f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0256f0d2-3efa-455c-8c0a-d2a70e6c87d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1976704c-40ff-461b-9856-c1588fcb2e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d389662f-f0ce-4514-96ae-44f7043992d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c22e51a1-153e-455e-8619-c8382c0cade4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56e9df33-9f90-491e-850c-f92bdcb513ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d7569f0-ecdb-4edc-85c6-7b6b0ac930bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b004d16-ce54-4743-9b79-a1c782cd8080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f89a4137-b390-42b5-b232-c520c960fb96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 826f4fb2-101b-4319-8519-9ad53e4cbc11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e98e82-2ff8-4363-aba7-d77045d3131c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed5f917-845a-4492-9c0d-527e1d8472a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 341e4d57-322d-4707-a8d6-8652c5151df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 554debfb-c648-419d-912d-4c519053714d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be210bd-1ed5-4790-8d17-967bdaea7c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc63ef9-4a67-4497-a492-c75caa3954ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c907a9a-b999-4b4b-81e0-9122457eec44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc23816f-7fbb-4cd8-9b85-7b2fde86e9f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16ab2c37-54c0-496e-88bb-a43790fe5621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8c5188-4167-4e57-8696-4520a2b79546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d43f261e-446d-40c2-90b1-9e13a75cf4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cb1d8b6-4bcc-4379-aa81-dab4f435028f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf39c5b-9ecf-4232-83de-01babd433f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02bc0b14-5907-4c13-abb0-6e0a7c278c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fc45417-627b-4c77-8f04-1ff41a30ecc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9ae6f3b-9ed6-4bc1-b21f-34c86a1e3cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 531a1912-6d4b-4407-8b1f-114a78e1bef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eb50d1e-2ba5-42cb-81b5-9505a6262bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efb8ebd3-300a-4fab-b362-f9d4ee1726f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1fcee1d-125c-46e7-8f15-9e383763b456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7b4bea9-10f6-4531-9fba-f6f2d3e34197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcbd45d3-b651-4e34-bcb5-cf9fc5736bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8231366-8465-44eb-a252-c985672d0039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dd58e45-a49f-4a8f-886a-9f7b7a6f6196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07293ab0-eb3d-4bca-805c-621b40ea5702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcd326a9-dec5-4296-8c3a-6a40fb045d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976b7657-24f3-41b7-9ea2-12a8b71c0081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46580a59-8515-4f20-8eb5-64be144807dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb0ea640-8667-4d4d-aa42-d479a5d757d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f7c253-0fa7-4d41-af51-18f99fc267bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 773b50af-04b7-4af0-8cfa-59ab4be8b578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 721579ab-0ed6-462c-bac8-32a9a87a234c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c2bb670-9d0a-41f4-8a24-15f230b7b73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0a5c34b-5f19-47fb-a3b1-df797e356bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0734c067-00a3-4f66-8f6e-81bf0275f7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a56c9ddf-542c-4969-b986-319a48ce2f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e325480b-4caa-4677-98f7-1ce9f4fb7749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 389d8055-b013-4abe-836e-a37ee90a1ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 431058ad-04e5-4e89-81d6-2f88d4fe1ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1aefab8-8850-4733-a42b-358b35024063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35fffe8a-8dc0-4916-9799-e4be16d0229c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c24830dd-5624-427d-8a9d-fe24933dcf57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c8a884e-386f-4b5d-97d6-76418d2a204a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6320fad2-0317-4169-9d32-d6cdbb80e3a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1ec0b82-831c-4bfb-8b5f-9aa1a4ab4d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa0b31d7-ab3e-4249-9f2d-efb06983d92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7af50d7f-13d7-45ce-8dee-eea0867b6e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65c78fa6-c346-4220-85d8-8a02ec380f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8915c1e-943a-45de-b042-387b4215520c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e83fd8-d4c3-44d6-a612-d062863ce706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30568ada-eb6d-4edc-a761-957716315e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 706f7b06-422d-4c52-9886-6d3ae806d3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06223a88-c88a-42d4-8b86-d7c3d1c554a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee5aee0a-c759-4df8-bdb9-a2f49043b54a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4abab5b3-4886-43f6-80a1-28e0ffe24951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5711691-dc37-48a8-92b6-6be50271268e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa7bee5a-9b36-4d21-a3eb-0c836d28a533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc534069-36f8-483c-9a9d-ae0f44e239c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02f0dfeb-f6d7-45ea-b8ae-f290329625e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f191a2-2630-4493-b204-705ece2f9fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a502d17-5cae-41a2-9d7b-36e928bf2157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f756b1a4-4df1-4139-b76b-96b456eae4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0736aca8-b58b-4f63-a846-3c915d7e3efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c75afcff-1e02-4df6-b393-6abceb8cc51d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79658df4-dab6-482a-941b-cfdb49898c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f04e0cc7-3b8c-4bba-b5d7-abe23449e626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820980ee-cb8e-4507-b990-e3f6e6c29eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5d4b105-f6f4-412a-9246-c9f05cd2c903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8a10506-70b1-4d8f-8866-580636459c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c1f0bc5-1e7b-48a1-94db-2cee828f45d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2419394b-9223-4c6e-b252-f8f1733ec636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4c7313d-3986-4b43-bc45-642be0a8cfd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f45553-8ff1-4d70-9f44-4bf8b722a87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a7ece6-01ba-4fd7-8785-5792571358cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c51a820-9f72-42e7-97c0-8b48714c5e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40d6080d-e8dc-45d7-8ee9-7d926fbc48a5
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_10
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/test_labels.txt

📊 Raw data loaded:
   Train: X=(4872, 24), y=(4872,)
   Test:  X=(1218, 24), y=(1218,)

⚠️  Limiting training data: 4872 → 800 samples
⚠️  Limiting test data: 1218 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_10 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2355, val=0.0904 (↓), lr=0.001000
   • Epoch   2/100: train=0.0875, val=0.0902, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0825, val=0.0873 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0811, val=0.0865 (↓), lr=0.001000
   • Epoch   5/100: train=0.0802, val=0.0869, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0798, val=0.0872, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 1 Summary - Client client_10
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0038
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0104
============================================================


============================================================
🔄 Round 3 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0774 (↓), lr=0.000250
   • Epoch   2/100: train=0.0819, val=0.0777, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0818, val=0.0780, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0817, val=0.0781, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0813, val=0.0788, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 3 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0007
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0042
============================================================


============================================================
🔄 Round 5 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0845 (↓), lr=0.000063
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0799, val=0.0847, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0799, val=0.0847, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0799, val=0.0847, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0798, val=0.0848, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 5 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0002
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0001
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2494, R²: -0.0016

============================================================
🔄 Round 6 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0714 (↓), lr=0.000016
   • Epoch   2/100: train=0.0832, val=0.0714, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0832, val=0.0714, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0832, val=0.0714, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0832, val=0.0714, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0832, val=0.0714, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 6 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0017
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0032
============================================================


============================================================
🔄 Round 7 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000004
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0816, val=0.0788, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0816, val=0.0789, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0816, val=0.0789, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0816, val=0.0790, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 7 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0003
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0032
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2484, R²: 0.0055

============================================================
🔄 Round 8 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 8 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0009
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0007
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0012

============================================================
🔄 Round 12 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 12 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0017
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0072
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0012

============================================================
🔄 Round 15 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 15 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0030
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0172
============================================================


============================================================
🔄 Round 16 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 16 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=-0.0015
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0033
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0013

============================================================
🔄 Round 20 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 20 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0017
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0200
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

============================================================
🔄 Round 21 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 21 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0002
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0011
============================================================


============================================================
🔄 Round 23 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 23 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0014
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0079
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

============================================================
🔄 Round 25 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 25 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0011
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0032
============================================================


============================================================
🔄 Round 26 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 26 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0000
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0000
============================================================


============================================================
🔄 Round 27 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 27 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0007
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0033
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 31 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 31 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0010
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0038
============================================================


============================================================
🔄 Round 33 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 33 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0005
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0014
============================================================


============================================================
🔄 Round 34 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 34 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0009
   Val:   Loss=0.0671, RMSE=0.2590, R²=0.0021
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 34 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 34 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 34 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 39 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 39 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0009
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0042
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 39 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 39 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 39 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 39 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 47 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 47 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0013
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0025
============================================================


============================================================
🔄 Round 48 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 48 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0002
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0029
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 51 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 51 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0011
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0172
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 51 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 56 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 56 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0009
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0009
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 56 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 59 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 59 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0006
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0021
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 61 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 61 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0002
   Val:   Loss=0.0694, RMSE=0.2634, R²=-0.0036
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 61 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0017

============================================================
🔄 Round 68 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 68 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0007
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0059
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0017

📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0017

📊 Round 68 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 74 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 74 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0006
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0019
============================================================


============================================================
🔄 Round 75 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 75 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0027
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0006
============================================================


============================================================
🔄 Round 77 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 77 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0005
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0081
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 81 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 81 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=-0.0027
   Val:   Loss=0.0937, RMSE=0.3060, R²=0.0074
============================================================


============================================================
🔄 Round 82 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 82 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0008
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0097
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 84 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 84 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0015
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0069
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 84 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 89 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 89 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0012
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0076
============================================================


============================================================
🔄 Round 90 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 90 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0002
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0004
============================================================


============================================================
🔄 Round 91 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 91 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0003
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0189
============================================================


============================================================
🔄 Round 92 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 92 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0006
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0020
============================================================


============================================================
🔄 Round 93 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 93 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0003
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0013
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 93 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 96 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 96 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0005
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0005
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 96 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 98 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 98 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0020
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0073
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 99 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 99 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0011
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0044
============================================================


============================================================
🔄 Round 100 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 100 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0007
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0040
============================================================


============================================================
🔄 Round 101 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 101 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0015
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0085
============================================================


============================================================
🔄 Round 102 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 102 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0000
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0001
============================================================


============================================================
🔄 Round 104 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 104 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0007
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0029
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 104 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 109 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 109 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0004
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0026
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 109 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 112 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 112 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0002
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0140
============================================================


============================================================
🔄 Round 118 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 118 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0010
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0164
============================================================


============================================================
🔄 Round 120 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 120 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0001
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0003
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 122 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 122 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0007
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0031
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 123 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 123 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0012
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0062
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 124 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 124 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0005
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0281
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 126 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 126 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0008
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0067
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 128 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 128 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0025
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0057
============================================================


============================================================
🔄 Round 129 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 129 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0002
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0135
============================================================


============================================================
🔄 Round 133 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 133 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0003
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0015
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 135 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 135 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0003
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0069
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 138 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 138 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0004
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0175
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 140 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 140 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0007
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0022
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

📊 Round 140 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 143 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 143 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0004
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0045
============================================================


============================================================
🔄 Round 146 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 146 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0015
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0169
============================================================


============================================================
🔄 Round 148 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 148 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0017
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0081
============================================================


============================================================
🔄 Round 150 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 150 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0008
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0022
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

📊 Round 150 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 154 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 154 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0018
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0113
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 157 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 157 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0019
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0037
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

📊 Round 157 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 162 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 162 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0011
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0311
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 164 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 164 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0008
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0038
============================================================


============================================================
🔄 Round 166 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 166 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0009
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0041
============================================================


============================================================
🔄 Round 168 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 168 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0003
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0025
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 168 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 171 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 171 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0045
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0192
============================================================


============================================================
🔄 Round 173 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 173 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0008
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0054
============================================================


============================================================
🔄 Round 174 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 174 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0008
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0033
============================================================


============================================================
🔄 Round 178 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 178 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0005
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0009
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 179 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 179 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0042
   Val:   Loss=0.0931, RMSE=0.3050, R²=-0.0127
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

📊 Round 179 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

📊 Round 179 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

📊 Round 179 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

📊 Round 179 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 185 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 185 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0002
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0044
============================================================


============================================================
🔄 Round 186 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 186 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0019
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0076
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

📊 Round 186 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

📊 Round 186 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

📊 Round 186 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

📊 Round 186 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 192 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 192 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0005
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0024
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 194 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 194 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0007
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0058
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

📊 Round 194 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 199 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 199 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0003
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0063
============================================================


============================================================
🔄 Round 200 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 200 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0011
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0017
============================================================


============================================================
🔄 Round 201 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 201 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0011
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0075
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 203 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 203 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0007
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0033
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 207 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 207 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0007
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0033
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 207 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 209 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 209 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0007
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0055
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 209 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 211 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 211 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0016
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0085
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 214 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 214 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0000
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0130
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 214 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 217 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 217 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0008
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0084
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 217 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 217 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 221 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 221 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0010
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0080
============================================================


============================================================
🔄 Round 222 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 222 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0018
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0074
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 225 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 225 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0010
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0040
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 227 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 227 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0004
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0012
============================================================


============================================================
🔄 Round 228 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 228 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0004
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0078
============================================================


============================================================
🔄 Round 229 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 229 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0007
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0027
============================================================


============================================================
🔄 Round 231 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 231 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0010
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0257
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 231 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 236 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 236 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0020
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0060
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 241 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 241 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0006
   Val:   Loss=0.0703, RMSE=0.2651, R²=-0.0023
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 241 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 246 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 246 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0012
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0007
============================================================


============================================================
🔄 Round 247 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 247 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0038
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0368
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 247 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 251 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 251 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0001
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0037
============================================================


============================================================
🔄 Round 253 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 253 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0003
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0034
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 256 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 256 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0002
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0003
============================================================


============================================================
🔄 Round 257 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 257 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0006
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0024
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 261 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 261 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0010
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0027
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 262 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 262 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0008
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0151
============================================================


============================================================
🔄 Round 263 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 263 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0000
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0001
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 268 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 268 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0023
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0088
============================================================


============================================================
🔄 Round 269 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 269 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0007
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0225
============================================================


============================================================
🔄 Round 272 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 272 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0007
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0017
============================================================


============================================================
🔄 Round 273 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 273 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0015
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0064
============================================================


============================================================
🔄 Round 274 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 274 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0025
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0090
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 274 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 277 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 277 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0019
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0067
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 277 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 281 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 281 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0006
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0030
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 282 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 282 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0016
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0053
============================================================


============================================================
🔄 Round 283 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 283 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0004
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0023
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 286 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 286 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0015
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0189
============================================================


============================================================
🔄 Round 287 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 287 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0007
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0105
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 290 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 290 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0005
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0041
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 290 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 293 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 293 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0011
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0068
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 293 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 293 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

📊 Round 293 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 293 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 300 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 300 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0011
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0002
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 300 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 300 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 308 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 308 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0013
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0261
============================================================


============================================================
🔄 Round 310 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 310 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0004
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0071
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 311 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 311 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0011
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0054
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 313 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 313 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0020
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0067
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 315 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 315 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0027
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0018
============================================================


============================================================
🔄 Round 317 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 317 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0006
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0010
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 318 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 318 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0027
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0190
============================================================


============================================================
🔄 Round 320 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 320 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0007
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0189
============================================================


============================================================
🔄 Round 323 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 323 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0013
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0050
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 324 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 324 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0006
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0143
============================================================


============================================================
🔄 Round 326 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 326 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0009
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0089
============================================================


============================================================
🔄 Round 327 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 327 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0011
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0033
============================================================


============================================================
🔄 Round 330 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 330 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0012
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0020
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 332 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 332 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0023
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0075
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 332 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 332 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 339 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 339 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0028
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0543
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 340 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 340 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0001
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0008
============================================================


============================================================
🔄 Round 344 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 344 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0013
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0044
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 345 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 345 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0018
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0033
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

============================================================
🔄 Round 347 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 347 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0013
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0001
============================================================


============================================================
🔄 Round 348 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 348 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0012
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0046
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

============================================================
🔄 Round 349 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 349 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0029
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0303
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 350 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 350 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0003
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0005
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 351 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 351 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0001
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0001
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 358 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 358 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0016
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0057
============================================================


============================================================
🔄 Round 360 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 360 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0003
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0074
============================================================


============================================================
🔄 Round 361 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 361 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0021
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0105
============================================================


============================================================
🔄 Round 362 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 362 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0008
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0020
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 364 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 364 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0007
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0042
============================================================


============================================================
🔄 Round 366 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 366 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0010
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0024
============================================================


============================================================
🔄 Round 368 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 368 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0019
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0150
============================================================


============================================================
🔄 Round 370 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 370 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0003
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0013
============================================================


============================================================
🔄 Round 371 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 371 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0004
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0020
============================================================


============================================================
🔄 Round 372 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 372 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0010
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0003
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 372 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 375 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 375 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0006
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0085
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 375 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 375 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 380 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 380 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0014
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0046
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 382 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 382 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0007
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0386
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 386 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 386 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0008
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0029
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 391 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 391 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0015
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0037
============================================================


============================================================
🔄 Round 393 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 393 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0014
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0060
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 396 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 396 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0003
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0009
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 397 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 397 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0013
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0296
============================================================


============================================================
🔄 Round 398 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 398 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0022
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0230
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 399 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 399 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0005
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0031
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 400 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 400 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0010
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0093
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 400 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

============================================================
🔄 Round 403 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 403 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0018
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0171
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 406 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 406 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0005
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0068
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 406 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 410 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 410 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0008
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0035
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 410 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 415 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 415 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0002
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0012
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 418 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 418 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0005
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0188
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 423 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 423 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0002
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0218
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 427 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 427 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0018
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0122
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 428 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 428 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0014
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0096
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 431 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 431 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0012
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0057
============================================================


============================================================
🔄 Round 432 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 432 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0007
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0023
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 436 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 436 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0018
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0042
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 438 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 438 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0023
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0018
============================================================


============================================================
🔄 Round 441 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 441 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0013
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0016
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 441 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 441 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 441 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 441 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 441 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 448 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 448 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0016
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0068
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 449 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 449 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0011
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0005
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 450 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 450 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0001
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0014
============================================================


============================================================
🔄 Round 452 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 452 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0013
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0039
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

📊 Round 452 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

📊 Round 452 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 456 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 456 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0017
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0053
============================================================


============================================================
🔄 Round 458 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 458 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0009
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0061
============================================================


============================================================
🔄 Round 460 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 460 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0004
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0073
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 461 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 461 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0027
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0114
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 462 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 462 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0000
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0005
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 464 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 464 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0003
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0045
============================================================


============================================================
🔄 Round 465 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 465 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0028
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0197
============================================================


============================================================
🔄 Round 466 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 466 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0005
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0016
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 467 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 467 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0001
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0044
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 470 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 470 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0004
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0044
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

📊 Round 470 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

📊 Round 470 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 474 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 474 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0012
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0059
============================================================


============================================================
🔄 Round 475 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 475 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0012
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0060
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 476 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 476 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0005
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0032
============================================================


============================================================
🔄 Round 478 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 478 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0003
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0023
============================================================


============================================================
🔄 Round 479 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 479 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0022
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0073
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

📊 Round 479 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 481 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 481 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0007
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0021
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 483 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 483 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0003
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0064
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 484 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 484 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0010
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0030
============================================================


============================================================
🔄 Round 485 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 485 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0000
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0064
============================================================


============================================================
🔄 Round 486 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 486 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0004
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0008
============================================================


============================================================
🔄 Round 487 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 487 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0009
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0044
============================================================


============================================================
🔄 Round 489 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 489 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0013
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0048
============================================================


============================================================
🔄 Round 490 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 490 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0005
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0304
============================================================


============================================================
🔄 Round 497 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 497 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0001
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0010
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 498 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 498 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0001
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0017
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 499 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 499 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0004
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0007
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 503 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 503 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0009
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0052
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 505 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 505 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0003
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0011
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 508 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 508 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0019
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0125
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 508 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 508 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 512 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 512 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0002
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0012
============================================================


============================================================
🔄 Round 514 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 514 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0002
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0017
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 518 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 518 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0001
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0014
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 519 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 519 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0001
   Val:   Loss=0.0891, RMSE=0.2986, R²=0.0000
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 520 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 520 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0002
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0060
============================================================


============================================================
🔄 Round 522 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 522 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0012
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0039
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 522 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 522 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 522 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

📊 Round 522 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 531 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 531 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0005
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0021
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 533 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 533 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0001
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0047
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 534 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 534 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0001
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0000
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 535 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 535 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0002
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0013
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 537 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 537 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0013
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0076
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 540 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 540 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0019
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0088
============================================================


============================================================
🔄 Round 542 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 542 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0003
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0016
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 543 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 543 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0003
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0014
============================================================


============================================================
🔄 Round 544 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 544 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0022
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0131
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 545 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 545 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0043
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0078
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 545 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 545 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 551 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 551 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0010
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0030
============================================================


============================================================
🔄 Round 552 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 552 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0023
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0064
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 552 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 558 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 558 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0014
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0011
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 559 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 559 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0007
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0021
============================================================


============================================================
🔄 Round 561 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 561 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0006
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0370
============================================================


============================================================
🔄 Round 562 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 562 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0012
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0018
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0016

📊 Round 562 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 562 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 562 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 570 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 570 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0025
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0004
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 571 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 571 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0004
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0017
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 574 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 574 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0002
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0000
============================================================


============================================================
🔄 Round 575 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 575 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0009
   Val:   Loss=0.0693, RMSE=0.2633, R²=-0.0039
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 576 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 576 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0013
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0046
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

📊 Round 576 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 580 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 580 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0004
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0051
============================================================


============================================================
🔄 Round 581 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 581 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0012
   Val:   Loss=0.0703, RMSE=0.2651, R²=-0.0054
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 583 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 583 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0004
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0011
============================================================


============================================================
🔄 Round 584 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 584 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0000
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0018
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

📊 Round 584 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 587 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 587 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0005
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0016
============================================================


============================================================
🔄 Round 588 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 588 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0022
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0088
============================================================


============================================================
🔄 Round 590 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 590 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0010
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0012
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

============================================================
🔄 Round 592 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 592 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0010
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0034
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

============================================================
🔄 Round 595 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 595 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0016
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0067
============================================================


============================================================
🔄 Round 596 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 596 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0001
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0126
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

📊 Round 596 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

============================================================
🔄 Round 600 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 600 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0020
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0110
============================================================


============================================================
🔄 Round 602 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 602 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0010
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0040
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0013

📊 Round 602 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0013

📊 Round 602 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0013

============================================================
🔄 Round 607 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 607 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0014
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0008
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

============================================================
🔄 Round 609 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 609 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0002
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0013
============================================================


============================================================
🔄 Round 611 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 611 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0002
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0060
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

📊 Round 611 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

============================================================
🔄 Round 613 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 613 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0000
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0002
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

📊 Round 613 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

📊 Round 613 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 618 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 618 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0011
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0133
============================================================


============================================================
🔄 Round 619 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 619 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0019
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0166
============================================================


============================================================
🔄 Round 620 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 620 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0014
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0048
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

📊 Round 620 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0015

============================================================
🔄 Round 623 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 623 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0043
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0076
============================================================


============================================================
🔄 Round 624 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 624 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0035
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0168
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

============================================================
🔄 Round 630 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 630 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0013
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0038
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2491, R²: 0.0014

============================================================
🔄 Round 633 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 633 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0001
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0197
============================================================


============================================================
🔄 Round 635 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 635 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0000
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0151
============================================================


============================================================
🔄 Round 636 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 636 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0003
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0036
============================================================


============================================================
🔄 Round 638 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 638 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0002
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0009
============================================================


============================================================
🔄 Round 644 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 644 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0001
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0005
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

📊 Round 644 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 654 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 654 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0017
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0403
============================================================


============================================================
🔄 Round 656 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 656 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0036
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0140
============================================================


============================================================
🔄 Round 657 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 657 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0012
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0031
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 657 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 660 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 660 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0020
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0153
============================================================


============================================================
🔄 Round 663 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 663 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0012
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0035
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 663 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 666 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 666 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0004
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0291
============================================================


============================================================
🔄 Round 667 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 667 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0004
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0075
============================================================


📊 Round 667 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 667 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 675 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 675 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0005
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0213
============================================================


============================================================
🔄 Round 677 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 677 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0006
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0026
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 678 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 678 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0002
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0005
============================================================


============================================================
🔄 Round 680 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 680 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0012
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0315
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 683 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 683 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0036
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0053
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 684 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 684 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0005
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0018
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

📊 Round 684 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 688 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 688 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0000
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0042
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 688 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 691 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 691 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0011
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0054
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 698 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 698 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0002
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0019
============================================================


============================================================
🔄 Round 699 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 699 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0010
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0046
============================================================


============================================================
🔄 Round 700 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 700 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0007
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0019
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 700 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 705 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 705 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0015
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0044
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 708 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 708 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0013
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0069
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 708 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 711 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 711 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0019
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0042
============================================================


============================================================
🔄 Round 712 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 712 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0000
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0000
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

📊 Round 712 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 716 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 716 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0013
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0047
============================================================


============================================================
🔄 Round 717 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 717 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0005
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0017
============================================================


============================================================
🔄 Round 718 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 718 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0015
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0070
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 720 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 720 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0006
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0063
============================================================


============================================================
🔄 Round 721 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 721 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0007
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0021
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 726 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 726 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0012
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0052
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

📊 Round 726 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 729 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 729 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0007
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0058
============================================================


============================================================
🔄 Round 730 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 730 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0009
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0048
============================================================


============================================================
🔄 Round 731 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 731 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0016
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0012
============================================================


============================================================
🔄 Round 732 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 732 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0008
   Val:   Loss=0.0696, RMSE=0.2639, R²=-0.0210
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 733 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 733 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0011
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0039
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

📊 Round 733 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 736 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 736 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0011
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0006
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

============================================================
🔄 Round 737 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 737 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0013
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0066
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

📊 Round 737 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 740 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 740 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0000
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0099
============================================================


============================================================
🔄 Round 743 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 743 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0008
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0021
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 744 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 744 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0006
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0009
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 744 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 746 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 746 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0002
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0004
============================================================


============================================================
🔄 Round 747 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 747 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0006
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0003
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

📊 Round 747 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 749 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 749 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0005
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0024
============================================================


📊 Round 749 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 753 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 753 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0008
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0019
============================================================


============================================================
🔄 Round 754 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 754 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0008
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0041
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 756 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 756 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0001
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0010
============================================================


📊 Round 756 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0016

📊 Round 756 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0017

============================================================
🔄 Round 760 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 760 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0008
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0126
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 762 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 762 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0021
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0061
============================================================


📊 Round 762 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 766 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 766 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0006
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0025
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0018

============================================================
🔄 Round 767 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 767 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0024
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0099
============================================================


============================================================
🔄 Round 768 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 768 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0004
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0029
============================================================


============================================================
🔄 Round 769 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 769 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0003
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0084
============================================================


============================================================
🔄 Round 770 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 770 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0002
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0003
============================================================


📊 Round 770 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 771 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 771 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0013
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0044
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 772 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 772 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0017
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0054
============================================================


============================================================
🔄 Round 774 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 774 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0001
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0011
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0019

============================================================
🔄 Round 778 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 778 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0013
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0081
============================================================


============================================================
🔄 Round 779 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 779 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0031
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0192
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

📊 Round 779 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 784 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 784 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0012
   Val:   Loss=0.0698, RMSE=0.2642, R²=-0.0114
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

📊 Round 784 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 788 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 788 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0018
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0006
============================================================


📊 Round 788 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 789 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 789 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0003
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0032
============================================================


============================================================
🔄 Round 790 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 790 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0000
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0036
============================================================


============================================================
🔄 Round 791 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 791 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0175
============================================================


============================================================
🔄 Round 792 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 792 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0010
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0093
============================================================


============================================================
🔄 Round 793 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 793 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0010
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0031
============================================================


============================================================
🔄 Round 794 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 794 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0016
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0048
============================================================


📊 Round 794 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2490, R²: 0.0021

📊 Round 794 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2490, R²: 0.0021

============================================================
🔄 Round 799 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 799 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0003
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0022
============================================================


============================================================
🔄 Round 800 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 800 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0044
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0451
============================================================


============================================================
🔄 Round 801 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 801 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0012
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0106
============================================================


============================================================
🔄 Round 802 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 802 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0010
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0364
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2490, R²: 0.0021

📊 Round 802 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2490, R²: 0.0021

📊 Round 802 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2490, R²: 0.0020

============================================================
🔄 Round 807 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 807 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0009
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0074
============================================================


❌ Client client_10 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
