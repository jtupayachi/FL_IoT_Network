[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7470ffb4-a671-457d-bc70-c8a6133b80a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5de44fac-d02c-4e2f-8c24-e6da57c8dcfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99f46029-3991-4749-9979-51f38fa5ebd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d31a5a1f-21d5-4ed6-97da-9db7f5d1bb7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6194e74-1fb0-4955-9f5d-feeae482ee21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e59a22a4-fc45-45b2-bab0-914510c42f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5877da6d-deb8-451b-8fa8-6e93495f1b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff858fd-774a-4e72-a663-cbb83230ce79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac00dbf4-2872-44f6-972f-e19d1a3aa85e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edbd0ea7-9a66-46fe-ab05-6004ca6ea6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8dc4119-b635-43db-8462-4bf621c0641a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c89a3b-a45e-49a2-9808-2dfc87cbfcf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 748795be-6a21-48e3-a078-2f77535f9a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f1ca26a-eb54-43ca-9fa3-db6eed0989d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a87ea9af-00d4-41b8-8f8c-df0cf5c8e9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe97a1b-3dbb-442b-b7ba-f371685bb77e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7445400-8b8e-429c-a4e7-d3868a1a9930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed828d6-d2a9-4b63-abc9-bda0f50d8c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe078947-d77f-4516-8e17-622376720405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5663ba56-d21d-4af5-bf21-bc6d816f6e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 366361ca-506d-40dc-90af-80f9b995ae1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3beb5068-ce4a-4169-8e58-88e8b7964813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2846add3-b665-4784-851b-4ef7727721e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a403f56-89f4-4018-9922-1117f470eb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8df01647-fa43-4bc7-9dd9-f18e02dca05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e4e6c9e-8d38-4c38-aaa1-0345746ab2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98215d74-c56f-40f4-976e-907722d4941f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c42a57-82e2-4a02-8f27-56c8bf44963e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2d2455f-fb97-4585-a686-d7fdccfe56f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b2be2a8-e0bf-4ce0-a8b1-4c72c42253d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c33b837d-4ef4-40f6-a77e-4cc60a90befa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c30fdaab-be80-449d-ae1e-58fd990b3070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec63f893-aa5a-4d65-8f3b-87c725467723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 661ca030-778c-46e4-bad1-3627741952eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd49498d-8c7a-4e87-8b5b-ce918bf8c768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919aafda-7280-455e-a42f-292a9bd84df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5208ef88-d18f-4d02-8ce4-b401897da8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc46665-e8e2-42c7-b051-cc6d0023973b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdc9b042-9b0c-4376-846e-289e1fbc7c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7934019f-3d23-4567-b4da-68889a15dafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1298b77d-f8c8-46f0-8aa4-d7aabc377422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7edb9e9f-0cad-4333-9fb3-905ff07c8760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c8fe6f-d2c4-455f-a7a3-49220eb3ef43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ddcc0d6-f37d-440d-bb6e-dc2657b4088a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42505b59-deb2-469c-90fa-6c3548468a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ffd1cc-1bfa-41a3-8c91-660b8155a247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b32ac5b-d869-43cc-b118-e9484c5efd93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdc84238-1dbe-4a36-a1f5-aaedbd61c4e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3611756-85d5-459b-8ef0-43cc3a30e5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06bb3558-cb6e-4dce-a8e8-628af29f37dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b62645-6294-4796-8ccd-1a451ab87b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c4d761b-205d-4df5-b8ac-4dd32aa5de60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14fe8e17-b331-47c5-909a-b780b207c140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59bb5f68-727d-4742-80ac-90d427d471fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc09b35-e2fa-484e-ae0c-a74c71fabfc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7645af15-b850-4498-a525-261c5ee21aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5737cec-26dd-4fd8-8f7b-5b0a1fe58fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e21df016-bf27-4a51-90f8-c3a77bd800a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24dc47b3-4764-4eb8-9289-ffb4ef03f861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b22800c9-20d8-4de8-9021-151559dd4b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80e5bfb9-6e17-43f2-9cd3-ea8ee992d735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9334a4e-6942-405e-80bd-2f11fd9e4499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 187aee71-ce9d-416f-a2d7-5258282437a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f69243-39b3-469a-80fd-9a8903a9dc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01f29f20-18a2-4514-8e00-dbf9861427d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6955355-1b0b-4d17-8b8c-4fdadb7abb65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adddd15d-dbaa-49ab-9705-923486b65695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26b72f48-03d1-41ac-a76a-1e80363642a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32ea4bc6-f907-42fc-86b3-468ef2eb0296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11c41e57-e551-45b8-986b-553d852070f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d87922-35d3-437e-b83c-43010d29bcc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 252be01c-3c89-4d45-a28f-d4e899e4445e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73c1868f-a176-4ebb-94d6-522743d76def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d0c3f66-90e8-4f2c-985a-8c67eef543ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49cf07b-148b-4f3e-b032-feb3e1430468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2af9d1fe-f296-48ee-9dbc-0f18224987d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e6c4b42-221d-45e5-81bf-463d05ce8afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30dca8f5-4c54-492b-a216-76831a207ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9176029f-7afa-40bd-bfa7-8121dc3c9462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c3bfba1-0c54-4d5f-9c91-ab149071c575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5548c05a-0131-4450-9f06-8e775e0f25e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48a8a8e0-10c0-4e98-ba26-d6b9bb086b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0775970c-8fcd-460f-8768-8b82c742590f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4276c93c-2a43-4f37-801a-a210c9aca55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eac77208-007c-4dbf-9154-c5af7b278901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5db7b7a-66b4-47c5-8c2a-b1d8656fbf47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c970f1a-9a32-42d0-8ff4-564f0c95e90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8d4cb03-d123-41b3-95d9-2bfe446df3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02721f2-89cc-4a9d-9fdd-314a8ca9c73b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f4d11f-646a-4a6a-9fe5-558f6d4ca970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b95da2-a382-4248-9c47-1f324146fb63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a1c089-8ee9-44fd-91b8-e99ab2945c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b365c5ca-a339-4cce-aeac-43dbabef2bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae682218-3f92-4137-ad14-0882f2b72de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b83419c5-c3ad-4b31-b15b-5590dc393d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c3755e9-673b-4b4f-9c44-5747c2aa3554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 281474e1-5e23-485b-a8f9-9bc1f30b6991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2425d2d-be5c-4240-9682-8ec2d496604d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea60c793-e027-4850-8ccd-a92e71f4196a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7027533b-0d63-48ea-8f06-a5d9537b8c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 067bd21c-4967-4ff5-aafd-31dbb715d01b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1fdbc2c-4d36-4a9b-b204-7feb5978adb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8faed261-01b9-447f-b7f2-4a749c0b20a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fda66d3-aaf1-4a37-8ad3-dcb19a7b3187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cabca6c-6b3e-40c7-ab57-e0adf8c76ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb581059-6c29-478d-bba7-edf3bb2b827f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee41ebfd-6573-4966-9740-c9b6d1c2abd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d580aa2-3248-4eb6-8b31-57a6828236f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1eced20-c068-4005-819e-96cbfa85b50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f71ce731-1810-4f89-b560-bf31c945d3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ca7033-0f87-4fbd-984c-6cc1bac9da75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a26cebe-cf07-4077-a32d-110daca7d635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e5dac20-f258-4b8b-9bb5-ffc946f53566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 919d5420-91f3-4033-8828-82f802a84fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc69efcc-b3c5-4e45-b9f3-88af02108fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9854e73d-98f8-4eb0-97e1-3809c4fc93d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a45835dd-128a-4327-8d22-acb574662ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a280e54-616e-418e-b159-bfa060a612aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f598438f-e9e3-4afc-833d-cb5359443e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74bac155-9337-4eab-9e43-37dcdd6057f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922f8ab4-bd16-4129-9329-feef5f851e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a49b3e6f-066d-4a39-9a02-e6620e41f761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76501bcb-a434-45b2-8030-8fccbc60fdae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 899502f2-aed2-4896-b414-5eba7e8a5a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6ee0e56-765b-409e-aa3e-87ff158daeba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 418c57d7-8e0d-4f90-a564-c7aa50ad91d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 785e28ee-aed8-424c-96ad-fbce4557785e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 364ce693-c63a-42a1-af76-5c9815907d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6135c84f-9ee3-4046-91ed-939eca51dbd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6709b57a-8756-4244-8ab1-0eb72b99cd7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c450aef-e6a0-44f7-a14b-98e515999ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 703822ae-0f4f-4ca1-8c74-a826cf01527c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc915e19-cb25-422d-9da3-29084ee62ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe149232-52c0-47b3-b697-7e5b257c0787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 335669c4-5566-4af3-ad0b-5537b1ce6cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 425ae7f1-1719-4356-a3b4-e291bc037ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57b70c89-a8fc-4678-89f9-f77c9d5354ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154755cb-655c-4d51-954a-075a8b481ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0dbd294-8dc3-403d-a126-64b7fd6f1db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3036565-3402-4016-88e1-f2c93badfe7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9db1bc3b-7750-4bf3-9fdb-9f8213eb124e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 881c34bf-3076-4f73-8a54-f7df20a7e611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bf4368c-d3a5-4bad-973f-71bb30f6c3a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89710452-91a2-4441-85cd-e64529372144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c3b3311-9c88-45b9-8d4a-61b2f84fda4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeae2c94-c57b-48db-8473-088ffa1cb928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ab097c8-4d58-41bd-8d94-ba232abf74ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc4da2dc-cdae-4850-99b1-4ef1b866d8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee873e55-0f76-4e9e-87a5-b7a405814e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97fa4432-fe2b-4086-8af0-2ae31b9f28d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e822ef07-1b9a-451b-b75e-7833ee872935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1bbb024-5ccd-4ae5-ade9-255fffe4e6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9fb7f15-f33b-4064-baeb-5a3b0ce4f56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085a7ddd-4ffb-4f61-aa08-c28c42045675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01e9c710-e5db-4d57-8474-811793b85676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d2b0e3f-1c76-4077-ad8b-56b32bf35414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36ddcd10-8d6c-428b-931e-3ae380f115b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf263e9-39ea-4520-ad99-bad055ecf15c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c350d58b-41b9-4189-8458-b3ad7bb636be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5989f8c4-a5df-4b53-a9ed-2abcfe679494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 146d5af5-79e0-4ad6-9a88-b83af476bfce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe459732-84b5-4c76-a563-eb164420e560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a73b6f4a-4a74-4363-b4b4-23040662f4b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4490c9ca-34e6-48d2-b149-8ed42213ac90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb84cc8-4476-4a7f-98e6-4936cb6dcd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e69e476-4ecd-4d62-ab95-da5707f067bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90e0ad5c-4273-4202-b519-9f8ee9478566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 998aeee3-2a12-4f09-83ef-947d394ee58d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdda6a3e-bad4-43ee-935b-234d1b8f3d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309fe21c-1cdb-4cca-9cf8-b6245754f1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43cf3e09-f3d3-4770-9e68-7dbf85130a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8e17cb9-a949-4609-838f-e0e07237528f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e09fa73-0f7a-41d4-ac93-0a8af971e26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6c35399-062f-4230-9e76-a030b199c70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d00c62cc-a3c9-4b18-af4a-b6738c503f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da2dc8c3-3550-48c1-869c-f0ab162c477c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c8e7199-865d-4e7d-98f1-75f6ebb89040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784a826c-b778-4f1e-88cf-27645cd8f1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c98c70f6-9822-4004-8c45-2978dd6f32e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42095a3b-1667-4500-a28f-0ae4fb942263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f19cac4c-fd3a-4ea9-9ab3-05b7784ae593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19148ad0-e503-4a10-83b9-59396ef61195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 363caf7c-bcbb-4107-bec5-2d14a3546219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbe243aa-b149-4747-b140-a2f47ecbf1a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57d99eef-db2c-4365-a113-562c2faeaf44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3908396-39bd-4cf8-ac5c-3209e32865ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8842a15-21b5-4fb7-afc5-5bc1442bd45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84d8d66c-9e61-4998-bec4-918e37c35150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d73f17d3-1d7d-496f-8f5e-527497c9b286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a20ed09c-e7d5-4183-b6fb-436b5b3f25e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90d47add-9f38-4e8b-97be-acd4ff0a4b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b2f034-e40d-48bc-a683-27fded746085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb695ae-f6a8-4462-becf-83e61f94cd14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fc5c700-4bc4-4c13-be40-27c694657fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a6182b6-6467-4f90-b90b-6aaf7e421af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62feff51-9f58-4e3a-9b38-b30a1dab16f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb1fb906-14cf-4ba5-8fad-b26d84118809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de85e8f5-89ab-40dd-8ae9-dc16557a710d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b22bdeb-f5e2-4ded-8a6b-82aa5da5311c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ae1f081-8547-44c5-9fad-e1b577dfc6e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d0dc55-ff6e-49a9-a2d3-6d7860907bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dbd38f6-4258-433d-afb8-c86d7f6200dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be020adf-d6bb-4abc-86f1-18080d93a108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c65cae72-1e75-4502-b38a-c10daa49c9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e06b214c-6bab-4235-8f4d-aa827eb87955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66820799-3330-424d-a289-86f1c8a52be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01450d00-4c98-43be-a639-bcc15454397a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f07c412-c1d0-4042-9206-421785051186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f08dfef-87ff-4f9e-8a26-79633590c3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbd90964-85aa-49d6-baf3-bef359709cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff845a9b-65f4-4020-bee1-2e02a3c88888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6163571-15ac-4149-8e1d-bb8ae323eb75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 576ac7f2-8286-4d0c-a46e-bd651e690efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93f129f1-91fb-4b05-a47c-04e0426defc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 774c66a0-95cd-4e18-b310-d4a6c5f71b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd8ed08-7253-4288-9938-bd8f36bd7b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26f176e0-4204-4c5a-a1de-ccf9adfa6043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc08695-3dab-4cfa-867c-befab704bd88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efe8c23e-63c5-4cf6-9934-5ec466818a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a042558-9381-4e58-9512-82529c4ce1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0101f7dd-11e2-4c8e-a249-741bc0252b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b25de80-23c3-4d6e-9083-1c4d22a81083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 005b0d41-5a78-44db-8c84-53aecc12d107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d342339-94d1-4587-93d8-e72ecccde37c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c82ccc56-2aa9-47f2-8d45-42e91eddb505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 337e976e-b06b-48ac-9843-355ed3c96858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5afed72a-b68f-48cd-ac12-54178d04dd37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 589f78f2-0f0b-40db-8373-9fc7e31fb8c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be6cdf3-733e-49f1-a0f9-e43cf2420f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b239fb-1e53-4b57-9181-a447ec1768e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 549d169c-9997-487b-8d62-34105fd955e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c35ddef-ec1e-46f1-a3a2-7343db2655d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 338874df-eb13-44d5-90ec-6ba03992f821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95716b40-2225-4627-9398-f2084c9c1645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07a3c5f6-c8f4-46a7-839c-9d6c2d61f5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d30c5fca-bdc5-44d1-b552-b1387f7c38a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 244832c7-9402-4644-9fa1-6a3567502ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e7552ca-df2f-4010-a141-719a3ade6eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aef9bae-92e5-46bf-ae3e-fec1ddf2ecf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09905e8e-4291-49a9-867b-b40d6b7807d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 395fd1d5-97d5-462e-8562-8721bae21063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89895353-8052-4783-b5bc-0a97cca82515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 287f3f0f-3c98-4498-9683-d617b1c3bcdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1b4255-6309-4e5d-8a87-5782632945e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a108b7e9-66ef-43ad-95aa-69b95307efd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2272e712-5ff7-432d-ac9d-1ef5628e5222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd45c4e0-1270-41fa-bf2d-42b227dfeead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2debc240-e127-418a-a875-5df47fe12407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af557cde-d46a-4658-8d29-efdfcab5ce6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e991e08-d937-4686-88dd-714985a894b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb42144-2c33-42d3-b3ca-65ace90901ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4632301-9df9-49b9-a404-7dac21e34550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be009cb7-4a5c-4e93-8ee7-89d6906f954d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2b93c13-9a7d-40d6-b03e-1f53017b6f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f99a89-5165-4350-94f7-86ef1f31b5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 679a7596-fd89-44e9-8c44-9d15c20b2daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14f20580-4f23-444e-a226-8b4ca03789e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 410471b3-6c38-4506-812d-78d3d1cf7f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b72850a1-355b-4afd-b17c-252e3b372f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c05a2b-d6c0-4ade-bea4-77c8f1c5fa29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45bbad5b-5cee-42e9-a0d7-1b52111f2848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 911ac01e-ff49-487d-84ef-0862af6ec6e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07aa343-77bf-4dd4-b5d1-8bbb09b83504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff4d9ee-e85b-4cd8-91c1-e47401c81986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3398cd6f-72d0-4305-b52b-977f8f697a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e3c3906-09b2-4599-88f3-5989504d2653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0842ea6b-33a7-4044-bbdb-f8de1f5a2dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b5416d1-b291-4740-994f-b7a70c0a1575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69c3cf89-cf33-4c5c-9f5a-782d869b0905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dfe74cb-34e0-435d-b1b3-9df59fc42cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de430e3b-b71c-4e84-bcda-e57742bc1c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d1dae8-86f3-4191-967c-28e608c38739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f0922ce-298a-4804-8a6a-fd83eca2c990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50c09ac7-3046-434c-999c-ae6365913c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecc25e26-a91e-4836-b478-cfff3087dc5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 113770dc-4a7b-4a9f-b21b-85cc5019aac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 223115cd-7507-4dca-b379-577f52ff3432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fa253f4-c91e-4347-91fa-e5075edea2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2ee7f40-2db3-4dce-afee-bf5aa27deaf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edad59c0-901b-41f7-8ea3-47d64233b828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba631032-6df9-4932-82e4-e15c681690ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e047297-b2cd-407c-9587-2df170eaff9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f95294a-b0ce-4bf8-aee0-9f34952338f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 182149b4-7011-4515-abac-d38c48816bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 205f933d-56e6-429e-89a8-c9f1db5721ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29505934-ec67-4a3a-a7be-d95cdd78b7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3102820b-c4a6-49a3-b98d-8abe79ebed59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0ced3af-baa2-4b2c-a627-a16c751efa3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f30644e8-e8d5-45a1-ab80-66bb49795339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c04afeb4-7c71-4f7c-be4f-c684768f3872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c8384f-d28b-4908-bce8-f55c332547fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0557202a-0c17-49bd-8a6d-f6b386c34ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d04dc827-978a-4b7b-9292-2e946f1d4bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eca1828e-b1a0-42e7-ac32-5732d7add6e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ffadac8-e3ec-47c8-9d91-af9bcea63a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d6216ca-cb16-466d-8963-e197bdd7fd95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72a43855-7377-4cd3-9348-faaaec9cafc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5774fc0d-ea52-4ec2-affe-2ca63d95a44a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 250e3399-e911-45c2-9627-5bc45d45aa18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d47591-576a-410c-b694-e12d44f6febe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eda4aba-4025-45af-ba82-ad5882723142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c31caf-34e1-4d57-952c-87b82f12ef77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 049f2d14-e25f-4586-983e-1e932da9f7a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7a43cc-3857-463b-a5bd-398c7efa3847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 933dc60a-be19-4b4e-a989-0c5d0e1a7634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68781261-9f20-40a1-839f-bae52f4275b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15f45802-0354-4617-949a-02b16696a534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fa1f4ba-d946-4510-991a-4429f462ea05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be9040e1-0eb3-4513-976b-7322b03ef02c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efedf6dc-fc74-4b32-a938-bc95a248f2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dabd2b3e-4b07-4fc7-8a1e-b4789f15668f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcd0327c-d22a-4455-b59e-43924c896b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f6f971-57dd-42c6-bf24-f848247454d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90b09324-1dcb-4bcf-b996-e5c57498c0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b29d6c7e-1c8d-42be-b783-b6d1751498b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81941473-d15e-4223-bf75-d316bd8dd364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35c7567a-ea88-447c-a879-85f46d4c7469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67548b1f-fb72-48cf-9082-167db9541f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79cd2b4e-9b22-4ed7-bc17-8005bf136ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77462e65-467d-46dd-8ba4-40763e23e0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a957a7-7497-4020-9630-e98ccda49937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2dee47a-8e37-4eca-a3ab-32642921c18c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc752ac-3707-4947-8034-89fe7a352e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ec04009-d9d9-4c26-b19d-0d0901b5a4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9a79ed0-59cb-4109-9e01-db7f293d39d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ac95583-01da-46e4-8fd1-80385e59fa74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 564403d7-2474-4c71-bd90-477db6902431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a39869b9-de15-4fb5-8964-b2cb9ff51f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26fa23a3-7c15-4b7f-a288-f620ce695572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4785eb04-bef4-4207-a4c3-7daa3dc8bf6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4bc33f6-0214-4e1f-a664-8c607662323b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb642c14-dc29-4d74-ab2e-688495820b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff20275-8789-4f11-afcc-f631ca0f5b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 474ca51a-0e77-493d-b53b-350988134d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f050f8d-a7a3-473f-8595-24687c04be40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f0b9ec-2d0a-47b1-8c3a-a7d6cdd86b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed579a60-81ad-4b0a-867e-c11df4eae580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4438309c-4727-433e-acba-202e5ca21ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48b938d7-05cd-4847-b0bd-1b3b12d05d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a90591-4d88-44de-8cdd-a45658afe7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 724295c5-52e2-4476-a18c-8de4f8b8b585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbae03b8-b16c-40a6-8ad2-cf1b77b6d492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccefecc0-d055-4ea9-b9bd-532331c12c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d671b3-209d-4a77-95a1-468acddd8fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47328282-5bf8-4a66-aa41-2fe680b54c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7def1cd5-e639-4c32-b852-c9fea054cb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbad5f30-0593-429d-9da2-9b2057f18095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ed1a40b-ec3e-40d2-8444-9e9882e3c1fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f189464-7c5a-4dd3-a91d-6de81cf53ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b88e7e0-fde5-4d03-92a8-ff50678c8167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3781fa22-9621-4c88-9600-dacb78cdcf1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd7dfb31-4e13-446c-af53-f4198368c50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58955651-64e5-458f-bdf3-4aac6e40e7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ca11bd7-4c16-48f2-ae3c-0e5f2fa21b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec81be2a-3efd-4083-b3e2-17ad917d67ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c52f19ff-747a-4801-93a7-e9610c138a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81660663-449e-48df-8bfb-89e3d8c3622a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6487d284-48e6-4a87-8b69-98bb676e919e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f66df20-defd-4f5a-9319-ee3d1adb12e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 414af82a-51ac-405a-ae58-935b03bb95cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3eab054-e03d-4ef4-af96-12dc9aefc73e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8778a71-fb53-4c3a-984f-78aa287bfa1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba2ca775-2648-45c9-9cd4-d64c9e983b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69593a9b-0e53-4b89-ae5e-bdd49f856069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e031c23-e3e4-40d1-98bc-5218c775accd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8674d571-a3d2-488d-8dde-499612bf7cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d417973-b973-43e8-97a0-6916d0c6669a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a71bccf-0585-4be8-ab60-cc5591d77083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfd27003-ce22-4ab3-8fec-aee22e8ef8b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51a1f230-6f56-4b5b-89d7-6a50e9ead4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56951e5b-2be4-41a4-86ac-54ef2ee8fd87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6c46e92-d05b-4871-9924-6ad61edd701f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32390a09-02e4-481f-a1f4-2c9abc560fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1426cad2-cd7d-48c9-8955-fcddd49d8da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6127366d-9235-4dac-9f68-ff75f4cbad69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad2fa19-ff69-459c-ae38-b38beda9e5bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86167911-8229-47a6-9ae2-516b9e5a6c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee21c76-0c05-4702-a931-bc3124386f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7892c7b-3b4c-4b1c-8f68-802dafeda22c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 971c639c-ec83-435a-a295-8492e08a7a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message facc1c99-f732-4d4c-8867-d79470049f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad651a2c-8513-484a-995a-f59704aa9e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb147104-248e-4739-84c3-cd383f0d0135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a99b2ae1-18b9-4400-ba5c-e45a06cf1bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7879ee6-8a9d-4cd2-805e-18574c980b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15827318-db37-44c8-9120-76978ef31a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1fb6da4-17a1-4b5a-bc6b-88e6c2765813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ec0814b-f662-447b-8edd-b8a3ecfb14c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c29363ad-c691-44de-8824-3465b5d6a514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e51aa02-bcf7-4538-9f79-78c8527eb262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11be5846-ba5a-4d73-b8fe-5b6a2611cd5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3656910b-fa27-4826-b291-7c88cc8555cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01114ede-7cc1-4d72-a997-caaef164c038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0d9e3f3-db97-4e5f-a3f6-3d7b30f0136a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4584eb0c-f708-485a-be35-f5cd16a31bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7acb2786-94e3-4ba6-be54-59b71676ce32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36c27e4f-4c48-4934-a97b-d5d0174053bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f301b2a-cf75-4786-9c25-db72430fe89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9d176b2-0ae9-42fc-8712-8c275afdf9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3532b98a-4b7b-4554-9230-a17170225937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9848d4c-2fb2-4aa0-8ba5-74a92c5955b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75c605b8-88d4-4ee2-8890-f7d34738826d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d9a5843-f887-4068-b4c8-ced0107af5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff051b72-66c4-41cb-b94c-b29dcbb0fa76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68ad4f86-bfe8-46c9-9a34-fbcc81c881de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a9bb4b-6152-4840-8b90-e7f41de92073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2462ba61-9fe8-4768-8f89-ae22263118b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25655043-b77e-49c2-8c0d-2e1def2b74e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e890a395-80be-4243-bfac-75809741f205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ed6516-fde4-4f67-9d76-ceed57f9b503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c6ca68-035e-451e-aba6-c7f2a6cfe7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 083896a8-01e8-4267-83b8-ebc9f7ed2b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2d5fad8-08bc-4efe-96b5-0d1c5a9b8d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b45193a-e951-425d-b89e-bf2718302516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eed8aa81-fded-4f02-88a4-dbbec5bce030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebccd3d5-f960-4f41-bfa8-0c74e6043c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20101533-c539-45b8-9a07-fe886193e70f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12426953-2a39-4200-8e1d-86df05bc6288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733a0c32-94c1-4a57-8573-f3c1557d54d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b278a5-4b93-489f-ae67-78a9ad8ac23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae7774d8-fddb-45c4-8f6e-086129d469cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32451b5e-70a8-4bb5-a514-63f207282828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be2d396c-4ce7-4a26-aefd-8a6e284b38c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86df8228-7a32-4ba6-89b0-2995037b47c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6e886be-5950-4ae7-8100-9b582bea2bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c219071e-c179-45dc-93b3-7646ced4951b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dedacbc-d8e6-47e7-8e0a-f41cb749dfeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d43dfd89-62dc-46f7-af89-49ce642a4a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b915f20-dbab-4d96-ba65-10ce5ca2c368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c985ed97-435a-4833-9902-1a815ca8c9ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea90268a-df46-4080-93e7-a96ea893a5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 735c6819-e30e-48f1-a6fc-358a6d325ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44046e31-3c5a-4f9c-afd5-ededed2169ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49e6706-4c56-415b-a98d-2258a1158bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4900799-0d76-465f-b273-9a9a1f6c747d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588a4377-617e-4f11-9724-868f163da66a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb2eeb7-e4d0-40af-9e91-8f2bdecda603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1662ce54-1837-4a1f-be6b-15219488d59c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 557519ec-e23d-4191-aa5c-4675e90cfba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0302be36-4bc5-4154-9029-16003a3b0c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b4b05c-5e54-478a-bd9c-453075ad7e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1faa9b96-cec0-4bba-a8e6-837fe10dec0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a065e557-1af9-48dd-8217-ea80693563c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead5b9c0-0494-4f6e-ab6b-5bf8b79dff64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64bc5d8b-8d91-400d-881a-36d7d0247bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a00c04a-a732-436e-965e-934f98bb06e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad37c65-490a-42e0-b623-fd3f2d8a286e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53458b4a-acdd-4160-b5c1-52e324e586ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9a145c7-3f30-43f8-89ab-6d55c6dbe4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48389369-2569-40c8-a83f-f19fbf9aee61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b42dfe50-a3d6-4226-8bc9-3d0bce337471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da47575b-b4a9-4788-a745-b2468dfee253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61366b1-edf6-4a27-812f-f3577ab9d749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c4aebf-82db-4d55-8501-7eaae64907f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecfc023f-6da8-4b14-b2f2-c4d7da3dbda5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 108becea-146f-4c78-a0ae-2170691982ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b39e7280-84aa-493b-9b74-94cf56c54242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ea84495-15fa-4990-b1fd-190d18c3de56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdfa9ae-1ca4-4247-b895-4e43e9cbce19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1557a141-fd41-4509-a023-a208cf1af38a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5595e9f4-6d4b-421f-a38a-5584477b7882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa35b8cf-9f0b-4d8f-a759-933fc1ac6ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96182c91-4d35-4040-b092-1e23e9ee64d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c9d87f-57bd-4622-a1f7-4802db353609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa560aa2-8e1f-4be0-acd6-c2582064579b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c6d907c-3712-4b60-8bed-c7a9aaa84ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccc672f9-54d5-4548-989e-f587f0fa08e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76ba6c08-1555-4b34-9eda-2c25f89f6acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7c3faaf-8fb7-4053-9685-aafc3e287e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc864aef-f3c2-4b34-8a4e-649d36ea6b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61cab552-a7f2-4ae0-a838-0611a1e42407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1916ef-fd46-4382-a136-6c38034d8c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d9787e6-a425-4625-88ea-f61428b58cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b66236-0d43-4f72-b40e-20864d00e8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 084ccd69-9b2e-4bfb-b66e-b597e83babb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc1385d-228b-4455-8860-0f28d183eb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c437d78b-dcb6-48d2-b04e-3a3af9d61740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee38084d-a992-4e3d-a9e3-e0296040332f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d09f86c2-4c65-44c6-81b4-257ca9f13b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e64b8f6-1e14-4d83-85a6-bffe8b34d8ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d311326-aa17-44f5-a2d0-512e6ceee078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f271051-2c77-4c46-87b3-0f3611365e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ba17ae-6c37-4618-807c-e7b96e43de17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17915388-91df-469f-b216-9059c516b800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c1f9651-7dfa-4ed1-991e-2740e99b7897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0805329-0e74-4812-9765-519696082a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14ea7b00-fd09-47c1-aa7f-154aa2963c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a32323d-4cec-4136-bcc1-4e0ecaee9f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cb01757-0623-49d8-80e0-bf4e40e74993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7343485a-8a30-457f-8b49-fd6667d3f425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca72f6a-a2cc-4b94-bd08-c613a9358edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d88fbf79-c86a-4f7f-a095-d4486148e693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13b1a7e9-0c55-479e-a36c-ff22c7066cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4bb5e17-7070-4fe7-acf0-4c865f9b58f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6097a4fe-379b-414a-b047-a58cddd45199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3347cc6e-70ae-47b1-8597-88563f682af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d5ce035-a95c-4a54-ad18-15e57840aefb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e4c4d76-88fd-42ce-be22-089fb4ad5ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc377104-5772-4964-b26b-dde4e964ab68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e23fe9a-617f-46a4-8ac5-e29f5edf969e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c2886f-7f39-45c0-a86b-9bd55a7bb176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 835f8ff4-0e18-4625-b084-b086a7dffa1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 053069b2-3529-4a18-a765-3f068821040b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb82f455-03c5-442a-8983-fc3f0460c155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 057bf755-84f4-4188-ba6e-8f65b529e944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ee0e061-3917-4d19-923c-25a070921834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f11b892b-e430-45db-9fe1-ed9534c5930f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5fb012-17e4-40fc-b4de-c0b8f070402a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 780cc21c-15b7-488c-839e-3b4c6687df19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd22e7e2-357a-4de6-a58d-d3caf5b0c0c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a13567-5395-48df-a35e-f0359473fb5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff15d42c-91a7-45a5-9b6f-a88312ec1d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063d93df-84c1-4e99-8824-83f57e3237d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae0f56e-9024-4228-aea5-20434c1ae381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea4da6ee-90a6-458b-b4d1-d0c8057f091e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 880aacd4-14e4-4bc6-9677-c02148d5b5c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97aede34-282a-4df5-9d69-b667179757aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc95e356-f9dc-451f-aac8-6dae5dfedbad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b40fcaa-fbb2-4e91-aece-e41287c32881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac7da0ed-8610-44b9-92bb-cf7cede3141c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ddaad1-c75b-461d-9c12-37b840a169f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8a5dbe4-abca-47bd-b7d9-1bd65aba54e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1a08534-18d1-4c42-b747-b6f9ada085f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6487eabb-8705-4540-ad43-7ed7efb1db8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3ae6e18-d143-496c-b8db-7ceb55ede4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcce084d-0eb5-48ed-b90a-155592ff5e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9d0a87a-33c6-4ae7-9984-9a4f7ce384e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e830ae-8251-43d6-aa0a-cfae2e13edfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a6aef55-415c-4d61-b384-45e2baaf94e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1328bec-91b3-41f7-9ab6-f684860aae8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5c28faa-76a6-4ae3-b2fa-0158594265fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15d8ce59-5cc9-4168-ac9b-e1d1df27c7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf153d81-1b62-45b1-806f-ff6c126dfcc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011aab69-79d7-40ef-a487-b0a2f654735d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f1c8789-e314-42d6-b247-e13cc4856812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 740e8d62-b637-4bc7-9a37-1356b22f2b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f56c3f6-2730-46e5-a286-0a7197ab261b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e06bd01-5a12-40b6-a48c-fa2f75b08e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42bbe551-020a-44aa-ba82-aac723bee669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc43fe07-4119-4023-9e97-ee2cbc078c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9763e68c-304b-4dab-9689-ff92374c165a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26b677f4-be0e-4dec-b070-3fbfb8be6d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 941cda9b-d09c-46ab-8765-e27859c203ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce6e17d6-8f7f-42e4-8de1-ec6cf3c1c559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52dff1cf-1b40-4de4-99e2-6311dbd565d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7166e3c4-5fbb-408d-a33e-49a9a11ad58a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3651ba-f976-487e-bb0b-0ae4db1d0990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5278d9d9-efbc-4a30-95bd-c6cbdaae3ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16ee2869-808a-432f-a9b0-1152432fa0ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f9cc986-4f98-459e-a55c-7d943cad0380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 782a4837-9de5-49c9-a953-07b9ba5330f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f50ccc9a-50f5-4d71-9792-04573499c248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1facea25-76fe-4f9d-aeb7-fea56f48ca46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f51f09-68fb-4539-80ba-25da2d9b9abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53153da1-d0a0-4dae-8d02-bb5853efb7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f6d5616-f11a-4da6-b352-1cf874ce3f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1128d5f4-0568-426a-80a2-625a467c0ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 587e8ac9-d2a0-4f76-b21a-3aec6bc663ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a15a2f8-19de-4ad3-8e6d-a3dd605e9d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ca4ab6d-3eb5-43c2-a325-5777d0c3ee2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 111c5af5-6665-409f-adb5-269fe595e8d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d2cb2a4-7b97-43cc-ac7d-e24110aa3130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dccf34d-8c33-4858-8e28-15408d4a73cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be6c708d-9960-4f0f-a4a3-2e2df4d37bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65c66ad-f223-4f9f-94d0-e15622636f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6facb4c-990f-4805-b5e5-577c460254f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df83ec7f-9034-4098-b43c-d04956affd6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b847a13-106d-44b9-975c-8b593bd6aa76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc36d85b-12cf-4315-a3e3-3ca4b47c61d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c595af4b-a300-4b45-826c-4409f3b52ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe55960-1fe5-4fd0-8bb0-91cca2fe75e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f11e8626-6a60-4d3f-958d-77098550d070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5838360-ce30-4b5d-9072-5c8ce38f2d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff5d9d4-666f-47f2-a057-49b439175455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad421a58-cc87-4e66-a2c3-2f85dc14460a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5897e02-d6e1-44fc-83ab-73c84b717f38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 562f9ef4-fa98-46ee-8ec6-4540c2c0fc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c73e369-33e5-42b7-a9d4-4cf437a72a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4033652-aeda-4909-9704-4599d16f760f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57d36e98-681a-48eb-93ce-f67dd479c001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2f3162e-5e8c-42a7-a959-a64bc18989b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aae45b0-8bb6-4544-b8d8-dd503700f6cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49b40147-41ae-4d04-bf6a-55136aa4a55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8c598b9-bf1d-4fa7-8584-fd496eecf982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eb56087-618b-4eb9-bb44-889c271bc1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad08d465-368e-4bb7-b863-40dbf64b2860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b9547c6-cecc-4ccf-bb46-c7e524f3401e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42ece4d3-e733-4a51-8aea-97c28f15e5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33b5835-a0d0-4d75-9e1b-85bc039d4273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dfc4beb-794c-4d7a-ba9c-b3146a9d434d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb76ca2e-2101-4d30-b20a-fe6ee0a000ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52dec8d9-191e-4a43-acb0-02d7da27577b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f672c38-1865-45dd-8c76-28449905763b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af7c5f5d-01fe-4d04-9b01-e5d5dbd609c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63207279-7181-466c-9cac-e2133c8c5e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 938ee290-1540-4ceb-9af8-b974e66e2fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 637d55af-fa92-4b69-8289-bb5fe8afaa88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08bc8aa1-41a9-43af-9fd6-0f1c33162962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21fd3261-a6a0-4f3d-82f6-bde33e33b062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7b20086-2843-4e6b-bcc7-2f50c50d45ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccbcf5f4-f019-41c0-aedf-3232f3304369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f9abbe-552d-4d8a-8c95-1258d17feead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17af403c-ce80-4a5f-aabb-82bbc0351adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0b2c479-02bc-49d4-a15c-7d1fe1a66bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d90acbf-5262-48e3-a054-f12456af31ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52848b07-1a82-4f12-a474-b14548adb837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7224364-9806-44eb-84d0-69b197f58612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2b2fa72-bd24-4310-a4bd-a7b2c8fbd5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e187127d-c95f-47a1-9ba4-bac3af33880c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17f15d0c-6514-4682-ad4f-55649a7a5cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f25ab572-d6dc-4854-821d-cf424a4ff9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae3fb29-e7f7-4de9-8958-dc3ce7716961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 309265e7-4089-428c-8fea-b24ade2a4f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66d95d55-1398-46ac-8161-43e36d1ed4ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf60ba3-1992-4fa9-8a0f-9bed9aa96ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55064a84-63eb-412d-a380-73185eacc65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 592c05ed-d887-4938-8b0c-4b793c7b8341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeb10c54-2742-4b48-a033-c87fee4aa13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de3a5a6d-9df2-4bf2-a0ad-21abb9848cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b321bf14-2f87-461c-9c68-6616ec183d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ed5b6a-a59c-430f-bed5-5ec6195488e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 872758b1-69a0-4341-a8d2-7025bfa65c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdba2021-24d5-4c1a-bdb6-0d3dd61c1401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37129b6b-c2bf-4f80-897b-ab08c3db1b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a61c147b-c823-4dc5-9823-8425f7cfb6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e491fc32-8649-4975-acd6-1fd974b88ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f7f4ca-549d-4047-b11b-0feebb445abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d42f43b-61a8-4f8d-917e-4c37c3ca5051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f47fd425-ebe4-4d59-ba0d-26ed7005f6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 161b6db5-235f-4023-ab27-21a34388025e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 549d53a0-7a93-445d-b327-84b634429ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f6e0ff9-ad7d-4803-9f01-abba641318e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50bc7262-8653-44c1-9d59-c44c469b1a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12e77090-86e7-4686-91bd-f790f36e8eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb1bc4b-9719-481b-816d-ab56a6db1521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e053009-8aee-4bbc-a7cd-2af59023dea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c537a0-608a-4a24-97d8-c3d9aab70456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e32be5d8-56df-472e-95e4-0b60f84fabd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef92abb9-53da-4efa-8937-b3b8ad7f2766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 989883f9-e6ca-4a8c-9c68-cc930b7c667a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fa05830-becc-4412-bb61-17765c527d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 466d306d-b994-41cc-8fc5-51d529a7759a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_11
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/test_labels.txt

📊 Raw data loaded:
   Train: X=(6688, 24), y=(6688,)
   Test:  X=(1673, 24), y=(1673,)

⚠️  Limiting training data: 6688 → 800 samples
⚠️  Limiting test data: 1673 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_11 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2391, val=0.0878 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0845, val=0.0847 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0848, val=0.0841 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0855, val=0.0810 (↓), lr=0.001000
   • Epoch   5/100: train=0.0837, val=0.0807, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0830, val=0.0804, patience=1/15, lr=0.001000
   • Epoch  21/100: train=0.0818, val=0.0793, patience=1/15, lr=0.001000
   • Epoch  31/100: train=0.0790, val=0.0777, patience=3/15, lr=0.001000
   • Epoch  41/100: train=0.0710, val=0.0772, patience=6/15, lr=0.001000
   📉 Epoch 43: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 1 Summary - Client client_11
   Epochs: 50/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0849
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0445
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2461, R²: 0.0009

📊 Round 1 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2457, R²: 0.0047

============================================================
🔄 Round 5 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0808, val=0.0829 (↓), lr=0.000250
   • Epoch   2/100: train=0.0802, val=0.0830, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0801, val=0.0831, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0800, val=0.0831, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0800, val=0.0831, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0796, val=0.0831, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 5 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0070
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0179
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2459, R²: 0.0025

============================================================
🔄 Round 8 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0712 (↓), lr=0.000125
   • Epoch   2/100: train=0.0827, val=0.0712, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0827, val=0.0712, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0827, val=0.0712, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0826, val=0.0712, patience=4/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0825, val=0.0712, patience=10/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 8 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0084
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0097
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0039

============================================================
🔄 Round 10 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0808 (↓), lr=0.000031
   • Epoch   2/100: train=0.0805, val=0.0808, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0805, val=0.0808, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0804, val=0.0808, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0804, val=0.0808, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0804, val=0.0808, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 10 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0112
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0002
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0039

============================================================
🔄 Round 12 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0796 (↓), lr=0.000008
   • Epoch   2/100: train=0.0809, val=0.0797, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0808, val=0.0797, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0808, val=0.0797, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0808, val=0.0797, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0808, val=0.0798, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 12 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0092
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0063
============================================================


============================================================
🔄 Round 13 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0739 (↓), lr=0.000002
   • Epoch   2/100: train=0.0820, val=0.0739, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0820, val=0.0739, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0820, val=0.0739, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0820, val=0.0739, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0820, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 13 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0094
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0044
============================================================


============================================================
🔄 Round 15 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 15 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0103
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0005
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 16 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 16 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0104
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0018
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0040

============================================================
🔄 Round 18 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 18 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0070
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0138
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0040

============================================================
🔄 Round 20 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 20 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0074
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0082
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0040

============================================================
🔄 Round 22 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 22 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0100
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0171
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0040

============================================================
🔄 Round 27 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 27 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0044
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0076
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 28 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 28 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0098
   Val:   Loss=0.0672, RMSE=0.2593, R²=0.0027
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 34 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 34 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0007
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0115
============================================================


============================================================
🔄 Round 35 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 35 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0088
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0078
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 35 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 37 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 37 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0122
   Val:   Loss=0.0866, RMSE=0.2944, R²=-0.0412
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0040

============================================================
🔄 Round 38 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 38 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0093
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0065
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0040

============================================================
🔄 Round 41 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 41 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0088
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0076
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 43 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 43 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0086
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0054
============================================================


============================================================
🔄 Round 44 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 44 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0078
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0087
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 45 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 45 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0077
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0024
============================================================


============================================================
🔄 Round 46 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 46 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0086
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0186
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 46 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 46 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 46 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 46 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 46 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 46 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 64 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 64 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0035
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0051
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 65 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 65 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0093
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0040
============================================================


============================================================
🔄 Round 67 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 67 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0035
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0018
============================================================


============================================================
🔄 Round 68 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 68 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0077
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0061
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 68 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 68 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 74 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 74 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0082
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0110
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 75 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 75 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0108
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0001
============================================================


============================================================
🔄 Round 77 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 77 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0093
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0045
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 78 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 78 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0098
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0010
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 80 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 80 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0068
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0111
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 81 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 81 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0071
   Val:   Loss=0.0900, RMSE=0.2999, R²=0.0106
============================================================


============================================================
🔄 Round 82 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 82 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0090
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0066
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 85 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 85 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0060
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0187
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 85 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 85 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 85 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 91 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 91 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0106
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0048
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 93 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 93 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0098
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0044
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 94 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 94 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0039
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0066
============================================================


============================================================
🔄 Round 95 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 95 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0093
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0056
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 95 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 98 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 98 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0091
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0087
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 99 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 99 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0100
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0102
============================================================


============================================================
🔄 Round 100 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 100 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0090
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0056
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 102 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 102 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0071
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0072
============================================================


============================================================
🔄 Round 103 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 103 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0091
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0050
============================================================


============================================================
🔄 Round 104 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 104 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0073
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0146
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 104 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 107 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 107 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0059
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0182
============================================================


============================================================
🔄 Round 108 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 108 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0091
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0013
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 110 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 110 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0099
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0041
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 113 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 113 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0076
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0009
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 115 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 115 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0067
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0092
============================================================


============================================================
🔄 Round 116 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 116 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0062
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0044
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 116 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 116 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 124 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 124 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0090
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0004
============================================================


============================================================
🔄 Round 126 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 126 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0100
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0040
============================================================


============================================================
🔄 Round 129 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 129 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0063
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0076
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 132 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 132 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0081
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0074
============================================================


============================================================
🔄 Round 134 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 134 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0096
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0014
============================================================


============================================================
🔄 Round 135 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 135 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0092
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0041
============================================================


============================================================
🔄 Round 138 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 138 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0115
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0311
============================================================


============================================================
🔄 Round 139 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 139 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0094
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0067
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 141 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 141 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0099
   Val:   Loss=0.0687, RMSE=0.2622, R²=0.0038
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 142 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 142 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0087
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0026
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 144 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 144 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0092
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0052
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 144 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 144 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 152 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 152 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0116
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0157
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 152 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 155 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 155 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0104
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0028
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 155 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 157 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 157 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0095
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0284
============================================================


============================================================
🔄 Round 158 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 158 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0108
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0016
============================================================


============================================================
🔄 Round 160 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 160 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0092
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0070
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 161 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 161 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0111
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0018
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 163 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 163 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0067
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0179
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 164 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 164 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0092
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0055
============================================================


============================================================
🔄 Round 166 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 166 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0081
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0091
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 167 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 167 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0088
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0071
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 167 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 167 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 172 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 172 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0070
   Val:   Loss=0.0694, RMSE=0.2633, R²=0.0148
============================================================


============================================================
🔄 Round 173 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 173 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0087
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0077
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 175 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 175 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0107
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0006
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 175 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 178 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 178 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0136
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0185
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 179 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 179 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0085
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0088
============================================================


============================================================
🔄 Round 182 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 182 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0076
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0056
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

📊 Round 182 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 186 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 186 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0082
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0099
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0040

============================================================
🔄 Round 188 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 188 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0086
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0016
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 192 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 192 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0067
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0073
============================================================


============================================================
🔄 Round 193 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 193 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0101
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0007
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 194 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 194 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0069
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0160
============================================================


============================================================
🔄 Round 195 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 195 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0078
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0127
============================================================


============================================================
🔄 Round 196 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 196 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0098
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0027
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 199 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 199 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0066
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0179
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 199 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 199 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 199 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 206 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 206 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0073
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0108
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 208 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 208 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0082
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0094
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 210 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 210 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0077
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0123
============================================================


============================================================
🔄 Round 211 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 211 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0096
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0055
============================================================


============================================================
🔄 Round 212 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 212 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0110
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0028
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 213 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 213 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0085
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0087
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 213 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 215 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 215 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0093
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0068
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 217 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 217 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0081
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0007
============================================================


============================================================
🔄 Round 218 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 218 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0071
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0038
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 218 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 222 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 222 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0057
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0071
============================================================


============================================================
🔄 Round 224 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 224 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0086
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0070
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 225 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 225 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0071
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0112
============================================================


============================================================
🔄 Round 226 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 226 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0085
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0081
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 231 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 231 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0050
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0170
============================================================


============================================================
🔄 Round 232 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 232 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0065
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0059
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 234 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 234 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0102
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0517
============================================================


============================================================
🔄 Round 235 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 235 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0071
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0143
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 238 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 238 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0085
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0064
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 240 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 240 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0090
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0076
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 240 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 242 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 242 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0045
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0029
============================================================


============================================================
🔄 Round 243 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 243 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0079
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0118
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 244 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 244 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0095
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0057
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 246 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 246 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0071
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0086
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 248 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 248 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0072
   Val:   Loss=0.0679, RMSE=0.2605, R²=-0.0028
============================================================


============================================================
🔄 Round 249 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 249 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0094
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0035
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 249 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 255 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 255 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0094
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0050
============================================================


============================================================
🔄 Round 256 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 256 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0094
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0017
============================================================


============================================================
🔄 Round 258 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 258 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0067
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0027
============================================================


============================================================
🔄 Round 260 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 260 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0086
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0092
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 260 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 265 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 265 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0102
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0423
============================================================


============================================================
🔄 Round 267 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 267 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0075
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0102
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 268 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 268 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0082
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0114
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 268 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 271 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 271 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2820, R²=0.0061
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0060
============================================================


============================================================
🔄 Round 272 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 272 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0085
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0103
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 272 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 272 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 272 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 277 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 277 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0095
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0039
============================================================


============================================================
🔄 Round 279 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 279 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0078
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0129
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 279 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 279 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 284 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 284 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0070
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0139
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 284 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 287 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 287 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0084
   Val:   Loss=0.0679, RMSE=0.2607, R²=0.0092
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 287 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 290 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 290 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0037
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0081
============================================================


============================================================
🔄 Round 291 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 291 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0097
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0122
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 291 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 293 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 293 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0102
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0168
============================================================


============================================================
🔄 Round 295 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 295 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0100
   Val:   Loss=0.0695, RMSE=0.2637, R²=0.0021
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 297 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 297 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0103
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0099
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 299 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 299 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0067
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0054
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 301 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 301 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0092
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0050
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 302 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 302 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0091
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0049
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 306 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 306 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0070
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0165
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 306 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 306 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 309 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 309 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0098
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0049
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 311 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 311 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0115
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0095
============================================================


============================================================
🔄 Round 313 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 313 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0098
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0047
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 315 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 315 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0077
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0072
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 315 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 318 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 318 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0103
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0042
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 318 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 318 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 318 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 326 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 326 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0090
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0044
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 326 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 333 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 333 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0110
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0090
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 333 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 336 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 336 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0090
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0011
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 337 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 337 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0101
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0036
============================================================


============================================================
🔄 Round 338 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 338 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0094
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0026
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 341 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 341 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0075
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0118
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 341 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 347 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 347 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0091
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0046
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 349 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 349 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0074
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0007
============================================================


============================================================
🔄 Round 351 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 351 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0085
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0066
============================================================


============================================================
🔄 Round 352 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 352 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0051
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0190
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 352 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 352 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 357 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 357 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0091
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0057
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 357 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 360 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 360 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0115
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0113
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 360 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 360 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 364 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 364 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0097
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0043
============================================================


============================================================
🔄 Round 365 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 365 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0077
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0122
============================================================


============================================================
🔄 Round 367 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 367 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0098
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0001
============================================================


============================================================
🔄 Round 368 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 368 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0121
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0311
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 368 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 371 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 371 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0106
   Val:   Loss=0.0894, RMSE=0.2991, R²=0.0026
============================================================


============================================================
🔄 Round 372 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 372 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0092
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0070
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 374 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 374 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0101
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0007
============================================================


============================================================
🔄 Round 375 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 375 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0083
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0106
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 377 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 377 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0081
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0114
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 378 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 378 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0068
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0091
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 378 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 381 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 381 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0092
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0008
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 384 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 384 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0089
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0084
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 387 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 387 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0082
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0115
============================================================


============================================================
🔄 Round 390 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 390 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0110
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0086
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 392 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 392 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0104
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0020
============================================================


============================================================
🔄 Round 393 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 393 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0065
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0146
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 394 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 394 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0084
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0097
============================================================


============================================================
🔄 Round 396 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 396 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0080
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0032
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 401 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 401 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0090
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0080
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

============================================================
🔄 Round 403 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 403 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0085
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0032
============================================================


============================================================
🔄 Round 405 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 405 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0092
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0216
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 405 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0041

📊 Round 405 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 405 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 414 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 414 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0100
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0030
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 415 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 415 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0086
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0198
============================================================


============================================================
🔄 Round 416 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 416 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0096
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0064
============================================================


============================================================
🔄 Round 417 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 417 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0088
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0088
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 417 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 422 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 422 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0087
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0096
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 425 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 425 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0085
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0095
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 426 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 426 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0072
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0153
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 428 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 428 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0103
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0014
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 430 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 430 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0083
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0110
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 433 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 433 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0056
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0073
============================================================


============================================================
🔄 Round 439 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 439 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0073
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0115
============================================================


============================================================
🔄 Round 440 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 440 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0099
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0030
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 441 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 441 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0097
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0168
============================================================


============================================================
🔄 Round 442 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 442 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0081
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0113
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 442 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 442 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

📊 Round 442 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 446 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 446 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0083
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0114
============================================================


============================================================
🔄 Round 447 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 447 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0111
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0007
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 447 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 447 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 447 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 452 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 452 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0066
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0119
============================================================


============================================================
🔄 Round 453 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 453 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0083
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0115
============================================================


============================================================
🔄 Round 454 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 454 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0071
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0169
============================================================


============================================================
🔄 Round 455 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 455 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0080
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0096
============================================================


============================================================
🔄 Round 456 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 456 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0068
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0132
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0041

============================================================
🔄 Round 458 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 458 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0103
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0041
============================================================


============================================================
🔄 Round 459 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 459 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0094
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0011
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 464 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 464 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0106
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0115
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 468 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 468 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0043
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0063
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 469 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 469 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0103
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0084
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 470 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 470 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0083
   Val:   Loss=0.0696, RMSE=0.2639, R²=0.0105
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 471 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 471 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0093
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0049
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 472 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 472 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0115
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0015
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 472 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 472 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 472 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 472 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 472 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 472 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 488 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 488 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0088
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0041
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 491 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 491 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0094
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0075
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 491 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 493 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 493 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0083
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0037
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 493 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 499 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 499 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0084
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0073
============================================================


============================================================
🔄 Round 502 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 502 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0077
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0141
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

📊 Round 502 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 507 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 507 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0092
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0068
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 509 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 509 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0093
   Val:   Loss=0.0909, RMSE=0.3014, R²=0.0001
============================================================


============================================================
🔄 Round 515 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 515 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0088
   Val:   Loss=0.0906, RMSE=0.3009, R²=0.0081
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 519 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 519 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0057
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0005
============================================================


============================================================
🔄 Round 520 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 520 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0112
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0230
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 522 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 522 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0094
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0070
============================================================


============================================================
🔄 Round 524 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 524 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0052
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0103
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0042

============================================================
🔄 Round 525 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 525 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0086
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0012
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 525 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 525 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 531 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 531 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0084
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0025
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 531 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 531 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 536 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 536 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0078
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0127
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 537 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 537 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0082
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0093
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 537 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 541 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 541 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0080
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0098
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 543 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 543 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0115
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0227
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 543 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 548 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 548 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0103
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0018
============================================================


============================================================
🔄 Round 550 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 550 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0101
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0028
============================================================


============================================================
🔄 Round 552 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 552 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0108
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0150
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 552 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 552 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 552 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 557 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 557 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0092
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0067
============================================================


============================================================
🔄 Round 558 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 558 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0098
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0048
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 561 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 561 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0118
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0264
============================================================


============================================================
🔄 Round 562 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 562 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0092
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0012
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 562 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 564 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 564 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0082
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0112
============================================================


============================================================
🔄 Round 566 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 566 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0067
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0035
============================================================


============================================================
🔄 Round 567 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 567 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0098
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0013
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 567 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 572 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 572 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0108
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0236
============================================================


============================================================
🔄 Round 574 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 574 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0071
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0093
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 574 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 579 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 579 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0075
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0099
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 580 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 580 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0099
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0012
============================================================


============================================================
🔄 Round 582 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 582 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0092
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0067
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 586 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 586 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0083
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0073
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 589 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 589 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0098
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0050
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 589 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 589 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 596 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 596 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0066
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0145
============================================================


============================================================
🔄 Round 597 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 597 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0097
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0098
============================================================


============================================================
🔄 Round 598 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 598 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0095
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0036
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 599 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 599 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0122
   Val:   Loss=0.0661, RMSE=0.2571, R²=-0.0084
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 601 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 601 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0107
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0270
============================================================


============================================================
🔄 Round 602 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 602 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0075
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0140
============================================================


============================================================
🔄 Round 603 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 603 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0079
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0074
============================================================


============================================================
🔄 Round 604 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 604 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0072
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0039
============================================================


============================================================
🔄 Round 605 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 605 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0081
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0090
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 605 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 605 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 605 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 605 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 612 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 612 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0080
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0101
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 612 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 617 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 617 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0043
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0156
============================================================


============================================================
🔄 Round 618 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 618 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0088
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0041
============================================================


============================================================
🔄 Round 619 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 619 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0121
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0167
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 620 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 620 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0108
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0033
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 623 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 623 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0077
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0115
============================================================


============================================================
🔄 Round 624 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 624 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0062
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0169
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

============================================================
🔄 Round 629 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 629 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0068
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0170
============================================================


============================================================
🔄 Round 630 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 630 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0119
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0138
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0042

📊 Round 630 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 634 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 634 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0129
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0323
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 636 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 636 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0019
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0221
============================================================


============================================================
🔄 Round 637 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 637 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0046
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0037
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 637 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 641 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 641 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0095
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0075
============================================================


============================================================
🔄 Round 642 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 642 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0100
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0045
============================================================


============================================================
🔄 Round 644 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 644 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0086
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0109
============================================================


============================================================
🔄 Round 646 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 646 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0074
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0126
============================================================


============================================================
🔄 Round 648 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 648 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0101
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0005
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0043

============================================================
🔄 Round 650 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 650 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0068
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0104
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 650 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 650 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 650 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 650 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 660 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 660 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0107
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0173
============================================================


============================================================
🔄 Round 662 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 662 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0112
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0082
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 663 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 663 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0079
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0121
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 665 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 665 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0101
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0021
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 665 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 667 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 667 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0069
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0107
============================================================


============================================================
🔄 Round 668 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 668 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0067
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0167
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 668 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 671 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 671 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0075
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0141
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 671 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 673 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 673 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0077
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0120
============================================================


============================================================
🔄 Round 674 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 674 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0115
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0036
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 679 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 679 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0077
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0098
============================================================


📊 Round 679 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 679 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 685 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 685 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0066
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0076
============================================================


============================================================
🔄 Round 687 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 687 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0111
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0035
============================================================


============================================================
🔄 Round 688 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 688 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0075
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0072
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 690 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 690 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0111
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0196
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 693 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 693 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0105
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0033
============================================================


============================================================
🔄 Round 694 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 694 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0098
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0164
============================================================


============================================================
🔄 Round 695 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 695 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0088
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0079
============================================================


============================================================
🔄 Round 696 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 696 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0088
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0091
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 696 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 696 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 696 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 696 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 705 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 705 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0055
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0149
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 705 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 707 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 707 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0094
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0079
============================================================


============================================================
🔄 Round 709 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 709 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0079
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0130
============================================================


============================================================
🔄 Round 710 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 710 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0091
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0096
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 710 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 712 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 712 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0094
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0056
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 712 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 717 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 717 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0113
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0099
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 723 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 723 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0047
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0072
============================================================


============================================================
🔄 Round 724 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 724 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0105
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0009
============================================================


📊 Round 724 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 724 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 724 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 729 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 729 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0101
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0021
============================================================


============================================================
🔄 Round 730 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 730 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0060
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0067
============================================================


============================================================
🔄 Round 732 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 732 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0096
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0067
============================================================


============================================================
🔄 Round 735 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 735 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0091
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0092
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 737 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 737 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0095
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0038
============================================================


============================================================
🔄 Round 738 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 738 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0089
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0103
============================================================


============================================================
🔄 Round 739 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 739 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0080
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0123
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 740 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 740 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0081
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0085
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 741 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 741 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0079
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0144
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 742 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 742 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0096
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0066
============================================================


============================================================
🔄 Round 743 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 743 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0090
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0096
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 745 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 745 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0081
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0062
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 747 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 747 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0075
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0040
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 747 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 753 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 753 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0089
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0104
============================================================


============================================================
🔄 Round 754 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 754 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0073
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0139
============================================================


============================================================
🔄 Round 755 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 755 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0104
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0071
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 755 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 758 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 758 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0089
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0096
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 758 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 763 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 763 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0091
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0069
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 763 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 769 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 769 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0133
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0172
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

📊 Round 769 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2453, R²: 0.0043

============================================================
🔄 Round 776 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 776 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0087
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0113
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0043

============================================================
🔄 Round 779 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 779 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0087
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0072
============================================================


============================================================
🔄 Round 782 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 782 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0094
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0088
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0043

============================================================
🔄 Round 783 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 783 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0110
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0022
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0043

============================================================
🔄 Round 785 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 785 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0080
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0063
============================================================


📊 Round 785 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0043

📊 Round 785 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0043

============================================================
🔄 Round 787 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 787 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0094
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0052
============================================================


============================================================
🔄 Round 788 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 788 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0084
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0121
============================================================


============================================================
🔄 Round 790 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 790 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0090
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0107
============================================================


📊 Round 790 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0043

📊 Round 790 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0043

============================================================
🔄 Round 794 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 794 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0103
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0052
============================================================


============================================================
🔄 Round 795 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 795 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0057
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0237
============================================================


============================================================
🔄 Round 797 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 797 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0083
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0116
============================================================


📊 Round 797 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0043

============================================================
🔄 Round 798 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 798 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0060
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0024
============================================================


============================================================
🔄 Round 800 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 800 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0098
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0052
============================================================


============================================================
🔄 Round 801 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 801 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0053
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0123
============================================================


📊 Round 801 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2454, R²: 0.0044

============================================================
🔄 Round 804 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 804 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0072
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0125
============================================================


============================================================
🔄 Round 806 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 806 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0088
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0054
============================================================


============================================================
🔄 Round 807 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 807 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0049
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0012
============================================================


❌ Client client_11 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
