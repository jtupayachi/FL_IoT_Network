[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03fd9e6b-ee36-4fde-a65f-efcabd7180c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7415200-b473-477e-9268-a41b50fa29b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379072ec-3ccc-4d1b-a694-ff1559399ef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c1f1182-cd1d-4fdb-b461-f8284b5a56f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 798f1b21-6ba2-48d6-b7c5-1f269fdb8895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebf15dee-55aa-4f94-8a08-87d7a6faa800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc511763-d2f4-46df-bbc0-181ac0130d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 945e8a5b-ac37-43c5-8023-494b01dab258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4731e9ee-3169-4b50-9b7b-c5f0cea7a34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d0fb93b-83d8-410a-9289-dadd2c694e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3aa1716-5f72-40ca-a821-5a5d80ec092e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbe8cdce-fd8a-47de-85e9-deb0e9055ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfafa3d4-cc4c-4bdf-a8be-c2218154eb1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f148bee-2ce8-43c3-9059-760c64b8d958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 288f924f-8750-43e1-b3ae-77a97be263e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b3461ca-6e21-4254-a224-3d9819b6d803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ca6961b-be1a-4330-be89-a2e6b8087ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b46e006a-ff3b-434a-9029-c4e912812962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 777ee8d2-54d1-47a4-8b26-a36babd854ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79d201c2-ef3b-4f0f-90db-6703c31d7506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4084ffe8-9a4a-42c1-a5f6-a4a596f5c220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb441628-acfe-4034-92e9-ef0dbb8478c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad04f64f-f767-4a08-a704-89191c2658c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3b833d-18f8-48f9-b62b-7af39b9b6438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69687fc3-8ffc-4878-bd82-a5ced76ec7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c577274d-a8c2-4653-9522-d3ac0a096644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f609dbe-c2d7-4d0d-915e-fe22d60641ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13cdcb43-f4ff-4471-b555-cdeb45aa6488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9804d7c1-e4d8-4e7f-b3ac-ce27a4806794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5ff8ae7-49fb-4a6c-b0d5-7c09e1ff13e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 431cd989-dfa3-4b1b-ac2d-4a90200fef5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5ebf3a2-3c5d-4d47-b4c8-a093767ea5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd9c48c-0693-407c-bd82-cd8aac1f5cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12999fa6-9cf9-415d-b843-204a230034ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aee5e75-883e-4e95-811a-9de4ada9a288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f6685a9-e95c-4d17-a378-fcf088113672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88e1624c-16f5-4c29-a79c-6e97a98e74c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6fa174d-5637-44b9-9da1-8cad8a9a4c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7531f141-dada-406f-8a86-8c6edca52c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 053937f9-3c67-4a6c-9fee-52f6524f4897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d7b8c79-d34c-4a37-be9f-68967169150c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd84e58-b99c-482c-87fc-c5fd4e8c4b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 249a80b9-55ef-498f-baef-c28aeb475e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88bdd4f-3b62-4cc4-9390-eaf2b1c3b4a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd6c20b6-2d5b-414b-bcbc-a3608ed15ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7618b6b-3823-4270-94a3-119f6898f4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b050576b-2e9d-4033-99ad-db7b2323ce43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cd139e1-210b-44ce-84d0-f17e8459e9a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a92d2a-e15f-4d0b-93d5-01b0c15c589b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf3bee55-3c47-4566-8c10-769b3b07b27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b913849-4f45-4ba9-b399-19b8077e40f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0966f20a-6d64-4f2f-8655-3a055408fc82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f81db2-aa8b-4818-abc4-0d4f6d04c08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fc88671-1c6d-453b-88e4-1bb788c35c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccdc8ce1-2dda-4d7f-bf0f-a7dc2c30680c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aa5ec1e-69ef-4f9d-bc73-00f4529d00fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84751343-ffa9-47c0-9fa8-8e33d77786d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abccec47-a115-4a6c-8550-99589d48053f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cb7c706-c31c-4584-8aa1-6b26915db57a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 754d0150-19df-4e9a-9264-de8408dc5824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b232e76-886d-4c74-bc3d-3369375f5842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de01060a-1f25-4047-a22e-54ab7f4948a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddf21cad-633b-4ad3-b4ae-514a770cf5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a4c632-d1d2-4d53-b073-38b10d7886f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97596af7-531d-49a9-9b9a-874ed29b96b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd310455-12dd-43fd-b94f-e01a90ec9b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aca4e927-e00d-453e-a5ce-d2243e64bf00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ec3ce71-9086-45ca-b7ab-9897e533be15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb082ce5-2f27-4924-8b13-94093f7be648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f20eeb3e-1b61-4a75-a9c3-66f19b52f483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e53287-a5d5-4768-a70f-128434b9abba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f77f8559-6c3f-451a-9545-0d356d36a0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ffc1302-c941-42f6-8134-eca27e12b0d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4805e7bf-bcbc-4401-a10c-faffaadd0100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9fe488a-5af1-4ff8-bde9-d26041ddae35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a43c8a9f-d911-4c3d-af26-23eba99db8b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3fc8106-9a94-4d6b-aba4-d0af2f9fe32f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc7aa187-a123-47fe-934d-f2cc5529944d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9239b549-079a-4ed2-84d2-8cd0ae2ad165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3d6df35-e138-458d-bbd4-d6a0be4eec93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7f2b7fb-1f90-4f0a-8f7f-93139565d116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f8ab6a-de0e-4be3-b186-fb5289328b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61065a2e-db14-41b8-871d-de4f9489973b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c73c7278-a180-436c-b3dc-e831f16439ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b422803a-ee45-4d36-bbae-feaa9dcbbf4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 945dd8e2-25d5-4a49-8829-2455f7504302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a352f43-2175-4fce-a7e8-a9c55f7df642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03094b5d-c692-420c-82fd-f5c057d8ecdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d85c72-51e2-43f5-8d08-9c1f8f23733e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4ab24d9-e891-4829-a52e-786ad140e3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4eb42bc-5bb1-4f31-90cc-84984efe2034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81b462e-fa11-4ca3-a75c-d684bd916265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56e93296-7d08-4576-ae27-fa6ee88d73f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9927008a-e4dc-4b1d-a76b-4483c83f09c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d6252c-c2c9-49f3-8a4b-68bb59c5c9a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c8bf4d5-537a-40e4-ac4f-b647d7941bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9446b71a-e552-4b3f-a619-24d3aa348da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90623628-0d70-462c-bacf-7f185bad433a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c39fb2d6-d27c-4aed-b6ff-41462302a8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ab0b14-f3f8-488b-9c07-c9dd4ad8d7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4565245f-5b54-4b63-aef7-1ed32e930bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 832a0f7c-f809-4083-8735-0faa8e670b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1154df06-7115-4acd-9010-af4068f45e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d61d068-fb31-4aae-8b2c-191594dc57a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7e37d88-6e71-429c-97f3-fcd8fd3fcd68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34553710-1540-42f2-84b8-5e112b04dc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6e1cc18-ad81-4e34-a7b4-dd44c873f42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd198e37-88b4-450d-a689-984892daaae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c7d09a0-b758-4671-b48f-20d03b65d932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b847ef66-9675-4e5a-b991-1a72088a4be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 734b33e3-9140-41a7-89f5-5d31ce89182a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75cd151c-f31d-4c95-813c-f288430d6ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ded47914-dd2b-456c-8e6e-2ed0895252bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d032d9-63f9-4d63-921d-da2b4d85d669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8259cfb-7558-44a0-9a26-98a67930b618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68967209-f587-4fd0-bdd6-b4771b63373f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 137f4587-b87b-431f-af93-0c5378435364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5b4f3bc-09be-40ac-9a75-e9abdc73d968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 477c9f3c-afcd-41e4-87a9-8a1b0bb3db6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d86d78f0-9d7e-425d-b5ee-d8225d3a47d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05eb41a-3868-4f0e-bcad-7b29a8a92681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df6c7b67-cf5a-49d9-a4f6-4fc4d76a02fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4deee4-5c3d-4e73-8322-af3b6c6846cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fa226f1-2465-4cd0-8169-40896ff8a264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a27686-3cd1-48d8-808f-f968f95aaa65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c0a17a7-a6c1-40c7-9433-ce9dd1f62f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87686cd1-295d-4931-a81d-6ca74aad565b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 080b4729-ba11-41ff-a4c6-11a86f34cd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f3baf60-521b-4cee-8148-10c801ef0794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d890de-da42-4735-b318-911d909af276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f1b3ef-1976-4928-86ac-498cf752450a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b00cf371-e967-4581-baf9-2b2db2c8759f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b2071fa-746d-4184-a8c9-de6eb7d450ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03778b25-ecf8-4e9f-b6d0-777c171012cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62bc1e35-03cb-4269-b178-9b5962b60b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72c5d723-76bf-41be-8754-30186a914339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88808de5-6e6b-4356-bf95-2a1b5f9dedfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 705361bf-9bce-478a-b091-284046568dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60beff4b-a2ac-4726-9783-f83c80bef08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b163b20b-9efe-4058-8209-b9279d60e641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c26e08-13d6-4c04-bead-700273dbb317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da391cab-331a-426f-b485-d806276efdbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f35c0109-ee6c-4e36-9c46-0d24d2a8cebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1af2ef6-35a8-4510-a605-70e7da60c8e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6a33dee-0627-41ee-8eef-596e74f12dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6746b36e-8bfa-49af-8b4d-e57e40880449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10111d16-63d4-44b2-bb63-7c1d7404d4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbd67738-f029-4e07-8227-8719fe92ba2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9049b76f-2b3e-4798-b5e5-ff7171b87442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d8bfb4-a0b6-4ec2-909c-7b617d8c1475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13e4c75e-479c-4bcc-b376-589140a3888f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e64d9711-71ca-413a-a6d1-c80b530734d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feb23117-2ecb-47b4-ab41-635085aab3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7fec03a-e8fc-4c3c-abba-ba5fd7ca8a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 526a06ce-f216-493a-b633-a1ca67f79005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27bf64f8-1ef5-4ec8-bfe3-36f2403097e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c2ede8d-9f95-48a6-a45b-3ee443157782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed78e71-481e-40cd-800c-b9820da408d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ebe51b7-c532-49b3-8e28-d81b236d76a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4171ce5e-6fb7-47a4-ad1b-3b4e3c97b317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 712aa0eb-b16a-4862-ba05-27db7f621e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac898205-74d2-4742-ac30-8cd7506a86c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9091abfb-ea6c-41f0-b100-c2d9581d70c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09eb0abc-4cc3-40c8-a8bf-9320225b2b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6e71432-cc99-407a-818e-8e1430f7507f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2b8caaa-37ed-41d0-aebe-c496b5b4403f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 887f93ec-da04-4b13-b468-2efac4f80247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31816bab-99ef-436e-a54a-d01641fbada8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 438cb614-92a1-4815-bf7a-07a8d82dd736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f9073cd-8f7f-42f6-8167-5dbc8c7a8db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4bd412-add0-44b0-9ca5-e6f953ac4405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2622e04a-6230-4702-9c29-68e27df315af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b1b75e6-d8a9-4445-9e95-a665bc02fa82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afd9cf92-45c1-4515-802d-1f197ccae674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9205ffd-d52c-440b-a903-c61ede428785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44035bde-b0f9-4776-803c-eca7c6b811a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ebb2eba-44a3-4b22-a039-039388f9e6cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11fba85-2926-405e-965d-e3d3f3985a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87d773c9-b022-46f1-ae8d-93261c71cd25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b9d0c54-d783-470d-bf5c-58b937287447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 743ef287-ce73-43ff-b70b-9f6d27eab46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08224126-f082-4621-9129-9ad41dc43b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 750656e0-c020-4a49-9e4d-d83ee7651ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6c9a3d9-5284-4bb4-9293-8c8ac44cd30b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd867278-9b7b-4105-845e-453bc1abb9c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea6ebaf1-7311-46cc-9f66-2e5a73aab407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd8c5e0e-9415-4a28-9ece-9c3699b92086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6caebd34-12d9-4e92-8a0c-c0e0cd268665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dfcad46-fbdb-4cbc-947c-36d0fcba4674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ba4b33-7d1d-44f0-be7f-69e0871e1b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3584b860-727f-47ac-90cf-2f936b702367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a2c5ba-9e40-4b60-b41a-47772dbda98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b0c5d8-f07f-45f3-8949-23d19814dd15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d8031f-f853-4e9f-b2e1-a3fd63392af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 220c50b3-e553-4f6e-81b9-bfea250ce531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f1fb1b-f990-46c1-986b-04dffdf52f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7751937e-c42f-47ca-94f6-ee7eeb6530fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b953c1-f350-43a5-abaa-26a75378b38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01e5b115-16bd-41b8-8b88-29055ad74e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f31d07db-491d-4822-af03-4ccfc9a5b220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2c46220-3ff2-491e-abee-3c8e7b7ddad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0328034-b81c-401c-a08a-194cd23322a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a5416bc-1c98-4d94-8eaf-f591ed301af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a9ffb84-cd7d-472d-b31e-c31343bffb14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e240cf5-94f0-4bb8-93b2-9e21274ba4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e67066d5-300f-4fb6-a3de-a17cd3814016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa63f772-5194-433c-b2ac-2351d1b79b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bffa666f-c7c9-46fd-867b-876d247e1083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa4cbaeb-adbd-45b0-90de-4be3ad1ece0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b7b008f-4201-4e40-9eab-4b322baa7e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8e66ffd-7ad8-4720-978f-7e038715854a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b452e4-4642-4d3b-ac26-06f6ce466960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec5275ae-9435-447a-a939-9dd306a87584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96eacf38-54b6-4f17-8377-f231ca840652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7926f4f8-8e6f-4582-8e70-ec8f600f3d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07bb37f1-8e98-4821-8f7e-d3977557b488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18668be-c8a7-4464-8f23-da96e9e51ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f66207a-9cc2-4fd2-926c-b2fd7db8916d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed88ad50-a551-4b15-b224-20dc99b33629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeac58c8-4ab4-4bbf-93c7-58a3dfb77d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e2dcd9a-ebb6-4236-8bf4-fc4c2b65e2a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 283a3b6a-a422-4ef5-8c3f-28ba97b70434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa95826a-bf47-4e6e-8e72-689cfd5eb5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a29c1d-387e-4564-bc27-ecebbdb491ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27b8060b-2408-459a-b5c4-981fd62e6a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9183dc4-164e-4800-b457-91394ba0ecd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d74f92b5-7e4f-47ff-9234-6119e5a002b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7455deec-20fd-4b65-8444-6552d6a9756b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fe1ddad-d9d6-4fc3-b6c2-adbd18aaf8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3a02472-5f5a-4bfd-bc03-a1386eba9e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71fe0c75-7819-479a-aada-99d27397305c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d76892b-5399-4777-b316-0fd23ff1667f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deb61200-9a5e-4944-8911-9c077ea806f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eca194d-6f94-4ddd-b0f9-4b14e18136f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc73165-eb64-439b-a2e6-79219e2dfbc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3979a0d7-3c1d-4c0e-827f-545b02b9d85d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c50639e-d3e8-402d-9ab0-e6ca45e2a2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deb709f1-f77f-4019-8e9b-fd1eb5f9c01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc60d2f3-e920-490c-96f8-3bc14024b3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21d87c95-1960-4883-90d4-cc8bdb7fc7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8f5ba41-6143-4c92-a0b9-765acf2bea3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6af62e4-d99c-4359-82b5-8870a68ab294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9349adc4-0b66-450d-8ba1-e3bfac475f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e582e4-7a35-4982-8763-34c981a43267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7752100-da72-4bba-9186-bc29b19c3a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7aedb77-6333-4ddb-b1e3-ff3743d15786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f3ffaa-fa1f-4160-b3f6-5744dbb15c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f241094f-d41f-4310-9d80-dfd48c6072b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309a4990-61be-4437-8461-9d2b84f955aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae375b99-9a11-48ff-8446-c0ffe39526f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0d4414-41de-44fa-b9d8-0f504dcb82d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a65df72b-d61a-45e8-98bb-516414fc6336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b467cae-0c50-4efc-a83a-8421c4fdcd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b377b9a-8493-415c-b227-8476c808ec6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc33df73-a95d-4b16-8ce6-d1b8cc6d8c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4029cc3-cb38-455e-9bce-4e9ec6139ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a382a76c-f4ea-4220-bcd7-66712e9510c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dd0ba44-a017-4b81-ae39-77fa29f7dfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbed75fd-d2cc-4e50-b27f-b5e6888bdf0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 753a7008-e467-47ce-832b-cc3a81d3458a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d497bd9-8ef4-4b9e-b484-359d5f91900f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5edcd053-5cea-4c06-9a2f-4f52b582db71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5205510-9fd3-4274-af89-66ae30a37153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42b20732-3707-4886-8298-0f0ff37abc5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5e3a1a-ccdc-4fbe-9747-8b893ffb960b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 947bb7fb-3a51-4325-bf2f-5e4068df50d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec2d868d-e56e-4593-81bf-9ad3510c0574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc5a0d41-0f14-4abe-aa97-c63b3cb14b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7871189e-72b2-4296-b0ab-829d18e69c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31f5e308-7eee-46e0-b4b3-cc980dce5665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3b62b27-cf05-4d27-a1cd-04ce93ebbe0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423e95fc-064d-4c12-b824-166202980ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40c914cc-8bac-48a7-a453-6bf2dc8e01ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5da3ff-e66e-4f7b-852c-dcfd1b30dab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f112b38-9bcd-4348-86dc-f1f8eaf17451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a38e60b0-828e-4ae5-b8bb-4ea13884f218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6edc0655-71ea-4f92-8dd7-41863a7c6fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a05b25cd-4b2a-4050-a015-75ea87acd7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ca547c-aa06-4327-9633-d510831095e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92995ec9-1609-4b8a-ad87-2ef7e0fdcba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f9b973a-54e8-4e12-907a-4b502b0f4fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81e577b0-bb68-4a2f-befb-b5fc96b472e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76526341-ffe1-4310-9663-307bb9d7f4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da9f0e9d-8bd5-49c2-a7df-c779414ad4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4e36456-6a47-4e46-8a0d-aa4bb310f2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d62ea75b-d416-4322-b2cb-9f32cd09056f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc193c8b-b0c7-4776-a232-149624d92359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 129eeec8-6454-4fa8-8a13-62b8f0e1b2e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d33bf0c-bdc1-41b8-a45b-ed22ddf909aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc162d8a-77e8-4764-a41e-a6900ad6b458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c5c3fc-dd19-4c98-abf6-c7c1d801d05b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf58a42-1456-43c0-b7ec-103fa9fc1aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6fbd1f-d43f-4e55-8174-ea2053582c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476d2b23-08ed-44ad-97aa-19d236ecac59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fea4521-7371-4cb3-bc8e-d5dea0e43c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad6b0ff8-7bd3-4d22-b58f-38f77a24ec3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 928ed96d-f43d-4e61-894e-7cd58b051f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e18c5d58-9c93-407d-b615-f7fc21a880a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fba34075-4696-4b64-904b-5df5e75a1909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bdadd77-f7fd-4858-8ce4-168805dcf87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92f9d9ef-a876-4ac5-a2a0-729aa71e7d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0778ba8-74a1-4675-9686-fd7c54fcfeae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 948fef33-15d4-4603-903f-ba0c0980bb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 203f27f0-3675-466f-9884-f2a8f5cb577c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a9eaed5-bcf5-4242-9875-b27b9b4d6490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5694cc6f-a856-4707-ba1a-6e91ac6c3f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ce0a73-d921-4473-bb04-4e4341956571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4627a3f7-1bca-4878-9311-99888c6a05fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e10ed6e-6647-4026-9e2e-7c6e488c71bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0436c725-8208-464b-93df-555e313b12ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c15376d-ca0f-4fc8-bfb2-c6249d5f3151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 058fa2b5-859b-4809-b698-f4a1f7aec69e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad9aff08-5f41-4251-a0c5-466393a22ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12dc8cc2-53e3-41ae-bff3-d4cc1888a535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20da2316-1436-4ac8-a0c4-4461e6e74d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b53eb11-0284-45fe-8584-9469a484977d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aa649f9-08cf-4706-bbee-b9d6b46ffb1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6527a9aa-84a2-4fc6-b643-c142f0687789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06031fe3-fb7b-49c4-8f6b-d4cfb7c3c70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08842c23-1134-41e7-8f9c-a35d8f48d030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a2e5659-af7d-4d03-b75d-91120a43c5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb3a289-79e0-418a-a0a9-6c62be56a136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c81f49d-98dd-4e25-b9a5-4ad94a0bd4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac695fe4-6818-469d-8b1a-70b77713c7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f703ece-6fe9-447d-a7c2-7e720dc60669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e010caac-d4ad-458e-9fc4-3d4ce8c1440f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc037c2f-0bab-483e-896c-53c6c23424d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da54c7ca-8a56-4ad6-8d66-a21f116122d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98112fae-f7cf-4500-b1d7-9eaafe379133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb7b6a8d-0de7-43f8-989f-de2cfc60114c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ce6444e-5885-4cb5-9347-f156d08a2526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50fefb4e-7d1b-4e30-9467-043ab8bb50ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee2da5e-d5b4-4273-a05e-58cd1630d489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71b1b869-cfee-4b7c-862c-0841abfaf226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40b88385-f597-4271-90f0-e79d6b0ebf18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5386354-7aa1-4bd4-9820-b2df8cee85fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de09fd1-1af2-48ea-868e-16a53a6e2ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cb1342c-5303-46ba-ab27-947919c5c583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aa85488-ce3f-425d-a242-6bae5b90b8fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4c2c3e3-6fac-46e2-a1a2-66fad5633f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16665f12-c78f-48b6-b437-03fdf16210d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85366c76-79ff-4715-bd2e-6fcccca0a23b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe0d2eb8-365d-4627-bdc3-10681c4272fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5586d95d-0912-4f3c-a12d-7454d142d8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47970fb3-0edf-49a0-a1cc-60940fae8380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8372e68d-8692-476d-930d-99f3a3f5167b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52c86092-05a4-4fdf-b316-9a081eaf98e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0f9289c-5c76-40df-921a-3ee33909c265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83f37cf0-dcf9-4680-9c01-8686364171a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c8723a7-2bf0-4923-ab4b-4309a1596332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b1411c-6ab0-4aac-bb4c-25cae0ea59d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f82d124-a4d7-44ff-a515-cba419967243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d579dbe1-bdc7-466c-a0f6-8adbe54cace8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 789adf67-e280-4ba2-8f7d-c69b60e4d4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 912a6ad1-54f8-4a02-9aa8-6f378e5d4f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5148deb9-0df6-42d5-826a-8316533f6744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9b742ca-ac2d-485e-87f8-6f1bb7d095f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81a953c2-5e31-4e5a-863f-fd746cfd5c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2119edeb-2845-4721-be56-bccfa2c6fbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d4160f0-bbf2-43b9-b686-da146f55e673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14fa415e-e5f6-49f4-aa98-b7f68f6d4113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23126873-e342-4722-ae55-c1a1c8aefcf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b99ec6a5-9e5e-4a01-b69f-61f8b9d9a2a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ae93d1-7f60-4435-b33a-210fde3ee611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f33e8b40-2162-4535-8afb-1413d2b48f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2e12485-c1dd-4df9-bf9f-eab8c35f335b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dfdee7c-95f5-4a72-af5b-a306ef3de0b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ea334a5-a582-4833-a588-9c6dc078cb16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b25656b-1505-4d21-b0c5-af3dfebe8bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 582f85d4-4b2d-4437-9963-3ebb90355ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20eaca83-92cb-4903-8cac-f1a07241d63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f4e0f5-1867-4f2a-aa25-5b82e1eac404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed7858c3-4829-4a16-9e7b-3ce76fc00d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7fb1255-f6bc-44e5-9dc0-6b453c07e261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9af35c9-84c0-4712-bdbd-735dd16c644f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c47e4445-459f-4ab6-95c4-3ca8aa251c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01bb23ac-f617-49fe-9eb8-b4a0f088ba3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3885477-0379-4ee6-98cc-d005ae368639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fe5c473-a826-46ce-a39f-f6dbe7c334bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f43241d-a4fe-4726-9aee-5779acc33876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd7f386f-1ea7-4ed7-a46d-05d2891402cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ae48f5-8ea9-49ad-8651-cc63799472b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7746a9e9-7543-4151-a47e-8b0c75aedda6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23232160-b6c7-4615-85aa-340deb553097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d12d00c-0347-400e-a0c3-b46cbe4bf203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c60545e-a27c-49e3-939e-92639cb1c1ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff127245-a84e-4601-8c1b-b49806d8656b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7fb2e92-06d0-4166-9be5-50b9802cb42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ef693ce-52c8-46fc-9f0d-abc413183e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5655e33-45c0-4381-88b4-80f393210595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f46d67-479c-47a4-808b-d1986fe8cc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a034b6fb-4429-4e31-af54-2e7376d26d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 449c87a6-a08e-4a99-8e87-5cfaec0cf991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5d26494-bd10-41d8-8b8c-9744e2e7b9e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d708d42-8cd2-4db4-b96a-3a96b9f14bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63cf0219-c530-4060-8d07-12c3fe0d3247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49218f10-575b-40bd-8355-6985aabf0c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7467e5b-aba6-42a7-baaa-db4ffa209930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 376263a4-0f9a-47b4-8f45-194123e8a77a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c41a7e88-9571-44e7-94e3-102691df1fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e0c1f40-cc77-425e-a440-985092db8234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c667fe4-4d50-44bf-87a6-4d8ac8de3722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5938aae3-226e-49ad-a9c2-973973cd334b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbf215df-2107-4fe4-8e00-fdcf7c5ed4b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d18fe3ad-4edd-442c-8f6b-5e161c26ea1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 125b3be8-1008-4cd2-8c12-3578817a6bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97d8c5a4-3804-4a21-b1b2-287c0fa9cba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ca75432-4f8e-49a9-bff0-7122a34e74aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e963c9-5e18-404b-a8b0-27caf27b35c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f4fef7-8366-48a4-9990-adac7394dbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 412de048-dcc8-4496-be97-e414ad157b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99ddda42-a6e8-462b-ac43-89c6c574d48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d984ffa-70e5-4f75-b60d-af6da82fcb31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 343cbe88-35f0-4c65-a729-a470a9f21bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2195f17-f7d1-42b7-adf0-1000c3cb1edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c92a7c-5aad-415d-b988-25f48fa0574c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee2eec3-a0c2-4d8d-b28b-3818841ada24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdd9c8d9-c3f0-4af7-8e42-69179286dc6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7c457a4-edbc-4adf-a922-a102ca242324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4430119b-c928-4fdb-bcd7-e3b52cd62ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7980bbf-babe-4435-a3fd-2889d90b2ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca2b2d34-55fe-4851-b954-dc7a2a362947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104b6ac4-933e-4cec-8594-f2161e5dbeed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b83ade1f-a27b-4ecd-a284-7e5714b2b4af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 246963bc-2edc-469f-856a-4f7d85a1a166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 383cc546-5089-4177-abf3-d1f5537e4d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed95965-8572-423a-bf95-99f4b17f3880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 962240a0-5857-4491-a00f-5a34e8e00491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84dca773-a6bb-4ed1-ab84-00957201cd3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 946ba641-cfc6-4f10-82aa-f65f8d3d9ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a067893b-3119-49f4-b743-a392c1468cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a533353-71c0-429e-8d71-85f9c0e6403c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d36d11f6-69ec-4fab-8a51-d30ecb3daf4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09669d08-12a6-456f-bb68-68058ef37e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bf28167-b9a0-4800-a30c-c4e9aea9705b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed0f0c9-bff2-4662-a449-994a02e98565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17ff9f7a-4278-4fae-998e-5e8cce92494d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b49c806-5f15-45b5-84b3-ae44d6105308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d575b1-e5e1-46a6-9b8f-fe08b614b2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d02c147f-9f7c-465b-bea8-db01e3239b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e1e4eac-c41f-4bc8-9c95-faeb64728d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca2adad5-14fd-4358-9306-5d3d0610d6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7180ea7d-d9ab-49c5-90bc-f161f28d8ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86f1fe19-4e45-4fd7-bbcc-5e5a6bf3a992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea0d6074-0662-4263-96e7-3c159401627b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cf6b4c6-009c-4b36-9eda-5e501efadd14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2a67505-12d9-4ba3-b917-38dc5b5316f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b71b4b4e-9c84-4d48-b28f-590566b1060c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e8e4ea2-7a1c-42f5-a5b5-01d036b11f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23608ed4-d5e5-4e01-a204-7271b389e9d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21022da0-a586-4073-ae08-aa3c563dd938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cea52c9b-9259-49e5-86ec-8f1233edf2be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 091c07ca-2147-4b7b-bfaa-7c4ae766cc67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a54d4cf-fcb3-4882-b3a8-a123d8e36df3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0233126-a287-43a1-be33-98be2f41abc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a160e510-5f5e-4065-8d7f-5c65b888fdc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e9190d-c598-4fd3-bc5a-b6fbdf46394a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8ea4733-3dbd-4003-b1aa-35a69a489061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47ca43a8-2704-4369-a323-24ec0d970c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4de3c05-a620-4a6f-b43d-4a58df051d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c1e5fb3-2af2-40c7-81a4-cf25bfa68844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bf318bb-4d33-402c-93fe-e4f6ae23d516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17b8d896-62b5-48d2-81e4-9a979bf57dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32b3cd95-b6fe-4ed3-b5ff-fef2cf9bfe46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5560a22-9083-4a07-8380-ee47b0b340d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c6676a8-5c9a-47ce-8cbf-096a7c88c8ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aa489db-10c1-459d-bd9d-c6a1e94adfe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a773b3a2-4437-45f5-9890-2d7c02891181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9deb5c7-8872-435a-8a2f-72fd6e902feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16ae3597-2df0-42c3-b308-78eb3b63cbb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dda60e1d-98ec-4e14-8bb9-e1e5998ab7c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e4ca5db-531a-46f3-8259-8376cc5e3d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef69f6b-ebbb-41a5-a949-16b6105b8a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a27363c-169f-4b7c-8dfc-24f5ffee8f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a129f00c-9aa6-46f6-900f-0dc9aef438ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab37be5-66c4-4998-b2e0-d257935ab87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2213147d-b021-4657-96d0-4101ae1eb7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fda7011-3502-4780-9a51-b9bbad2cbcaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1357d804-01be-40eb-8c73-b9d42dc1af00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2710b8cd-1c05-48aa-81b0-1208cd70b50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d49eeab-6aca-4d9e-a303-0134a557d186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message babb5c5f-0e74-456d-a489-57f57a9b0fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7acb693-d6a9-4e3a-abc3-0c663dd7b92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a04359e8-449b-4982-974b-e18eea4a7534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ba8243-fea8-4fb6-804d-4674a7d29f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ab8250-277a-4a1b-9bc8-75fbcafc2251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0d76cd2-5b63-4b21-aabf-6cc730c32e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 283dfc13-206f-43de-a98a-331560d8d557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4db1121d-0b2f-4fae-af82-4962d232b99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b10c493-672c-49b9-a79f-3d22d7ac4223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba7ce99b-bcdf-4c38-a89e-b07232dc8494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb2c500b-8e98-4ffb-9b07-16faacfde7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69efae4f-56e3-465d-a90d-130dc6016f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f199f8fa-5a99-4d43-9024-7e418a851a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d556321-28d0-44ff-a6be-e13a61e52529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1fd2655-eab5-4799-8eb2-2cc24fcbf107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 697be958-ccce-4e16-a46d-fe92540cf18c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1f1568d-c60c-45ab-9d3e-a61bc808f454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57679079-9ecb-4c4f-a5ce-0ac2de9f1085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7670b69-c52e-4faf-ae33-b0c1b40e8cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c8af6e4-6545-49a0-bdf4-91412145157d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3920420e-bce1-4002-811e-50b7afadf0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d729dd3-9072-42c1-9029-782a281b61f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f73e83c1-276f-400f-bbb9-0ef54ef58efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd870ac7-e784-4d87-8290-14fbbcbe71d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70312fa6-87b1-46f9-bf11-c074481ea329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 285811eb-3b04-4394-8f43-34b4856e408d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2bf069-9e19-4711-8a08-c332fd647f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeea2532-c215-4377-8619-7e448117a224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57839ef6-b3a5-4c59-8ee8-523090f918d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe68472-a40f-4cea-8a57-b8dd1ea2ee6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5136f4bb-5b0e-454a-b474-ab87d1dac2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38e5a745-5e4f-4ed8-997c-6619b6f1206e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97af6de2-650c-44c1-821a-f1adc4b78585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b883a37-7281-471b-b306-27f820f90e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47eb735a-b1ae-4cfb-a27e-fe1c774e4f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 308098c7-f5f7-4f5e-8ab5-98e8e8b431f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0736584b-876d-4aef-aadf-c1beabbf68c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d05ff624-a48a-46cd-834d-cf73f2a3b330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ca6791-ee35-4ef0-9e5e-f8b9cc90830e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bed8691a-8c8d-44a0-bdf0-f09f9a41fa7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6012f369-cc02-4497-99fd-6818f97800f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7c7630b-ef10-401c-9ce5-d470e565527c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8b59339-6093-4295-bd36-b3fc786e2bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 062c82b6-68d8-4d02-9a79-70aa3bd3cfe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 165d3537-ab7a-4714-be65-178167effa6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf256eef-0ea9-4db2-8f38-b578514bc7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ab5a558-14ba-40bd-8082-5293959f2554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aba35e75-dced-49e8-9975-6929bdd98178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90016a9c-77e9-487c-84ee-cb8216516b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be51746f-f433-4fc0-ad03-b5dbd7580df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a9d476-378b-42ee-b231-b8b6092f1423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6d2d114-f8ea-4a09-bbf6-5137f2639a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 732e7c48-cb8e-427c-9cfc-dc696eec8ca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 778b7dfb-f8b7-4996-8086-c824fcc68616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2262fc11-d4ca-4a03-8222-b3243e13597e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c0c6add-ee78-4437-94ce-3d1dbd263da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 609cfc37-5d23-4be9-926d-62ee689c3265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b1801be-d46d-496c-9401-c68d24517de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e8c3e6-5906-4725-acad-93c1e92355ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f030796e-86af-4846-ba74-0948a8b7d0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b595054-852f-44fe-ad28-305649a93482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35798bda-7484-4432-bbf8-6b69a759010d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db82ca10-20a9-4e7b-9bf5-09025fe9b2e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9865b801-bd67-4732-9e77-12ffaa2f8637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e52705-decb-4b82-88e0-c968a323af3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba0af82c-e961-46ea-a3c2-be32d16058d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5878df78-28b7-41aa-bfdc-0729e6d00bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f7a6247-5f1b-4ec8-bc7b-9792f914ed1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c90d3d6-9d50-4285-9bb4-2454bcf8a6f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321d6681-2257-4fa3-9560-b4674f2fa15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfdb790c-4115-4795-9b8a-c54ca716304f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 265703f8-0e40-4d30-85bd-fa32648f4a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edfe3b27-af7b-4e7e-900f-17d46cff48b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a94e84b1-5450-4919-a204-898ccdd66ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74c89891-8f8a-4784-90fd-5d8ec13884cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d66f5930-e0be-4ddf-a58e-bb06eb25cc82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b2ac6a6-4fd1-48b0-baad-40a6d42ebf2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f0da148-5654-4889-933b-911cbedeb36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1216252e-0ac9-411b-9889-fb41cc33db25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cd6523d-2c53-420c-b774-5b49b61a6d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 875608d7-201c-44cd-b6c6-ecdbb86296f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea50bebf-0d2c-4d17-a512-e93ae601fb53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a6e4e4e-f6f4-46f4-85c3-31ab576cacd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e6852d6-91bc-4e2a-b288-9dd5fbb37535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84dc3dba-8205-48a4-a411-230e31556e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4902f3e-cd91-425e-8e9c-788c3ed0069c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e6bf9d2-f717-4706-90a7-183f398393fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04b12a13-640c-42b9-af7d-4bdbf5d21549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee5c84b-8e38-4989-b927-3d9a67dc05e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5783dcad-d3eb-4299-a777-2d978e775312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67f6c908-f39d-4ce6-90a2-394881918f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f1241ae-66c3-4d2c-b96c-06b6b70cc602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a5e3bc-adda-4d2a-9653-246ca70d07ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4856a5d1-a671-4c44-88c5-6cdc1ec764ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5bd9889-7f4a-4ce3-a886-2b508eaaef79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfef678a-961b-4a1e-a9f8-1041ea291244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 714ebf9e-45d8-446f-b7b6-92f20895a641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea4db198-4c09-4bc4-b399-31c849193049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 698e663c-4719-42d2-af0b-b10456bc5c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d38039ff-7595-4354-a8eb-b1c3051e2b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb389bd-b430-49cf-a920-0d8a09de656a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3893476e-341b-46e5-a12f-1ea1bcc01c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de747509-fc12-49c6-8445-8b6b53d6a17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e456547-dd60-440e-8cc7-f623038cc0d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf35e0b2-95be-4fae-b6b7-6e089c055ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db8051e3-baaa-44aa-be19-01c8f7c8e2a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc313447-5382-4974-95cc-495bca013cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59486ee0-00f1-46a7-845e-816273f8eb62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49455b1-b193-474c-bf50-2bef4987a3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82e6e40f-9ce8-4dd2-97ca-18fc83ec625e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6a72681-4719-4bf1-a172-3402376947aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8baf096-524d-47d3-91d1-0874a94b7b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbc5be30-8c81-41e8-80f2-1886b2d9ef81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 433215ea-9a4a-4c83-97a5-19589198b8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4520a40c-6218-473e-aed8-b5312454265e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4591337-dade-4e0c-a891-71a696ea08df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c247d4ab-aeba-4268-9b41-ba96acc69bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e23cd9b0-bb00-4136-b5db-ce49f778387d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8d296b-76a0-4c1e-9a23-a5f8e32eacda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77807fda-9bc7-43ee-bd8c-1e4fcbe917d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e69ea95-b3af-45fa-95aa-d3c73281fb0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c721481b-c7b3-43ad-b071-707ea966a649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0fbfea8-8ca6-4831-a46c-71c55ab408c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1ab30ff-6084-483d-937c-7c6f7b228cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b969215c-d5f1-4518-a87b-691083060baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd3b4c7e-5007-4aa8-9aaf-62ed119d4740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e2d72b5-dedf-4bc4-a11f-2ed2c916525c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9b350b4-8415-40ff-a017-dfbc3c69537e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcc29fa3-6dc3-4317-bac9-1c05edf1792b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62b8894b-c6c5-435f-9e24-a8c81f45a38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85905d9e-f60f-4373-8015-5e61b3f50558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5f1c8bf-1211-4334-b88a-ecb459f119dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42fca895-b586-4994-85e4-071daf0b766a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4febab3-2ef6-4c7c-87ca-c76fc14e08a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2b454b1-4650-4708-8178-b460c45bf229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64c1a22-fc00-44fb-a3fc-fd86ebde61c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd65daa5-9166-4d26-b835-a8558ad75c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09e03ab7-9149-4d47-829f-c6a8138fb56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e69255b-6e0a-4ea7-be05-5f57bca3832d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37cac4b2-0149-49cc-8f1e-3ddabcf36aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51c3d0e5-bf23-4502-955f-ea8e1a840d94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13a8c0cf-9c8d-4ec5-a0d0-afeef4734f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68fd0012-258d-4913-8952-4cb93615520a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6ce7747-7eee-4cae-90c7-4c10325a2935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5d1fc2-970b-4c26-b9d0-823b4c3902af
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_12
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/test_labels.txt

📊 Raw data loaded:
   Train: X=(5148, 24), y=(5148,)
   Test:  X=(1287, 24), y=(1287,)

⚠️  Limiting training data: 5148 → 800 samples
⚠️  Limiting test data: 1287 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_12 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0886 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0840, val=0.0880 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0867, val=0.0856 (↓), lr=0.001000
   • Epoch   4/100: train=0.0878, val=0.0858, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0868, val=0.0861, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0839, val=0.0857, patience=8/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 2 Summary - Client client_12
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0081
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0014
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2525, R²: -0.0053

============================================================
🔄 Round 6 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0843 (↓), lr=0.000500
   • Epoch   2/100: train=0.0835, val=0.0842, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0832, val=0.0841, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0830, val=0.0843, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0828, val=0.0844, patience=4/15, lr=0.000500
   📉 Epoch 9: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0814, val=0.0853, patience=10/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 6 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0076
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0044
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2519, R²: -0.0012

📊 Round 6 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0003

============================================================
🔄 Round 9 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0730 (↓), lr=0.000250
   • Epoch   2/100: train=0.0858, val=0.0732, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0856, val=0.0737, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0853, val=0.0739, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0852, val=0.0742, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0847, val=0.0750, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 9 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0045
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0086
============================================================


============================================================
🔄 Round 10 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0898 (↓), lr=0.000063
   • Epoch   2/100: train=0.0819, val=0.0898, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0818, val=0.0898, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0817, val=0.0898, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0816, val=0.0898, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0813, val=0.0898, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 10 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0017
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0032
============================================================


============================================================
🔄 Round 11 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0812 (↓), lr=0.000016
   • Epoch   2/100: train=0.0838, val=0.0811, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0838, val=0.0811, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0838, val=0.0811, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0837, val=0.0810, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0836, val=0.0810, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 11 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0006
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0049
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: -0.0001

📊 Round 11 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2521, R²: 0.0003

📊 Round 11 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2521, R²: 0.0003

============================================================
🔄 Round 14 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0820 (↓), lr=0.000004
   • Epoch   2/100: train=0.0838, val=0.0820, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0838, val=0.0820, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0838, val=0.0819, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0838, val=0.0819, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0837, val=0.0819, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 14 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0004
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0008
============================================================


============================================================
🔄 Round 15 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 15 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0021
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0081
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0000

============================================================
🔄 Round 17 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 17 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0017
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0046
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 23 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 23 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0010
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0012
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

📊 Round 23 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

📊 Round 23 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

📊 Round 23 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 30 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 30 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0014
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0014
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 33 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 33 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0003
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0014
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 35 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 35 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0015
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0004
============================================================


============================================================
🔄 Round 37 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 37 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0007
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0032
============================================================


============================================================
🔄 Round 39 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 39 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0007
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0007
============================================================


============================================================
🔄 Round 40 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 40 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0022
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0049
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 44 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 44 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0013
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0029
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 45 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 45 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0009
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0046
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 49 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 49 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0001
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0009
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 50 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 50 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0016
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0007
============================================================


============================================================
🔄 Round 51 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 51 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0001
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0000
============================================================


============================================================
🔄 Round 54 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 54 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0006
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0004
============================================================


============================================================
🔄 Round 55 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 55 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0005
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0010
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 56 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 56 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0014
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0026
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

📊 Round 56 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 60 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 60 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0005
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0033
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 63 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 63 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0002
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0036
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 66 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 66 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0009
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0041
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

📊 Round 66 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

📊 Round 66 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

📊 Round 66 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

📊 Round 66 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

📊 Round 66 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

============================================================
🔄 Round 75 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 75 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0000
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0026
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 76 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 76 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0002
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0037
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

============================================================
🔄 Round 79 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 79 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0023
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0023
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

📊 Round 79 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

📊 Round 79 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

📊 Round 79 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

📊 Round 79 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

📊 Round 79 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 97 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 97 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0001
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0017
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

📊 Round 97 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

============================================================
🔄 Round 100 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 100 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0012
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0065
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

📊 Round 100 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

============================================================
🔄 Round 106 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 106 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0002
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0022
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0001

============================================================
🔄 Round 108 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 108 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0028
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0108
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2521, R²: 0.0002

============================================================
🔄 Round 110 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 110 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0002
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0024
============================================================


============================================================
🔄 Round 111 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 111 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0007
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0106
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

📊 Round 111 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 116 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 116 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0070
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0371
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

============================================================
🔄 Round 121 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 121 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0026
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0045
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

📊 Round 121 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

📊 Round 121 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

============================================================
🔄 Round 125 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 125 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0007
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0008
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

============================================================
🔄 Round 126 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 126 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0010
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0016
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

============================================================
🔄 Round 127 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 127 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0001
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0019
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

📊 Round 127 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

============================================================
🔄 Round 132 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 132 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0019
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0106
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

============================================================
🔄 Round 133 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 133 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0015
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0064
============================================================


============================================================
🔄 Round 134 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 134 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0036
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0023
============================================================


============================================================
🔄 Round 138 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 138 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0020
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0107
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

============================================================
🔄 Round 142 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 142 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0002
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0008
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

============================================================
🔄 Round 144 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 144 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0006
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0049
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

📊 Round 144 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

📊 Round 144 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0001

📊 Round 144 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 153 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 153 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0012
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0021
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 155 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 155 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0013
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0078
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

📊 Round 155 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 159 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 159 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0010
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0067
============================================================


============================================================
🔄 Round 165 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 165 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0003
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0013
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 170 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 170 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0017
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0057
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 171 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 171 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0015
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0191
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 172 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 172 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0011
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0073
============================================================


============================================================
🔄 Round 173 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 173 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0019
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0076
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 174 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 174 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0001
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0017
============================================================


============================================================
🔄 Round 175 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 175 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0001
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0001
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

📊 Round 175 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 179 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 179 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0032
   Val:   Loss=0.0962, RMSE=0.3101, R²=0.0015
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 180 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 180 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0033
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0113
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 181 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 181 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0005
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0003
============================================================


============================================================
🔄 Round 182 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 182 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0023
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0074
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 183 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 183 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0012
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0160
============================================================


============================================================
🔄 Round 184 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 184 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0002
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0023
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 187 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 187 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0029
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0188
============================================================


============================================================
🔄 Round 188 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 188 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0005
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0005
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

📊 Round 188 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

📊 Round 188 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 193 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 193 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0004
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0008
============================================================


============================================================
🔄 Round 196 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 196 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0007
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0009
============================================================


============================================================
🔄 Round 197 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 197 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0011
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0042
============================================================


============================================================
🔄 Round 198 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 198 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0010
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0014
============================================================


============================================================
🔄 Round 201 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 201 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0010
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0001
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 203 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 203 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0008
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0061
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0003

============================================================
🔄 Round 204 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 204 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0018
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0048
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0003

📊 Round 204 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0003

============================================================
🔄 Round 207 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 207 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0023
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0066
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0003

============================================================
🔄 Round 209 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 209 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0011
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0047
============================================================


============================================================
🔄 Round 210 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 210 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0046
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0045
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0003

📊 Round 210 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0003

📊 Round 210 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0003

📊 Round 210 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0003

============================================================
🔄 Round 216 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 216 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0025
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0077
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 217 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 217 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0018
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0080
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 217 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 224 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 224 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0020
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0076
============================================================


============================================================
🔄 Round 225 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 225 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0006
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0051
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 226 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 226 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0017
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0115
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 230 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 230 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0017
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0099
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 230 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 234 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 234 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0005
   Val:   Loss=0.0967, RMSE=0.3110, R²=0.0008
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 236 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 236 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0031
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0092
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 239 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 239 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0012
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0154
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 242 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 242 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0019
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0049
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 242 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 247 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 247 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0017
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0247
============================================================


============================================================
🔄 Round 248 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 248 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0007
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0298
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 248 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 251 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 251 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0007
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0084
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 253 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 253 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0027
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0098
============================================================


============================================================
🔄 Round 257 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 257 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0003
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0045
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 257 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 266 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 266 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0005
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0055
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 269 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 269 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0021
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0024
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 271 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 271 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0009
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0009
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0003

============================================================
🔄 Round 273 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 273 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0013
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0028
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 273 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 277 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 277 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0012
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0024
============================================================


============================================================
🔄 Round 278 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 278 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0007
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0004
============================================================


============================================================
🔄 Round 279 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 279 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0027
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0226
============================================================


============================================================
🔄 Round 280 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 280 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0001
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0034
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 284 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 284 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0001
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0145
============================================================


============================================================
🔄 Round 285 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 285 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0014
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0024
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 286 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 286 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0003
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0007
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 289 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 289 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0024
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0185
============================================================


============================================================
🔄 Round 290 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 290 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0010
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0005
============================================================


============================================================
🔄 Round 291 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 291 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0013
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0053
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

📊 Round 291 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 294 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 294 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0015
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0333
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 299 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 299 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0011
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0006
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 303 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 303 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0002
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0025
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 305 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 305 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0020
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0102
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 309 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 309 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0002
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0024
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 309 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 314 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 314 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0004
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0023
============================================================


============================================================
🔄 Round 315 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 315 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0007
   Val:   Loss=0.0695, RMSE=0.2635, R²=0.0072
============================================================


============================================================
🔄 Round 317 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 317 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0062
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0189
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 318 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 318 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0018
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0155
============================================================


============================================================
🔄 Round 319 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 319 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0016
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0427
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 320 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 320 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0033
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0047
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 320 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 324 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 324 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0015
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0070
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

📊 Round 324 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 327 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 327 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0022
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0043
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 329 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 329 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0012
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0019
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 332 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 332 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0005
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0024
============================================================


============================================================
🔄 Round 333 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 333 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0029
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0204
============================================================


============================================================
🔄 Round 336 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 336 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0011
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0073
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 337 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 337 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0015
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0035
============================================================


============================================================
🔄 Round 338 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 338 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0007
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0003
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 338 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 342 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 342 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0005
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0058
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 343 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 343 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0004
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0052
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 344 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 344 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0006
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0010
============================================================


============================================================
🔄 Round 345 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 345 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0008
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0006
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 346 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 346 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0018
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0040
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 346 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 352 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 352 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0016
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0022
============================================================


============================================================
🔄 Round 355 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 355 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0013
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0046
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

📊 Round 355 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

📊 Round 355 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

📊 Round 355 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

📊 Round 355 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 362 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 362 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0003
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0041
============================================================


============================================================
🔄 Round 363 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 363 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0016
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0068
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 364 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 364 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0000
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0358
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

📊 Round 364 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 366 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 366 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0017
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0095
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 367 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 367 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0023
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0061
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 368 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 368 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0003
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0025
============================================================


============================================================
🔄 Round 370 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 370 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0008
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0069
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 374 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 374 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0017
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0015
============================================================


============================================================
🔄 Round 375 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 375 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0006
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0049
============================================================


============================================================
🔄 Round 378 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 378 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0050
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0012
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

📊 Round 378 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 381 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 381 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0011
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0055
============================================================


============================================================
🔄 Round 382 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 382 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0014
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0038
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 388 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 388 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0004
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0040
============================================================


============================================================
🔄 Round 390 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 390 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0006
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0012
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 390 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 390 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 395 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 395 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0019
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0270
============================================================


============================================================
🔄 Round 396 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 396 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0021
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0051
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 397 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 397 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0002
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0084
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 398 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 398 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0024
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0094
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

📊 Round 398 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 404 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 404 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0009
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0026
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 405 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 405 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0015
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0025
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 408 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 408 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0004
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0049
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 411 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 411 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0028
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0090
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

📊 Round 411 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

📊 Round 411 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 418 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 418 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0024
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0202
============================================================


============================================================
🔄 Round 421 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 421 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0022
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0108
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

📊 Round 421 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 424 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 424 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0011
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0009
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

📊 Round 424 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 426 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 426 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0023
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0068
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 428 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 428 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0008
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0007
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 430 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 430 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0009
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0036
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 431 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 431 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0018
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0086
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 435 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 435 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0025
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0118
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

📊 Round 435 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 437 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 437 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0007
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0009
============================================================


============================================================
🔄 Round 438 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 438 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0002
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0044
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

📊 Round 438 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 445 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 445 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0006
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0280
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 446 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 446 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0022
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0002
============================================================


============================================================
🔄 Round 448 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 448 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0005
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0010
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 449 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 449 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0030
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0287
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 450 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 450 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0012
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0019
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 452 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 452 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0017
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0031
============================================================


============================================================
🔄 Round 453 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 453 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0005
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0013
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 456 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 456 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0019
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0103
============================================================


============================================================
🔄 Round 457 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 457 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0023
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0118
============================================================


============================================================
🔄 Round 461 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 461 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0008
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0146
============================================================


============================================================
🔄 Round 463 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 463 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0016
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0060
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 466 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 466 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0001
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0012
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 466 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 471 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 471 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0015
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0039
============================================================


============================================================
🔄 Round 472 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 472 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0028
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0095
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 473 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 473 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0009
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0068
============================================================


============================================================
🔄 Round 474 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 474 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0010
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0077
============================================================


============================================================
🔄 Round 478 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 478 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0024
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0406
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 478 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 478 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 482 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 482 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0019
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0046
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 483 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 483 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0003
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0002
============================================================


============================================================
🔄 Round 484 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 484 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0013
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0053
============================================================


============================================================
🔄 Round 486 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 486 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0001
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0025
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 487 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 487 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0013
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0014
============================================================


============================================================
🔄 Round 489 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 489 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0025
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0064
============================================================


============================================================
🔄 Round 491 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 491 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0011
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0078
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 492 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 492 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0007
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0009
============================================================


============================================================
🔄 Round 493 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 493 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0007
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0001
============================================================


============================================================
🔄 Round 494 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 494 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0003
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0036
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

📊 Round 494 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 498 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 498 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0009
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0092
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

📊 Round 498 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

📊 Round 498 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 501 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 501 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0024
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0176
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 502 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 502 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0013
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0017
============================================================


============================================================
🔄 Round 504 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 504 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0007
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0013
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 505 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 505 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0008
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0043
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 507 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 507 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0027
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0075
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 509 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 509 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0015
   Val:   Loss=0.0894, RMSE=0.2989, R²=0.0083
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 510 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 510 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0051
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0165
============================================================


============================================================
🔄 Round 514 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 514 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0010
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0001
============================================================


============================================================
🔄 Round 515 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 515 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0001
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0037
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

📊 Round 515 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

📊 Round 515 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 521 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 521 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0011
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0027
============================================================


============================================================
🔄 Round 522 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 522 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0025
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0209
============================================================


============================================================
🔄 Round 525 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 525 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0003
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0012
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 528 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 528 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0017
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0085
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 529 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 529 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0025
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0084
============================================================


============================================================
🔄 Round 530 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 530 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0000
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0057
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 530 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 530 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 535 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 535 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0002
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0004
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 536 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 536 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0015
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0046
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 536 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 536 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 540 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 540 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0007
   Val:   Loss=0.0906, RMSE=0.3011, R²=0.0009
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 540 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 542 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 542 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0013
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0020
============================================================


============================================================
🔄 Round 543 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 543 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0005
   Val:   Loss=0.0954, RMSE=0.3088, R²=0.0022
============================================================


============================================================
🔄 Round 544 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 544 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0018
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0049
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 544 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 548 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 548 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0066
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0262
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 549 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 549 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0025
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0073
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 550 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 550 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0021
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0044
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 554 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 554 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0007
   Val:   Loss=0.0961, RMSE=0.3100, R²=0.0014
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 555 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 555 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0001
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0040
============================================================


============================================================
🔄 Round 556 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 556 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0019
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0029
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 556 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 561 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 561 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0017
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0027
============================================================


============================================================
🔄 Round 564 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 564 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0017
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0044
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 566 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 566 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0022
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0107
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 566 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 569 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 569 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0002
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0041
============================================================


============================================================
🔄 Round 571 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 571 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0023
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0147
============================================================


============================================================
🔄 Round 575 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 575 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0006
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0034
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 579 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 579 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0004
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0019
============================================================


============================================================
🔄 Round 580 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 580 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0024
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0010
============================================================


============================================================
🔄 Round 582 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 582 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0036
   Val:   Loss=0.0986, RMSE=0.3139, R²=-0.0095
============================================================


============================================================
🔄 Round 583 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 583 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0007
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0007
============================================================


============================================================
🔄 Round 584 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 584 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0003
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0020
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 586 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 586 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0001
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0125
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 588 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 588 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0016
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0177
============================================================


============================================================
🔄 Round 589 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 589 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0027
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0068
============================================================


============================================================
🔄 Round 590 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 590 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0003
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0016
============================================================


============================================================
🔄 Round 591 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 591 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0011
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0027
============================================================


============================================================
🔄 Round 593 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 593 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0018
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0039
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 595 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 595 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0016
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0033
============================================================


============================================================
🔄 Round 596 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 596 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0016
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0038
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

📊 Round 596 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

📊 Round 596 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

📊 Round 596 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

============================================================
🔄 Round 603 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 603 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0004
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0021
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

📊 Round 603 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

============================================================
🔄 Round 609 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 609 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0025
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0201
============================================================


============================================================
🔄 Round 611 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 611 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0009
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0087
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 613 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 613 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0020
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0246
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 615 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 615 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0013
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0062
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 615 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 619 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 619 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0007
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0012
============================================================


============================================================
🔄 Round 621 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 621 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0008
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0019
============================================================


============================================================
🔄 Round 622 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 622 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0011
   Val:   Loss=0.0891, RMSE=0.2986, R²=0.0008
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 622 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 622 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 622 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 628 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 628 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0029
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0125
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

============================================================
🔄 Round 629 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 629 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0029
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0162
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 629 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

============================================================
🔄 Round 631 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 631 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0020
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0131
============================================================


============================================================
🔄 Round 632 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 632 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0006
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0090
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

============================================================
🔄 Round 633 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 633 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0015
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0067
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 633 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 638 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 638 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0008
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0016
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 640 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 640 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0013
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0129
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 643 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 643 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2933, R²=0.0024
   Val:   Loss=0.0731, RMSE=0.2705, R²=-0.0152
============================================================


============================================================
🔄 Round 644 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 644 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0010
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0045
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 649 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 649 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0003
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0015
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 651 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 651 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0017
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0060
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 651 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 658 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 658 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0015
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0052
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 658 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 662 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 662 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0005
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0021
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 662 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 667 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 667 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0026
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0292
============================================================


============================================================
🔄 Round 668 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 668 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0003
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0033
============================================================


============================================================
🔄 Round 669 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 669 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0018
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0037
============================================================


============================================================
🔄 Round 671 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 671 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0032
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0114
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 671 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 679 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 679 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0011
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0064
============================================================


============================================================
🔄 Round 681 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 681 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0013
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0126
============================================================


📊 Round 681 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 683 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 683 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0009
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0011
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 683 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 683 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 687 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 687 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0014
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0082
============================================================


============================================================
🔄 Round 688 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 688 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0034
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0190
============================================================


📊 Round 688 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 688 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 692 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 692 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0018
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0031
============================================================


============================================================
🔄 Round 693 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 693 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0015
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0014
============================================================


============================================================
🔄 Round 694 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 694 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0020
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0034
============================================================


============================================================
🔄 Round 697 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 697 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0033
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0099
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 697 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 700 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 700 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0011
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0018
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 701 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 701 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0012
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0031
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 703 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 703 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0002
   Val:   Loss=0.0953, RMSE=0.3088, R²=-0.0069
============================================================


============================================================
🔄 Round 705 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 705 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0019
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0029
============================================================


📊 Round 705 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 710 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 710 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0004
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0034
============================================================


============================================================
🔄 Round 712 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 712 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0041
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0179
============================================================


📊 Round 712 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 718 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 718 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0009
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0082
============================================================


============================================================
🔄 Round 719 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 719 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0001
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0055
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 720 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 720 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0004
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0032
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 721 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 721 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0030
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0102
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 723 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 723 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0013
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0028
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 725 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 725 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0033
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0111
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 726 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 726 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0006
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0017
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 727 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 727 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0032
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0105
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 727 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 727 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 732 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 732 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0018
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0031
============================================================


============================================================
🔄 Round 733 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 733 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0009
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0005
============================================================


============================================================
🔄 Round 734 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 734 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0027
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0131
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 735 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 735 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0000
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0041
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

📊 Round 735 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 737 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 737 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0015
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0021
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 742 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 742 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0000
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0027
============================================================


============================================================
🔄 Round 746 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 746 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0018
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0055
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 746 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 746 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 752 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 752 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0003
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0111
============================================================


============================================================
🔄 Round 754 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 754 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0010
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0127
============================================================


============================================================
🔄 Round 757 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 757 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0006
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0057
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0007

============================================================
🔄 Round 758 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 758 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0018
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0018
============================================================


============================================================
🔄 Round 759 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 759 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0007
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0046
============================================================


============================================================
🔄 Round 761 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0998 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0998, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0998, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0998, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0998)

============================================================
📊 Round 761 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0007
   Val:   Loss=0.0998, RMSE=0.3159, R²=0.0017
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 762 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 762 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0032
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0119
============================================================


============================================================
🔄 Round 763 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 763 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0016
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0038
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 763 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 765 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 765 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0009
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0005
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 765 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 767 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 767 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0013
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0053
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

📊 Round 767 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 771 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 771 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0020
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0114
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 774 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 774 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0003
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0011
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 775 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 775 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0016
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0020
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0006

============================================================
🔄 Round 776 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 776 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0003
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0020
============================================================


📊 Round 776 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 778 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 778 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0008
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0025
============================================================


============================================================
🔄 Round 782 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 782 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0007
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0016
============================================================


============================================================
🔄 Round 783 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 783 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0017
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0051
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 788 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 788 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0006
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0005
============================================================


📊 Round 788 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 789 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 789 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0014
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0039
============================================================


============================================================
🔄 Round 790 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 790 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0038
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0217
============================================================


📊 Round 790 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 794 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 794 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0010
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0038
============================================================


============================================================
🔄 Round 795 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 795 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0020
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0034
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 797 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 797 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0006
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0001
============================================================


📊 Round 797 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

📊 Round 797 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

============================================================
🔄 Round 802 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 802 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0005
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0366
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0005

============================================================
🔄 Round 804 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 804 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0034
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0029
============================================================


============================================================
🔄 Round 805 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 805 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0002
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0030
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2520, R²: 0.0004

❌ Client client_12 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
