[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0902cf6-8f99-4314-b0cd-59daaebf1e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9922d1e-42b5-4c7c-835e-31bae9fefd9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e163b597-8d8c-4180-9c15-13dc2c0a60f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7264484a-d2ee-4c04-a4fa-cb851d8ec875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 247db682-2589-47df-a306-e76512f87804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfe2dc93-5423-4dd8-85f8-3eeeb4fbc6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b05dc77-59c2-4850-bdd8-78d7016aee04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78f0f834-fa39-4b5a-9df0-b2929e8cafba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89217bec-7932-4910-be27-4397ffc0a5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 029ff040-fca2-4eaa-9841-0db939a9d09a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eaab696-dfae-427b-bb17-f725a413413e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a34be6f-039c-472d-b8dc-88294ddd7018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dd5ebad-d140-4319-a90f-7fd538571d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b896feb9-2658-4848-90f3-bbae59f92787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf03d14d-defd-48df-9a07-ddaaaefe22c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcbd52cc-cdfe-4b0d-b3db-e2691c0b6a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 487d984e-a0d5-49e8-80a5-7bae5cffb352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 368ed027-a05b-4d32-891e-5a8ddc805acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1163f81c-48f6-4bc7-880c-94910fe02d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bfd93e5-5aa8-482f-b43a-94367904a535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 257885cb-1da4-4db6-9bd8-48e92e786e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 347297b1-2d95-4802-9134-16557244a901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e8eff7-2e08-4318-b04d-8063a75d6a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dba3c7cf-d108-45ab-9c3c-c093200607e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78cc906b-a33c-4da1-80ea-11b4d812a812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5264daf6-c9f8-4def-8553-1bb608e522ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d8e1605-dbb9-4fb1-b16b-1528d42f765c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd346a39-5acd-407b-901d-327980c7ac1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e7e9f1-19f5-4e37-98d9-393e3015a7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfe6ea52-9455-4f67-9543-25430f0c6ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14679714-4197-4c6a-85a4-f8dbbc7f024d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da5a3282-fc53-415b-9e8d-d65a251ef63a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed6d374-df8e-42a7-ac51-62e4ba54dad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc40f81c-6119-47ff-beec-2d9bf71b97c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b71091e4-5064-465d-80ea-e4052634b23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5737140d-5711-4859-a8eb-f7713c73e6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe1096cf-56b0-424b-99ec-474c2e1762fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 281b78a5-88de-4422-b382-003d82c2c745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b195e36-6e24-492e-b649-c1d0d6ef8c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5661f4c0-0222-44c9-a4cb-efa75426bb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa1c328f-453c-4908-b418-9647b47b399f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2750ac1-6b08-4af4-a2e9-3b28d41e0fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91be6a91-a563-4f7b-895e-9014e61f4ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26d7eaf9-d145-469c-ae39-c9b7b038e07b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0537a5fc-5a5e-47b3-a1ee-fd6c567d749a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe780fe5-9d92-4e8a-a73d-83cfe6f475f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d2cda74-2551-447e-a1a4-86d5631a319a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e63e5911-fb90-4cee-bb8b-5d12550b05a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3db46cc9-5caa-42af-8e81-5a346075496a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9218eeac-6207-422b-9dd5-b458d14f0ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b911165-6768-4132-affe-22fce181de50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df67ce3f-2240-4fe1-9f1e-c3722598a45a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39f4d6f8-ed7d-49a8-a3b8-fcb5cc1fdebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab6bae38-972c-409f-8602-c78e65174248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b255844-a8c2-4cae-b757-e23128297795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1663143d-4eef-41c7-be1b-dc69999fdd98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c135276c-74e5-4394-987f-78494ddbdaf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23b90d78-58a3-4e6b-b7f5-b402cf47fe5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 938dabcc-1b4d-4068-bbe6-c516db0fc8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ebc146-f971-4347-ba0e-c459fe95ac73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cedb2b3-9c75-4431-88dc-9fd925711904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ac62f5-cd50-45ed-94ea-90c86a624dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce3c82d2-91b4-403c-975a-f0d0e87996c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff03c92b-cd7b-463f-98c6-133e923f99b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 299c0ae8-05eb-4fd7-b216-5f87f7e73932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef8435b7-4f08-4edf-92da-79f3ed91e025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88204fe0-8a45-49f1-88a0-b0262ad8d34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a9bb54a-a004-4717-9854-a2add8b4f217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deef64d2-8900-4704-bd20-f2749948b9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a68563f2-bb5c-417f-a65d-a248aebe76e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec45111-c66f-4d06-b3f2-c80f3471800a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc8a9505-5ad4-4b54-b928-133774283315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ef5df02-f37f-484c-a694-4b8e028db0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f60dafb-7612-4a9e-9e36-92be8201337f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 096ab05b-4528-400d-be63-9ccb82bd33b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aff484c-d5a3-46be-b069-324bde58a242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eda7c14-876e-4690-b68d-3eb61148e6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3479fe86-4218-4b73-a2eb-c0482610bedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02b5d42d-0061-40ab-af02-a28cbafe8947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca119a4-a501-4790-bc7a-d8e9035e34f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d927e6b-be32-4f34-b0c5-ace4c8401b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 559a0356-bd94-4468-a1ad-fc73542f9eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18276ae3-af25-47d4-af69-fb3c3db08aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f524053b-baa8-484c-83b5-9a26005c2821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fb8eb03-9e0f-4ed4-8f3e-f6ed3b40db1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f92f8db8-8fcc-4639-866a-92e8da567c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99bfac31-e807-42ca-9f72-82e8df166968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0df8fd6-5dfa-4caa-a1f3-ff0897f8d616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acaf153e-1fa0-4073-82c1-e9aa5f42f7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a7f3b3-f5d9-440c-b828-b75efc33ed73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 932935f0-74ec-4bda-9ec4-f8d1cff1c0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 540b6de1-e43d-41cc-9755-b429909b5658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d59c9cf-a7b1-4adb-af24-a0bdf483b01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2394fc2-7b0e-4e0d-b714-2bbf88322b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0bcbd36-87bf-48e7-849a-425fea1ebe0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9e5f492-e271-4bf3-8bb4-e7d94be23457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 546dbd6b-7b09-4ac9-9e89-df80417f759a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d887b37-7fab-46f5-85a0-62cfb265da28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40c154b4-73f9-4b70-bb7b-7d632d110b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e27fab8-024d-4936-90cc-99e429143481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a60f958c-772f-4a19-9fa5-f0e415732ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56e9396d-3bf7-4811-ba94-fe69f33f05f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32b34420-482e-4f8d-a7ab-fb8d4b2f49fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9821ce81-7637-45c0-b331-ac65686a4900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48d567cd-d0b0-4df7-aadc-d5c517a6ce19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb58aa4b-001f-454f-bb83-bf83d83b24b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 421272e2-0a0f-4032-bc8e-cb022e234d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad6d07d2-4546-416f-9963-fa27db3c835f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c4056ae-06d3-4ade-a40d-db1bdf9b2648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1e149ee-f7ce-4d1c-b171-8da86cd99a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c0ee7db-b4b3-4c15-8e67-db777462804c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df0539d-05cc-4254-a449-f36c9613a7b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03cd5ff3-5e4c-41c3-80c1-b8d463f6caed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b8a11c-ebbf-493f-9ff2-a0fa97ef18ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa6a8b6-22df-4ef2-9f5a-e69d0371b657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3d1a202-3968-4364-921d-88b7d2c000f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8c53e9-7f50-42b6-9645-989c73aaaee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c87fe2e-c827-4a30-936c-40c7879bdb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c8425c1-102e-4e13-ab89-da439856dfb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7227e7ab-da38-4787-b21b-4de6c48970a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd052982-b484-4ce2-b057-7f0d610e60e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a16f293b-2bfb-4d81-a48e-5684918db5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e16b5ba-5303-455e-b70c-feea247c68bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca7ce49-3b2f-449d-9aa9-c7963b461903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c2e1025-48c3-4e4d-9bcf-6b1eeaaa3ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49041c48-6fd9-427a-b31d-135dae8e1809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e29c9ccb-dacc-411c-9bc7-2ff31e815fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a763d437-0eab-4438-8ec8-3ae4a26711b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 618c8e99-183a-401f-90f7-a4684b49ae1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f083066-66e3-4e45-879c-3bdcd5d5e9aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fcf4a7c-809b-46f5-99b1-a1572151873e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca9561c2-cc20-491f-aafe-c92081ad9e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f4f26a4-b7d9-4ea2-92b1-9b6946bb874b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff18a1f9-8081-4353-a440-f3d90b3022d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d50071d-602b-4848-89a5-f95c1e922bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 345c00db-5d03-4366-ac0f-ec37ce043351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a5dd48d-2230-4136-bec6-b35855bfc092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ddd5932-6763-494e-a14b-0f70b7411bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7866e5-d518-47e0-9d82-da592ab7f25c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21647085-896c-462a-89a3-9bcf251077db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 198e2b86-27aa-4e21-98c7-8665709456f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b3cc2af-e438-443f-a577-e89de7659d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6642ea7-cfb4-42b7-b748-87287bd919ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc388c0-a57e-4b1d-9124-78921683c6d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05d77f0d-86e3-4e51-80da-1b61f528beda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad80d22e-3f78-41aa-a47a-82f485121164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 068a7c4f-b076-4994-b6e4-b60f6e1871ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3da1dab-8918-431b-95e1-5d1e64c378d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f6b88dc-f9bc-4a6f-82d7-f2b296ccc880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9407479f-6372-448c-8dac-a710b093652c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 650b280b-ddb2-4876-b119-a4019521291c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad45e62f-2940-48d6-9f8a-44125977e7d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 030660a8-2f1f-4614-92c1-7e555340a1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 930873f0-5997-43d0-82bc-e48c4c82c02c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edf99aa7-c9dc-42a8-a439-dad7c4ea17be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a29c13d-ac01-40cd-94c6-968ce2a14722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b64737dd-c48b-4799-80fa-de6c248c9728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 320717bd-b90b-4337-822e-3792212e9ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cd2cbc6-9b3e-41ac-9abf-459bc3172f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536c0646-7a05-4712-baa0-c8660f3b4fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c71082cc-8c76-4e3a-90fb-616926ae188e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c33087a-6b50-4f54-8eda-a4a931094381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d00f90c-c751-48ed-b6ab-cd223fc9e952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d80ac28e-74bf-4c6c-8cdd-2487d6ac72f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011305eb-9760-4fad-81bc-5b58937b474e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acb1dab9-427e-4393-b4f7-5fc452fb7de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a8de44c-69d8-4b16-a238-75dcd57d7200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2c4761-2a83-478d-a121-8614c48d9ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e0dec70-514c-4c1a-a1d1-4ccb003253d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81484b87-f8c1-479c-8edd-4fd0298f4812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ca9ce90-4a89-40ea-a1a3-ecb3b18c742f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c21d718b-2420-4402-92cb-154c98039dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5c093ed-93c4-44cf-92d8-b400fca7a6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5a37b03-8fce-4af2-a6ba-79bdf77cb015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d8f9fd2-7003-417c-ba8a-0080ea3f2f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b47e9ba-e93c-4f50-bc10-98a072f4dbdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be9165c2-37fc-4fa6-88f9-c07404dc4a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6498c510-1708-4ee8-8c8b-5c92899ab4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 860c3cc8-c779-455d-a58e-de79f183e3a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfaf0a52-242d-4e71-a620-1da10087e17c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d3baeb7-30a6-4c37-ab7b-22f22f0a66a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7810102-c26c-4bd3-8a77-af4aebd64f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73662eb-1f30-4912-ac59-4e7c3651de2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c009b22-a4ab-4bc3-8acd-c9307c2a7bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b3b8bc-9430-4bd8-a9d0-81e43f1b9702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa08c7df-3df5-4870-b882-ae07bea0d242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cc46424-141a-4731-be82-32f72d57aef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad696b9c-5e29-4995-984c-a7af73a24184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ba0908-8cbe-4e88-8343-551adba59a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba4b7c7b-2dd7-4bb5-b21e-d82de76e1800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e86fb7c2-50f4-4603-b69c-f21ffb35267a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d89db7aa-9fdf-4e9e-8af6-509f26a112ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8658ff-b0f0-4daf-9035-e4c1ee03c3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d37d7beb-cb24-4eb4-852a-68bc8549df7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9c97386-6df2-4a2f-9959-789f8cd100a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbde9e88-a524-4767-95a1-536383364731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1479c70-c11d-45c7-ba41-58ab14927c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6e79f9-4aac-4b78-bb3f-a0e6505f09dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ba7d74-747c-4c0f-a962-6287714ea6de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02fea6de-86e0-49d7-89d7-2ad7ea9e4ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fdef667-b184-4d2a-a508-dd6dd31265eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cac3bd5-b01e-45f9-97de-3320c04ee03e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2cd05ad-271b-4ada-a0b2-a410cc293a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 715e53eb-b8ea-423a-8999-43f2b8824f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a15c9d04-c976-482a-b6e9-73f871e8a1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97a823e0-b27e-464d-a20e-1090e8527027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 840fd935-c370-47db-a7e6-970d2b9c4597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56b11869-7df3-4c8d-ad51-61684633f6ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1409ba6-3dad-4b2e-ad6f-e116373d05f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2c961e0-7c57-48e8-9ab6-9b6a19887384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08cdc3f8-d1dc-4342-9521-95206acc578b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a772a99e-2cd6-4279-991b-ec956164c470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39a3dd7a-cf0d-491f-8bac-0c01a1278cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 460a74bb-ac87-43ce-90f6-3c76ed672084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd1155ee-3095-4db1-a852-0e8c75e539e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c962b1b-f369-4f02-80f4-f610aa254523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee28b6b3-2ba9-46ed-b4a6-d0fe2cd5edc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 780389f6-3f1d-4308-a5f7-d1968a03eb13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8666fc46-0c3d-4568-bf6d-8e8b01bd3b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd80e318-8e9a-421c-8b59-1158e29c73ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f45340b-69a2-4cad-b0a8-ac321cbb2b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98e664b0-986e-4dc4-bd74-a6b7a9290f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6d3cc4b-be8a-4e2c-ae81-c2ad2740eb25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 906c964b-d399-43b4-b0fd-1c19c8aecfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a5cb7ec-55b4-4191-a777-39b6bf298feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04dbc5ee-f637-4973-96c7-54f58bd767e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 862862d0-59e4-4818-9af0-63a7c291ce7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ddc112-0967-4d42-8547-1e1dcafa9e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfa05d2c-c2b5-4639-a0bb-9f8f2704f9e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4215665-6e89-4dd5-b006-65932e6e278c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b401ee0-e037-47f1-b0c7-d80632ad1a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea34806d-d7c5-40c2-a87b-e29c1a4279fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08172838-9a7f-47e7-82a1-daceb72f38a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d430fe40-5a41-4fa8-8fd4-852b542e8694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7241ef77-53bc-4f8b-98ae-6b870337e1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73fbfe1f-0ead-4e80-85c7-d28043ca7b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1156924-df95-4f6c-9ff6-ffe313718ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 583d2adb-2277-4968-b7e1-f6d050fdf983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adb4973f-33ac-4539-8b9d-2c2ec4aa9750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deafd28d-7da1-4d1b-9355-8d6724815753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df93f37-f3e2-4613-bde4-f2d20863aed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90159a44-ffcc-4986-a40f-41e824474b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7004fc9b-e253-4ffc-9e32-9d377eec83e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fec1c268-3f4b-499d-a7ae-23a68ebf966c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fa99689-4be0-497a-aa13-53331ff37dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a98925f-85ec-47e5-ac0f-be9cd02cbb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6a87292-8c65-46bf-bacf-19d44a759465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42dbeda2-ba04-4eba-bade-e8fb878d0e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813fbd5f-30dc-4ded-adc8-3c46494d540f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a749b80-9b62-48ca-990e-059c88d37ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c25b4f7-4120-409c-b592-730336933463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd580d0c-2554-440e-ab13-e33885eaeb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12fba505-2da9-4108-a22a-86f7ec816b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81799d71-38fc-4332-9f92-b9a442365ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36e200bc-e890-4324-8fc4-531b71a6f792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1f7389b-b8ef-48ff-b1db-aeb08233f26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 892ad554-db9b-445a-9e78-4833d6210932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e3f80c1-20f1-4f98-95b9-ea8cbe4b02d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31659c38-393a-4dc4-aeac-7d2be3084398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2c15df4-28ac-408d-9eb6-91f79dbc2d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c21727d8-acaa-45ed-b750-d3c027f4e5d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4f0f839-e9f0-4a16-81c5-7351cebabc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e24252d-64cc-4dc5-b337-244d6516d63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1182247-9c65-4555-8c15-c46e604ae7d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 982fc567-d7af-4e8a-bf53-2efe4ca5cecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0164740-06a4-4df3-b2db-2bb567726191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb8cf375-bbdd-4c16-ae28-d4a8be529840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34fb5721-b63c-4351-87d4-96f058257d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83625c9a-3a87-4b21-9870-435db93ff40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad76108f-d22b-4bad-96bd-407fcf18a15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41325e58-296e-404f-a739-34077839d83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3d3e9c3-ca89-4331-ba94-9dc471f6914b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 289d1fca-0f5f-4dec-8ddf-c060557746f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01abc864-c506-4d4e-960b-ba5964b47659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38c47bd2-3f4c-41c4-98b2-a76bfceb5d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deed759d-b7a9-41b8-bf7c-7441ca0a30b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ebe88cf-b88b-45b9-b0ba-f9195508cb91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 680caeab-1f7f-4ec8-8869-e65a0448d27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d02d599a-b1f9-4540-9f90-b9ab9e926446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a69e8e2a-d5e7-4273-8cbf-d0dd5dcf9fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b74406e-ee06-47db-97ea-026b76e6693f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 665021ac-7f06-4745-b662-b3b0df609d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29411359-b080-4cc6-b55a-c9e89c4f2113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62f61617-5d15-4b7b-815d-b694d8066f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f3b4552-3075-4291-8dd4-0ea69f4f2755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52b0cd59-b466-4c8e-8fbc-fa225a3224de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9702a29-4eaf-486d-b1a1-d620f5425580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e69ec34c-9c53-4cee-be9d-8042d6279867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a32cf310-d4d7-461c-9b31-222d10931e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4c351b-fd06-4227-a985-06328bed399c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec62ac1-b4f6-470a-b0ba-e2e7f94a79b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d466c04-0792-4706-8115-1f9a22d953c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1e83038-cc1b-430a-94f0-2038c7fd0f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581ba195-7c9a-405f-a76e-08d666d5b38a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcb9d88a-5837-4c17-a449-06a0fc33d556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce7a4f1-a987-4268-81f9-56f0261c7dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee6d90b-ce22-4114-96e3-452f4d526312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3226a402-0c1e-4e05-8d8c-cbe810fc7581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e748a53e-20e5-4f48-8521-51b0c45110c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cce90dea-8087-4172-9659-fb3e4e84c0ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6b4c771-09b3-4a8c-bbd0-83a60fb21b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb099833-74ab-4b3d-afa1-b6764e40e3f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74417219-a850-4cab-a4c9-9a202ef38dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38866efa-9de7-42ce-bbaf-528a5a8b7c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b342bbe-91fd-4b9f-8f12-b1c3fcfe75c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d27634ae-d8a2-42e7-a00e-4248006a82f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96dd01f4-dfa5-4736-ba79-5f52e30eea54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcdbe546-440e-4d66-b8ac-40ec4fac13b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3ac45f-0cf3-4570-8784-922f16e55c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df6f77f-cff9-4aae-85bc-e0ec460307a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5982dabd-0335-4df7-a461-469fb0b3068f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 338cb427-fe63-485f-bc80-1ca6fbf23b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e9ff4b2-6901-42c3-854c-41a84719339b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3762c566-658b-43d7-977f-8a37003468bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0324f92d-6d1c-4ebc-8157-2bb35fafd0ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f19da5d5-d8d5-4ca9-88f6-ba5edf52f7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76b17679-3879-474a-ad2c-28eec46cff7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb999be6-f5d7-4323-bf7d-41bbe63b3757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6869527-5111-4d3e-80ab-5af3ac804cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d46810-8400-46e7-9618-bfac5038a9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c838104-07ec-4a86-a3b7-a5307fc110e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5b65be-dd05-403f-a8be-05d95f5e1b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a77cc4c-4374-4214-b416-3ab1e1f4778f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 533435de-69d1-4c16-9d98-bc7952daa10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 735164ff-dd8d-4e68-9cc8-058ca4496fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee68090-b010-4cd8-abf4-c4867233c8ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b15493d-39d1-410f-90ba-cb33323e20cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd73a04-1ddb-4725-9792-2ba0fb58b3a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee96595a-bf2f-45f8-b636-40d3cfa1c836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29f6a6a9-7f75-4980-9f1c-d5b31516bb3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d629175-5def-45fb-b1af-82fe3fd912a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d115906-8067-4b40-ae2b-105bf443aa08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30961338-50ee-4448-810a-2c4c44fdca99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f22ad73-0d84-4976-a166-e1597bde2349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4ba278-1f53-4c76-bd06-4903cf3dbfdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbbb7318-4599-4213-89d0-ddef2cf34c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b52bb7ff-7663-4192-887d-f1c763eeff34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4fd2955-833e-4db9-8bda-1bcf61e8fde6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b4a2c64-30a6-4fcc-9376-e180da1f429b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f892f4c8-7fb1-4077-99c7-f778f7567ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 592c126f-0bb2-4e82-b39a-297c07803297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3224bfff-de8c-4ff4-97a8-60b80fa6887d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0da2933c-5152-41ba-9982-8a909a14314e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03791b8d-d37f-410a-8af4-4b688bdf29c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3989a80-e0fd-420a-8c2a-75e75fd67d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 015a8abf-ea65-4382-9e86-bdf0e90d30b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9619f748-dac9-48ea-a28a-5aa50b08794c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 126bd9cc-e957-4fce-b6b0-d1f405e01d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73302210-c363-4a54-a1ad-207f17adaa63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 954933df-d831-4a7c-842c-2554a2066bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65308c66-86ea-44ad-8cc6-72b75cf2a2be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6991aa28-cca9-4f4f-8bb1-e0f37f7a67cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f7a034-daf5-483e-8f49-b22684f209d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e57ab477-1bda-4ca6-979b-618b7e9f0c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50ad4143-7fc6-45eb-bd6b-8bfa1a7a4758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf0b78b7-ec3c-4ca4-a93d-63d32f134a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05168912-18cf-4a71-9951-5342bdb335da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e1f674e-8df8-4fe6-973a-01b4c966b877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02574a3-9aef-4c09-bf41-916b901cd66e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60053b0f-af92-4559-9fff-9a05669e96a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c23c2ed-3861-412d-ab5a-8fa2b51e81dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9d848f-e621-48d7-bf07-09bdf314e73e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a65e17f1-19f4-45eb-908f-a23ab50d02a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a60d187-79df-4047-a728-e7b96583481e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9203367-54ee-4245-8f2d-ca53c0260555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e58d909c-1d12-45f4-a425-69ae6fd8923d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12472dd6-9694-450f-93a8-24e70d0ada85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad8ac6a0-9a83-48f5-8b71-6b3554fad68e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72057211-14d7-4ea7-b5e5-3ceb020e328b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07957eb8-9b83-436b-b17e-35e18bf218ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459b7cb6-f40b-4321-be8e-09b3a7252a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3450d7eb-20e7-4104-8715-135a8cf31a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d21fd179-b90d-47b1-9353-bd582a81fef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c3b336c-d191-403d-b77e-4631834db4b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32381446-7fe2-4e72-8c3c-12f4fa669bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddfc9a9e-45c4-4331-bd90-fe49fdf81df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e74ed29f-8dd3-499b-95e4-09aedecbefa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca479d47-0ecd-4209-aa00-f4cfb524e5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d5d4b1e-41de-4008-9f64-8266986e552d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 761c5c47-979a-4e5c-8321-e7fa09648120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6e29388-8504-40b1-be71-4089a3bd8efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8382dd7-426d-45ce-a6c1-43e865ec6193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 435dca88-62b4-43a4-8b88-c385b6de2bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41b1c50-06f9-415d-83fe-9a446993c966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da372125-7e6f-4e63-a54e-a5a99036633e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d5e6a48-0244-40da-8c25-b3dc000cc933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dbac3a6-3b2e-4753-a8cb-afa72fb124f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd3b8bf4-6c0a-466a-bcdf-e94bc7ef94a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ea9648-bc84-4590-afd1-4aedeb3c7a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfb7a546-9674-41a8-9a62-ecee1746682b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 213a4045-db9a-42fd-9ab9-f8014aaf0760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c0c0b4b-da56-49ec-8881-33dadc14f149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e7b824e-df61-4d93-b9fe-65e55305fca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41a2d59-492e-41d1-aaeb-cd405dbabc92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d024b7ce-09e8-435f-9bde-f5a031c18802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c9443a-6085-4353-baa7-4e6226f9222c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 872fa394-8227-438f-89a9-fcdc68631916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd192822-4eaf-415d-a3ba-cd3724656033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a50ef499-41a9-490f-b2fa-877f34043ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb8c6a5a-2eaa-4c61-9268-6ff93aef34a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26228cbd-fede-48a8-86ec-bee597d2c069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bb76774-73ed-403f-9ca0-94d0b3096c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4bd612-681b-4180-b7f8-eb2f0d29f76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87a34fb9-2e83-4097-8c67-369056080383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b1eca2e-6227-47f4-857c-03054c0ba3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecb6d22a-a76d-4c3f-bb1e-e9841f34bcbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b11fd76-c34e-4577-8725-48863134db69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af893fc-47cd-479c-a756-cd5b3b648207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18284ace-19a7-4d45-80fd-1e8ba43ce010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dc62972-e0eb-4c66-a59c-603abf840a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffccbbac-a56c-42d0-802b-ff35d8f6ee1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb38bfc-b018-438e-99a4-4186305bfee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6dbdec-ec43-4382-846f-df5fb729067d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45725ad8-d221-4e56-9f43-7a2c381e9bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ff43c46-f5e4-4eb3-891a-d7b9a0b1357c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a7075ca-d669-47f0-bb89-91aad16de02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d11455-53fd-41f7-9cd8-8c3d9688f2da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cfe8665-9471-4188-9733-1d8d8672f7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea90918-6d55-4f59-8f56-7156c57ab9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e2de19-9b89-46df-838b-46f9b46cfb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef8001d-6e72-44ea-bb26-3619da8041cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e78a2db-e071-4a90-8849-873e4d2e8a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c271cf2-0cc4-4ae5-9707-fe1fd16c2eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af879689-85b5-4ac2-a8dc-6244182c88bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f2fbf5-32b3-4b93-8816-3b97acfb9164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf18c3a4-3930-44bc-8381-e82dfcaf8747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6775d26-8dcb-4ec8-b98a-939641d17972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7789113-3f78-43ef-b83e-b9a3d352e5b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81465c0e-cb46-4c6f-918f-e66075c5c1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f36742af-76e8-4486-a47e-538d5d30ee6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4fee6a0-7b9c-4df6-b592-dc08967bd1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49b0762a-fcf3-45bf-a227-e914d11d3fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e05252-60f5-49f3-a4af-f99fdd867519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476e203e-e6be-4a28-b191-2abb2ede23b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23b36e6-80fc-4935-afa4-bfdba9e10d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f7d5f8a-e963-48c1-b426-7e7fbfc84169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a4b1f7a-6967-4383-bc6a-2d0acc81a15d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5219875d-d74c-462c-b6e0-23b7cac25c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 483fdf08-046b-42df-a4ce-70d666387a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ff937f1-fd51-472a-a2da-3b81fb75cc07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddcfff53-96a5-4348-b817-ee009a73a9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d44c06b8-664c-4d33-874a-c4292f95d541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bfd0fe3-e717-4535-9f5f-ae7a289d2a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 219557bf-8668-4c5d-8cf3-91deb83a1c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e96a1495-810a-4bc3-82fa-5738b917e608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5b92c34-021b-42f2-86e0-6df128492bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a8c50c-53f2-431d-8429-6d0f181333d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 183bec6d-3312-4f26-bf09-897290eb7eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 942af1f7-93ba-4968-aaff-4993577818bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a73c652-b957-4f0a-9254-a6448dfe6769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a947fcc-606f-4ef8-9789-f2df57da169e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c078691-6b43-4686-a152-fd6e46bf6bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cba08255-fa38-497e-bbd1-0d858177c95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a2b89d9-658f-46e0-a401-02294d4381de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22e87fd9-4ace-41ab-ae0e-ba0c08e77005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c842d542-00d6-4e89-8a65-e3645884fb90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 992fe346-d0fc-4db0-9c4e-84d36ed30b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8d54896-d45b-4903-b36f-d251ae4accb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15c9b18f-1b14-45d7-ae34-a18aafcd5118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f90081a6-d002-4370-96b2-cc1a44c10cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ba0301c-4ba8-483e-b7ed-1ba76c2c7964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42170218-f19f-482e-abec-6796586eb339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48d068f8-26f8-4792-9757-013216bab26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af4d890-e83a-4494-85a6-6a8621ed8111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f59511-4218-4ed1-be60-4bb630a3c5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e125cbd6-df44-4009-adbc-4fb4bdce4aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7acdca90-6e5b-416d-afe6-9d846d73b45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fd1509f-8859-435b-9d35-895cb4875790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62413a27-15ec-49dd-8c95-392aa7633368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f48d2e59-6e45-452f-9fc3-16ca08bd46f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 823f960e-9021-45d3-b0f7-d4917aff887e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a318fbf-c7bf-477d-a273-90a6636ee5c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3566491-043b-4b14-9edc-3ae183815b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0247806-3b21-4a90-a05a-84387833df2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68cffc86-80e8-4aeb-b86e-a0fcfb913c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23859709-3cc2-47ef-b776-65a3c569202e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11ceec56-c43e-4e45-b0fc-1b5e7ecedf8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d70e6b-49b3-4c41-ac49-51fc9edfaf8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b45da98-8da2-4242-b291-b5b2e41fa2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfdfc8b0-3152-452b-8df9-61efaedf1c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17211e3e-f932-4b5b-9f99-90b794be4ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 669ab9ff-a3eb-4fc4-b5fe-dfa1fe0d1755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a792c25-ea96-4465-aee1-8e0d8ea4fb1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88231b59-3574-4eba-a970-c3d406e137f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff58cc6e-e7ff-46a6-9b7d-234bddfc1b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 805a44d8-260c-4532-8772-905dc17da18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c91f8fe2-b046-4b00-9700-120b713706f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9864e46-3c42-45aa-94d3-51349b89c2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d62a16-73c8-4539-bdf0-dff4284f6d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ab60aa-115f-494f-90ff-7bbe84ebc5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30d60c75-1b41-4ee4-8571-aa65e2284d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4df2815-3fda-4494-b02c-a0cc6279b5a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a71621-39af-46af-9d98-aea79334acb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40e6eaeb-8be4-409b-99d9-2764f3224682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b229cc-40bb-48d7-b96e-1ca02d5c9e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbfeef7c-efe7-4da8-aced-1e87d6e5fb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375fa0a0-fd89-46d7-95ca-5cc6a43d5c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84883072-89c1-4012-beec-cd70116b2eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a051eaa-2271-4659-917c-11f985783dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b69adfd7-9ff8-467a-8e7e-576d509065a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dee40196-8a95-4285-898a-925791c4501c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 166b8b14-9686-4207-be40-17afe08fe63c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db43fbe9-9577-4696-97a2-6cf84d956cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ffad26d-9b1a-4b9d-82c8-d5aa861dbd3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90db2beb-afb3-4861-9ed6-59cb8c40afe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0bb9e6b-39c1-4960-b13a-7d5ce3aac827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbeebe66-192a-465b-8639-f90407cc47ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e3fa312-1d32-4a6f-a267-a3c1d964ca67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 448f7859-614d-46af-bc59-b808bbc1454a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d860533-1c68-4a7f-9381-e6c33cbb7875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22cefd46-2255-4898-b261-ca956e5582a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35a123f6-d9ac-4d1f-9593-171ef9e08d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9e497d9-3cb8-4d84-9698-013321abbc37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a24eb1-d401-49ba-9bd8-45877b810cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04525e5c-8105-41f5-b5a5-7a58d29508b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92809473-75e4-40d3-9300-50c4527ed854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1517c0a7-64e2-47ff-b3f2-087fc66911db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 562b6bc2-3e00-4dcb-b83e-c30b333ebde3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27c8f20d-777e-41c3-916f-39d7abf76b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d5e4aad-e638-4490-800a-3ee8b9179243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddef3290-0f04-49bb-bb73-3063511fd20f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8342e246-414a-4a17-846e-d5f71e821749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c754ae31-6cf7-4d5f-80eb-3061fc1b57c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4d08930-51c5-4f86-92b0-acfefd4979f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4bc04d4-cf65-4525-bf9b-57ef1a367e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bbd251f-b3c9-428f-8eac-0a7c442dcf5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc908b67-b37d-4ffa-9f43-a3063dc01cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb463e71-c472-45f5-af7f-6023bb981140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85ee6e58-dbb1-41c2-9461-23873dc3b773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cfa167c-b796-4c34-a879-c92f56017567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1318d91-d402-48a6-8313-263a939314d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c614c4b6-6dd6-4cf0-9e79-0cbfa11a1191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a3e1a5d-16f1-403f-b4b0-a8d17c83971a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29c5f198-94ce-43a2-92a4-6001c672afd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de5a1e55-50b4-4a2d-b4dc-912c53ab79e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76a0b16a-ddaa-4091-b5bb-d91dbabf1215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5909b976-7ce6-4975-9386-c2524d7b7f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d8a364-08f1-47c5-b96e-40533c5367e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bee3c54-3fc9-4d13-9a72-95da3a869670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4fbeea4-9a88-4c34-932c-eb9f3a0c38c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ce305cb-149a-4e22-85ca-44b2e74a9386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 580044ab-67ad-4e80-86f9-2365292295f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed7be50-5a97-4414-89db-ac7693ab5eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcb305c5-37e2-46f4-a4ed-39177a01387c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f869bb3-dda0-4141-8254-079bda229d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f03a0618-e597-4d1e-9caf-12eb60e39077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd1faf7d-8d55-4c44-ad26-3418675dd189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54dac6e7-405d-42bd-95f1-2187d6ee16d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 961ca516-4a33-4961-88bb-0c82cb80ab40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abcd2eac-693d-4074-a462-40da51ac3550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10e4e104-68b2-4b50-b689-3d84c004372f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93025903-bb35-4456-a8d4-99c96b004c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3f39e18-0c51-4875-968f-2c17e7a38b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d75b06ca-945f-4026-a7a0-e7412f23f7fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54f8cca2-d17d-41ef-b697-d7b93c607d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fc05ae2-ec7f-4303-8400-c8ea4fa29f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68761896-863e-4194-bd44-d6535e63860a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d323004-0280-49f4-8106-707ecb6ed2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f84dd7-226c-47b1-8392-3b8e6769ef2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fffa8166-9a7d-472f-b843-af4bc7aa8e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8255f86-affd-439b-9566-bc5fbb6c0f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 290fbc98-e1bf-4133-9b03-926f1bdeae8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de4ac5d7-25cc-44b0-98c4-8b3597a27b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa25bdff-6987-49dd-85e2-f771ed55a5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c35f2f4-5aae-4cb2-880f-a11bbcdf91a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1a62063-d3df-4b9e-a8a8-c0197be9aa9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb6a0848-aa75-4769-874e-c68678b7258a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d087238-53d5-4460-977e-353311687c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ef6947d-b61d-4d44-822b-0bffc2f2ab54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ea2f518-3ea0-499d-94ac-cf98d5cbd59d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 674e7f5c-eae4-496f-940e-8b756170fa9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b827cb-f8d6-4828-a7fd-544efcfc5a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b146d4ac-7d47-45cc-a80d-113f62823677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2527ed7-28f0-4dbd-b350-c1ab49cd388b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ccfbe6-f8bd-4252-900b-0a1a9483907f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a63d159-fb13-4b47-95ae-70eeba6f0fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91822ff4-172f-42c0-a13c-7f5cbde1359b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 932a7c28-3ab4-44bc-b46b-e5ce846cd879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db97ebe1-a6cc-49ed-89a5-4873b281a101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b025ddfe-e7ca-4949-bbca-a4845c776239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b612a7a1-f0b0-4789-8ccc-b5670c3b770a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a5eb89-09cb-4e28-a0ee-69e38a93fc77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0006b55-4f93-414c-b0a8-34d77fced344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6b57bd-535c-4e18-ba41-7233977146cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b9a6a60-a530-4417-a6d1-57a351ee7530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b39532-64d1-4668-b23b-2251bcd98c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6206f0f-d18b-4961-9a35-0370fa94ecc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a61a6de-bec8-4222-b8ba-70d054dcd645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1339c89a-9cc9-4c81-84f2-cf655499d748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a88e7e8-56d2-4d83-8510-6843381398eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f04d4db0-d137-442f-b93a-252e5849453a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d0b65c1-99e5-4c47-b6ab-beda92222b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16eb4049-9a17-419a-af34-a04891b7c0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab1bf674-0a36-48c2-9406-9df3c9634b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 278451d3-6b65-4846-88c0-80b906c8dadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 802d0da7-1695-4096-b77f-d051e776e46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 995dcadf-f7e7-4239-8c68-9ccc5a244123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5050e8ec-eb71-4295-855c-dcc2ed54f566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c66ca60f-848a-418f-885f-efe7a9cebb06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ffe630f-0606-4347-8fb7-91e74c030b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2193b25-9d45-445b-8ecf-771bed224d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a23f34-6f98-4a57-8d18-dfbb4253ae52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a373abeb-7311-4e5a-8650-941b1fb11ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 364555f1-fdcc-4f43-a74c-73580d472842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36b50d81-b452-4848-b75c-b8fbb85a9575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33620335-de5a-41b6-8d8d-095413592f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d100f5fb-e017-4185-bfc8-eb98b485a551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a8819da-825f-4320-9509-329cd5886d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42af4f80-2ff3-49f5-bc40-9023113d2452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7259cfd3-542f-43ad-b8d1-541d8ca84e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4539ee4-1662-4363-b157-2962fe150121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ce99f1-fd0e-4be5-af8e-c4f964508877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5854e00d-da44-4358-bb61-93c925919ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5804d318-acd0-4093-a370-364521dd87da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66948097-bb66-4343-a2be-e154f890b2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fb57ffc-ba54-4ccb-a36f-df389a6c7d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aacd9128-39bd-44e5-9c5d-1440735896ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 375ca8e0-ac1e-4b1c-883b-7f13a3367022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e3f2fb5-5947-4665-9bb7-38755d29140e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d695d72-6f09-4213-b7a1-066aa0edd6cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3ffb96e-27c0-4bcc-b305-307d0bdf6baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42051d7c-17a4-47a1-b184-f60621c7e488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e35e96e4-471c-4be3-b080-3cf75db2bee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad6a949e-2143-4268-b19e-b816cc960fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d7905f-7a75-4aa4-9865-fc217ee9a3a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14b88bfc-0824-498d-ab43-ebe3a09c0086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb94e50a-a762-4ade-9384-a4972b9f6cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 016c6278-131b-4049-8f91-7f5f47aa7a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82035342-5819-4260-8412-5e80989df27f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c98886-8f96-44a7-b228-e367714cb27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad7b77b-d1cd-43fa-84f8-ebefedae99f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dc8dfd0-dc0b-4e9d-b4b8-ce8e06a35468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acfd5ae8-da7b-496b-a7f8-e8342c4aa823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c446ac-e758-4acc-b8fa-4f8c52d8794f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e176d2d-30b2-4e91-847b-53600eb4ff6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd786cdd-12c4-464e-b02f-59d265fc2266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cca4d6b-27d5-4466-8adf-deadf0805413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d286e0a-bc34-4a33-b9d5-1daacf3a1442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99db0e06-40b5-4a85-9e89-b99151bb2e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af904577-fcd3-4365-9749-c1d5fea042ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 676cba62-ca9e-43e6-8227-20f5397b0b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13982c17-aaf9-4c2c-bd85-f02666d3ddf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c650b48d-3ad1-4ee2-bea0-81b06ef0efbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3b0347f-7af7-4e1a-8269-75a2d2b59ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9972d50-b4b8-4005-a103-3ffef989af68
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_13
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_13/test_labels.txt

📊 Raw data loaded:
   Train: X=(3174, 24), y=(3174,)
   Test:  X=(794, 24), y=(794,)

⚠️  Limiting training data: 3174 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  785 samples, 5 features
✅ Client client_13 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0862 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0842, val=0.0851 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0840, val=0.0845 (↓), lr=0.001000
   • Epoch   4/100: train=0.0838, val=0.0843, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0836, val=0.0843, patience=2/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0818, val=0.0868, patience=8/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 2 Summary - Client client_13
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0118
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0362
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2469, R²: 0.0065

============================================================
🔄 Round 3 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0834, val=0.0863 (↓), lr=0.000250
   • Epoch   2/100: train=0.0825, val=0.0862, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0821, val=0.0863, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0821, val=0.0863, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0820, val=0.0863, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0816, val=0.0864, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 3 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0136
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0004
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2471, R²: 0.0072

============================================================
🔄 Round 5 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0817 (↓), lr=0.000125
   • Epoch   2/100: train=0.0841, val=0.0815, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0841, val=0.0812, patience=2/15, lr=0.000125
   ✓ Epoch   4/100: train=0.0840, val=0.0811 (↓), lr=0.000125
   • Epoch   5/100: train=0.0839, val=0.0810, patience=1/15, lr=0.000125
   • Epoch  11/100: train=0.0836, val=0.0808, patience=7/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 5 Summary - Client client_13
   Epochs: 19/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0094
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0130
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0027

📊 Round 5 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

============================================================
🔄 Round 9 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0930 (↓), lr=0.000063
   • Epoch   2/100: train=0.0811, val=0.0929, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0810, val=0.0928, patience=2/15, lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   • Epoch   4/100: train=0.0808, val=0.0928, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0807, val=0.0927, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0805, val=0.0927, patience=10/15, lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 9 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0082
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0059
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2478, R²: 0.0025

============================================================
🔄 Round 15 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0853 (↓), lr=0.000016
   • Epoch   2/100: train=0.0833, val=0.0853, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0832, val=0.0853, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0831, val=0.0853, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0831, val=0.0853, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0830, val=0.0853, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 15 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0066
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0009
============================================================


============================================================
🔄 Round 16 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0896 (↓), lr=0.000004
   • Epoch   2/100: train=0.0823, val=0.0896, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0823, val=0.0896, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0823, val=0.0896, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0822, val=0.0896, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0822, val=0.0895, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 16 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0049
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0091
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

📊 Round 16 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

📊 Round 16 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 21 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 21 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0062
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0048
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 24 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 24 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0048
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0050
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 26 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 26 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0048
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0069
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 27 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 27 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0043
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0124
============================================================


============================================================
🔄 Round 28 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 28 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0070
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0063
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 29 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 29 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0053
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0059
============================================================


============================================================
🔄 Round 30 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 30 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0069
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0013
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 32 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 32 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0054
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0057
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0029

============================================================
🔄 Round 33 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 33 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0057
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0063
============================================================


============================================================
🔄 Round 34 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 34 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0057
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0054
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 36 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 36 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0046
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0106
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 40 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 40 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0065
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0036
============================================================


============================================================
🔄 Round 41 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 41 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0073
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0001
============================================================


============================================================
🔄 Round 42 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 42 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0078
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0074
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 43 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 43 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0072
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0182
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 45 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 45 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0058
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0062
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0029

============================================================
🔄 Round 50 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 50 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0056
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0072
============================================================


============================================================
🔄 Round 51 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 51 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0078
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0021
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 53 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 53 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0064
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0190
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 55 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 55 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0040
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0051
============================================================


============================================================
🔄 Round 56 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 56 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0031
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0131
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2478, R²: 0.0030

============================================================
🔄 Round 57 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 57 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0048
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0079
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 57 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 63 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 63 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0054
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0058
============================================================


============================================================
🔄 Round 65 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 65 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0038
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0079
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 65 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 69 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 69 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0029
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0100
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 70 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 70 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0050
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0040
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 75 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 75 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0074
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0004
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 77 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 77 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0050
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0089
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 79 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 79 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0036
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0113
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 79 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 83 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 83 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0052
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0088
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 85 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 85 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0052
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0037
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 85 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 85 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 90 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 90 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0087
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0043
============================================================


============================================================
🔄 Round 91 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 91 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0064
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0045
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 92 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 92 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0031
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0310
============================================================


============================================================
🔄 Round 95 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 95 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0075
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0011
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 95 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 95 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 102 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 102 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0057
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0023
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 104 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 104 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0044
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0046
============================================================


============================================================
🔄 Round 105 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 105 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0053
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0082
============================================================


============================================================
🔄 Round 107 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 107 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0068
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0032
============================================================


============================================================
🔄 Round 108 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 108 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0058
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0063
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 109 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 109 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0066
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0031
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 110 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 110 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0037
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0009
============================================================


============================================================
🔄 Round 111 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 111 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0083
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0045
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 111 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 115 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 115 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0062
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0003
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 115 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 117 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 117 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0056
   Val:   Loss=0.0979, RMSE=0.3130, R²=-0.0008
============================================================


============================================================
🔄 Round 118 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 118 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0050
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0101
============================================================


============================================================
🔄 Round 119 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 119 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0057
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0065
============================================================


============================================================
🔄 Round 120 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 120 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0063
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0043
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 121 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 121 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0060
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0048
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0029

============================================================
🔄 Round 122 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 122 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0062
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0030
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 122 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 122 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 128 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 128 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0071
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0019
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 130 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 130 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0059
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0068
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 131 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 131 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0060
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0023
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 138 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 138 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0056
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0044
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 145 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 145 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0061
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0078
============================================================


============================================================
🔄 Round 146 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 146 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0052
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0065
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

============================================================
🔄 Round 147 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 147 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0061
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0086
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0030

📊 Round 147 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

============================================================
🔄 Round 154 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 154 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0058
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0074
============================================================


============================================================
🔄 Round 155 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 155 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0052
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0076
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

============================================================
🔄 Round 156 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 156 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0076
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0005
============================================================


============================================================
🔄 Round 160 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 160 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0058
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0073
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

============================================================
🔄 Round 162 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 162 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0065
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0028
============================================================


============================================================
🔄 Round 164 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 164 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0055
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0012
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

============================================================
🔄 Round 167 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 167 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0053
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0047
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

============================================================
🔄 Round 169 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 169 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0059
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0065
============================================================


============================================================
🔄 Round 172 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 172 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0070
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0018
============================================================


============================================================
🔄 Round 174 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 174 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0047
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0089
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

============================================================
🔄 Round 175 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 175 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0078
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0001
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

📊 Round 175 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

============================================================
🔄 Round 179 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 179 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0073
   Val:   Loss=0.0970, RMSE=0.3115, R²=0.0028
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

============================================================
🔄 Round 180 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 180 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0061
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0008
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

📊 Round 180 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0031

📊 Round 180 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

============================================================
🔄 Round 183 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 183 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0062
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0062
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

============================================================
🔄 Round 186 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 186 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0067
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0044
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

============================================================
🔄 Round 190 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 190 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0052
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0076
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

============================================================
🔄 Round 194 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 194 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0054
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0041
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

📊 Round 194 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

============================================================
🔄 Round 196 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 196 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0064
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0046
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

📊 Round 196 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

📊 Round 196 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

📊 Round 196 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

============================================================
🔄 Round 202 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 202 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0078
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0232
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

📊 Round 202 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

📊 Round 202 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

📊 Round 202 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0032

============================================================
🔄 Round 207 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 207 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0063
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0014
============================================================


============================================================
🔄 Round 209 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 209 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0069
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0017
============================================================


============================================================
🔄 Round 212 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 212 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0037
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0028
============================================================


============================================================
🔄 Round 214 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 214 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0061
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0063
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0033

📊 Round 214 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0033

============================================================
🔄 Round 218 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 218 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0059
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0073
============================================================


============================================================
🔄 Round 220 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 220 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0073
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0028
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0033

============================================================
🔄 Round 223 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 223 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0061
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0030
============================================================


============================================================
🔄 Round 224 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 224 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0066
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0026
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0033

📊 Round 224 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0033

============================================================
🔄 Round 226 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 226 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0053
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0094
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0033

📊 Round 226 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0033

📊 Round 226 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0033

============================================================
🔄 Round 229 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 229 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0045
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0110
============================================================


============================================================
🔄 Round 230 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 230 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0067
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0055
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 233 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 233 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0068
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0046
============================================================


============================================================
🔄 Round 235 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 235 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0064
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0065
============================================================


============================================================
🔄 Round 236 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 236 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0073
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0019
============================================================


============================================================
🔄 Round 238 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 238 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0059
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0033
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 240 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 240 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0072
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0032
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 244 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 244 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0075
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0021
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 246 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 246 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0069
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0032
============================================================


============================================================
🔄 Round 247 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 247 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0073
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0024
============================================================


============================================================
🔄 Round 248 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 248 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0058
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0032
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

📊 Round 248 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 252 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 252 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0068
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0010
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 254 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 254 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0060
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0111
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

📊 Round 254 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 257 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 257 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0074
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0053
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

📊 Round 257 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 261 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 261 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0067
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0052
============================================================


============================================================
🔄 Round 263 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 263 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0075
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0021
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 265 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 265 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0082
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0230
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 266 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 266 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0042
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0077
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 270 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 270 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0056
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0291
============================================================


============================================================
🔄 Round 271 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 271 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0062
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0067
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0033

📊 Round 271 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2477, R²: 0.0033

============================================================
🔄 Round 274 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 274 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0059
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0009
============================================================


============================================================
🔄 Round 275 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 275 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0055
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0032
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 279 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 279 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0071
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0037
============================================================


============================================================
🔄 Round 281 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 281 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0082
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0075
============================================================


============================================================
🔄 Round 283 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 283 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0054
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0103
============================================================


============================================================
🔄 Round 284 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 284 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0065
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0044
============================================================


============================================================
🔄 Round 285 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 285 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0045
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0150
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

============================================================
🔄 Round 287 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 287 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0071
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0047
============================================================


============================================================
🔄 Round 288 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 288 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0063
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0036
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

📊 Round 288 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

📊 Round 288 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

📊 Round 288 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

📊 Round 288 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

============================================================
🔄 Round 298 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 298 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0079
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0009
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

📊 Round 298 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

============================================================
🔄 Round 300 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 300 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0063
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0067
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

============================================================
🔄 Round 301 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 301 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0067
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0054
============================================================


============================================================
🔄 Round 302 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 302 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0051
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0042
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

============================================================
🔄 Round 303 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 303 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0045
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0044
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

============================================================
🔄 Round 304 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 304 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0057
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0078
============================================================


============================================================
🔄 Round 306 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 306 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0064
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0074
============================================================


============================================================
🔄 Round 308 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 308 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0072
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0027
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 319 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 319 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0057
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0102
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 321 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 321 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0057
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0100
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0034

============================================================
🔄 Round 323 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 323 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0066
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0065
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

============================================================
🔄 Round 325 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 325 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0059
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0016
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

📊 Round 325 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

============================================================
🔄 Round 330 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 330 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0065
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0075
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 331 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 331 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0077
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0013
============================================================


============================================================
🔄 Round 333 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 333 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0061
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0096
============================================================


============================================================
🔄 Round 335 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 335 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0064
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0004
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 335 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 337 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 337 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0073
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0060
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 340 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 340 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0074
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0042
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 340 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 342 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 342 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0065
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0031
============================================================


============================================================
🔄 Round 343 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 343 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0051
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0065
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 343 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 343 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 343 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 350 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 350 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0068
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0018
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 350 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 354 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 354 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0072
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0030
============================================================


============================================================
🔄 Round 355 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 355 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0068
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0047
============================================================


============================================================
🔄 Round 357 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 357 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0076
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0018
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 358 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 358 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0037
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0134
============================================================


============================================================
🔄 Round 360 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 360 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0068
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0016
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 360 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 367 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 367 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0073
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0045
============================================================


============================================================
🔄 Round 368 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 368 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0069
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0089
============================================================


============================================================
🔄 Round 369 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 369 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0069
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0063
============================================================


============================================================
🔄 Round 370 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 370 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0060
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0097
============================================================


============================================================
🔄 Round 371 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 371 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0090
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0026
============================================================


============================================================
🔄 Round 372 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 372 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0052
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0314
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 376 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 376 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0053
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0128
============================================================


============================================================
🔄 Round 377 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 377 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0045
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0081
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 377 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 381 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 381 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0067
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0059
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 381 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 383 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 383 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0063
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0028
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 386 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 386 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0081
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0121
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 391 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 391 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0068
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0023
============================================================


============================================================
🔄 Round 392 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 392 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0070
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0059
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 392 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 392 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 396 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 396 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0059
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0101
============================================================


============================================================
🔄 Round 397 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 397 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0058
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0017
============================================================


============================================================
🔄 Round 398 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 398 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0062
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0051
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

📊 Round 398 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 402 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 402 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0083
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0100
============================================================


============================================================
🔄 Round 403 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 403 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0071
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0019
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 404 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 404 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0044
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0054
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

============================================================
🔄 Round 406 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 406 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0060
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0103
============================================================


============================================================
🔄 Round 407 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 407 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0061
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0102
============================================================


============================================================
🔄 Round 408 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 408 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0073
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0027
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

📊 Round 408 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

============================================================
🔄 Round 410 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 410 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0069
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0246
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 412 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 412 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0063
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0049
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

📊 Round 412 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

📊 Round 412 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0035

============================================================
🔄 Round 417 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 417 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0064
   Val:   Loss=0.0918, RMSE=0.3031, R²=-0.0000
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 419 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 419 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0083
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0003
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2477, R²: 0.0036

============================================================
🔄 Round 421 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 421 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0061
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0092
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

📊 Round 421 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 425 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 425 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0065
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0048
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 426 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 426 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0045
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0169
============================================================


============================================================
🔄 Round 427 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 427 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0047
   Val:   Loss=0.0752, RMSE=0.2741, R²=-0.0137
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 429 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 429 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0072
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0037
============================================================


============================================================
🔄 Round 430 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 430 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0072
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0040
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

📊 Round 430 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 434 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 434 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0056
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0103
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

📊 Round 434 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 437 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 437 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0074
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0001
============================================================


============================================================
🔄 Round 438 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 438 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0084
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0088
============================================================


============================================================
🔄 Round 439 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 439 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0073
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0041
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

📊 Round 439 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

📊 Round 439 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 445 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 445 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0077
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0013
============================================================


============================================================
🔄 Round 447 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 447 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0084
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0008
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 450 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 450 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0052
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0135
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 451 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 451 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0059
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0005
============================================================


============================================================
🔄 Round 453 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 453 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0059
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0105
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

📊 Round 453 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0035

📊 Round 453 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0035

============================================================
🔄 Round 456 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 456 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0069
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0065
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0035

============================================================
🔄 Round 459 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 459 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0059
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0080
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0035

============================================================
🔄 Round 461 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 461 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0057
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0018
============================================================


============================================================
🔄 Round 462 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 462 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0073
   Val:   Loss=0.0918, RMSE=0.3031, R²=0.0013
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 465 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 465 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0070
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0090
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

📊 Round 465 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0035

============================================================
🔄 Round 468 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 468 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0045
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0036
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0035

============================================================
🔄 Round 469 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 469 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0052
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0132
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0035

============================================================
🔄 Round 472 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 472 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0069
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0064
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

📊 Round 472 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 477 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 477 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0087
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0066
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 479 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 479 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0048
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0098
============================================================


============================================================
🔄 Round 480 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 480 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0084
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0010
============================================================


============================================================
🔄 Round 482 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 482 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0073
   Val:   Loss=0.0950, RMSE=0.3082, R²=0.0047
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0036

============================================================
🔄 Round 487 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 487 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0059
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0090
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

============================================================
🔄 Round 488 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 488 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0067
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0064
============================================================


============================================================
🔄 Round 490 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 490 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0071
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0005
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

============================================================
🔄 Round 492 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 492 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0070
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0054
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

📊 Round 492 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

============================================================
🔄 Round 499 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 499 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0060
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0026
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

📊 Round 499 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

📊 Round 499 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

📊 Round 499 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

📊 Round 499 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

📊 Round 499 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

============================================================
🔄 Round 509 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 509 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0047
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0088
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

============================================================
🔄 Round 515 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 515 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0062
   Val:   Loss=0.0906, RMSE=0.3009, R²=0.0045
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

============================================================
🔄 Round 519 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 519 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0058
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0098
============================================================


============================================================
🔄 Round 520 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 520 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0064
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0096
============================================================


============================================================
🔄 Round 521 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 521 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0055
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0238
============================================================


============================================================
🔄 Round 522 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 522 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0058
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0042
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

📊 Round 522 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0037

============================================================
🔄 Round 526 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 526 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0063
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0042
============================================================


============================================================
🔄 Round 528 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 528 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0075
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0005
============================================================


============================================================
🔄 Round 529 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 529 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0076
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0005
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0038

📊 Round 529 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0038

============================================================
🔄 Round 534 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 534 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0069
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0068
============================================================


============================================================
🔄 Round 535 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 535 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0036
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0080
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0038

📊 Round 535 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0038

============================================================
🔄 Round 539 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 539 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0085
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0094
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0038

============================================================
🔄 Round 540 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 540 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0053
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0044
============================================================


============================================================
🔄 Round 541 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 541 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0074
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0059
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 541 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 541 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 544 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 544 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0064
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0072
============================================================


============================================================
🔄 Round 545 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 545 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0082
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0022
============================================================


============================================================
🔄 Round 546 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 546 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0044
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0115
============================================================


============================================================
🔄 Round 548 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 548 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0062
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0074
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 549 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 549 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0069
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0076
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 549 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 551 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 551 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0079
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0016
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 551 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 554 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 554 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0072
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0041
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 555 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 555 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0076
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0012
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 555 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 557 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 557 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0047
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0169
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 558 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 558 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0088
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0017
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 558 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 558 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 563 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 563 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0067
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0029
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 564 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 564 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0075
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0055
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 565 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 565 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0060
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0106
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 565 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 571 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 571 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0078
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0149
============================================================


============================================================
🔄 Round 572 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 572 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0057
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0061
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 573 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 573 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0065
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0015
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 573 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 575 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 575 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0062
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0056
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 575 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 583 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 583 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0057
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0127
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 584 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 584 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0084
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0183
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 586 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 586 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0081
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0007
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 588 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 588 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0067
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0087
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 588 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 591 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 591 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0064
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0088
============================================================


============================================================
🔄 Round 592 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 592 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0072
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0028
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 592 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 597 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 597 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0070
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0074
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 598 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 598 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0066
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0077
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 601 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 601 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0057
   Val:   Loss=0.0861, RMSE=0.2933, R²=0.0124
============================================================


============================================================
🔄 Round 603 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 603 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0066
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0094
============================================================


============================================================
🔄 Round 605 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 605 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0041
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0041
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 606 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 606 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0060
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0038
============================================================


============================================================
🔄 Round 608 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 608 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0075
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0054
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 609 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 609 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0050
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0147
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 615 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 615 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0092
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0007
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 616 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 616 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0082
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0056
============================================================


============================================================
🔄 Round 617 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 617 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0063
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0092
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 619 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 619 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0077
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0051
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 619 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 624 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 624 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0072
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0025
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 624 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 624 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 624 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 624 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 631 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 631 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0060
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0007
============================================================


============================================================
🔄 Round 632 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 632 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0077
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0022
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 632 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 632 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 632 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 632 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 632 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 632 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 632 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 642 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 642 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0079
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0037
============================================================


============================================================
🔄 Round 643 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 643 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0077
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0011
============================================================


============================================================
🔄 Round 644 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 644 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0081
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0026
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0038

============================================================
🔄 Round 645 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 645 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0081
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0029
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0038

============================================================
🔄 Round 647 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 647 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0063
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0003
============================================================


============================================================
🔄 Round 648 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 648 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0067
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0082
============================================================


============================================================
🔄 Round 649 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 649 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0074
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0023
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0038

📊 Round 649 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 653 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 653 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0072
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0034
============================================================


============================================================
🔄 Round 654 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 654 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0065
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0029
============================================================


📊 Round 654 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 654 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 656 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 656 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0090
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0025
============================================================


============================================================
🔄 Round 657 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 657 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0067
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0019
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 659 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 659 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0076
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0049
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 661 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 661 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0081
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0010
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 662 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 662 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0086
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0011
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 663 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 663 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0085
   Val:   Loss=0.0781, RMSE=0.2796, R²=0.0002
============================================================


============================================================
🔄 Round 664 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 664 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0062
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0073
============================================================


============================================================
🔄 Round 666 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 666 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0053
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0108
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 672 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 672 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0070
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0055
============================================================


============================================================
🔄 Round 673 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 673 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0064
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0075
============================================================


============================================================
🔄 Round 674 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 674 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0060
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0107
============================================================


============================================================
🔄 Round 675 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 675 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0072
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0004
============================================================


============================================================
🔄 Round 680 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 680 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0053
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0030
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 683 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 683 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0069
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0003
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 683 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 688 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 688 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0075
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0053
============================================================


============================================================
🔄 Round 690 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 690 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0071
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0073
============================================================


📊 Round 690 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 690 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 690 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 690 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 697 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 697 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0071
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0035
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 699 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 699 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0071
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0076
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 699 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 703 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 703 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0070
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0003
============================================================


============================================================
🔄 Round 707 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 707 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0063
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0100
============================================================


============================================================
🔄 Round 708 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 708 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0067
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0033
============================================================


============================================================
🔄 Round 711 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 711 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0064
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0035
============================================================


============================================================
🔄 Round 712 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 712 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0072
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0060
============================================================


============================================================
🔄 Round 713 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 713 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0072
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0023
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 715 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 715 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0078
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0032
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 715 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 717 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 717 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0070
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0077
============================================================


📊 Round 717 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 717 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 720 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 720 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0080
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0038
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 723 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 723 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0057
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0003
============================================================


📊 Round 723 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 725 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 725 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0070
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0067
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 726 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 726 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0084
   Val:   Loss=0.0960, RMSE=0.3098, R²=0.0029
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 727 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 727 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0062
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0096
============================================================


============================================================
🔄 Round 728 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 728 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0071
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0075
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 730 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 730 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0065
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0101
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 730 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 730 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 730 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 730 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 730 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 730 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 739 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 739 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0062
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0111
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 741 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 741 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0049
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0082
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 742 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 742 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0059
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0020
============================================================


============================================================
🔄 Round 745 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 745 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0070
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0080
============================================================


============================================================
🔄 Round 747 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 747 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0052
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0036
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 747 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 749 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 749 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0076
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0046
============================================================


============================================================
🔄 Round 750 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 750 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0084
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0004
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 750 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 750 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 750 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 760 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 760 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0077
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0025
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 760 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 760 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 760 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 760 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 771 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 771 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0075
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0030
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

📊 Round 771 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0040

============================================================
🔄 Round 775 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 775 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0061
   Val:   Loss=0.0950, RMSE=0.3082, R²=0.0018
============================================================


============================================================
🔄 Round 778 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 778 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0086
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0016
============================================================


============================================================
🔄 Round 779 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 779 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0074
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0051
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 782 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 782 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0077
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0109
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 784 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 784 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0074
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0033
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 786 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 786 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0036
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0093
============================================================


============================================================
🔄 Round 787 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 787 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0058
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0010
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 789 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 789 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0068
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0065
============================================================


📊 Round 789 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 792 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 792 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0069
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0069
============================================================


📊 Round 792 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 795 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 795 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0095
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0138
============================================================


📊 Round 795 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 797 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 797 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0071
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0076
============================================================


📊 Round 797 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 803 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 803 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0064
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0091
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

📊 Round 803 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2476, R²: 0.0039

============================================================
🔄 Round 808 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 808 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0077
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0021
============================================================


❌ Client client_13 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>
