[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af52949d-e0de-41bc-8a4b-0fc98bb06125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a351ea38-a0fd-46cf-a9de-e78c6cd33c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 699a84ab-fe6a-4597-a6ae-b5da12b4e3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f644041d-7a32-4c5f-94ac-ff884bc74503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3e72e66-3013-4077-ac93-0e7010d6c2e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d062b2b0-8f8c-4d5b-a8c1-b71b2bd94eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c3819a-cbed-48cf-b336-0560db63828d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09e210d1-91a3-4767-adba-a24257e129ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab08688f-3738-4a51-8554-676daafb18e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaddfb17-9ca1-4421-8f4d-b2e8bb3d5409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a135705-97a4-4ffb-933f-558c3e13b777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1dc40da-c493-4520-b0fa-3e69b25e2309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ad57ff-1bce-47c8-b319-d35cc237a057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d009965a-cf68-47b3-b2d9-97287b6c4b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f19c7e-4ab1-434d-9a95-41a69dd9e2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b7af0cb-771f-442c-acc7-7011040ba2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f924ac8-1da4-47c0-afe4-dec994ad9069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e745a9b-ad12-4552-a1cf-270425a7f774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4098d7cd-8315-4c6c-8132-d37235ffb243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dbe9503-3eb5-4ed3-bf4a-5f469af86e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d6b33e0-8cb4-414f-804e-bce6d9104b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54c99b9f-aff6-48af-9e74-78c39ab4e4b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 100d9e78-d216-47be-95b7-8dec6b1e3221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a5bcb0-81b2-48f5-826c-3f095976c66a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fe78124-c021-4544-9080-3214d59a8525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0517b045-ca6a-4430-9c36-c6cbcc30a937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c584d091-b856-4482-954d-3a5684b1fcd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf7f330f-929f-4588-9ab2-91ba1d39fd21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d14f2d1-522d-4a9d-9d65-feaced4a1021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 843f331d-00a4-49a7-a251-c3fb3f24d228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaec8b1a-d57c-4f84-810c-b5065b253068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dc97ddf-8266-42ce-9f84-199b0a2172c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a74173c3-f4e8-4c9d-9f4f-038f9419e5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fdd507f-47db-459a-b79c-5a288630240e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bb909d-9a90-4ad7-adfe-b62124490001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb2c534-8040-458d-a449-1e2e3a2fd38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a302602e-b679-4f11-ae49-1229fcc8f06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72a9711c-9396-4ddf-99c2-86a9fd1504f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3271048-8dfd-4949-80f7-d2ea6f32e94c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63209988-a08d-4ecd-9e74-3b7c5bb1a8e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a68885c7-0f0e-4898-ad5d-962d58bbfff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7a25f1e-8373-441d-81dc-2d4a6c726bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c5f92e-0656-4ea9-b0ad-41d9cc50008d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f4fdaa-baec-4fdb-974c-e22032d0c422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 585a5a87-57c5-4505-baec-a58ea81bab85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abf25e57-473a-499c-8a55-5894eb46e4a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7631293-930f-4e12-94af-66dfa1f8897b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d493ba1-7577-4f85-9168-e15e7f9889d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e48c3ede-b34d-4bc3-8c40-35978ffe83db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182fa930-e147-4fbb-871b-f66ec09fdda5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f82192e-0d96-452d-90f7-2ec83669eb24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be33cc01-8741-4534-8452-54bc2b7514b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d866abb5-99cb-4e90-a9e6-e30ba5146f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc23da8-a7d9-4671-af6a-c9d336401f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cce58e0-1455-4138-8ce8-db473855826d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3344f288-fa76-4f5b-b533-c5b6da31071c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77e6e58c-f41a-4849-b10e-c6195e8f1468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18136a5-3272-432b-a7f9-55411a3a1367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5e205bf-7f19-4d53-9a0e-0bc9e99ef935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8462f9b6-041a-4dfb-8fa0-11479c1c2fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2f4d4c-f526-4da8-8f0b-2fc6e10b7156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aaf412b-b1dc-4fa4-a5f6-1f5d5e7e79cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e50108be-d640-45aa-a453-a3d331d282a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5efb739c-25c8-45a6-af4b-599749429fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 157f5b17-7891-4bb3-8a75-02d2308be13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36bc5cb0-0731-42d0-9c55-40c81b8c8e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e7e646-39f6-4951-a5df-ec906586a978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9166478a-3565-4f25-a1e9-a7621decd022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d885d264-e6c0-4852-ac5d-557fc7c23af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd144c11-237d-43bc-9c76-0e8c740392b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 205b8d99-114c-417b-9557-1288320522f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c155f45-9465-4f74-b564-79382d738c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e2ec32b-83b3-4940-892f-6b61375faa69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 910d49f9-556c-4efd-861a-7653958034bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81d8c2a3-eb1b-4e2f-8387-8ce6975d5ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de3458a-8f3e-4ed9-96c2-03c94d8c76b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 110bfad3-f471-4147-9b27-da5eeb3c5fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26bebab-b96d-4409-af9a-3757823003c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f356bc-ee5e-49d4-95fb-678570dc46d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74418319-0e59-43fa-9814-b8c2b959b3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c12eeb23-4e7e-4c0e-bd86-da56aaad2954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae115256-c604-47f8-8728-933ef8bd72d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab8d0edb-4a7f-4b87-94bd-1e4ffa332df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5c2993c-e444-4b0d-ad92-87efa54f46b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff60fd0-d866-4a16-b943-2e2de634f12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5714b4d1-c18f-41e2-9e6d-09eb166f514c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a418d23-8681-4d02-a7f2-bdc6d6a833ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c9239c4-64a2-43a3-9e5d-f165bc910339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b0ba0b-453d-4e71-820e-10ebf7ac30f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d681ef3c-72cf-4c75-a288-1020af0ca3cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3057865e-601e-41c7-9c18-463688a349b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4d2ab2f-2047-4033-85fb-e2213826b7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa327076-804a-4194-acc1-9a59be074577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 923f81f4-1074-485c-8ffd-d1a8400ccc80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53806513-6a20-45ac-8894-13ba8abeba75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a07fd903-627d-45b1-a87f-cc505c09a13b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e7290a-1170-4244-92e6-c46e5cf1420f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7195be-f547-46e0-a99d-f1fbd720d3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cfc70b4-6589-4b46-b23e-80789c8520fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ea8f503-3803-4b6b-a3f3-224f584c7b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b7bf6eb-9b82-4aa5-82f3-4982a82c7928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cdcd563-013d-4024-bb65-6e8cb6165058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 391b0827-db60-45b2-b4aa-a853f12415d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed08cb9-f8c1-4dc6-9171-c2c84ab861a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b97a603-2fb8-469f-9d1b-15a06e8f3dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c158ebfd-9c6e-4982-9149-43d7c2247ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a257fdab-afb9-42db-9365-b807fffa3421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 565e3f3c-ee22-4aae-89b7-c7a0915686d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 129701cc-971f-43dc-862d-3907b450c3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3753327d-3e8f-4187-a577-f5d195da0851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0624b44d-11a0-48b4-8368-b4b0b45bef66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc0b24d1-7569-49a8-9636-29ae96b39d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a0e9e5a-adc0-43e3-8bab-2613ad7e5f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ddb8917-17e4-4e04-9341-eff1835524a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9570485-cbe4-4842-99df-d3c8d337e87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a80e69f-dc22-4569-b539-c55aade7a12c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22551a65-1a78-439f-8daf-97a2df7d811d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d54df086-b686-44e3-81d3-e9a08ea684d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bdb2afc-74ad-4e36-8dbd-2cd3e169611b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4d07540-52ff-4a97-8a91-9be9737448fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d93c51c4-7eab-4ab9-9135-0d2febc5d535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc6aa03-0277-49f3-b458-ebfbfdb53ac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e54f5f0-abcc-4e71-a898-2846e87119ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d303b733-b268-4108-b0a7-257f92da7ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2646a97-3732-4622-8253-2a258beb1952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e4a21ee-4325-463a-b4cd-aebd95926529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8d6af60-4fd2-4cc8-acfc-d23493766d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e7e1c8-b710-4dfb-a586-77d89856773b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 538f753e-b333-4474-b58d-c65510fb6da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b13ae849-7aee-4c18-aa0b-25c97266944f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff3efe2-2165-48cd-b041-c50e3a33eb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19827a9c-7aa7-480e-b8f2-58b203755fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f63a0fd1-b280-468e-ade9-b54a42815db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d8d6c7-b60b-4e2d-8fe3-9b5adef2f954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bc0c348-2d14-4d9e-ac48-392f3f7b349d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb83ec67-db78-4731-8c45-df29915297fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be8fb23c-345c-4bb1-a2d6-76c41201bc3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47bedf2f-e622-4a63-bb22-4ae797e16165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5ecb219-c435-444a-acf8-4c8dbbebc6e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c241455-d523-4ed8-9155-11c90fb78edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4706ff31-38d0-46f2-8df5-6ad619d09381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a32463b3-a9b8-4e66-a2c8-9e6ca915fce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1271fe5d-fa52-48fe-bcbb-2bf0e52b2dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a515f6e7-0f6f-4cb8-95ae-2017f716bb90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd101c9-2ae1-4e99-940d-e88f5897490d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07261f1-afd9-4ad4-ad0a-d1e13c02fedf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30d34a5e-7989-4fa8-8811-088bae59c8d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b27047b9-2d78-4390-845d-5b9c3a2cd97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50cb7424-aaad-446c-8fa1-f43fabccbe93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c564cd50-2a1f-4e33-9bff-a31c83786911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a77b6992-f719-49e4-ab2d-ab5243e456e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7904188-3747-4362-81f2-73995178413a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f40d9cc1-b444-4238-9a65-b6a5ebfb767c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95104939-be84-46db-8e4f-2e571ef15db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8571fde5-d99b-4954-a2e6-accb093d31ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1f8b743-5646-4a91-9eee-3dd8f6c071ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7704d61-8f1f-4212-8e28-9bd5c4a7b96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed23f40a-c449-42df-bed5-1264563c6408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b52efaba-932c-446d-b458-3925615c94b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 332291d1-911a-4f48-ab2a-b82e91fcbc23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c92d9c-3aad-4f20-ae63-2bd71e0b609e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edf90b5f-f3e4-47dc-a4a4-90ec124ae62e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3320c50b-767b-4c57-b594-c91311ff3fc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67c3cc2e-ee83-4fff-8754-fb5acae5eaa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80f09590-7d86-4be1-80e5-941eddc36bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98a251e-5841-4fb8-b06d-82dab0e8ebd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27579817-4a89-4dcf-93a3-b65640d98a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cc9d85d-23af-4ed0-b871-9440716710dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a23feba-5eaf-4672-9a75-22e28fd5cc30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1587b866-9b71-4877-a971-449c762892b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 162a705f-6e87-4cb1-a43e-31ad7e23d8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2c69a97-0629-4e0d-a308-ff211f399a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a2d2cc-b4c7-4277-9356-2459ddfdb9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 116f521c-2c22-4fd6-bca0-209d5967be58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cec7fbc-dba5-40f8-bed3-f064e5741020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a268b4a9-c1fc-4492-a0da-9b67613fd727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 671bd0d8-76dc-4ba9-9f86-bdab4a034884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 420ffa2b-be57-421e-9887-92d5d6f53d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f2fdd42-43af-493d-8d09-cc347ecc7c6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 244aea5a-78b9-40e4-bd28-ec745d8ea7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bca0d950-396c-41f5-be5a-5d5c583cdf4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d2886b-4486-4367-af89-4e865c5de8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a75e523c-e5bc-4c7c-9609-b2b4580cfdbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 424c31d4-5f6e-46eb-8c40-2b13e342adcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d4ccea4-4ad0-425b-8a6e-b8ac7dcc494d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dd7df4e-b0df-4fb4-8ee4-bd97c604381b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df800798-fc1f-4141-828f-33b17cd57e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ca8beb-62a7-484b-a720-4e2419559925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5752997-afbc-4729-a526-1961bd05ce74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe087612-f1a1-4bb0-8928-43e781d9a31b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfe27046-a3dd-4c52-9be6-8455e64bcf7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cceb62fc-392c-4b11-8254-e6381372fe51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ba2cbbe-d5e3-4a7a-8589-dbe0d8eec774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 989b843d-fa74-4b51-aee0-d1ff158134c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb37891-8531-431c-9f13-f3a89ffbd107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93cceb34-1fa8-4bd9-9c96-bbf7da9ce5e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ac3b20-c47a-477b-a169-df41e4a81cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e543c47d-8bfc-4ab8-b858-56f60198badb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a366ab78-bfed-4df4-bf23-09fcbc948198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0be99d9-e079-43a5-beb9-6458542f4c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 440aa62e-0bf9-40bb-a330-97cff349b09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0e8d92a-1530-4782-9a8e-102e478c8ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cccba7f-40ce-4d37-97e8-3a072e0beeab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba30cef0-17cf-45a5-8801-dd08bc62b81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eb7983a-a179-4364-9ef2-becc1e1bc8bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a55684ad-6aea-4101-9272-c4b2b4cda08e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07d16300-4f74-4230-8bfa-812723dae473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9343e8e2-cada-481b-9f38-0a03970d3c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19aff3f5-2887-4d64-aff3-4723acd8c7f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e5ad571-570a-4da3-aa5e-8bbfdfb4be0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1876db1-326c-44a1-8c46-82ec2bae6c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d4d8e3e-7f39-4001-a418-bc537fb81fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e60a4ea-a2ca-4fba-8004-bcf7bb9bb008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b95b8b1-f8a5-4706-9227-6be72a3c8acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdadbef5-2d63-4313-bd6a-157aef05d71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a19187e9-e963-4cf2-bc54-a9b65c7fe271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92615e3c-b0aa-4309-8599-914aed127800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ffa1d9e-fb87-4f9d-aa8b-234c59865d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7542468-059d-4a38-bbb5-c188ca4108fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df0c698c-e77e-4b80-ad41-b4e60019760a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ceba53-d4b2-4f25-9d2a-8fa9564e0498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6bc3ee5-55cf-4e91-88bd-8c99206afbc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e290389a-31f8-4812-affa-3935c28b96a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a66d79e-f516-4cce-b262-8e759ce00b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4420a40-ce09-4d99-9d45-69f00879ec00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48dd10be-d877-424d-8c65-c29ba879e3ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d6d9144-314e-4932-b9ad-5b29bb19c192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9baae2d-53ba-4e1f-9634-62083a7406a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e3158b5-d0a9-4ae6-80c8-2b510c869abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a75ca582-a40e-48af-94b0-8bf678595f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c3749d8-ccea-400d-945b-1fb26ef818d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6a24ea-53c1-4431-ab46-d3ecf64520f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3e6718-4b61-47bb-a198-618446a9bc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 504ba1c0-5d4e-4be7-8239-5dfa07506513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad03915f-27ab-43bc-9330-3374b4f03ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7effed39-5941-4020-806d-db13f40d001e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7593b0bf-f984-4e9f-87ec-a1b42b78f071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4d13c4a-4b46-4ce8-a595-0056ca3a9ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79b967bf-b107-4e92-a574-e97b57159b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b28940-b6d5-4e31-8a97-932e8c4496cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ef9173-641b-4e26-899b-969dd7c819b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aabb4484-08ce-4145-95d7-ba39b5350a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31fb1241-fd8b-40c7-9d83-4cb619c7ffb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b2ea4bf-04da-4d05-a384-0e2916a4810e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a28d8447-24f9-4345-bfb2-da1f5ae11e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00ecd9a7-9d12-482f-96ea-cf2d1a3e1494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cda8c68-a979-4ff5-93cc-aa7549ee8078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55257578-5061-47d1-afa7-57f60a2dfb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74e30508-043b-4fa8-b531-ac8055b2f41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5cec72a-f1f9-447d-9119-443fa9a87283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 642398bd-19b2-41e6-93fe-bb2b304f8ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcd34c63-3e1a-41d9-84c3-347976628975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 825d48af-e7c9-498e-863b-ed5a6d59dc02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e85f004-76bc-4d2c-b4c0-fb13d8a6582e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 355909c5-c37a-42a0-8cc7-552df7dc3af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0554974-9954-4eda-944f-a2218c311c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1723ee4c-72a0-4efb-8671-5b850e200bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf4302c6-3f17-41a2-81cd-5626f6dd5d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e4af9f-bfd6-4a22-ae74-33631b151cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19dbaae6-bd49-4cec-9b6d-6a2ee7f0fef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a67c9b06-02cf-4891-8efc-53420a469e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f307567-c317-4238-8c63-8a5ea062aa39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8769fd1a-d631-4220-ada9-e3ed11f5546f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43a07417-f6f5-4249-bf2a-87fd2f40cbc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fe4450b-1d34-4bde-b33b-89147fb27245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b7df65-6208-4dc7-beba-efcd31713636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e496017-5469-40ea-8758-a6e93a6df3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87c6f044-9d8f-4a67-8475-ea0068be126e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a758cc64-534c-49d7-b0d4-8b148d555e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cc6f9a3-07e1-4948-a4ab-fa2662496ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3038785-b087-4162-9fb3-81922d0a3ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec3296c6-4498-4347-bc85-d134c3fe9c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fb2f480-3c0f-401f-ad7f-6394f327fe5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3119cd52-97e1-4090-b5c4-067eeffe0e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c6a3f26-f930-4bfc-8de4-de42aa8cd5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b032b7a-54ff-4507-a86c-4bd7ba97e7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4bd33bc-1d25-4b71-8f9a-ee3386a2f261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6f6ed29-0965-4170-9fda-fbcf3fa0ae17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1abaa414-7092-49ac-b424-912d03fa7dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15cb1894-e1b2-4d18-bae5-0b06a478c343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f830a0-b177-4050-b2c0-37887ecf74d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 583302d8-bcbe-4952-9866-94ff95e54a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 959350c5-6c4b-45cb-91f5-ef22266687b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01aa6b30-c3d4-4026-9bc7-bd8d68be1ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45837639-d864-45d8-8a48-74ba91961c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9393ce1-b7d6-4774-84fd-8baae7529190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d5b0876-2e5b-4320-9ef2-18161990b09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dcf3ad3-8855-41d2-a163-2b1b755cff20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a51bda29-49e9-469a-8947-503a5922f29d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fa1b958-b74a-459d-af94-6bc9331ae0ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 071e65fd-395d-4a21-9f35-b9b2c8fc2976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 587c50bf-d080-40bc-9eb0-6eeb4aa747d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6374dcd-ec53-4521-8cd5-1eec0bdca51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0346efe-bc3d-44cb-a58e-568046c96ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d951eb57-d75a-495b-bbcb-325f2056f891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c0b9da7-b601-4a28-aeb1-a6558ac598b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ed03be3-ebcb-444d-9155-7368ded64761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dc2e218-5358-477e-811d-f58c2d1724c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5540bc89-516a-4bef-9cae-5c08db2e3d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a561fd-a48b-490c-b457-865d4f6d677f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f78f4cfc-a484-405d-85b7-7cf173e7436b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa7bec8a-f294-4847-9dff-172e7117af89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a733a7e-2548-44dd-8794-07f9cb69acc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b387d291-5cbe-459d-9f8d-5610fdf4543a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1003047a-5037-4e60-8102-5481447d6744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c03514f-d7e3-4732-917a-8d8a4ab73918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05829ef4-a545-4232-9f97-6f04efb395ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ffc5f95-0b9e-408b-a265-8c1e31abbd56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b27189-b01f-4083-903a-4a4b21187b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d8275ba-1285-430d-8d00-856fed95d522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56f96348-222f-4c9e-a108-9e589f36125d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c84dcd-96d7-457a-a03c-ee2476fbe9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a40dd978-8b17-4879-a4fe-cf98b92794ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d17130c3-160d-4fed-b4d7-53766e68f80e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66527635-9cb0-4587-ad33-ea9124de6666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f630708a-f3ab-4229-9324-035785087252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c812fb8-e755-4657-af4c-f2685ac78379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22509734-65c7-4453-b0a2-031cdb449608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d5b9bce-05f6-49cd-bf3a-dec7571ffe91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be08578-a532-41db-8657-ede831a77352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b124f8ab-3620-4aa1-bddb-236e194d9cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 685d0b0f-0787-412c-9d67-a35e479fcfb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 057b6ae6-ba5e-4fac-92a8-a0fb074e369d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a783ec3-836c-42f0-9f5c-67ec675d368c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f940c195-f1d9-4401-ab32-aadb08c56c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d89f3af8-402e-43ec-848c-2ac8e28006d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0803ed89-59b1-4d95-85e6-6065490d7234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d886e3c-9ca7-4557-a2b9-1202843e90a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07603271-fd27-4769-9138-57e03079745b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4242b4fd-7716-410a-9377-393e02859490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb62a32-036c-403d-90eb-a0519dde0022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d63acd-dccf-470e-b739-540face19efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f3f555c-29a0-4be2-abb6-e2db9fba92e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfac2c09-1a0f-426c-8292-df80fffddb6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 356f267d-f909-43d3-87a9-499a35bec945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e42a142-6a7e-449c-b27d-54cd1708154e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397f2095-cd85-4604-9530-2848e2171ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9392304c-3dd1-4c35-bac9-52ff2d517c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 904d602d-b334-47d9-9f8e-d59b020e5326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ffaacfc-7bdf-4654-8fbd-cad039741c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd461d4f-b630-4add-b6d0-21768b2d1f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe2f72ba-099e-42fd-9a58-e70834efbf4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1fcf5d4-cb85-4d34-ad4f-a8201e50c7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a7ffa90-beca-4a32-b341-a5f26621f1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 612ab5d2-65ad-44c9-96cc-5c581061ba6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb0db6e2-81ea-4cbb-892d-fb1eea62846a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b70694c2-cf4f-4cca-b914-0526832f18f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a25552de-b8c2-4b30-af58-090e757d0e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a34145d3-b0be-4388-b710-0bf11dc235b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f83bb6f-99e5-405a-ae4c-bc5d321fb936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2505311-8df0-4d8f-b78c-7504756add0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fed6db4-7b7b-4dc8-b158-e482a5c482a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff3de8a-6aa0-47ec-aaf6-34b447855a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8baa5785-c49e-4194-af21-a94ba5ba922f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bc4705d-61ef-4e92-9350-89d43d7baf3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd0c0850-b932-456c-823a-8e0b9de416e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bbfaeac-c469-4776-93a2-8d981ed6c73c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a65d8177-1c33-4fda-b3b4-315ce42f5b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8875d84-edfa-4f97-9f07-91b26c5dd0c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c63a528-2793-4b36-9677-785eaf5abc52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b686c9a-a9ea-4221-8ee9-2493f256af5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6811a0df-1a24-462f-a6c1-b6ada92932a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e75fc6a7-5d1f-4b2a-808e-3f46ed9a504d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83d2b09b-eb46-46a8-b596-aa8e53f1e13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f934f56d-852f-48b5-955c-8a33fc079ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 651ca6e9-7756-427e-9cad-34557f45c172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93618433-daa7-4980-bde9-0e9650410866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2baca98-9993-4de9-a60a-f7a063278bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4075c792-45b8-4738-940f-9a3e43ed8c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f867b379-0fa6-4429-bdde-6cfb5558d96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d990266b-c8c0-4f41-aaa6-c82d4506607c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7f741f-4319-4f62-a6b6-dd758a7a69f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e6759e5-d2a6-4493-bb8f-737f304acbf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aa59fc3-6302-4eb5-a477-867d2f82941c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48e7298f-6ed1-43fe-9ca1-85d14b0b364f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 011ec149-58f3-4690-b7b2-a715affb90c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97a96568-762a-4932-955c-23ec48cb8ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1171e74c-1a99-4755-a151-7630fb794a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d8dfa2c-392d-42a7-b6e4-9733365245a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5800411-a971-416b-8194-df9485134e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2a48599-9931-4457-a103-68927f878a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e13caf0-a345-48a0-811b-9b84d52b9a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13414501-083c-4817-9ee7-c534e6503a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 965bf90a-3f38-49aa-a447-ceb11568edf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad426e5e-3a28-4c1f-9697-580da2cb8fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d544df5-a2df-43f0-8cb3-4cdd14dd0303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 426ecc29-305d-4975-a674-716b44054177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5803af60-6308-447d-984d-f75dd92b02f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad2ad65e-4f45-4581-9996-46d76398b03e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe46213-364a-4e2b-aad1-92ff655c432d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0c9a270-ba78-4b84-b57d-9d998756821b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 161915ad-ef3c-44b1-ab4d-957d05d25983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10cdb95-826e-4e65-8ccf-0f22ddb040cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 858c9a61-8263-4d36-83a8-de6f5df0d9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c90c9444-c49f-4aaf-8dfc-1c063eeeedf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af16b048-ad6b-41b2-bf85-4b51b16e0732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15e92d35-d4f4-4a16-b0d7-5ec062da9251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff64db1-c5b4-4a68-8dd3-4602b2196d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0fc3712-7f1e-40eb-9aaa-205060231ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0aba6b6-e5f2-4253-925f-4ba60e82136b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ef1f90-cccf-4984-98da-29950c41adc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70028a36-262b-4dfd-9855-fd9cd8e899fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 433143f3-ad72-48bb-b21b-09e09f37c20b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ac7d86-33d1-4276-8e76-b5242a60fc80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d1ac462-c1d8-4629-9f4b-7fa1f89e02a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef3a5e26-4b1c-4ffc-8127-595251a47ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 383463e6-6510-467a-9332-a1351d657e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47641fce-50fd-4a32-b8fa-dbcde4a29d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c36b95d5-0c29-447e-9db7-dd9e9a59ca8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6091155-a7e8-48c1-8bf0-9af9031cc8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcc9b01f-acee-4cd4-9140-618f744ef7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 913be0c3-8c83-484c-baa6-bd4b6d0b8668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c044226-e859-45ae-83ce-e8e6695c20a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81a3cfd2-5ed2-4c25-ac4b-32f6a533c800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd5f1b7b-1386-4bf9-b2e3-80e41422991b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0d5b03e-f8d7-44c8-9dd4-35f8bd52868c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89e24007-044e-493b-8c6b-55cacc0d3de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c04f57f-3421-4594-94dc-51b2048080d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6728477-069f-4c8e-875d-3bc05325bbf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be9b98f0-1876-47fe-91b8-bd8f6df5cc7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ac2b75-78bf-404b-940e-a8efd9a66f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c80964-84c7-418a-94bb-22aae5b5307d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57e0e6c4-28ab-4966-82d6-65b64611b24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 251fc673-f364-45ff-81d2-6be4464e0df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d095f4-36cb-4388-a32a-8a79804a7ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cff3f2c-fb53-4e40-a234-6ec9f7256980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d366c92c-7496-4726-afff-f24f86b7eba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15075fc1-742a-4744-b2b8-f71f496048b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e948739-9fe4-412a-b64f-947aada07635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca0d96c5-7e4d-4af3-82b7-fb71f0fc5656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46ed283f-525d-422b-8758-8280f3974dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09907b90-2073-4851-bb75-339d16a8199c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92a837b3-d8b2-42ad-a883-d61c27ba7375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 986dae4a-fe97-4a00-b7a0-7f5ac20eee45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3dc46e-9a9e-46d6-aecf-3b587231b4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1787c5f-8927-4380-a5c1-4cfd5f5e3d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e743a26f-9066-44a7-8cd1-d736ab7a346c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bac55cd5-eab0-4f58-b682-f3867bbf0641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a18881d9-4850-4e9c-a180-f61c9839aa7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b26fa1c9-5b56-4811-919c-947fbaa554f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bec5fde-3302-4e4c-b360-3fc2d235daf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfe3b6fe-9848-4eaf-8434-302ebaa305f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be0ea708-de10-402e-91f7-29fd5f9a563f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 128c984b-9c42-498a-985a-8a95043b0bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2367e265-fdc2-46d5-905b-58d21a511d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dab69cb-9028-4974-9a99-a4df0ae58852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47e043f8-cc1e-4a1a-94ed-73e7920109cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e314769b-3b7a-4aef-8b57-8081f1b449ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1ccd98-e1a7-4922-a3a7-fb0727e6a36e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7da4f79d-461c-4594-ab0b-b888377703c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93f312df-d66d-44c1-ac64-baecccf1fef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f9cb5f0-6e04-463a-89aa-0add12ed6daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fbde7f8-c697-4ee0-b112-c55b9d434066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b036cf80-b16e-429b-a3c2-5df07081f929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c418afda-f541-4a3c-9c81-226dc3e2ddef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2cd66fd-2380-4aaf-8495-aa6e82407a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec92700-aa5f-45ea-918c-2fc888c7957e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b51431f6-ccb6-4262-9046-7b1a6be0aee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c21282e-576c-425a-86e7-c3a64917271e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4eb9f0c-5e3f-4601-90b4-b7be38a8be11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d64e53c8-8ade-45fc-8092-2ee4b519a4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e585677-609c-447a-b4a8-8060981e7172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ddd9482-5aa2-493c-82bf-d9887488ebac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd43d521-858f-4fd7-9a77-c7d7b865b80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f0fa764-04d4-474f-a973-e3dc9c846437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d17e55f-6d59-44a6-9d44-8f2d9289633c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 584471bc-8933-4821-a9e7-d4a8eafeaea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a320552-269a-4682-9ead-54353040c714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da7091c1-bcca-4e65-b8dd-461a519972e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc1bb6c-5838-43df-894c-ae7772554615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 811a9ee1-e8a2-45c9-9788-3089165e587c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82520f6b-5aae-4a35-bb32-f113fe77147f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 055c3baf-8776-4517-8988-75abfca9de5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fbbd198-8afe-40e3-8daa-a3478a046343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8f2e7f-58df-4067-a24c-ef05069b1a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3792cb18-236a-488f-99a5-1d4a335f71b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f8057e5-adbb-498d-a1cb-803405a741d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d84835e-0deb-459e-82d8-492ae3ee302f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a365f0-3122-43b0-a2b1-ad6d2da8d4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message add08574-2e57-46b1-ae0a-6fee12b811d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de956f07-6205-4fb0-be4d-fd189432be94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e97575-c863-47f9-b814-cc52130349da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a32965d-f88a-4e6a-baba-f94414fb149a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb3915f-d3af-402d-bed9-8afa10751628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cd66cc1-0d8a-46e9-a2c4-062d5d5b07ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d875165a-1110-47bb-be56-4c2bac7a0695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22efe8ff-2c14-4a23-8245-e9caddcdcedc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40ce7565-6660-400d-a9cd-524597053e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c24e34d7-f435-4383-ae93-d77c123d9d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56dcd1de-67d6-4284-a058-806190cabae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdf3a0b-9dab-4d59-aeca-d4cbf08927da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff6d3ea8-169e-44ec-84cc-3f761cf09840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de94993-1eb1-4a63-8271-a34c850d0fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f528794-2aca-4d3a-9c8e-67a8d038c458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64856af3-f3ce-4259-997c-7150df1e9754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 091476c3-4c2f-48dd-ae54-0797f04297d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 366fb55d-ea7d-4c2e-971e-4f2448ea7a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d986712-1b25-4978-aed6-393de6026352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c09fc116-40d2-4ee6-87cc-3683bfec2c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8d9bc3e-46ef-4a55-856d-f5de016287cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 256bc965-ab01-4ffa-b70c-7252fefa6a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f84be88a-09b2-4e21-96ac-833fdf9a3a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f54403e3-06da-4b59-8a59-3bbf5edfd810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12dec81d-6f87-4484-9a22-bf8cfe904ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a60fc6a4-0d94-454d-bf26-013161411c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4c9796b-c9c0-4f9d-95a4-ca8972ceacbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bd1bbaf-b265-4f50-8ce1-183f7e680772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f13a5f60-4ab3-475e-9056-9fb0ab7d35ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc7f7d7-efda-4eb2-9b01-e1042363ff0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 307f24fe-dd4d-45bd-adac-d900656f7805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55182914-78a5-480a-854a-1c378a491786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b26a292f-3326-42bb-a60a-1c25dcf7415f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c307a258-4d09-42de-91cd-04c84cb52f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 671fc10f-c532-4cda-b7c8-38c93518c655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e82be6-440b-4088-ae63-9d531fac27e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 315902dd-277a-4331-b397-530bba2ade0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fa8cc5e-eb98-408d-99f0-04f36734afe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a21643a-7f6f-4388-8d05-7a8af543c391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d19e6d1c-6d96-408b-95b3-6e933981a7f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ea52b76-7cb5-4630-be46-f14af89cc7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adfa8064-5e1d-4ef7-9598-289dfcf7ba9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96025f1e-e1c5-4d41-a40b-6a06693e568a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b01dee-fbc8-4769-b369-49507fe2e35b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02a305d5-2f12-4501-b300-abf8ff327917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 251f21b9-9de5-41fd-94ac-34fb9786b696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91412131-d829-43b4-933c-72fab283932f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0bfb7d5-d97f-466f-a243-45f301f4b272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c6e529-0d32-4960-b6a1-21cc4f38a9fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb206596-7153-4fc6-8d5b-1004ea5f5224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22e616f0-a4e2-46c6-a11a-b0b31b84ac52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 325669ed-4440-403f-9424-2df2ecc5c9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ed0440-6d4a-42b4-adf0-76e29a453105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb7a32e7-a218-4756-b1ad-ad7f8bfe76a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfb55d19-4c00-4a37-8e09-72eb4347875c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e4cf0d-908b-4b8e-9555-c27e3cd148da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee21a8bd-db91-4506-bbdb-b3d7b2556512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faeec3f7-0d81-47f4-b1c1-e0e23a8329d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0296666-3dab-49a9-94e8-f19276ecef83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b25a64b-e60e-4118-ba2e-8222bd8d491c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3eff744-06fd-4ea5-bf5f-addbc3b8d23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef18c326-bd2c-4339-8c24-6bee951dba7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8535fcb9-fe16-4249-a5b1-48ba278a2d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3010438c-8da0-46f0-8048-412fecde4bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 969f46ee-171d-46a4-a3b5-92cfa29b68ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3187c03-be5c-425c-a141-c53d3c6ed0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4743b677-792e-46ba-a0e5-73c6316a0226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36fdf2a4-a166-4e37-a15d-61a537e6a59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f17dc121-f0c0-4c9d-af88-628d1b953457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c250758-2f84-43f2-982a-2997089d4235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17296166-0326-40fc-8fca-a69ede8ad695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55a22527-ec00-4f94-b8e3-94e154e7a908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b45c53f-3e39-4304-8158-19eb4bfa2cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4d35ad7-dbcc-49f7-9841-f823dc51530d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62167de5-b6ab-4b2f-915a-9f8d6e9ca3f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5cab3d5-ea63-457b-b441-2d0479f7126d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7fb304b-4d23-4d26-abb8-24e1792b2238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aebc06ad-fae1-4f50-8e72-80c365864e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1456134-1f04-4493-8a12-a56829735ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 685d7745-e9db-4d49-bf32-598106f897e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4570ff-30b9-4e7d-a0b5-0cb06f8bf785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0a18efd-97b8-4533-b55e-08f520a118c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c47ef736-b25f-4747-a4f4-71958b21f41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d7376a5-1f52-4ff6-998e-abd53f1331ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1636f026-8a9a-494a-9f09-c1797816540a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f6a6ebd-1c3b-4e8c-af22-a865ab259db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a07dfe1d-eaaa-44fb-bef9-234fd97ea6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd7c05ea-9d52-4ede-84e8-7552da8bb810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055acb23-c54b-4ec6-b364-5794f33ee24e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f485d3fc-a0cd-4386-bdcc-8ce15de2193d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e1e9bb-641e-4a65-9a8a-09357da9b4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bea6077-b5bd-4841-a137-a3d4046c4de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d467647e-403b-43ec-8504-176ee17acb26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 252c46db-a838-4fcc-b071-3a0ff26339b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e47a17b-19b8-403e-87b0-d47e7a47383f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 725fa152-ba30-47bd-83c5-2dbe1c5ee84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb93d84-012a-4861-ac9f-64cf286e21dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7bc19b9-17d9-45c4-90d9-f5faf22af0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aab74195-c2bb-4e30-92ee-fc6c1a55327e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6a254f8-cdfe-48f3-9536-26f54afd2994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cf00976-1f5b-4d2d-8f8d-f598d6b507fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca0638e3-e55c-4a61-9309-9725858071d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52b2b968-7893-4216-ad6b-f0673dfc1e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71cef0b6-df83-4c1d-96aa-bc0db2990d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a909d95b-7ccb-4ca0-8874-d1eb6887c835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df05291b-1780-416c-b541-910bf0cb105b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4123902-3a04-4ba1-b98a-25e24c20213b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58e76e45-7cbb-465a-9651-94884ca39259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48ff4211-5ed6-4ebe-bad6-a0525c343e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f283fac-77e8-43c5-816d-7dec0b844f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd50379a-1861-4e53-a3cc-d019e16a8c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b61dc93-55e1-4c55-89f4-dc2e750b30c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b231bdc-41ad-4195-9f82-ab96e82aa7d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18494e87-e8cf-461b-892c-96fe6a4001d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 741877c3-5a8b-497c-9d0a-4db27ff53979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f7e13b-cdf6-4210-afda-8329507be640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 779118d1-1c1c-48e6-bbba-e5bc7ee445ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4adc9e07-32b8-4b77-8c91-547b753a60c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9c4d3ee-0c87-41d4-8d67-fdee7d8428c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 971e65cc-734e-4f5a-8e9c-137104487383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f87bb53-0e6f-43b3-aee0-f68bdfff9328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68652123-8231-4b67-858a-ec7666884a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73d6e9be-eb00-4f3c-97f4-b741e320741e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6af7787-3115-4f7e-b24d-e66393ac771a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e0af615-6370-4964-a679-f158e76cab4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42a9be72-03df-4262-a2b1-fd593574dc7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb7af5fe-cef8-4dfd-b2ad-262422b50f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0814481b-3de2-479b-beb9-635ec851387f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b1a3b1-a61a-40b1-8892-f793be266301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f186d264-d526-4003-bd57-35ecaea8279e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a247eb0e-bb19-479f-9f5c-17ac26c68b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 911dd75d-7234-4143-933e-8138205da76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08cd6705-e56a-49f5-b6df-ffc68b745bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23ca731f-edee-45a0-9bd4-eee710de93de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c2ce23-9a6c-4897-9de2-cdc6f971cfac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b8ead2e-5ca0-4dd4-97e5-51b2e4a8865a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d173206e-a49c-4d47-a092-d2dc6c94470b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1df33520-d2b7-49e5-bcd5-8c2452ce7af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 181dcf85-85df-4827-acab-0150f4d84b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df63e4ed-9df1-43e3-8dc5-ba194af0d14d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc90e76a-959c-46a5-b060-6e9404cfb59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4fc3059-d884-4cd0-a0ce-79d4875711e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaef9f2d-6ce1-46eb-9007-458346ff50b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6513c9c-7c8d-4df7-82b2-aef9dd52342b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3bf8dea-5354-4f9e-ab20-530b43be2aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a12730d4-0da4-4923-b91e-272d7a8bddeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff077c2a-a800-45d0-9393-c1060cd7a0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6396cfd4-a0de-42c2-9702-65215baef26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bafe813-0eae-44a2-9c38-71a20be025c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e66fc850-2cce-4715-986c-0e9cf91a2801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f09f34-db5f-479a-bbaa-a8e97d0a6576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c547c9d-d75c-4c57-a7dc-dfcb92ff42a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d74c7d37-b228-42e6-98ba-7607aa30b535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72c4330-fbf0-4517-b6f9-bb986f87e081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75439d7c-3b49-45b1-ad82-a8ee9389fb29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2830351-1033-4c3a-a3de-0f1ba8cb60f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2359d3d3-c2f1-41b1-ac6a-777024170c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2349038b-759e-41d6-ba60-405457daba24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a01a994-f63a-4c26-b20d-0396c1b8d538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16c19c4c-ec3b-47bf-9408-e779543b0813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13a2d64f-f80d-4178-b2e5-d46990ff3413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7f75dbd-3fa0-4214-9e28-673dfe9fbb4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b510461b-b225-4b12-a358-cacd2d368743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063990f0-469f-41cb-912d-a970a94fca74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b85597c-2cc1-4996-bf75-eae5a3f57af3
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_14
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/test_labels.txt

📊 Raw data loaded:
   Train: X=(5733, 24), y=(5733,)
   Test:  X=(1434, 24), y=(1434,)

⚠️  Limiting training data: 5733 → 800 samples
⚠️  Limiting test data: 1434 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_14 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2487, R²: 0.0011

============================================================
🔄 Round 3 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0975 (↓), lr=0.001000
   • Epoch   2/100: train=0.0862, val=0.0978, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0868, val=0.0958 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0862, val=0.0952 (↓), lr=0.001000
   • Epoch   5/100: train=0.0854, val=0.0952, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0830, val=0.0952, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 3 Summary - Client client_14
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0190
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0363
============================================================


============================================================
🔄 Round 7 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0924 (↓), lr=0.000250
   • Epoch   2/100: train=0.0854, val=0.0919, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0853, val=0.0920, patience=2/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0852, val=0.0919 (↓), lr=0.000250
   • Epoch   5/100: train=0.0851, val=0.0918, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0847, val=0.0917, patience=7/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 7 Summary - Client client_14
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0067
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0024
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

📊 Round 7 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 12 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0850 (↓), lr=0.000250
   • Epoch   2/100: train=0.0868, val=0.0849, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0866, val=0.0851, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0865, val=0.0851, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0864, val=0.0852, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0857, val=0.0854, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 12 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0044
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0073
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0027

============================================================
🔄 Round 14 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0778 (↓), lr=0.000063
   • Epoch   2/100: train=0.0883, val=0.0778, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0883, val=0.0778, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0882, val=0.0778, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0882, val=0.0778, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0880, val=0.0777, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 14 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0037
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0099
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0027

📊 Round 14 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0027

📊 Round 14 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0027

============================================================
🔄 Round 18 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0871 (↓), lr=0.000063
   • Epoch   2/100: train=0.0858, val=0.0871, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0858, val=0.0871, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0857, val=0.0871, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0857, val=0.0871, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0856, val=0.0871, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 18 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0041
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0069
============================================================


============================================================
🔄 Round 20 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0918 (↓), lr=0.000016
   • Epoch   2/100: train=0.0848, val=0.0917, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0848, val=0.0917, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0848, val=0.0917, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0848, val=0.0917, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0848, val=0.0917, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 20 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0048
   Val:   Loss=0.0918, RMSE=0.3029, R²=0.0037
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0027

📊 Round 20 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0027

============================================================
🔄 Round 24 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0767 (↓), lr=0.000004
   • Epoch   2/100: train=0.0887, val=0.0767, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0886, val=0.0767, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0886, val=0.0767, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0886, val=0.0768, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0886, val=0.0768, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 24 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0028
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0037
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 29 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 29 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0061
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0149
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

📊 Round 29 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

📊 Round 29 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

📊 Round 29 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 34 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 34 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0042
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0050
============================================================


============================================================
🔄 Round 35 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 35 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0038
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0065
============================================================


============================================================
🔄 Round 37 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 37 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0056
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0065
============================================================


============================================================
🔄 Round 38 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 38 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0043
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0054
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 40 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 40 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0048
   Val:   Loss=0.0961, RMSE=0.3101, R²=0.0028
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 41 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 41 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0016
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0028
============================================================


============================================================
🔄 Round 42 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 42 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0054
   Val:   Loss=0.0996, RMSE=0.3156, R²=-0.0006
============================================================


============================================================
🔄 Round 43 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 43 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0054
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0008
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 45 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 45 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0045
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0047
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 48 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 48 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0044
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0037
============================================================


============================================================
🔄 Round 50 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 50 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0073
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0089
============================================================


============================================================
🔄 Round 52 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 52 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0037
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0115
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 53 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 53 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0024
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0115
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 55 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 55 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0014
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0121
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 58 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 58 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0042
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0069
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

📊 Round 58 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 60 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 60 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0035
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0008
============================================================


============================================================
🔄 Round 62 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 62 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0029
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0011
============================================================


============================================================
🔄 Round 63 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 63 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0043
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0054
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 64 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 64 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0022
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0132
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 66 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 66 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0023
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0013
============================================================


============================================================
🔄 Round 67 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 67 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0030
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0030
============================================================


============================================================
🔄 Round 69 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 69 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0026
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0124
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 72 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 72 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0046
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0037
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 73 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 73 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0039
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0065
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

============================================================
🔄 Round 78 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 78 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0057
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0020
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0028

📊 Round 78 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

📊 Round 78 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

📊 Round 78 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 85 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 85 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0055
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0014
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

📊 Round 85 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

📊 Round 85 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 89 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 89 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0011
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0194
============================================================


============================================================
🔄 Round 90 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 90 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0047
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0025
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

📊 Round 90 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 92 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 92 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0055
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0004
============================================================


============================================================
🔄 Round 96 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 96 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0049
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0004
============================================================


============================================================
🔄 Round 98 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 98 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0030
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0006
============================================================


============================================================
🔄 Round 100 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 100 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0042
   Val:   Loss=0.0933, RMSE=0.3055, R²=0.0016
============================================================


============================================================
🔄 Round 101 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 101 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0049
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0002
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

📊 Round 101 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 106 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 106 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0049
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0017
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 107 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 107 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0035
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0056
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 108 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 108 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0059
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0008
============================================================


============================================================
🔄 Round 110 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 110 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0061
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0177
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

📊 Round 110 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 115 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 115 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0016
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0010
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 117 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 117 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0020
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0138
============================================================


============================================================
🔄 Round 119 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 119 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0042
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0059
============================================================


============================================================
🔄 Round 120 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 120 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0047
   Val:   Loss=0.0947, RMSE=0.3078, R²=0.0039
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

📊 Round 120 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

📊 Round 120 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 126 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 126 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0044
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0050
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 127 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 127 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0046
   Val:   Loss=0.0960, RMSE=0.3098, R²=0.0039
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

📊 Round 127 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0029

============================================================
🔄 Round 133 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 133 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0057
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0129
============================================================


============================================================
🔄 Round 134 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 134 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2921, R²=0.0032
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0022
============================================================


============================================================
🔄 Round 135 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 135 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0051
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0017
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 136 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 136 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0037
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0078
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 137 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 137 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0036
   Val:   Loss=0.0940, RMSE=0.3065, R²=0.0079
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 139 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 139 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0046
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0059
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 140 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 140 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0045
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0134
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 140 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 140 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 140 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 144 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 144 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0054
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0010
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 146 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 146 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0056
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0014
============================================================


============================================================
🔄 Round 147 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 147 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0067
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0057
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 147 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 149 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 149 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0031
   Val:   Loss=0.0944, RMSE=0.3072, R²=0.0059
============================================================


============================================================
🔄 Round 150 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 150 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0083
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0133
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 152 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 152 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0048
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0006
============================================================


============================================================
🔄 Round 155 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 155 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0058
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0039
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 156 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 156 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0036
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0054
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 157 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 157 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0063
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0045
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 158 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 158 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0024
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0129
============================================================


============================================================
🔄 Round 159 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 159 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0053
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0085
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 162 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 162 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0058
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0004
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 163 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 163 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=0.0046
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0014
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 165 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 165 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0037
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0064
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 167 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 167 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0021
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0109
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 169 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 169 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0045
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0026
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 170 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 170 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0032
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0100
============================================================


============================================================
🔄 Round 172 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 172 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0056
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0015
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 174 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 174 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0053
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0027
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 174 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 179 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 179 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0060
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0068
============================================================


============================================================
🔄 Round 180 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 180 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0040
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0050
============================================================


============================================================
🔄 Round 181 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 181 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0045
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0046
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 182 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 182 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0019
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0078
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 182 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 182 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 185 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 185 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0050
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0040
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 186 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 186 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0047
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0008
============================================================


============================================================
🔄 Round 187 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 187 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0040
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0068
============================================================


============================================================
🔄 Round 189 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 189 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0051
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0004
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 189 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

============================================================
🔄 Round 191 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 191 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0033
   Val:   Loss=0.0952, RMSE=0.3086, R²=0.0063
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2484, R²: 0.0030

📊 Round 191 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

📊 Round 191 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

📊 Round 191 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

📊 Round 191 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

============================================================
🔄 Round 203 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 203 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0065
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0154
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

📊 Round 203 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

📊 Round 203 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

📊 Round 203 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

📊 Round 203 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

============================================================
🔄 Round 210 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 210 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0028
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0046
============================================================


============================================================
🔄 Round 211 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 211 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0038
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0067
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

============================================================
🔄 Round 216 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 216 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2966, R²=0.0048
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0002
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

📊 Round 216 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

============================================================
🔄 Round 218 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 218 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0031
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0499
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

============================================================
🔄 Round 220 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 220 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0047
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0013
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 222 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 222 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0042
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0035
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

============================================================
🔄 Round 223 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0994 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0994, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0994, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0994, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0994, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0994, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0994)

============================================================
📊 Round 223 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0031
   Val:   Loss=0.0994, RMSE=0.3153, R²=0.0085
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0030

============================================================
🔄 Round 224 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 224 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0055
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0079
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 226 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.1002 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.1002, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.1002, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.1002, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.1002, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1002)

============================================================
📊 Round 226 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0052
   Val:   Loss=0.1002, RMSE=0.3165, R²=-0.0001
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 228 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 228 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0048
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0005
============================================================


============================================================
🔄 Round 229 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 229 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0053
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0015
============================================================


============================================================
🔄 Round 230 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 230 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0028
   Val:   Loss=0.0942, RMSE=0.3070, R²=0.0072
============================================================


============================================================
🔄 Round 231 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 231 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0023
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0282
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 231 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 234 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 234 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0036
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0035
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 234 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 237 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 237 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0046
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0028
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 238 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 238 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=0.0038
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0059
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 238 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 240 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 240 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0034
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0000
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 243 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 243 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0082
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0138
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 243 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 249 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 249 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0043
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0049
============================================================


============================================================
🔄 Round 250 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 250 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0054
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0012
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 252 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 252 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0056
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0024
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 253 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 253 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0025
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0007
============================================================


============================================================
🔄 Round 255 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 255 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0015
   Val:   Loss=0.0972, RMSE=0.3117, R²=0.0093
============================================================


============================================================
🔄 Round 256 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 256 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=0.0051
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0146
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 256 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 260 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 260 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0045
   Val:   Loss=0.0909, RMSE=0.3016, R²=0.0038
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 262 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 262 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0034
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0057
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 262 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 262 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 262 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 262 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 262 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 270 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 270 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0036
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0069
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 270 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 270 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 270 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 276 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 276 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0056
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0020
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 277 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 277 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0050
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0038
============================================================


============================================================
🔄 Round 278 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 278 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0052
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0018
============================================================


============================================================
🔄 Round 279 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 279 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0046
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0042
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 282 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 282 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0035
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0066
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 283 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 283 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0050
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0226
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 287 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 287 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0041
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0057
============================================================


============================================================
🔄 Round 288 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 288 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0050
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0005
============================================================


============================================================
🔄 Round 289 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 289 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0049
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0001
============================================================


============================================================
🔄 Round 292 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 292 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0051
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0009
============================================================


============================================================
🔄 Round 294 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 294 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0042
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0030
============================================================


============================================================
🔄 Round 295 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 295 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0039
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0027
============================================================


============================================================
🔄 Round 296 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 296 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0056
   Val:   Loss=0.0847, RMSE=0.2909, R²=-0.0386
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 297 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 297 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0045
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0035
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 298 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 298 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0055
   Val:   Loss=0.0959, RMSE=0.3096, R²=-0.0059
============================================================


============================================================
🔄 Round 299 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 299 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0055
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0126
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 299 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 299 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 306 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 306 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2961, R²=0.0067
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0065
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 306 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 308 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 308 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0034
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0096
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 311 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 311 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0051
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0022
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

============================================================
🔄 Round 313 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 313 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0046
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0085
============================================================


============================================================
🔄 Round 314 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 314 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0044
   Val:   Loss=0.0954, RMSE=0.3089, R²=0.0009
============================================================


============================================================
🔄 Round 315 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 315 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0046
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0000
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 316 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 316 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0051
   Val:   Loss=0.0986, RMSE=0.3140, R²=-0.0149
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 316 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 319 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 319 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0027
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0047
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 320 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 320 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0005
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0023
============================================================


============================================================
🔄 Round 321 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 321 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0045
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0022
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 321 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0031

📊 Round 321 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0032

📊 Round 321 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 321 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 334 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 334 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0027
   Val:   Loss=0.0929, RMSE=0.3049, R²=0.0048
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 335 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 335 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=0.0014
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0118
============================================================


============================================================
🔄 Round 340 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 340 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0010
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0090
============================================================


============================================================
🔄 Round 341 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 341 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0031
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0010
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 341 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 345 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 345 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0061
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0025
============================================================


============================================================
🔄 Round 350 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 350 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0022
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0112
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 351 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 351 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0046
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0030
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 351 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 356 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 356 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0034
   Val:   Loss=0.0969, RMSE=0.3113, R²=0.0005
============================================================


============================================================
🔄 Round 357 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 357 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0059
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0011
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 362 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 362 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0008
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0176
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 362 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 366 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 366 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0032
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0077
============================================================


============================================================
🔄 Round 368 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 368 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0032
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0244
============================================================


============================================================
🔄 Round 369 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 369 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0059
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0027
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 373 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 373 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0046
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0022
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 374 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 374 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0064
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0033
============================================================


============================================================
🔄 Round 376 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 376 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0055
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0119
============================================================


============================================================
🔄 Round 377 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 377 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0031
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0056
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 377 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 381 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 381 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0049
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0027
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 381 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 384 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 384 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0046
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0013
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 384 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 384 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 384 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 393 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 393 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0049
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0025
============================================================


============================================================
🔄 Round 395 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 395 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0030
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0059
============================================================


============================================================
🔄 Round 396 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 396 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0048
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0057
============================================================


============================================================
🔄 Round 397 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 397 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0051
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0072
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 397 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 400 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 400 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0052
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0007
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 401 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 401 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0026
   Val:   Loss=0.0920, RMSE=0.3032, R²=0.0112
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 401 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 401 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 401 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 408 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 408 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0030
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0093
============================================================


============================================================
🔄 Round 409 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 409 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0033
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0007
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 411 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0997 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0997, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0997, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0998, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0997)

============================================================
📊 Round 411 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0040
   Val:   Loss=0.0997, RMSE=0.3158, R²=-0.0060
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 412 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 412 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0042
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0058
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 412 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 414 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 414 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0052
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0031
============================================================


============================================================
🔄 Round 419 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 419 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0044
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0044
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 422 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 422 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0045
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0036
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 422 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 422 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 422 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 429 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 429 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0052
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0012
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 432 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 432 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0020
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0131
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 433 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 433 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0038
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0068
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 435 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 435 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0033
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0024
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 436 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 436 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0019
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0148
============================================================


============================================================
🔄 Round 437 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 437 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0041
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0002
============================================================


============================================================
🔄 Round 438 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 438 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0054
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0031
============================================================


============================================================
🔄 Round 439 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 439 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0051
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0005
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 440 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 440 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0058
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0009
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

============================================================
🔄 Round 442 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 442 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=0.0023
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0125
============================================================


============================================================
🔄 Round 444 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 444 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0045
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0040
============================================================


============================================================
🔄 Round 447 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 447 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0043
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0046
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0032

📊 Round 447 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 449 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 449 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0063
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0074
============================================================


============================================================
🔄 Round 451 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 451 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0048
   Val:   Loss=0.0909, RMSE=0.3016, R²=0.0033
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 452 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 452 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0052
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0211
============================================================


============================================================
🔄 Round 454 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 454 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0054
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0060
============================================================


============================================================
🔄 Round 455 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 455 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0044
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0014
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 457 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 457 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0034
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0027
============================================================


============================================================
🔄 Round 458 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 458 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0018
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0151
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 458 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 458 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 462 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 462 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0037
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0052
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 462 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 465 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 465 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0033
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0030
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 468 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 468 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0029
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0135
============================================================


============================================================
🔄 Round 471 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 471 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0009
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0228
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 471 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 476 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 476 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0054
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0062
============================================================


============================================================
🔄 Round 477 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 477 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0041
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0053
============================================================


============================================================
🔄 Round 478 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 478 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0042
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0020
============================================================


============================================================
🔄 Round 481 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 481 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0036
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0004
============================================================


============================================================
🔄 Round 483 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 483 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0033
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0102
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 496 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 496 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2961, R²=0.0042
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0000
============================================================


============================================================
🔄 Round 497 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 497 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0031
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0097
============================================================


============================================================
🔄 Round 499 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 499 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0045
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0078
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 499 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 501 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 501 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0046
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0035
============================================================


============================================================
🔄 Round 502 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 502 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0045
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0041
============================================================


============================================================
🔄 Round 504 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 504 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0058
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0011
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 505 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 505 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0056
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0024
============================================================


============================================================
🔄 Round 506 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 506 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0069
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0107
============================================================


============================================================
🔄 Round 508 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 508 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0025
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0098
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 509 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 509 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0043
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0003
============================================================


============================================================
🔄 Round 510 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 510 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0044
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0007
============================================================


============================================================
🔄 Round 511 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 511 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0038
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0019
============================================================


============================================================
🔄 Round 512 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 512 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0044
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0002
============================================================


============================================================
🔄 Round 514 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 514 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0007
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0103
============================================================


============================================================
🔄 Round 516 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 516 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0042
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0055
============================================================


============================================================
🔄 Round 517 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 517 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0030
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0100
============================================================


============================================================
🔄 Round 518 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 518 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=0.0043
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0049
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 520 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 520 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0052
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0010
============================================================


============================================================
🔄 Round 521 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 521 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0018
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0150
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 521 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 521 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 521 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 526 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 526 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0049
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0068
============================================================


============================================================
🔄 Round 527 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 527 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0047
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0617
============================================================


============================================================
🔄 Round 528 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 528 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0024
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0032
============================================================


============================================================
🔄 Round 530 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 530 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0040
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0030
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 530 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 530 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 530 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 544 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 544 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0050
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0028
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 544 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 547 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 547 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0033
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0068
============================================================


============================================================
🔄 Round 548 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 548 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=0.0026
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0052
============================================================


============================================================
🔄 Round 549 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 549 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0055
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0150
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 549 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 549 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 553 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 553 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0031
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0091
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 553 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 553 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 561 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 561 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0044
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0025
============================================================


============================================================
🔄 Round 563 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 563 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0013
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.0099
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 568 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 568 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0016
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0465
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 570 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 570 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0068
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0071
============================================================


============================================================
🔄 Round 571 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 571 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0035
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0041
============================================================


============================================================
🔄 Round 572 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 572 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=0.0036
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0021
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 572 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 575 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 575 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0051
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0014
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 577 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 577 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0041
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0056
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 579 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 579 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0036
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0073
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 579 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

📊 Round 579 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 584 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 584 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0035
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0083
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 585 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 585 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0052
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0067
============================================================


============================================================
🔄 Round 587 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 587 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0031
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0093
============================================================


============================================================
🔄 Round 589 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 589 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0067
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0048
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 592 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 592 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0020
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0119
============================================================


============================================================
🔄 Round 594 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 594 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0019
   Val:   Loss=0.0900, RMSE=0.3001, R²=0.0135
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 595 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 595 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0059
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0020
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 596 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 596 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0035
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0077
============================================================


============================================================
🔄 Round 598 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 598 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0050
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0176
============================================================


============================================================
🔄 Round 599 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 599 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0045
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0024
============================================================


============================================================
🔄 Round 600 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 600 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0016
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0100
============================================================


============================================================
🔄 Round 601 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 601 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0041
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.0174
============================================================


============================================================
🔄 Round 602 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 602 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0055
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0013
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 606 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 606 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0046
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0025
============================================================


============================================================
🔄 Round 607 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 607 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0033
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0019
============================================================


============================================================
🔄 Round 608 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 608 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0052
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0065
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 611 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 611 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0059
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0073
============================================================


============================================================
🔄 Round 612 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 612 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0045
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0035
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 612 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 612 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 621 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 621 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0021
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0095
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 621 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 621 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 627 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 627 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0046
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0133
============================================================


============================================================
🔄 Round 628 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 628 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0040
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0017
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 628 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 628 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 628 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 628 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 634 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 634 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0055
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0034
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 635 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 635 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0050
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0007
============================================================


============================================================
🔄 Round 636 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 636 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0044
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0037
============================================================


============================================================
🔄 Round 637 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 637 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0038
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0047
============================================================


============================================================
🔄 Round 639 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 639 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0025
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0097
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 641 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 641 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0045
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0040
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 642 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 642 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0049
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0026
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 643 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 643 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0027
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0058
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 644 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 644 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0057
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0000
============================================================


============================================================
🔄 Round 645 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 645 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0047
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0027
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 647 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 647 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0020
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0095
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 647 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 647 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 652 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 652 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0041
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0056
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 653 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 653 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0029
   Val:   Loss=0.0959, RMSE=0.3096, R²=-0.0079
============================================================


============================================================
🔄 Round 655 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 655 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0018
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0146
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 655 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 655 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 655 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 661 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 661 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0022
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0049
============================================================


============================================================
🔄 Round 667 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 667 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0042
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0055
============================================================


============================================================
🔄 Round 668 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 668 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0043
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0010
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 670 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 670 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0032
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0059
============================================================


============================================================
🔄 Round 671 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 671 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0035
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0083
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 671 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 673 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 673 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0005
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0135
============================================================


============================================================
🔄 Round 674 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 674 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0046
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0024
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 677 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 677 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0062
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0207
============================================================


============================================================
🔄 Round 678 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 678 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0046
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0015
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 678 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 682 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 682 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0016
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0155
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 686 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 686 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0068
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0061
============================================================


============================================================
🔄 Round 687 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 687 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0029
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0083
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 687 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 689 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 689 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0034
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0024
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 691 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 691 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0045
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0035
============================================================


📊 Round 691 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 693 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 693 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0054
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0021
============================================================


============================================================
🔄 Round 694 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 694 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0055
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0041
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 696 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 696 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0002
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0331
============================================================


============================================================
🔄 Round 697 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 697 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0070
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0060
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 698 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 698 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0040
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0057
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 698 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 698 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 710 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 710 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0077
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0093
============================================================


📊 Round 710 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 710 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 710 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 710 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 715 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 715 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0042
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0031
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 715 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 719 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 719 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0037
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0025
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 719 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 722 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 722 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0047
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0034
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 722 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 722 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 727 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 727 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0043
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0036
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 727 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 727 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 727 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 727 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 727 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 727 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 738 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 738 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0047
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0024
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 738 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 743 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 743 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0043
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0064
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 743 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 743 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

📊 Round 743 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 750 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 750 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0057
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0026
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 752 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 752 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0012
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0152
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 753 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 753 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0035
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0077
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

📊 Round 753 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 757 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 757 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0060
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0037
============================================================


============================================================
🔄 Round 758 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 758 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0037
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0025
============================================================


============================================================
🔄 Round 759 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 759 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0061
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0043
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

📊 Round 759 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 766 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 766 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=0.0051
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0015
============================================================


============================================================
🔄 Round 768 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 768 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0040
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0018
============================================================


============================================================
🔄 Round 769 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 769 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0051
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0014
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 774 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 774 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0057
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0002
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 778 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 778 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0049
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0036
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 779 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 779 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=0.0013
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0377
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

📊 Round 779 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 781 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 781 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0043
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0056
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

📊 Round 781 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 783 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 783 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0043
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0010
============================================================


📊 Round 783 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

📊 Round 783 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 787 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 787 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0039
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0071
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

📊 Round 787 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 793 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 793 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0071
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0054
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

📊 Round 793 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 796 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 796 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0034
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0013
============================================================


============================================================
🔄 Round 797 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 797 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0045
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0048
============================================================


📊 Round 797 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

📊 Round 797 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 805 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 805 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0027
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0090
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 806 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 806 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0040
   Val:   Loss=0.0967, RMSE=0.3109, R²=0.0009
============================================================


============================================================
🔄 Round 807 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 807 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0049
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0031
============================================================


📊 Round 807 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2483, R²: 0.0035

❌ Client client_14 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_message:"Socket closed", grpc_status:14}"
>
