[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06a65e81-fb2b-4cf3-aed6-fc4cb53d1e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598610a2-a23a-4915-842e-6610d02f3c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66126f5a-18d7-4b70-b7db-da3e6e0966b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a458c06-bc47-475e-9e14-398f5c1281ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b438c08f-279c-4a39-95fd-582d5b7bd5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581234ba-c881-4ebf-a846-8173b5e87725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b83916c-aa62-48e9-a40e-509c870a2085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 175043fc-814f-4469-8f2a-806991d86592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f28a4d7e-b487-4503-881b-e91fe880b857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56061436-ef2e-4f87-a48e-ddfa40e098c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc8e4cd8-b843-48b2-aff0-a690c25b6141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92cc23c0-d2d0-4c43-ad04-e8453d585b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84a34cbd-98b4-477f-812e-06828d96f4a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 947822de-f14c-427e-9f6a-ade2718e0ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5cb12bd-0304-4234-8fac-62de8b3dce77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177cac10-4ba9-4380-8790-c2fd547ed78b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67700376-ba4f-468b-bfda-8b25bd39299a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25805e08-33f9-4de8-b7a2-b1bc235a7084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c594c47-368a-4e5f-9bcd-408950e24624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4488add-0eba-445f-9807-666a20893696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79b099d-8e68-4cea-af5a-955ee43e9cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9077334f-baf8-4c5e-a5e3-dfb5bdd7fc48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2440d3d-cb52-4c72-9d72-0283609c6a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9ae3f0d-f6ae-46e4-83de-ccdc9799a9e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1827379b-9c5e-4bf6-ba41-c45130828c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7d94493-2bf1-4b87-9efc-9617678ee202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eadc085-ab69-4c53-b835-bea7e0dbd13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb47db67-53ee-4310-94bc-a3a3d5e0733d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 701507e8-b77c-4842-8acf-5e4402197aef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 432f365e-5f58-4e32-b101-2800447cfb5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82aeb896-03c8-42a4-804b-10ca3b47ae47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46aee4bd-f592-4fc3-83a6-94418449d26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 789560cb-7b6f-4439-8cb2-008b000b1063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ddfdcd7-6732-450e-9277-ccc3a42414d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ef8021b-4c13-44cb-90ab-d6c9c6a69ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3cf920e-1386-4695-ae80-ae6f7716971d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d38c01b-6682-44f3-a411-697532d83149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3e482e5-99be-4512-89fa-5ed595aa8c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a53e4db6-e578-4090-b6ad-8aad69ca336f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40ff02f8-261c-4550-a571-4fc4418807c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2254ca73-e0df-4c4d-aacb-76b6752fe6ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e8112aa-2e76-465e-8feb-5c18b7d83744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffc96153-3961-43dc-8f28-c936333c2b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5c85c7-29a4-4ecd-ad11-7f679f603b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13ce6329-bdb8-421c-8c0b-a688e249e3b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ea0cd2-e609-48c8-b59c-19cbe0a27d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61759a8c-6e55-4b6e-affa-03a85652c50a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5cef5e6-3905-4a17-a6f6-aad5bdfb3dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f0f5a55-2bdc-4495-81d5-614cf2788f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a046e76a-d4f7-40ca-b9e5-812cb854a892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be0ba2b6-a184-4fb3-a7ce-bd19e8e34d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 460018ca-ab2c-43a3-b8e3-2afb2d65e817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b27e125-a99c-42d8-a1fa-c89b7a7c962e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65a85d7f-fab4-47ed-a3c4-1500ca23b113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ee3987-c569-48a1-a77b-9c50a1400a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dd4ff9b-c4b0-4e05-9415-94734ade74b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f861dd98-b8a4-4e8b-b1ec-da61bb35dad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df200a0c-1fc7-4aa8-9b9e-c4eb80c26dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdf5ecc3-68cb-42a9-a0e8-b574f79d7372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b1e83bf-7c29-4423-941f-29621d87ce28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5678517-5ed1-4f67-bfce-279fef9ca59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41eb8724-0bbe-4a14-aabc-f822e0e3dd90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f9e308-539b-4aac-9bf5-69955be9ee42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00a9b8de-ae6d-4b54-9afa-49aabfd966d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c510b14-894f-40a7-86d7-c2a454217df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 802cbdd2-9341-44b0-b6a3-148c749cdf89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e14f9e28-8d43-4e32-90fe-bdafb0338089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b613e3d-9f84-4b38-81e1-0575d2d81093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae2822f-3e02-4923-8453-6dbd49b8087e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcf87953-df27-42bf-a913-931fc0d9356f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4829f122-bdae-447e-b9bd-785366330489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49d76cb8-1214-4c09-9062-9947bc37d9e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 880e7777-cdd8-44b9-b63b-304be132415b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c197e3b5-871f-4a28-b15e-249a362e0841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ad717d-af13-4710-89a2-906e231e03a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7594228c-d9eb-4250-a58e-e05278e9b860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efee81ab-9e11-4db4-a532-63a0c658f6d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4efae04-b689-4fc3-ad75-059e2b84eb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74503ba8-c960-4875-848d-5a123c9005ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 978252d2-46a7-4b0c-b609-dc1122cc410c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 684e7ed5-2e07-4fe5-ab3f-1a911025e51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b06c1ff-d83e-46f9-83ae-bc880fd8e51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb86e43-5b62-4f82-88d6-9142b4fa4847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b153dd-520e-4b10-aa9f-f45c3cabe884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89801542-1570-4f11-b022-0300d62c1c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b3ee256-12c2-429a-b405-e9ba6499ef23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c52d5765-37ef-413a-8516-a29d45ab31e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efee19ef-08ad-4fce-a435-a28c742e7197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e8fa28d-b611-4d16-aaa3-73f956212aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e369ad6c-0b63-4f1c-9e60-239f65d8f5ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 292cd39f-bc1d-49a0-a515-c9e8e54f4e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45433cf5-5e1c-479b-adba-fc6e8ac135b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e6a6ded-3afe-4f44-bf20-65bcd7525b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9eb2a45-7f7b-4275-b24c-17f7cdfb790b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fcc885c-1104-4c9a-90e3-ea88d31254bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3715c73d-12e8-464e-8c8a-43ec8960198b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 272390fc-fa73-4320-8e9e-a0746ca170d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad3c3cb5-3934-47c6-b1b1-1e541658638e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94326790-5942-4b20-94fe-7fed5aa3e6c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c44796d3-8136-49be-b315-c9ae2e420e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d6ba0e8-b320-475c-a102-ab0f71874792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78fb7502-2fe1-47a1-9c5f-1971b1ed00c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c83574f-5844-4ffb-85b5-15c31bb01c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e7cb5f-0531-4fee-a6e0-ec06b302cfdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5078965c-d2fb-49ea-9932-b4ee102f7ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dba96e87-b248-4ff0-9453-3d9d06024261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c90f480c-a733-4eeb-b4dd-f271ebc1fbaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad0ceb7b-2d24-4c0e-879e-e78101f4dcff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e2d1621-7217-430e-bfaa-ca5719451d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9d2f7fe-2342-4eb6-b56a-268403a6defa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7919972a-236a-4328-a38b-e4984e34a5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92f613d5-22af-4ccc-becb-81c819f43f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5119a0e-98e0-4902-90ee-1ba393555944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31a3fdbf-ba7f-48ac-b33a-448aa236f82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7518ef-bcf2-4ab9-824a-efed8e903b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c661a88-73f6-4e7d-9403-b0d35036bd1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e07383b9-1332-414c-b422-1513131d6d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5aeaf6-ce86-4008-8cbf-d840a0c0eb48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd262603-7e61-40f3-a0fd-77b050f7e3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a54238bc-a34c-4c90-b328-57787bc342cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83d0f4e-865d-4d1c-8e9f-17d35a63accc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77e54b5d-d726-43ba-8cf4-e47acbfa11d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01503ba9-a3c6-452e-8b6c-ff1fc317c69c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d779bd6-3bd3-4239-8132-24ce8a783ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8409231-4bb8-43de-9824-e6354d661ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46800611-95bd-4bf6-9218-847e48b03102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba9450fa-99bb-4d83-84ff-1b69515a1318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a89f2f-dc4b-4e8c-912d-7c8eacca1985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 127aa334-b84c-4c1e-a45d-2ae28021880c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b213ded-7590-4e5e-a51b-176894716f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5baa0964-ceb2-426c-8004-92a765b3f09a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ddf441-e9f3-4798-88f7-3ff09274a467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85fcd800-3b99-4c3f-b874-90bd83b809b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c10b1a-cc45-4a20-91c2-73dd4641a202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 739a4cd9-6fa7-4e81-9540-82c70e862b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ebfc4d-a6d0-449e-aada-17c59e2bf683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e29efdd2-d98c-488f-ae81-ae7640974e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655b6913-d7a3-4efd-abe8-335ffb35fbc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55807358-5f5a-4ab4-ace7-9ca7c2c6849f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 785dd208-c0ca-4c2e-8703-21735cd36046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8338cf4b-6819-4321-ae1c-63fe122add3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79c4b4da-d4c7-47fc-8203-dadf8a9a8aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1076780c-35cb-4d21-8103-bdacefba39a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 894f200a-58e6-474e-a0fd-8daaf18b893d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6137a463-6ddb-4b7b-b5c5-5f8698e3ccfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6422788e-c624-4bb7-bdde-411f884c9d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfd87262-6acf-4c91-acb7-ac0872c2c8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b805319-2b9f-44b0-8ba2-08d63523ebbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 689818aa-a04a-4029-aced-33832b3282db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4629f373-76e3-48e4-961c-ded1c1e1c781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d793cdca-65cf-4af0-bd15-516e34b95f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f0cf5d0-29cf-4005-aacd-e405ea443b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea034e8-7dce-4b12-81b3-4f517ea9176b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14708216-8b46-41a2-8d01-547d27ba4a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbde9473-972b-413d-99ed-89ab4c8d1637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c76d62ec-907a-4443-abd1-af9875dfc41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 639d0b2a-25c3-4658-ac94-f63ba9c1908c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 142c5842-f1bf-4ff6-adce-7640412c2c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfcf7ea6-c12f-4a9d-a866-926f8a666efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff2d6561-211a-4eab-9ed1-5d38d4cd270e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 341b85a2-b3ef-4a85-b195-7974af5b5751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af27587-1dd3-4756-b1ad-47ad08312b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed8687c-8279-4ea5-83aa-3967eccd0fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d9fdec9-c091-4058-b6d0-755dd1c35375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 188dcb21-d8ff-4e72-9e60-ec1b8274e346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d560c94-731f-4dce-8643-56dd5bc077d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fed87926-2d90-41ec-9efe-7a5a655012de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd8e4318-22c9-45e9-8c60-8f6beab16e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7db6f4b-d88d-4440-a428-089f6ffe0c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6cbaec4-ef8c-4ecd-a4a8-690432a48030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93698111-be26-4244-8192-06a0991d6891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3380b11b-70b4-4f69-b4f1-07c6227081c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 024011ad-84fa-4063-9cb2-278bb4f4f114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 803c1871-39ea-45cd-aff8-d44544e94109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f38c6f-3340-4494-8ab7-1921cf0ea3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b92548ee-9bdb-49bc-94b5-d0f826d22597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcc88edd-9cad-4a30-85d2-8af2ac6d3e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0300d511-8319-4d18-a981-e6c77ef8b06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3846cda3-2a1d-4e58-9b57-a7e3cd420435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1e6bed1-c25e-4caf-8259-c64990c1175b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36a25662-3d64-4a4a-887a-1df5fa766586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89505a30-1eaf-47f0-a345-b7e2afc20d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae4a4d6-89cc-482c-b512-5b9bf3024208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 033e2782-1a82-4741-8dad-37a45d4f58c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37796703-b608-4feb-afbb-d37935a06d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f688db0c-2d6f-4d24-958a-b26b4db6eeb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2342a4d0-734f-4429-9fa9-a3d0fec399ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d166e0bc-2ed9-4dd0-90eb-7eb73e8fd273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ace7e3f1-bb6a-4f40-9783-df23f11cee32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae8cc53a-506a-48bc-9383-9bf60b688044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e58cd363-723b-45b9-8857-91ad923026d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24cfc4d3-3130-4111-a58e-83763db9ae20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6944ebd5-b9e9-436c-b9ab-426374801c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad4b2f0-329d-4518-a3dd-29b1797a6f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76df1e47-1ffa-415b-9ad0-8184f790d77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa1b8886-e1d3-4900-a659-435c07b7c036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e42a61e9-1d42-4ea4-81a2-10972c233433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c343c4-942f-4da6-b7e5-bb559eaf8f04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f2775c7-ad1b-40b2-861d-bd5b57aaa654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd51262d-a658-4de2-9584-98787a64513d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c9d961-c607-49ef-aeb2-0ec2582a53a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe3a42ab-3fba-4f40-8dcf-bcebe55f50de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae7c69e4-ef2e-49e3-9414-b2474d659fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bec9710-61a2-43a9-b1e5-d6e556306426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77d59d8f-9a63-49f1-9c8f-000e01822596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027714cd-0ca0-4355-acf6-cebc8f08ae3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a690c4b-df37-4cce-b0a4-4f147f39faa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e49c9673-1091-4665-9e8f-9c49c30e6e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dcd59c3-87ca-44f6-afcb-dfb2b513aa94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbc93a46-2290-46de-a9df-01b93c9469ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 451fbe49-e2c0-4c48-a90e-f89757fcaa23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8dba28-e0d0-48f4-af00-875f6d234e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f39bd59f-4b94-4c0f-bf25-581e27c30073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7499b00c-5e32-4094-af40-9a5b85da0be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83362d96-14fc-4281-bd7e-5e62b71f8b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b4c65cf-9f05-41d8-bec2-59187c0876f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49c954a8-6f9a-4d10-83ca-1fd64ea324db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87094759-a690-42a6-aae7-cae3424b8940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904eca72-9f05-42c5-80d3-dba893598b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96b4da62-2e46-4b2c-b4c3-d34d532d5bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b42182ae-7fa6-405d-9877-de86afdf58b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f06c6e72-bde4-42e0-9ca3-0038963526c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9529062e-76ff-4892-9740-90753232c9fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d328a13-dab1-48cf-b5c7-274ede8b9722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 917777b2-69ca-41ce-a006-b1a9a185a343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16106a9c-d624-4fab-960a-b18d86542b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de5b0a0b-8221-4d28-8aa1-e24d60cf0dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb60e77-33d7-464f-b533-637c96cad3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6d17ffb-e5d0-4ad9-a9cf-a98160ce1526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c6fa329-999d-4724-9bee-8c92d31a13aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd92d2a-3137-4514-a60e-4d51ab863402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a870f0a5-a160-4c42-a243-d739af70dccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f93a3e0e-f2ff-4e95-908c-80866835273e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 836a4460-cc07-4337-8b1c-8d4926f54897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5deb83f8-b66a-46cd-bc02-75ea046ea78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 616cd8b7-ddcc-4ea5-b46d-34260b425ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdb2e71-aa09-4315-ad8e-1e5fbcd4b934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a26b6d61-3868-4371-926b-166d320e06c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72f212c-11b8-4ad4-a89d-ddc1776e26fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78e064d2-96ca-4748-b990-060b08e45f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 050f972a-794c-418c-bd9e-d488c5b1a2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7069382-5e9f-4d98-b6df-c94543e247a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4370b52c-2bcf-4886-aae7-7a7d6f4496f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8970bbdb-a02c-4a64-8b93-e5eb1249c436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57f3cc6a-7d64-4488-b459-59890b0646d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86c18e28-9641-4492-8b03-3ef7d46aa63b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece4ae5b-6b8e-4b77-a84b-3a80523b885d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73432c44-5d28-4c7e-8b2e-d51fad636878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4565f793-050d-449c-8e59-01bb59f0a3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a259593-d2ff-4f1c-9838-2d1e9cde83ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8ddb3f-60cc-45a2-b2f9-e055e161c7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0932dae6-31f1-4b05-bdde-e76bfd355588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad76015-7f74-4f55-b7d2-041ff0565bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7505dfce-b5c3-4228-bbff-8f914404912f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 293c017d-a691-416e-9ed9-d828a909db12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e95dcfec-6e92-45ae-9811-d10ae5d60dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d36c9ab0-9826-4cdd-932d-91f34c791d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ced82df9-11eb-462f-9784-f6d03416c57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17778fca-2225-4195-aded-0f222bb50f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d3beb52-8170-4fcc-9362-7e5ea77d1057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e065ffb-ed57-4e1b-9c05-bcf409834f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b94f135e-f9eb-4ecf-b778-92333f3753dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96f5ade7-4995-4e39-9f5e-14cafbb1d328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ac7186-0aaf-42f1-a884-b9f213e41fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4c38fb4-a4ff-4cfb-b18c-78d33ec7d38c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ea1f73b-8216-457b-a439-3f049a0a6f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdd61d6a-2176-48d5-ae25-f7df0c723736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 253340e0-97b7-4604-9bf4-2b5c3ac7a788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 138cb88b-ab49-43b0-88cf-fa7b7899709b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28392971-532b-4e74-bebe-cea6c723e5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30b0ffeb-b19b-41ad-8dd5-57d751ab4b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e206c4-c72e-411a-a9a0-2038c957cd55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0f46d55-2245-4977-b6ea-c8194ee149cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 770067d3-e894-4109-96cb-487c3083284b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04265311-ed55-42b7-8bed-d486f538be7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c0ff117-967e-47c9-9edc-f91b4326030d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5708370-fc9d-4e3e-a8ca-57f70640a00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31259abf-d67d-4477-88d1-26eda8114490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b06f127-548c-47ea-9018-932bcaec9cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b66a5a2-b31a-4c82-92c9-6c8589392bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c4df723-3b66-4f08-b45f-31012bfe03e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d1a1a3b-07f8-42d3-b617-8f4cccf5715e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4b3dfdf-c8bb-4e23-8925-07b88124e04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f15de780-7234-4a18-97c9-dd2d189801b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbe1ca96-03f8-4722-9b0f-18a27fdc9258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 798eb0af-23b8-4123-9b67-0d9129d6827f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e3c0c6c-f4ad-41a2-a713-d12ab7e00afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f9038a-a985-43cd-8997-3f56bc8f098a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 721b3f6e-9817-42f9-8ec5-018090cd6100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d237b6cf-0b19-48a6-902c-447902ae25f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 843ef7b3-5d5a-43a3-91fb-d73bbe1db512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f1c53f-7b72-4bf0-b5c2-f04d5df53a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72c7dc22-ceb5-4385-805b-199e0f9e4bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b90984e-0d1f-40c6-9922-84ad7f63563a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45942bd2-8355-4485-bc2b-524f85584a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fc61e37-293b-4fbc-8132-92a992d3cce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4314dec7-d2fe-4238-856f-3040bd1a5788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e5f210f-bba4-4560-9631-7d8aa1d7f18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e79bcad-0bbb-46fb-ae02-40d6519f6950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bb30e2a-6fa5-4d39-8e7c-744157ad7d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0b44770-c3b6-42c3-923c-285eec542d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39832ba0-3676-4e5b-9520-68848568af7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ef3e04c-7bcc-48be-8329-4d0bcbe5d421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28159e92-2425-448e-b14a-200d0afad8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c7bd923-8eb1-4936-a438-2c8ab6460ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff2e6a95-f1b4-4867-8bc3-8a8e84a8dc6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9029e6b-5f89-4c54-aca2-564da1654411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65c0a997-2ede-4252-87f3-6dae5bcc7c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 202e843e-0724-4cee-833f-2112f099909b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee63367-dd22-41a6-960c-80f5bad13af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a36e4851-dc3c-4405-8a8f-881d04e15466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c349e1f2-6907-4be5-8e3c-35c33fbef2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68990e4f-aaf3-4117-9e86-45ac71c8aef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message babdd9b2-baca-436f-a5a3-13fd140cd744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a38304a8-6ea5-4407-a680-cfa390b2572b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7372e691-e4ef-4ad2-af34-64cb9e3e7ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02fa78fb-e1fb-499d-98ec-047391ba37cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adaf7a77-7398-44f3-bc05-2fb0406be609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 417f240e-66ef-470b-af8b-4df7d661ef8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1376a4c9-55eb-48e9-9aad-ec2cfb8e8252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 296bfb3f-92ae-413b-aa9b-35c9838dbcd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef33782-b1a0-484c-a1f6-cb5f8e104f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f6aadd7-d740-472c-9203-ddea682a1f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58eea15b-6c49-42d4-8716-53ef91322f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23a0771-ad60-460d-a416-d56152c407e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5584dddb-f356-4df3-bef9-6588336bbfb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb89f42-9650-4a1c-848f-2a1b724ef142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d622053-78e7-41ec-8a5a-b5b360353d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06eb5c1e-2824-405b-bf12-77ac0c5dbafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c984e7b-68ab-42af-bb07-f6c35e85435f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19f0d10a-2035-4f47-a601-537daad4620c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e494945-1721-49d7-a7b0-d74c010aa82b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db6ce71-2833-4068-b4ce-2157b624e802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d3f340e-3548-4798-9c17-a23cef9979e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e991fbae-e97f-4462-8626-1a947af2e98b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2cb2a2c-1631-44cd-84c1-0a242d5fb1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d0c2245-330f-4db0-93d5-9a42c4cacc34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25753e20-61eb-42ca-845c-130316789eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98ac089c-ac9c-4462-808c-611cfee17f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ede4d761-2a23-4a5f-9b9a-ff52c1d72aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64910caf-e75d-448f-8008-d19b6c5bd465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09e7502f-bd2b-4369-900d-21daf614354b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6da58f3e-20a4-445c-bdd0-81c7b1dcbde4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2130e518-c9d9-44ee-aba8-ea4aae7e191e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bddf9839-41cc-4c13-98e8-83d7e4138e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d143303-f973-496d-a384-9886f72102fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7827f1d-d548-4bdd-abab-ec1c07ee3fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c06096-7112-4e86-8b66-8a62f7f454d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bfaa869-27b7-42d7-ba18-3d29e3eb46b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8e818aa-85c9-47a9-a83d-08b01957c107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81982d93-e4ae-40ed-a929-ec830f5fd0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4ba6369-da4c-4bed-b3dd-57f07d4246d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43328ab9-f206-4220-934e-5624a00f22bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e467b944-5f75-4b59-b9da-61beb345a0ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8223566c-985d-413d-9fd7-c394384f92f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c014e9df-a1d0-4286-a434-61edc22794f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bb1c671-4ead-4e22-9c82-0bf608178518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51df51fb-8013-4b82-95f9-3470dbba202f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d076ab1a-ee55-43b0-8b2a-f98682cfd5c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8f2be95-8d65-4359-9ab1-bbd17524d38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd7241d-1435-43ec-aa4c-f174b4965c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b40c1666-4fbd-4aa8-adbb-da9f0e6bbe5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8490c215-dc49-4056-9733-f0bad9a0d50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6544a9c3-4d58-4e09-8ce7-a2eff0741028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3a4e96-8c7f-4b2f-a4dd-09b7c573abf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4388111-ca54-4d2f-8a56-6c4bf40a832f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 887138dc-f1b6-47c2-bc17-98f9ea2f6862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd6b4aa-d34b-4da7-81db-442ceb50a24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fa25c06-0cfd-43c5-a733-9b374d120953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96765a04-0e12-4a67-bd16-1bf2231dc070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d11fe96e-5ef8-4a8b-93d0-cfbd2382e2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d5e440-74ab-4336-824f-296941fd2474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9948cb4a-9b71-455f-ba9a-bca178f02ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be1b1830-88c7-446f-a190-140676796509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0197682f-cba8-4de3-95f6-b6c78cece536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b4c0804-bdfa-42ab-88a0-8994c4143af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6c43be2-eb3d-401b-81ef-418427b2492f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dcf74f0-f1f6-4f2b-96d0-06496e1b5048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 881981e3-557e-4d50-be27-e472dff4c0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa3da7e0-b2ef-426c-a791-ceaa025fcffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f14d5e-0ba7-4562-9b8e-af6a0c9f83fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d8944bd-9647-4a6a-9da2-849289a1efda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdb0c745-54cc-4bcf-96cb-da9f8dbe62dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff2edf83-a14a-4afe-905a-98f6014566aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc7b057-53ec-43e0-894f-be6488aa79e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b8e6e5-a0e8-4c0c-afab-b0e5f5931286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd554593-4e63-4e4b-a18b-3da30a2e6fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b90ebf65-6b4a-470e-9bc3-1c7f2245d3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd5883c4-f22a-46f4-bec6-4634d9c1f149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc995a63-3922-4bdb-a551-e6a8d2ca4e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39aabe7b-8f3c-45f4-8f89-9bf9bbff5643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f808d76-faec-4ac8-b9fc-da412b5b37cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 251643ab-28a2-4d16-9ec3-9ba93461c823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1676b7c2-bcdb-47c5-b4e1-0ee5821ebc9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88583597-9035-495f-ae10-f90e3b5e7b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df725054-2ab4-482f-9f0a-815f4b4d4383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48c49f61-4886-4c29-918d-c201a505bc15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3a36728-65b0-4107-9b69-5e6d46f25caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e126fdee-0e61-438f-ba2f-b30d9d65caa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65aff7f1-ca17-44ec-a9c1-75a8623628fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 550d25c2-f1d9-4c96-863b-77c6affd1d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8225ecf6-960f-4d54-971e-21237cf58287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d5f553f-155e-4f12-beb2-ba02c38f02af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f4b4b17-c306-4e18-9e42-74ab9b42d4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c27a420-c501-433d-b21e-46397a8cf1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bd12415-5fc7-4232-bda5-da2daabd144c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e03247fc-1841-4a29-a37a-88099563fd3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b2626af-a1ba-4ebc-9ec4-7473b92bd4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b37ec359-75b3-478c-a76b-cb9903065129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24e419d5-1704-4121-b3ed-f53b5c37d963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20cdd56c-7d6b-48fd-918e-b09dccf15647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 903c7137-94f6-49ed-87fe-e29a5353adfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e6e6aae-4f19-49f1-890a-5bc860d9e85e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bc53acf-7605-40a0-9f18-8d0a01ab9f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10bd3bd6-04eb-4de2-a3c7-ca79b6c85f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17853e11-8cde-4272-bf3d-2e148f687a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2129f08-271b-43f9-820d-7706547ba333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2213aad1-e001-419d-ab5d-4f28b8fd374e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f630f5d2-fc90-4a9b-b66a-13f541a5a60b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe6bbeb-81fd-47c1-8f1d-cfd5f8de82ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc928182-fe1b-44e9-ad8e-1bc200585fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bf0408b-1857-461b-80fc-6fc7091fc8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9933992-a61b-4ca2-9392-8cf3160ce9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b6430f1-c58c-4c72-9918-433cce95a0fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61c6b4ce-80c1-42f3-85c7-fe007839b32c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 683b27c1-7c8a-4e1a-993e-56980f7e1f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd05cbc-9e0a-4206-b964-c96b75d05dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02853831-52e3-4a21-83f0-c6e5de27c090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 312bb771-419b-4cc9-9b4a-25b4eccadebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c96d15-7b82-4bb2-981c-f8a74c5c107b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8465b9b-399c-4da7-bc4e-0ff5cbd1d766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ddf4279-8b77-466d-84a5-419641df21a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da372908-303d-4ec1-95af-523a3ebff4d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 292178cc-ffbc-4bb0-9d99-40f09fb64525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 630c2ba9-5f0f-4974-9719-e41db9687ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cf26144-a323-4d27-bdb1-b7b90af3b415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab7abf4-b167-4414-8d8c-072f0a4ad215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca5d22e4-8b5d-4214-8ba0-31bd57b1d970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b193ea1c-84d6-4bb5-aac4-000ed2f7c5e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fcbf8fd-391a-48dd-a7ad-78899e3ba9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1bf8273-5759-4a74-86a7-6e64fe81351d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 285fb4bd-62f4-4f6d-a626-bf38032b2c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 474919fd-7f62-4fe8-a3bb-d5cf2bef09a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efe250cb-f5f5-414b-8c68-f9523bad8cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a534c70-5987-45e9-adaa-7ea2e7b0a174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb5d8eff-bdf1-4648-a19b-75ec54743a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 757da3c2-6c91-49c7-a488-7e069eb65cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1abf506e-963a-4c6d-bd8d-70ac7ddc32c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16343791-820c-4024-b1e0-ad0a6f8fe148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2d5fbf3-4314-4c5b-9566-fb769b16a065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cfaf190-ac41-4ec0-91d7-279e3d62908d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bd9d4cb-2b06-444d-86f0-e8a73faf0b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dc5c9ce-cde8-4e38-ba1d-ac763e5e6c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49e8b2cb-1003-4e16-b101-64f3e5c66909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd2f57d-d5d6-4aed-a410-ec9d761e9789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02397cc4-2f32-4527-9138-46b9f9571b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f5662da-475f-4517-bac1-cb025b25b7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78b247a2-5342-46c0-90a5-ad70afc433d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a48a62bb-9314-45c4-8c85-530a6f10533b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be50c0f0-225f-4bf3-b319-fa53d31a784a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7dadd97-d84c-439f-be7b-4185145c2e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97df7eb4-7db4-49f8-9d8d-ef5f2468f524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8fecc00-b3ee-4963-8812-e9c5683e6880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c86a2e-cb07-4b36-88a0-ab168d9e2d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec75fbd9-1642-4559-a7c4-1bb878daedcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4763b611-2a90-4b59-bdf1-43a71d850643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad62025-efab-4c3c-9224-0d48496c3bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c067a3-48cf-41a6-b4bb-af9ae1b9dd55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f545062-aaf3-4250-8676-be4fc3a13f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 189b6ab6-918e-4737-af37-e2910a61eec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62fc8a6a-4f3c-4302-bad8-0f8591daba45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 951c12d2-02db-4908-bf4f-76cde6c8ce92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2b1fced-a5d5-4570-a861-a3c9c5cc3118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6836739e-a411-4cf5-8c29-ee337f5bb57a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f5b54ed-6f47-40d3-93cc-310d78f1e046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad9b11a1-7071-418f-b9ea-777572415d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7532dbdf-0375-49c0-965c-b26fc5118a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 880b227c-a812-4e40-94cd-10ac70b0ad8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40fe21a7-224a-4d70-a1ce-a3949099e630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb767620-608b-424c-9a7e-5d8366a33858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad0a8808-620e-44e1-a94f-c0ad5265aadc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80be1970-cb12-49e1-805e-0d3325a4850e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b37d459-2cff-45ea-b861-c940eb2ca98b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e37bf891-4b11-41d3-b982-92772275d8d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e46b0da-fee5-49d8-a264-8b63efad1513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47f066d0-4515-4845-8285-eeda2a70fc8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 786b2db2-49eb-40de-aa90-8ca1f5289cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cfb6df6-434b-4f3f-b4e9-7e39e1d419ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ddfdf33-d808-4c2d-96d8-850a4ee988ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1f307df-721a-4d1e-8f8a-2dccf5e9a26b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d97028f-a292-49f8-a716-91424dbc5514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4988681-3be6-46e4-bb25-60370bbffa02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73fc13b6-3aab-4e92-bf0c-ecc009b35707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86e5d34f-255c-4c16-8717-9562597d6a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f04c7319-8bb0-4a00-8fc0-f3d2b6a38260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec8819ac-7485-485e-886b-049f6bffb877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3692b0-7fc3-4f25-a055-0f87de35c3ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64ac11af-f3cb-49ce-b5c8-913463d59fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84783cd5-9525-47d3-925d-cb135271e50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f5f2de5-d162-48e9-b7c7-2be1bcc39420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e10cefd-f93b-4ebf-bcd5-421ab94e6f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9e0d7f0-6d82-48e0-ac11-aafe20c66c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df123014-8868-4fc7-9906-1c64da803062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a9810b-f014-4d3c-a3fc-34a068ceafda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 621576dd-d7c4-44c8-8235-12f8512f5950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc28d105-3535-43c9-ba7a-8b9acae3399d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17f873a9-960f-431d-af13-cb3324dfa520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a40fe064-808f-40ee-9bb1-1655b5f3b600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf54a50c-d551-47ee-9307-f93cb3e8716b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbc5bcfc-9331-442b-a1ea-806acb889044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cba8c53-1fb3-4540-b8da-e79154e25135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e4e8d0-7113-4124-96cc-fe39a24e129a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b3608e3-aebf-4361-aad0-fceb6ea987d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 583873bc-14ae-4d08-a345-a1497f9f53e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a13e74ae-1ef9-42da-8ff9-cc897fe4bf83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c994de63-82a5-49b1-9eb0-c741073ebbd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4c0299c-540b-4811-a1d7-0d514e6439df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1a29b6c-084c-45dd-afa2-dda4f2babb3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff820d4-5a5d-4f81-a47e-f7252cce4070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1b2e290-21f8-4d0c-a3c4-2ffc88e85961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 120885b4-e9af-4508-927b-a02732b93339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f07b8f7-1372-4a4c-9bc0-3c7f654de9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5e69473-d194-41a5-847a-8a26e7e2c812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7f60487-7b5b-4a5c-85d5-4a9aa24f2696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23afd92c-af16-4cef-87c4-d3794ace9715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45f2fa97-1c19-4490-8b02-05a8ba264c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb5646b5-18f6-4a37-a904-222b924e1f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 798a7d5e-ce30-44d4-b2c3-6aee63b711e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326dfe3f-df0a-4b2a-bf8b-041c9eaae682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b910b1df-d030-4452-bdf5-e47ee140d6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6b99863-2ede-4098-9e2f-9202fc6472a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9242e6c-4782-48e1-af2a-a498fc701d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e7f63b3-738b-48de-a0b1-ad9901ee23d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a51ccde7-5db7-4116-a418-2ff25b78882b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 352bd9fe-40dc-4e61-bca6-ec85d563f125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8110d6b-f4cf-47e0-aed6-ee6233dee225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc4387ca-c4cc-4a56-815f-fadb5d063c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e14c955-2fef-4afe-83ca-9f5c162c7668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38da857f-cf30-4d87-9b87-2e6c7450f908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 725c9195-c74b-4a69-8e94-54867108615e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6501c0-4431-4880-9880-0dd808f6ae29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08cbd43f-7347-4389-a2b7-b5b7a9edf8f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56998728-da49-48c8-a280-9c6e1f0e9f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c5d862-bc17-4b6a-abf9-347227129879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c3620bf-80a2-446d-8690-a915afa626be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22cc6de5-9c7a-4ba8-97d5-86b8117a483e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4d8a33f-055c-4d7b-8a80-5a99fc37fd62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9df1952-2b67-45bb-acfd-ef2139b0c1b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ea17af-ddb4-47b3-ad48-7be46cd750b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4ba2770-79d6-4803-8baa-5d0f11fa5379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37949fce-7804-41db-ab0b-14e9462f68d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d8158d-d3e7-4fb5-8f47-77f2d3c195d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a432c3f4-0a64-4069-bb48-9f31747ebcb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73584435-65f9-4c6d-9374-0ba38bbd1bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c99687ea-f983-4078-b17c-184827ffabfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc8d68b3-8039-434d-acba-3c96f2a3fb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69e25a90-a0fd-4e3b-aa58-450276f62e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de0ea8e-0bc8-4da3-b939-6536a84d921e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9382a0f-aefb-486d-9ed3-2a8252710282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d673f85-9e33-4497-ad45-54ef603d219d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6e0bf24-4a25-4ec4-8df5-25ff61f1892e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1550923f-506e-4f4c-b01d-eb33db55a48d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1512c94e-f26f-4a22-9b2f-0cdcad745f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3930a8e-5231-450b-8305-26786586b00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c66507-db77-49c9-a9e2-e2782bd90b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 708f6a38-d548-4fc8-ba9f-f6785794fa87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message def25995-5637-4b13-8998-5bf64d4c7d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bb62d46-8c12-46bc-b66d-51fdafd0f214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aafa36b-48e5-4e10-b6f9-585c341995f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dcaef49-581c-4c0b-b087-281b288151e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45a76baf-a742-409a-8d0a-d8b817cbf98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f44b6985-f126-4668-8c43-9163c58379d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ca566f-c5f8-49db-b808-e6c302739f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 801ac356-f34a-4d0e-8942-414f4d585913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97be49c6-c7ea-47c7-ae17-3bcb15b50d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f62e836-4a7a-4e08-8864-2301c22c621c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 362fd572-a2aa-461c-9bbb-d0af21874bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f63f688d-277f-4aca-a4f5-87191596f233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e315ec21-5b75-4433-80cb-c2f78c2e5003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53f67136-a69e-4efb-9f50-e9a96ed3e2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d247ff64-df4e-4adf-bd79-df140c63c3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6d75052-8d84-400b-a4f1-549b407669ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d80750ad-ffe9-4b2c-82e2-6df181e2e5fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a981efae-78ac-46a1-bee2-09ecd26381f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d7f724-66bf-482a-8109-8e19c58046fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1809ce18-9fd0-4736-8106-a07244e0bf5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb193614-0bef-4efd-8606-f97bfe3ce624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c12a975-b91b-4c83-8f2a-0e49d63fbdee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aff3530e-229d-4f25-8d09-cb6f1c83e758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2574591-e4b8-4e70-b637-f10d45335f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3104219b-d5c2-4ed5-baba-cb3c00860206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e060d4f6-7ee7-4448-91f0-a83aec186b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7020a1f3-6cd2-47da-b7ab-1059a0dceefc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c52c35-fae5-45d1-adf3-dd68d3562c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bcc3773-f4e5-44b7-b38a-765665a2950b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cba2992-feaa-40b0-960d-fcb17b36f018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 848b5d98-fe69-4c73-844a-1e5380061fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d97ee43f-86c5-4992-9411-f92bbec91405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf3916c-f74d-4dc9-847b-ef29acbfaef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aba7876-b4e1-42bd-8e09-ca7b8695178e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dee0d736-22a0-484a-a16d-3628828c8142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3920fb31-d3c7-4a28-b927-17fe320bce5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb9d28c-d191-4966-b0fb-ca939b4e2184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8425e78-8e05-4196-be50-a7d1fa9a67f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6853f29-9cb5-4724-9cbe-ed1051efc5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a69b293c-6235-4d27-9662-4769773bf922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe267137-10f2-4ca1-82ca-518a19031a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b608e75-fbc9-4b15-8407-3e0adcac1709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90765e23-7b7b-48cd-90fa-364f051b4098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 470e5237-dfad-4c04-8bac-91463f4c78fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01d5c187-ec97-497a-8068-123d21d482fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5075640-7975-4d82-ab2c-9a13b2e184cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d6b685b-3ea7-4f1f-a12e-a6f48c047476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbbb929e-d276-4f5c-b016-ca6856a6f819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd3ea3a-727d-4da5-aaf4-eefd995c8252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cacdce1-0120-4513-b60c-17a71ef289b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbc4375d-2a39-4c45-a9a3-851ce5107c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbe06fd6-9057-4bc6-99b3-fbde33db60e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c46657-af09-4669-aba6-e97c4294d327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ceb544-a6ae-4d7b-ab37-e0cbd17df5cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdcdcdc5-5a9d-4e06-b3a7-5690809fbac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fa13b86-7c1f-49b0-9a6f-e5a4cb0caa03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58a197eb-00e3-4eed-bda1-bb5e31866466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6df87b19-3cfd-4061-8a2d-9b0d40e1b3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0703220-97e7-42c4-8aa7-73f930e3d6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae0d13aa-2cb9-4660-8a2e-9e35917456be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7312e33a-88d1-47e5-9c46-4030da656887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4069bd8d-0fb9-462e-8d34-4fea8282fb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 319f65ea-98ee-48d9-9467-184ccaa724e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc223760-100c-42a7-a8d9-f56ed30fee2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e07bea27-a6f7-4bdf-8269-7c1766d38c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eea7303-243e-4dbf-b89d-496d03809213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb6ea3f-39a3-46f9-afac-3802f4070b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b66c811-2a25-4ad4-b0ff-af0c62b10cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4266bc44-df34-4e74-b41d-476f96c06d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45aaff89-510c-45ee-9ec2-9177693e69fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc79a86-8779-4a5a-acd3-8bfd4f59b658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 819c17b7-6c9d-439f-a945-eb12651d36cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3d43021-b240-45d8-8917-8bd71989849e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f02eef9-09e1-4ce3-a695-8f64b6f557a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15743483-93fd-4b97-82fc-3bd03c6c388b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1df8c66d-7aa2-4d0e-be54-585698e54123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1016c5e8-4308-4e27-ba85-75a6c9ee55e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88197ad7-1bb6-4e6b-8946-bd31de07912e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d13d85c-e8cd-4045-8013-21ad689e23af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2d15427-51ec-4e9a-a9c1-89b4b8442b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce730001-b456-4878-abb6-fd35315e19ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79688718-985c-4f34-9ea3-277b119b493f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc588d4-5ae0-465b-b6c0-d6cfdfba3f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15f919dc-5366-47f9-9d32-88f3026863a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda4f60d-23f1-4cf4-8b90-43a85042c0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3daec81d-1071-4845-a397-4a37fa767635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 616b4590-e3cb-4a50-a261-da78a5ff579b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9251b76f-3b5a-4a6d-926a-4c95166f3a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0efbe5c-5819-4365-bf00-543e72577f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa302256-5d48-4d57-a829-6c41d3792359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff1cf2cc-9a07-4d53-a0d3-219cf0cb2048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce1defc9-b519-4059-9ef9-965114fe2706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92c70825-092d-4d33-9848-599666342b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a809e50-32d4-40ba-a702-daeab2d5ac34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fe85a9e-26df-4751-b72b-8ec8fb693c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e299746-9225-41aa-a331-8229d27d926c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 132dbda6-7fa7-4a1a-9689-643779c737ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9d9e0bb-4b51-4b8e-8f2d-8eed58747bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51953431-f69d-4c25-b5d4-896e49896d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca84e60e-c1df-4b64-a3d8-40fd9d5f2586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a55d530-2d33-4cb4-96b3-4ed170c884cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01d144ad-08c2-483b-a7fb-dd2cf3b40438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bde0ccd-d1d8-4659-8769-34551dcb219b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1346ec66-2aa5-4551-9bf9-99e675952d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 110a9412-51ce-473f-ae85-a6a3e3a3b06f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7684bc3c-f95d-4838-9ce4-997dab51beb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 774f51aa-ffef-4d14-8952-b9e4915a3595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 515b2883-bcbe-4647-9b61-98fa93ca48d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f2e091b-4a8f-48d9-bcd6-560b0a00c267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f33aa3c4-7170-4673-8882-3aa3750a5cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0995d219-f4e4-4ff2-a32e-54b7afe92f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd539334-3f59-4c22-bc9c-b37e531e7ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 575b7bb1-d566-499c-8712-966b7a560b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a81c7b66-1621-424d-9216-a9b2bee1e959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b0aadbf-1bf3-4b1f-bbd9-a1bbc8ee755b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f7e0fe8-878b-476e-b4ca-88d1d06197d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d25cc3de-e4b9-4126-8762-1ef39deff8c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efe6883d-5e8b-4062-ac40-63c53245cdaa
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_15
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_15/test_labels.txt

📊 Raw data loaded:
   Train: X=(4476, 24), y=(4476,)
   Test:  X=(1120, 24), y=(1120,)

⚠️  Limiting training data: 4476 → 800 samples
⚠️  Limiting test data: 1120 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_15 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2491, R²: -0.0028

📊 Round 0 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2491, R²: -0.0023

============================================================
🔄 Round 3 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0879 (↓), lr=0.001000
   • Epoch   2/100: train=0.0815, val=0.0882, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0813, val=0.0883, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0811, val=0.0885, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0809, val=0.0885, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0797, val=0.0891, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 3 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0131
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0017
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2494, R²: -0.0045

============================================================
🔄 Round 4 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0953 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0809, val=0.0948 (↓), lr=0.000250
   • Epoch   3/100: train=0.0806, val=0.0946, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0805, val=0.0946, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0804, val=0.0945, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0798, val=0.0944, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 4 Summary - Client client_15
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0097
   Val:   Loss=0.0948, RMSE=0.3078, R²=0.0025
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0009

============================================================
🔄 Round 5 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0797 (↓), lr=0.000063
   • Epoch   2/100: train=0.0848, val=0.0795, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0846, val=0.0794, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0845, val=0.0793, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0844, val=0.0792, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0841, val=0.0790, patience=5/15, lr=0.000063
   • Epoch  21/100: train=0.0838, val=0.0790, patience=15/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 5 Summary - Client client_15
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0072
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0096
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2491, R²: -0.0010

============================================================
🔄 Round 7 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000063 → 0.000031
   ✓ Epoch   1/100: train=0.0829, val=0.0885 (↓), lr=0.000031
   • Epoch   2/100: train=0.0825, val=0.0882, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0824, val=0.0881, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0824, val=0.0881, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0823, val=0.0880, patience=4/15, lr=0.000031
   📉 Epoch 9: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0820, val=0.0880, patience=4/15, lr=0.000016
   📉 Epoch 17: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0818, val=0.0879, patience=14/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 7 Summary - Client client_15
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0079
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0091
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2494, R²: -0.0040

📊 Round 7 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: -0.0013

============================================================
🔄 Round 11 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0793 (↓), lr=0.000008
   • Epoch   2/100: train=0.0848, val=0.0793, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0846, val=0.0794, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0845, val=0.0795, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0845, val=0.0795, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0842, val=0.0797, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 11 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0094
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0017
============================================================


============================================================
🔄 Round 12 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0817 (↓), lr=0.000002
   • Epoch   2/100: train=0.0844, val=0.0818, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0843, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 12 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0112
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0001
============================================================


============================================================
🔄 Round 13 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 13 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0044
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0062
============================================================


============================================================
🔄 Round 15 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 15 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0124
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0039
============================================================


============================================================
🔄 Round 17 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 17 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0103
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0046
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 18 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 18 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0053
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0046
============================================================


============================================================
🔄 Round 19 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 19 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0049
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0049
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 19 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 23 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 23 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0071
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0004
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 23 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 28 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 28 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0041
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0096
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

📊 Round 28 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 31 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 31 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0088
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0042
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 34 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 34 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0052
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0046
============================================================


============================================================
🔄 Round 35 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 35 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0105
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0050
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 37 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 37 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0041
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0082
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 41 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 41 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0060
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0054
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 44 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 44 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0058
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0019
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

📊 Round 44 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 48 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 48 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0054
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0036
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 50 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 50 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0067
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0004
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 51 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 51 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0003
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0551
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 51 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 54 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 54 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0083
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0013
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

📊 Round 54 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

📊 Round 54 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 60 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 60 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0066
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0009
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 61 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 61 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0011
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0456
============================================================


============================================================
🔄 Round 62 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 62 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0083
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0001
============================================================


============================================================
🔄 Round 66 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 66 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0045
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0068
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 67 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 67 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0077
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0047
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 70 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 70 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0055
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0045
============================================================


============================================================
🔄 Round 71 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 71 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0082
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0055
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

📊 Round 71 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 74 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 74 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0055
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0035
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 77 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 77 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0019
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0323
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 78 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 78 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0090
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0006
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 78 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 78 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 84 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 84 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0055
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0050
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0010

============================================================
🔄 Round 85 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 85 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0085
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0038
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 86 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 86 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0023
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0182
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 88 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 88 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0069
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0007
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 89 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 89 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0057
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0030
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 91 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 91 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0054
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0031
============================================================


============================================================
🔄 Round 93 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 93 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0025
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0176
============================================================


============================================================
🔄 Round 94 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 94 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0036
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0118
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 101 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 101 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0030
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0163
============================================================


============================================================
🔄 Round 102 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 102 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0054
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0043
============================================================


============================================================
🔄 Round 103 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 103 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0111
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0046
============================================================


============================================================
🔄 Round 104 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 104 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0037
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0122
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 106 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 106 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0046
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0092
============================================================


============================================================
🔄 Round 109 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 109 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0041
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0086
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 114 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 114 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0052
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0071
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 115 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 115 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0030
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0234
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

📊 Round 115 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 118 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 118 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0042
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0104
============================================================


============================================================
🔄 Round 119 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 119 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0069
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0009
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

📊 Round 119 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 122 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 122 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0066
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0003
============================================================


============================================================
🔄 Round 123 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 123 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0062
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0001
============================================================


============================================================
🔄 Round 124 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 124 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0041
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0096
============================================================


============================================================
🔄 Round 125 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 125 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0086
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0021
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 126 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 126 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0022
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0222
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

📊 Round 126 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 129 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 129 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0062
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0061
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 130 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 130 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0066
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0006
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

📊 Round 130 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 133 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 133 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0034
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0260
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 134 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 134 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0074
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0018
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 135 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 135 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0013
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0210
============================================================


============================================================
🔄 Round 136 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 136 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0062
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0031
============================================================


============================================================
🔄 Round 137 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 137 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0051
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0059
============================================================


============================================================
🔄 Round 138 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 138 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0072
   Val:   Loss=0.0766, RMSE=0.2769, R²=-0.0095
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 140 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 140 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0083
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0047
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: -0.0011

============================================================
🔄 Round 141 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 141 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0048
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0086
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 142 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 142 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0039
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0120
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

📊 Round 142 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

📊 Round 142 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 148 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 148 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0053
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0046
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 150 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 150 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0038
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0107
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 152 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 152 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0106
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0014
============================================================


============================================================
🔄 Round 153 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 153 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0065
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0004
============================================================


============================================================
🔄 Round 154 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 154 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0032
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0143
============================================================


============================================================
🔄 Round 155 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 155 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0064
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0012
============================================================


============================================================
🔄 Round 156 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 156 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0094
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0035
============================================================


============================================================
🔄 Round 157 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 157 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0110
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0109
============================================================


============================================================
🔄 Round 159 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 159 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0034
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0119
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 159 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 159 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 162 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 162 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0079
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0061
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 164 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 164 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0060
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0101
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 166 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 166 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0026
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0319
============================================================


============================================================
🔄 Round 167 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 167 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0088
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0000
============================================================


============================================================
🔄 Round 168 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 168 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0075
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0025
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 169 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 169 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0032
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0122
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 169 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 174 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 174 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0056
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0023
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 176 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 176 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0058
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0027
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 178 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 178 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0053
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0031
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

============================================================
🔄 Round 181 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 181 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0040
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0082
============================================================


============================================================
🔄 Round 182 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 182 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0102
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0022
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 184 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 184 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0060
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0006
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 186 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 186 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0082
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0003
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 189 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 189 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0058
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0012
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 189 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0011

📊 Round 189 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 193 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 193 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0106
   Val:   Loss=0.0914, RMSE=0.3022, R²=-0.0076
============================================================


============================================================
🔄 Round 194 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 194 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0069
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0030
============================================================


============================================================
🔄 Round 195 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 195 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0060
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0082
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 198 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 198 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0073
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0157
============================================================


============================================================
🔄 Round 199 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 199 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0070
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0038
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 206 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 206 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0045
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0058
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 208 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 208 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0086
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0001
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 209 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 209 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0117
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0097
============================================================


============================================================
🔄 Round 210 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 210 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0087
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0094
============================================================


============================================================
🔄 Round 211 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 211 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0041
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0095
============================================================


============================================================
🔄 Round 212 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 212 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0078
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0085
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 212 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 212 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 216 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 216 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0033
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0102
============================================================


============================================================
🔄 Round 217 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 217 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0035
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0085
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 219 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 219 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0061
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0001
============================================================


============================================================
🔄 Round 220 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 220 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0008
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0516
============================================================


============================================================
🔄 Round 221 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 221 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0028
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0146
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 224 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 224 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0109
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0028
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 224 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 224 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 229 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 229 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0044
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0053
============================================================


============================================================
🔄 Round 230 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 230 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0061
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0002
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 232 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 232 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0076
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0034
============================================================


============================================================
🔄 Round 234 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 234 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0050
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0026
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 234 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 234 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 234 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 242 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 242 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0069
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0045
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 243 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 243 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0061
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0025
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 244 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 244 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0014
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0172
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 246 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 246 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0017
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0732
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 249 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 249 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0033
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0146
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 249 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 249 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 253 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 253 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0022
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0147
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 254 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 254 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0071
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0028
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 258 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 258 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0061
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0011
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 259 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 259 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0042
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0067
============================================================


============================================================
🔄 Round 261 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 261 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0040
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0065
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 263 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 263 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0072
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0020
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 264 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 264 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0078
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0085
============================================================


============================================================
🔄 Round 266 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 266 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0030
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0171
============================================================


============================================================
🔄 Round 267 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 267 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0051
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0066
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 267 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 271 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 271 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0026
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0218
============================================================


============================================================
🔄 Round 272 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 272 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0051
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0038
============================================================


============================================================
🔄 Round 273 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 273 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0012
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0288
============================================================


============================================================
🔄 Round 274 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 274 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0036
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0121
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 274 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 274 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 274 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 280 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 280 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0036
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0141
============================================================


============================================================
🔄 Round 281 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 281 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0070
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0002
============================================================


============================================================
🔄 Round 282 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 282 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0046
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0035
============================================================


============================================================
🔄 Round 283 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 283 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0057
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0007
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 284 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 284 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0035
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0156
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 285 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 285 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0036
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0077
============================================================


============================================================
🔄 Round 286 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 286 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0027
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0174
============================================================


============================================================
🔄 Round 287 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 287 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0070
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0054
============================================================


============================================================
🔄 Round 288 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 288 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0039
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0063
============================================================


============================================================
🔄 Round 291 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 291 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0032
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0113
============================================================


============================================================
🔄 Round 292 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 292 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0001
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0431
============================================================


============================================================
🔄 Round 293 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 293 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0064
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0001
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 293 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 293 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 293 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 299 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 299 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0058
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0041
============================================================


============================================================
🔄 Round 300 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 300 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0034
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0093
============================================================


============================================================
🔄 Round 301 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 301 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0046
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0036
============================================================


============================================================
🔄 Round 302 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 302 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0060
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0013
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 305 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 305 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0050
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0041
============================================================


============================================================
🔄 Round 306 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 306 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0051
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0015
============================================================


============================================================
🔄 Round 307 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 307 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0040
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0055
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 308 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 308 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0061
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0020
============================================================


============================================================
🔄 Round 310 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 310 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0031
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0137
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 311 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 311 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0053
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0026
============================================================


============================================================
🔄 Round 312 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 312 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0026
   Val:   Loss=0.0956, RMSE=0.3091, R²=-0.0105
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 312 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 314 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 314 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0017
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0182
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 315 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 315 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0035
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0116
============================================================


============================================================
🔄 Round 316 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 316 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0119
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0078
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 319 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 319 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0043
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0054
============================================================


============================================================
🔄 Round 320 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 320 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0045
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0075
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 322 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 322 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0018
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0267
============================================================


============================================================
🔄 Round 323 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 323 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0029
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0106
============================================================


============================================================
🔄 Round 325 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 325 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0045
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0048
============================================================


============================================================
🔄 Round 326 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 326 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0083
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0023
============================================================


============================================================
🔄 Round 327 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 327 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0088
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0039
============================================================


============================================================
🔄 Round 328 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 328 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0041
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0097
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 328 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 331 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 331 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0123
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0096
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 335 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 335 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0038
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0057
============================================================


============================================================
🔄 Round 336 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 336 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0072
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0035
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 339 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 339 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0088
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0121
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 339 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 339 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 345 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 345 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0167
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0338
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 345 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 347 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 347 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0028
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0090
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 348 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 348 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0085
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0040
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 348 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 348 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 353 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 353 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0061
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0111
============================================================


============================================================
🔄 Round 355 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 355 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0040
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0106
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 355 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 355 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 359 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 359 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0043
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0045
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 363 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 363 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0009
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0385
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 365 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 365 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0018
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0211
============================================================


============================================================
🔄 Round 366 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 366 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0080
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0045
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 366 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 366 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 373 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 373 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0003
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0349
============================================================


============================================================
🔄 Round 374 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 374 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0038
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0077
============================================================


============================================================
🔄 Round 375 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 375 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0055
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0000
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 375 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 380 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 380 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0072
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0028
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 380 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 384 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 384 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0043
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0051
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 384 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 384 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 387 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 387 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0033
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0072
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 388 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 388 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0045
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0045
============================================================


============================================================
🔄 Round 389 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 389 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0046
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0037
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 389 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 391 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 391 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0025
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0120
============================================================


============================================================
🔄 Round 394 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 394 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0057
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0019
============================================================


============================================================
🔄 Round 395 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 395 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0028
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0159
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 395 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 395 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 395 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 395 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 404 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 404 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0073
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0018
============================================================


============================================================
🔄 Round 405 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 405 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0025
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0132
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 408 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 408 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0078
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0070
============================================================


============================================================
🔄 Round 410 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 410 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0059
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0001
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 410 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 414 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 414 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0045
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0038
============================================================


============================================================
🔄 Round 417 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 417 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0065
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0036
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 419 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 419 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0105
   Val:   Loss=0.0918, RMSE=0.3029, R²=0.0063
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 422 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 422 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0048
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0046
============================================================


============================================================
🔄 Round 423 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 423 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0037
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0070
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 430 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 430 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0038
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0064
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 430 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 433 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 433 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0028
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0197
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 434 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 434 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0043
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0058
============================================================


============================================================
🔄 Round 435 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 435 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0080
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0041
============================================================


============================================================
🔄 Round 437 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 437 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0057
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0031
============================================================


============================================================
🔄 Round 439 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 439 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0071
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0051
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 439 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 443 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 443 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0018
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0262
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 443 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 445 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 445 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0006
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0734
============================================================


============================================================
🔄 Round 447 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 447 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0074
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0010
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 447 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 454 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 454 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0107
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0044
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 456 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 456 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0007
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0508
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 456 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 456 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 456 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 460 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 460 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0029
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0128
============================================================


============================================================
🔄 Round 464 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 464 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0065
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0030
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 468 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 468 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0069
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0010
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 471 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 471 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0046
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0064
============================================================


============================================================
🔄 Round 473 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 473 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0001
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0457
============================================================


============================================================
🔄 Round 474 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 474 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0004
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0363
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 477 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 477 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0017
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0234
============================================================


============================================================
🔄 Round 478 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 478 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0072
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0055
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 478 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 478 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 487 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 487 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0092
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0067
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 487 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 491 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 491 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0026
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0151
============================================================


============================================================
🔄 Round 493 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 493 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0043
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0041
============================================================


============================================================
🔄 Round 495 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 495 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0040
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0052
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 497 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 497 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0015
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0366
============================================================


============================================================
🔄 Round 498 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 498 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0042
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0046
============================================================


============================================================
🔄 Round 499 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 499 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0040
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0048
============================================================


============================================================
🔄 Round 500 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 500 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0041
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0055
============================================================


============================================================
🔄 Round 501 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 501 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0031
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0209
============================================================


============================================================
🔄 Round 504 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 504 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0046
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0028
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 505 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 505 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0039
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0058
============================================================


============================================================
🔄 Round 506 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 506 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0076
   Val:   Loss=0.0949, RMSE=0.3080, R²=0.0026
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 509 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 509 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0026
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0118
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 511 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 511 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0042
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0047
============================================================


============================================================
🔄 Round 513 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 513 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0012
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0298
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 513 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 513 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 517 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 517 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0021
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0164
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 518 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 518 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0042
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0049
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 520 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 520 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0039
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0102
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 520 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 522 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 522 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0032
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0080
============================================================


============================================================
🔄 Round 523 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 523 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0046
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0029
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 527 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 527 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0039
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0062
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 529 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 529 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0063
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0055
============================================================


============================================================
🔄 Round 531 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 531 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0015
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0280
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 532 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 532 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0008
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0193
============================================================


============================================================
🔄 Round 533 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 533 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0023
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0123
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 533 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 535 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 535 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0104
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0021
============================================================


============================================================
🔄 Round 536 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 536 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0040
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0042
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 540 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 540 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0044
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0021
============================================================


============================================================
🔄 Round 541 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 541 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0040
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0040
============================================================


============================================================
🔄 Round 543 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 543 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0061
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0020
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 543 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 551 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 551 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0033
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0062
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 552 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 552 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0089
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0003
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 553 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 553 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0026
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0087
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 553 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 553 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 558 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 558 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0054
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0013
============================================================


============================================================
🔄 Round 559 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 559 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0071
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0036
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 559 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 563 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 563 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0042
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0037
============================================================


============================================================
🔄 Round 564 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 564 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0015
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0175
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 566 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 566 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0075
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0077
============================================================


============================================================
🔄 Round 567 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 567 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0101
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0012
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 567 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 569 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 569 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0053
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0017
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 569 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 569 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 569 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 569 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 576 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 576 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0032
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0089
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 577 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 577 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0138
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0043
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 578 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 578 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0042
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0026
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 579 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 579 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0018
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0130
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 579 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 579 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

============================================================
🔄 Round 586 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 586 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0052
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0028
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 587 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 587 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0034
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0051
============================================================


============================================================
🔄 Round 590 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 590 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0050
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0048
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

============================================================
🔄 Round 592 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 592 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0023
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0136
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

============================================================
🔄 Round 596 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 596 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0022
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0103
============================================================


============================================================
🔄 Round 597 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 597 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0052
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0043
============================================================


============================================================
🔄 Round 598 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 598 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0088
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0039
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

============================================================
🔄 Round 601 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 601 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0025
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0103
============================================================


============================================================
🔄 Round 602 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 602 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0097
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0006
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

📊 Round 602 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

============================================================
🔄 Round 605 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 605 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0051
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0010
============================================================


============================================================
🔄 Round 606 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 606 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0092
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0007
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

📊 Round 606 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

============================================================
🔄 Round 609 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 609 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0034
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0071
============================================================


============================================================
🔄 Round 610 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 610 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0073
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0047
============================================================


============================================================
🔄 Round 611 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 611 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0020
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0135
============================================================


============================================================
🔄 Round 614 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 614 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0050
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0002
============================================================


============================================================
🔄 Round 616 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 616 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0050
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0006
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

📊 Round 616 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

============================================================
🔄 Round 620 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 620 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0052
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0013
============================================================


============================================================
🔄 Round 621 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 621 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0053
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0001
============================================================


============================================================
🔄 Round 623 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 623 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0057
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0018
============================================================


============================================================
🔄 Round 624 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 624 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0035
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0061
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 625 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 625 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0028
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0080
============================================================


============================================================
🔄 Round 626 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 626 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0059
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0029
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

📊 Round 626 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

============================================================
🔄 Round 628 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 628 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0030
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0126
============================================================


📊 Round 628 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

📊 Round 628 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

📊 Round 628 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

📊 Round 628 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

📊 Round 628 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0007

============================================================
🔄 Round 638 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 638 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0077
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0038
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 638 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 645 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 645 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0018
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0210
============================================================


============================================================
🔄 Round 648 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 648 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0031
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0121
============================================================


============================================================
🔄 Round 649 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 649 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0042
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0044
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 650 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 650 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0013
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0222
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 654 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 654 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0045
   Val:   Loss=0.0920, RMSE=0.3032, R²=-0.0028
============================================================


============================================================
🔄 Round 655 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 655 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0084
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0042
============================================================


============================================================
🔄 Round 656 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 656 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0019
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0206
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 657 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 657 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0056
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0026
============================================================


============================================================
🔄 Round 659 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 659 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0042
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0046
============================================================


============================================================
🔄 Round 660 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 660 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0041
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0050
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 660 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 660 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 664 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 664 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0045
   Val:   Loss=0.0746, RMSE=0.2730, R²=-0.0065
============================================================


📊 Round 664 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 668 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 668 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0041
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0039
============================================================


============================================================
🔄 Round 669 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 669 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0025
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0105
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 670 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 670 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0011
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0443
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 671 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 671 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0017
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0136
============================================================


============================================================
🔄 Round 674 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 674 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0030
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0084
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 674 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 678 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 678 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0067
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0030
============================================================


📊 Round 678 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 678 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 680 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 680 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0042
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0036
============================================================


============================================================
🔄 Round 683 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 683 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0029
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0107
============================================================


📊 Round 683 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 685 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 685 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0093
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0002
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 686 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 686 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0037
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0064
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 686 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 693 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 693 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0027
   Val:   Loss=0.0840, RMSE=0.2897, R²=-0.0100
============================================================


📊 Round 693 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 694 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 694 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0006
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0179
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 696 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 696 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0069
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0021
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 697 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 697 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0039
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0044
============================================================


📊 Round 697 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 700 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 700 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0088
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0084
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 703 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 703 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0079
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0051
============================================================


📊 Round 703 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 703 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 703 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 706 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 706 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0111
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0251
============================================================


============================================================
🔄 Round 708 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 708 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0053
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0082
============================================================


============================================================
🔄 Round 709 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 709 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0013
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0173
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 711 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 711 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0043
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0070
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 713 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 713 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0041
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0065
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 713 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 713 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 716 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.1017 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.1017, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.1017, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.1017, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.1017, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.1017, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1017)

============================================================
📊 Round 716 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2820, R²=-0.0070
   Val:   Loss=0.1017, RMSE=0.3189, R²=0.0019
============================================================


============================================================
🔄 Round 718 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 718 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0060
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0049
============================================================


============================================================
🔄 Round 720 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 720 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0031
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0077
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 720 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 726 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 726 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0075
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0024
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 728 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 728 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0056
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0022
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 729 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 729 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0062
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0026
============================================================


📊 Round 729 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 731 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 731 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0047
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0012
============================================================


📊 Round 731 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 732 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 732 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0067
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0019
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 733 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 733 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0019
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0162
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 736 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 736 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0037
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0044
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 738 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 738 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0103
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0067
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 740 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 740 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=-0.0052
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0016
============================================================


📊 Round 740 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 742 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 742 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0077
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0082
============================================================


============================================================
🔄 Round 743 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 743 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0047
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0060
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 746 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 746 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0032
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0094
============================================================


============================================================
🔄 Round 747 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 747 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0013
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0209
============================================================


📊 Round 747 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

📊 Round 747 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 752 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 752 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0042
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0092
============================================================


============================================================
🔄 Round 753 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 753 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0023
   Val:   Loss=0.0778, RMSE=0.2788, R²=-0.0114
============================================================


============================================================
🔄 Round 754 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 754 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0032
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0111
============================================================


📊 Round 754 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 756 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 756 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0031
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0074
============================================================


============================================================
🔄 Round 759 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 759 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0036
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0055
============================================================


============================================================
🔄 Round 760 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 760 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0026
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0129
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 761 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 761 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0042
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0038
============================================================


============================================================
🔄 Round 763 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 763 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0071
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0021
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0008

============================================================
🔄 Round 764 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 764 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0040
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0052
============================================================


============================================================
🔄 Round 767 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 767 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0062
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0020
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 767 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 767 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 772 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 772 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0049
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0004
============================================================


📊 Round 772 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 773 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 773 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0028
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0123
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 774 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 774 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0068
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0030
============================================================


============================================================
🔄 Round 775 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 775 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0025
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0114
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 779 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 779 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0027
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0116
============================================================


📊 Round 779 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 781 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 781 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0062
   Val:   Loss=0.0942, RMSE=0.3070, R²=0.0006
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 781 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 781 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 784 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 784 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0038
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0094
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 786 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 786 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0062
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0021
============================================================


============================================================
🔄 Round 787 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 787 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0005
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0388
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 788 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 788 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0068
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0053
============================================================


📊 Round 788 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

============================================================
🔄 Round 791 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 791 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0011
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0299
============================================================


📊 Round 791 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0009

📊 Round 791 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 791 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

📊 Round 791 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 798 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 798 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0011
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0537
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 799 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 799 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0058
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0022
============================================================


============================================================
🔄 Round 801 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 801 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0061
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0017
============================================================


============================================================
🔄 Round 802 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 802 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0048
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0045
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

============================================================
🔄 Round 804 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 804 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0066
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0053
============================================================


📊 Round 804 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: -0.0010

❌ Client client_15 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
