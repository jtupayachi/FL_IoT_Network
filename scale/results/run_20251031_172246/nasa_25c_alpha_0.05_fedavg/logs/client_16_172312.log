[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be24abd3-e4df-429f-b24d-7f95b1ed1159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f137a3fc-4bb8-4ced-a3db-f2aa3634c3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fee3197-9b4e-4e2c-8e14-65e113318446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b11d77e1-85ec-48e1-b22a-0ba4c13b4f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd08396c-73e4-4925-8f9c-a553580901fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e908662-99ba-452c-8cda-eea6dc613c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cefbb1c-f4db-48c7-9dc5-7299b9f8354e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 010c6ce0-eeed-4213-823f-7fc612e0b642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e6d8c5-51a3-46a1-9f56-aff2056ed07c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 372c7c17-4c40-4ccb-a427-d922ddc51b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63395fd9-afa6-4112-9e02-9f5268940844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fe7177d-35b4-4844-9999-598f71fb745e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49bf46f6-0f47-4411-b551-286acbfea6cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3413101b-ef4f-432e-8e0c-712f09d6a9a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b73c41a-218d-4328-9a13-3dd8aebd2036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a52756-5540-4504-a92b-ed7fb26be1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3644bc00-f168-48c3-81e3-fdbbef10b293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f60d0b56-c3ef-4380-84c4-dbbf864e68c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a825b31-2f60-4cbb-a9e4-3368941731ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85edd4c9-97ad-45d0-83bc-08d54ca26edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88fc07d5-a474-4dda-a8d3-a876d089d754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69ddf2e9-5090-40a5-8fe7-4387c2081398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfe25854-8c41-47d7-9a7b-d7179e7c7b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 032a8f9e-d81a-49e7-9e4b-e521264a2ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed15ff4-8285-492e-9fb6-d292f5e9a5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78c590d-ab68-4f66-af4a-1a6a50b171e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b22698b-103a-4225-bd1f-888ff7a6771f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e65f144-7585-457d-972f-5d80a26d5946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 807438d2-0b80-4863-b077-123a5f4a1910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ba4888-1a12-48b0-ac37-9a35d3666029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05c09f9a-0da4-4908-9035-a3708f93a96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba368a5-d828-42d6-82ea-c89fec310635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee2fe9c3-4101-4d2a-95ba-4024591dff15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53f416c0-1f9b-40cc-84a6-31c820a248eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44b356fc-5bfe-4a40-8d3d-755eba002ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76f74c9f-1491-42a8-8fbc-9159dc4b7465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0422fca4-b65b-44d4-8a63-5351dc91e292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45f1a099-7035-446e-aaf3-070fb31f17ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99ad10ae-6ace-4ff4-9d50-045061b5e9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6505423-a061-461e-b4d8-24870fb390e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b80b783-dce7-42b6-b231-08a8ab05847b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eb9fd8d-214f-4b33-9219-3d2c7aff9219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 037fbeee-0397-4e89-8964-30dd36360069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8f1959c-1e6b-42d3-bc17-91179b5c3501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2010b43c-d51c-49a8-8e23-fb1d42b93532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10a26ca9-129b-41f5-a9ba-b05bbe2bf330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8cf01b5-0fd3-4901-bd64-9c68347b5dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e74e5346-1811-48db-a585-7d54aeb48bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 017415b8-7929-4ee8-9326-d0556378beaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0872741-e8f4-44a2-be37-deedc4791ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f734528-e6b7-44f0-9d18-7caf11d694fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01706b5c-cc5d-4fd4-9559-8411cf50726a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06af1492-9c55-4f09-abaa-1999bc3cc8e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93c9e861-cd01-4060-ba32-b9c7e04a58cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e71d7f37-62a6-4ff7-b891-6456b505b575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fc30e34-d830-4c2e-8964-c676bc9d2f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4be13573-9eee-4a72-9562-b0d66335384f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12aac450-3e57-48c8-be50-441296dbafb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4144e2fd-030f-4cfc-8a03-1c0380c6b8cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73ac99b-bd86-410a-9383-9c3a07524004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e040f15e-ae0f-463f-9d5a-a71e4ecbb4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10b7fd7c-e860-400c-a16f-d0b8765053d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7a57521-cc6b-4070-9776-e18b77046e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3add079c-439b-4a64-96cb-f9f7a7ce15ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7e1b2db-1fdd-4857-95bc-d7fd5da31d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ca8f52-135d-42f0-a445-4347d423fa8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94a580d-badc-469c-89c3-f49417ed17a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70217593-d4db-4871-b783-e0534b0430c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e6adbed-6f17-43cd-a4ed-6d85714200be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00871ae1-a2d0-49e9-b2c3-6c4d59f2f40b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60b7f498-086d-42ec-ad86-86d56b55446c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93771af6-9397-4c2a-9624-44788f39f0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a07155-8edc-4942-a2e1-ba824d1a57aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a67c02-048f-461b-854d-366416eeba4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361520e4-208b-492c-ba00-b497ed181486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5685c0b-b945-48df-913e-1f3575d071d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aa3cbb9-e4a0-44d3-a87d-eca460abbdad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aed2962-3313-45b9-93b2-c918aef774b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11969c09-b4f4-420d-9837-41b29bae6374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79b87e25-709b-43a2-a215-276d26657ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf319700-c562-495d-8bac-f481850c5213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2f82b82-02a0-41a3-a6c9-54f9a0532210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67b5c4c8-44ee-4b67-bd72-9cd04e6f7f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 041aed93-355a-4fff-8579-c6974847b9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c96b544-343c-4293-a321-d460ff79b5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4009996-55d6-4554-95f7-6fab6d7bdaaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1605afe9-d1dc-4389-b57b-7982a9427515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5784630c-52be-445f-9683-34cd622f8390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a820faa-56c0-4447-b751-31c19f8014de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7ac0e42-e3bb-422e-ad56-6a03c6499121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00a38a4-87e2-4ece-ae14-b2e4e0460b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9725706-8baf-470a-bca0-f9c9b0ce6c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 216d2ccf-4ecf-4a4d-ae7b-8af36a9dda78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df3d3a73-e9d0-4a48-9b90-722954824b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6945288e-5c01-469a-b9f2-d50dfea43b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a447b6b8-8b86-4a84-983c-60dc12789082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a24723fe-00fa-42ce-a990-96b28850471d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5dc9309-eb23-48a8-bdd2-7d3f0273c334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56332e48-96d7-49e1-9d84-db42a5a8315f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b696b83-2536-4558-a407-0d176464cd69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3c454d-ca8d-4dca-bf9e-b4585404e5f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa58acf8-0d0b-4518-975f-838cdb1bef4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8b1957f-11b3-4c74-a525-ef494f409fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 541e95f8-382d-4b55-be40-a7dcad271a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9378d7d5-55c5-4628-bce4-adff7ac80693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4110a1bc-8fc3-4629-9c69-2b04a75260b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f28e48e6-7c0b-485e-b434-71ce8bda9e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b79d9d0-8e5c-4b34-bb0d-98d40b878e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b65456-a5f2-4fb1-823f-eb9f59ef292f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1980c776-86f6-4480-9fb0-36bd8334097b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b9a2b0-c205-404c-96e2-e18b506e61b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14865b59-c2fe-44ba-a052-39f2b2a12193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 626877f1-a968-4cea-a5ae-d673501a4857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b4398c7-6a9e-4524-9074-6c2fac09709c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eed8b6c9-8e87-4d11-818c-2a9acd172fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a341aa-1f65-42c6-af29-46cc3525d418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4481eb0-9d5f-4c35-b0f8-240d7d499a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7674cefd-003e-4175-a5aa-fab7019da83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf4915fd-e6c5-48eb-b20f-9140905126fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50b68621-73d6-4fcb-8a90-17cdeb97257c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aceaa401-2627-4d7b-b386-4b80ca466dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 606f4de9-78e5-465a-b2a9-dd91ea62cb06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 438e1d92-bae2-4e9d-b1ed-268e8f3afdbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b49df2f-d65f-4739-a5ae-6b0e454b4e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 642428eb-6660-4896-af0b-eb95d7405677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a73b3f-e283-4c58-8271-cfdb80bac27f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 687f9897-20fa-4b53-afb7-405fa41928cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73493524-638f-4486-9caf-49d26b430820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d2e17a8-c62f-48cf-a98c-645121250ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76cccb29-b9b7-425e-9b40-8d5439ebb8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22fc81e7-e624-4c3e-b18e-0695b2cf7d2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe65496-ea67-46aa-a673-5c5a3430e0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee97b9ac-6e11-4977-b22b-8b8c74e9599f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b768415-bcc9-46e7-a173-6f9076789acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d7e7999-751f-4c35-a994-b0738ae682bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e697ea24-8162-4897-9750-accd8e262485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d816357b-57da-4129-8467-22c22e7725bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49bb90f0-0e15-470a-ae32-6420fe55737a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93db402d-a349-4caa-941a-db187ac20c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b165b24d-8979-47dc-9d52-0206cbc9c434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e92e861-b3c0-4798-89cb-f621bee55837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a186fa1f-ab4d-4d03-ac24-6e914024bca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e8d6032-7a87-4f0e-a55e-f663fd910ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06a65999-f30f-4123-931c-85481852e3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 184b7497-d317-4960-a3b2-f93018b3b602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19cd98a1-15e5-4d44-ba76-601d2a72c231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eafb22ee-1222-4ae8-a152-88b82caa157e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da815b28-c57a-44d3-a7e6-3b6b86b2a3cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d440e9aa-e706-4e83-a578-41be4767dc26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30eb8d90-2f0d-4f3e-82a2-de8f2d9901cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b409c574-28ee-4c0b-b84b-dcb1e8ac4f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3971b2c7-4c6e-4d33-ae19-fa1525b62f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 443deac1-1b93-487f-8761-70e4aedbae89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da27f85a-0156-4706-8d49-4b23ceb5bf00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3520a9a4-77d9-4785-a258-98bc8d15b953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb1eb68c-2339-4915-9071-8eebef343d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e2ecc9-c3c1-4647-a269-8b4a04466710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31ee6b76-d1f4-4c99-8dc1-015267a58d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcdacf0a-e4b4-4508-88f1-4feebdc5f585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1713159-a6c7-4c00-b473-46d3ef2bb28b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38e38746-ada4-4a24-a230-074ea4a7b70c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 748b29c2-0caf-4be4-a0c8-6bd64f293e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 621bbd14-aa92-4f6c-a713-bd1899d7e340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d759274-9829-4b4a-b89a-7ed86a6e4f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d81b7e7-1b2f-41d2-80fa-512d2b891db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd98dee9-bee6-4942-a4f1-b252d03d30a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef22383e-727a-47c0-8a12-88a68c1b4c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 608440ae-bca8-4086-acf9-3cceb15f6bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 155e3485-745c-47aa-86b4-d4430fa4f5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec51318-5c0a-4377-b835-15b3af530c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81baa655-a8d6-414e-9c29-07022ab628a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d39aa295-3f90-488a-a9d6-0d1883284ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65c1a8c5-0316-4a84-b0b5-b3f774e8da28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a3207fb-b161-45e0-b10f-615a2f79e60e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3bdae37-1a9c-49e8-889e-1ffd523bc564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a79c683-da20-4bb1-8924-cef92e1be942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921f1b38-0b74-4f6e-b9ae-780004e2022d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a147df46-8496-4d36-b2ce-f0d4f4a451c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d3b9b6-af90-47c9-bbe4-d7466f299fb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa3d2022-4566-4d17-9adb-dcd438af1436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974a5e7b-325b-42be-9f49-2a3a153a3605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38ba4072-30d0-45cf-98d8-d300999a73a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c6b80d-e542-4b47-88c2-c4f002931a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec2f5b90-ba78-4b4b-a3ba-19b1b507652b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b571e8d7-01b0-4131-bcf3-c228244a9d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce9f8bee-a339-4bb2-9e0c-3c5f97d385bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eed8f5e-fc5f-49fe-b014-4a40740b4368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 966773b1-a557-4f0a-9884-a07ebe81efe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 217621a4-abd7-46e0-b71a-6fa2a8346627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4da7bc8-1f6b-4c33-a5e6-7b6186f1b76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a4e6206-84e1-4d3e-85f1-67bd14fb69e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50650a30-4ba9-46e2-9013-a632ff6bbcaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b4e2639-fb89-418a-8064-14d30596f8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3513f819-a7e7-4407-b53e-7a1ca9e84ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d5a68a9-61fd-4dbd-9cb1-2d7c55d0e5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b295eef2-197a-4c67-9034-5a25569e0214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d22280d-375c-4755-8724-5e91ec2b7303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 604252d3-d42b-41a4-9773-eda074362db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e73b9ac-675f-40af-9508-051f63b20da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0eb131-5a31-4c1e-8d42-2a6194ec9511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8d921af-a666-46ec-983b-e21cf0f368c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c6e4b08-5c2d-4ed2-a633-bddb56a37c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98be572a-fb9b-4f78-8fdd-0eeaec9a4b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcd426a5-29cc-4ba7-9777-0fede39fe602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 512c1b90-a73e-4a9a-a456-76dc3c1c3a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fa149f1-f2d3-4835-83c8-9957c004fa90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a90627b0-ed81-4f62-9db7-754595c2d129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee1cb30-acd2-4b28-98d6-b1ef86c3a178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0128f58-4750-4ba2-aac1-49ef248cc218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c10819d7-c9f0-4385-801a-44aef4f6c661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df89f6f-543f-44e6-a112-cfd4922c24c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4183c5a0-70f2-4912-ba30-8635a9d5b058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 300ec60a-bf45-4e2c-b2a4-7e200ac97042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cb4a7b8-dffe-40ce-acc3-5f70512ebdd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33752652-8c22-4a9e-9a6d-9a75fe8d9c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0a45055-7e89-4de1-9823-9f34dd73c519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 728cde4a-0c13-4178-b533-75f28863c5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25fe34c9-35c7-4696-824b-5a10afabbde7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a024743b-3768-4838-bedd-600e2906a8c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef612fa4-103b-41c3-a6d5-4b8fa4b32a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b3ca52e-c0d0-4c37-bd4b-3b873ec149d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f7bcd3-8ffb-4007-824a-5783918bfc55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f33d4f8-f83b-4c8c-a9b3-25e578a862b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e00084ca-8746-48de-bee0-39c13f0a0bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec5375dd-96e6-434a-8167-2e8216247895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 360bf417-3dc0-4c46-bc47-119004021be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78d75ad5-d496-4396-a62a-c999840b027e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7965f2f1-4b15-4dfe-a13f-7196cfb81f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6efb94bf-682e-4d1a-816e-a1eea8708d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a509e21-b2e1-4146-a4f1-c72f5d1fb2bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 485a218d-9dfb-4ba5-9ca4-15bfc48e0e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f48c1ba5-c397-4819-9634-1e112ffb0928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23237e04-dceb-4b1a-abc6-fea456e3b976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9832a01c-7c08-46b8-8e3e-ec19d54d5599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 722938b9-1f79-4a08-a675-6df70d631940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 322c44fc-3a6c-4e26-84f5-e1e4a3b871ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deb723c2-5c6d-42c5-8c2f-6c537ae5bc48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 526cff05-370c-4c26-979d-fe4b14c579ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3ec6101-9526-42ad-9196-53cb4f9b308f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 136c1f7b-e578-41ef-b660-418b5aa40e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2183753-69d3-4982-b8ba-46b0f6555ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6553c94a-f1e3-4cdc-b3a3-4907054f21a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 050a4c60-3f23-4aa3-83c0-1627fb3e78ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e64a6fee-101f-474e-8a7a-e1aaa9770302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b3c241-8529-4b97-98dc-a40590c824bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42d7aca1-01f1-498d-9f64-e330ad08b019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3e5e304-4227-4caa-aeb0-938052ead7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04fb4dbf-9184-44aa-bb9a-6682e03d8c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 126c55df-f496-49e7-9439-90991fe263b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c458b65-8e05-4037-b6ac-0f424708e350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b339f64a-1487-4bc3-a3b8-1abc70b80827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05daa467-2e2a-4a93-b0e8-4a36a55324bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be81175a-f55d-4545-a88a-b1563a83e28e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d7865cc-8971-49e8-9dbc-ec83f03745ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f76b30-9449-4fe9-a93e-28e192799277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec8f5317-d559-4233-8c62-bd5ff26e0787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5342b418-397a-4b50-8bc4-56f515764d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aca8fbdb-7f76-4df7-83f2-a5128b767de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a17942-b8d9-47f6-8d73-5a5626bf6f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1d448c3-3431-448d-9bac-b872fb313833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61e303de-5576-4d43-a005-046f235d1b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb211c21-44e6-4b35-8445-16baabb7e476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d07fb6b7-4638-477d-a290-4dc2a4ea599b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49369c83-e97c-4d11-8152-63e4bc26143c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 306584ba-a8f6-4308-a515-d09197432b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52211cd9-6167-4501-aeda-7c5680df056a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17a93d56-4127-4581-8e95-be4489bebf7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e3df58e-e6c2-444d-a390-60fb86b79c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65415e73-8bf6-4aa5-828a-bd5c8270f02a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68060ea9-4dc2-4f8e-9970-2ba352c9165e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e806c658-93a6-4be8-b9ae-569e74e7473c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f746ab5f-d731-437a-a065-e2fa735754fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21257333-2f32-4592-b886-34e2ba3ba0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1042047a-3d8c-40e9-911a-efeea5d82904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4584caa8-6c1b-4156-a4ed-7a171e8fec6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19c962c6-4e7a-4359-b5b7-d3d96a94e8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b11414e5-6580-46c4-8c1b-b46a219183d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9889987-de48-41a7-b380-60cc9aeb6f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b74c2e7-47dd-4639-8cf1-833b3eac9a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82bd1c51-59c1-400d-b205-711e8ece5c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56c237b3-02ad-445b-be4f-3d16857fa3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ea4d1c5-f72f-4856-8843-c0173f34d2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e017bc89-2ac7-414d-a46d-14cd885bd80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9dabbf-aa8c-44a4-b7a9-bfd4aa4836bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d1b965-e8c6-4a56-912a-0e324efdbb1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d722ea93-bed0-470a-8b0d-f4d3c9f043a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea2753a-c597-4fe7-9cd9-23aef6ef7d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce7ae0e3-42fb-45ec-b707-98cad2b0e4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e54fbd0-3e27-4676-9c9d-24223a72f7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd559e1-fdaa-43e1-bf59-652729083418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12d5d3f0-6ad4-458f-a332-4bcb577cb56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f6e6980-6f13-4a2b-86e9-173de3ae7987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 161263c9-4925-445b-89bd-c7cdad4c0aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4539b4d-4d87-4e2c-9bb5-ebf2b14e4fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf19a4b1-c359-4c93-abb3-03347fce3a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc50b51-3a23-4a02-b827-b08cb19b147d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8562a164-f3d0-4150-aca5-ca0682a65e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a293d0ef-3fcd-4775-ada8-1df9bf35f572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b92d4318-e2fe-4d71-844d-fe65c08e2add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeeb1fe6-55a3-4b45-83e5-bc04e290c0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9dd023a-9a20-4d3e-88a6-2474f6cfda72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 157b1676-85d6-4aaa-88f0-46ac25f4e09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ea7519-4f0c-4d3b-ba6a-18f642fa1959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 498490fc-eced-43e0-9682-73e7385529a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 151f4736-3fba-49d2-a942-1af531dd345c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa795984-3d3d-40c9-ac2d-7af5e04d9f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d62b6d67-e98b-430b-981b-c7141b275594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bab0623f-0f39-4aa5-ad1b-1f85a570e219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c52eac-db8d-4c50-8e0b-d42cf16d015d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f633f95-bea1-4abe-bb23-7b7f8b80a45a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3993426-68c4-41a0-bfac-49c3bfc74980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ed76ff-554f-4141-878a-59435270ce21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1320662f-af44-470e-b793-21c568161564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8040f30-8b7e-4dc5-99d2-125b9419d235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9de8a74e-97a3-4bf2-b0b3-302b6ef97ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be8707eb-488c-4af4-b95d-ffb67e62b4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65037ca4-51b5-43cd-a924-4ab7f526b46f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f548ef96-b073-4198-8d2e-30bc6f917198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea2337b4-e811-4aae-98f7-85f7f8ecd467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7147340a-a3c1-43ed-a14a-ccd85e7e9bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b940e3b-c852-4d06-84e1-eb82fa57720b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b622e0a-be32-4013-8b76-eafced2e3f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f866aa00-33cb-47d7-8eba-59c2fbfba488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae4f967d-66ff-45aa-907e-535cd2f67e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61635de0-3671-4074-bae4-24beb102ade8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aefb4768-0cbf-44a7-9043-799e51720b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2b55409-093e-496f-95b9-1aceae81fe24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81f6761b-c848-4acd-a630-2e6ff29c99fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 526685a9-8f5f-4b61-b3d9-c45b21898872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e1f061e-86e5-4dd1-bcf1-39da00652aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e86eed36-34ba-49c8-9aaf-080503b0e02c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c21852f2-56ed-4b16-b7da-bf92e8a20adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0e6c2bc-3b13-40f8-bcec-cc30fc04f8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3898f3bb-9711-4c09-bfc7-755878867e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9191db5-5470-4a99-87f5-ddae9c64029c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b3208cc-d1fc-4641-aa53-a6b10cd4e66d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dfa424d-dc9d-4296-8901-0d9888aee9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aaa35cd-d949-4408-8eb5-13301e2e7069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f04d538b-1903-412d-bf7a-c8e8328b3315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f1b6e7a-52c6-48d2-80b9-79586354a821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 752bc30f-0970-41ef-9ad1-88b369c9a3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25891295-dbb9-4abf-a917-69f6a5f6c54c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5749169-2e13-402e-b4c4-1ff6f541edfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e75747bf-f978-4d9c-b6b5-9874a6a16e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e9bd502-7625-473d-91b4-c299c8e50f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e0f50cc-cb90-424c-92c6-7fccea09d1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b393ac-59e2-4def-ba87-4886cdba93ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a98cc35-e52c-4cb6-aa2f-789ecb048d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1298ce44-e7d8-41f7-aae6-e40d7c1099ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d647f82c-b29a-4a3a-b2b9-c3020a7c896a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 890cfad2-6d9d-4c1e-8e74-4c2a2cb92c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c860cb72-ce0e-418b-bbd2-21b8cc306e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05dc6c07-d4e3-4257-86b0-95773aba133f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d798b4fd-0d7f-4d89-a0cc-2e8a0eab74a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27269209-3615-4101-9df7-e69b334c9f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4bf2e2c-502f-4826-bc3f-79c3e36630b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe0cd23f-abbd-407e-abb3-35227517b1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54164427-3071-4d7e-9c19-abf5b967a367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f06b840-c3ba-4cbf-8f59-dcc24dc4a7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11b33f7f-7f33-4ce6-b880-05813d802868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3099795d-1b8c-4de8-9c6f-b74369e048ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2afa9a7a-d868-41c5-8e34-b7464460eeb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afb56520-6c98-4dc4-8933-a127b9296876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af52dbe4-2749-44df-b95d-8bae0f0ec67c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef18e401-1e43-4b73-8a03-7a17b5f1e102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc28c1dd-e82d-4922-bcba-4df03b5ca31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 899c01fb-b1b9-47d1-a3f6-e1bc0785fbef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e41e6d80-27bb-447c-b1d6-a39b0313d7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9380e2ef-5df1-49d6-a67e-92c06e57c0be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 250f2a25-c631-49f4-be47-dd330bbe2085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f67e1221-e634-4bd7-bd2f-c7d0f01cbf39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4077146-799b-482c-b489-fe80117f5385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd23121-23a3-4192-9371-580ad52d7c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1871a578-e287-46f7-9099-058d2f33f29e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a041e2-d7b6-4596-9d59-099a511b672f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5427878-59b7-4147-ac5f-f2eb81622d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42d8a24f-6374-46a9-8d11-6b0bce905b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07cd160-6f83-454b-aecf-c21878796817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 059ef931-ee05-4485-b164-e957cd76848d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95f39126-9784-499e-96e9-32d48e788811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 180071fd-d310-4874-abb7-0c1068b71776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c1d7b8b-8b57-4728-882c-04a682c97539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f574912-30fd-4aca-95ff-93f7bfe37185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3e3313-efde-44b6-b932-793a1b227c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c69d5ef-64df-47b7-ae5c-d5ff24989874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8a51b43-6e26-4cf7-8b3c-846909318841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 760c6388-bd46-4f6a-9afa-e97d2f18edc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f24609d4-4fe3-4faf-8999-ecf4ae5ddc55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c31acf2-e5a8-4463-9267-cdf800d11010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e9be564-f614-4fb9-b5c2-742117850762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb15881-e3b7-4b1a-9642-5dd24a05858a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b30ca32b-3624-4686-a297-af299bdce889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37c8bbe6-f722-40c9-b151-a1e9b648f78b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 236e3882-724f-40e6-a5f2-41e531cbb968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41eb148-78a9-4733-bbf9-14eab2c16c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccf11ad0-e449-4fcc-9ed1-31fab702f51d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a87a276f-7c84-4e00-97ed-76c3e7c03aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae727e9-20c0-49fd-86ce-0cd1fc852e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc999324-9adc-4a4f-99b0-42f0ef193f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83fb318f-3b4d-4111-b610-25eed0528850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b90c4e1f-514f-4999-9597-70510f1a8861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20358692-601b-41c6-a084-567b75b9d6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 123a27fc-35da-458b-8982-638de28342a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a54120-1f25-4269-8dfa-6634c4c8a1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58967d5b-9e76-4aa2-b0ca-72fdea07128a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56e47a04-d976-475b-b31e-ce71ff78c176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9108fdd-ba48-4443-b866-762317789227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fe8cf1a-516d-42c4-8da5-2aecb2988e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 026e07fd-5573-483b-ac76-63ef97342c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d8bcdf2-72f5-4fc4-832b-8dccfe083950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa6ea41-650b-4f1a-948b-596e0acc3cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbb42d0e-335c-4c8b-bd31-388aeae72c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d92f2bae-0686-4755-9ee3-4a3fff6dff28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48e43a9d-a9bc-47a0-989b-56855a6d8df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eddb3523-8bbd-406c-9396-da34dcfd5d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d14138c-e1f0-4c4b-9200-b6fe8511c0f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c13f46-3d6d-4c98-a9b2-c5e7124743dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abbb43f3-8abb-45cb-b87f-2e4ed54ff22f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f1e641c-acee-4550-a5dd-c76f222284a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88d18626-cb17-4ede-ab99-0fa56921a70f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66bd1111-2873-4976-b8ae-dca53fa1a113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 636e1797-03c2-4a52-a7ed-56eb2698d199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3321422-0926-4f06-a0ad-f859bbd1b7d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c867941-5ca1-450b-9058-0d14b057e2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca64594-abfc-4c4f-9e0e-fc2b883825d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a35154b5-c32a-406b-83fb-73aa08a8a38a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 112973c1-7c28-437c-a686-79de3771b025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc576416-d070-4e3f-8ca2-d739b904f795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 643aeaa6-e3da-4580-a912-82f1e3622950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 324ba06d-5bfd-4ec1-8330-1bb8619f2a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff5e1d32-43cd-42dd-8885-f988f2a823dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 607fc6f6-9325-492e-a9e4-a0ab2a7f12f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b00d7dc-271a-4f8e-8923-fbf72e55519e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 065557e4-533d-49ac-9478-221c2cd9d1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 544dbee5-dca6-4139-b794-d7d19b0df750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2dfc281-b0a9-47bd-9b24-11bb837b36e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20fea883-aeee-48be-948c-ffc8b97b8131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1b5448-3069-4bec-a31d-fb8b7374d1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a73a0387-0c51-4032-95b5-a328ebfcdf76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 582bad2a-445a-4147-b336-77d8dc807032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99c81960-b9c8-4354-95d2-6609cc814345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff0c2079-2067-4faf-8d6f-cef6bfd89af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e799ddcf-9fee-4e7a-85c8-c1a31137f6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f5f3eae-9b0f-4cf9-afda-e975d292479d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a6c41c-3b08-4b61-bebb-9f8b8f3071dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afbe20c0-454b-4609-8c38-a622ea68907a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 451aef68-020f-4834-a576-b869f357307d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49260282-4e54-44fe-ac41-359c9425fd1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45ae48c8-9d46-41fb-92ea-ca4c84a2bdbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32d5a3b6-bbc1-4500-a0b3-a53573146f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32d8ffa5-ffe2-437c-8ced-99f94b4b02f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b534a0-0395-48bd-b239-4db1a3873fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fd999a9-042f-4c49-bada-5d2630b5def3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 811eba62-3fb1-4877-841b-a5a13a0b7644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5eeeab0-926e-4769-8a30-f9db9d02e650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c655a145-fea0-4c6b-81df-9c7a276ba0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a944f07-f17f-4a13-a6c9-3b89c1ef9789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 954fb6b0-0bf5-4523-bbb9-a5a1a105a619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a6c9c14-57f9-4802-9070-1871b0cb24e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ca532e-4afb-47c2-968f-6669306c82b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d182f9-0703-4d2c-8c4e-2e3716f904be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad38dff-8eee-4003-8a2a-4cbfa07d3535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd9b6da-5f4a-42fa-be74-56409b1a465d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84e82811-a71f-4b5f-a8ea-44032de85515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6894317-08d6-4a8c-aa97-ba5eba7b558b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a58c835d-c215-48c9-a9c1-271b8118538c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e15bbc9c-2625-4f07-b4ae-940e6fcf79a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0bc23a6-86b3-4a6b-a3b6-39050fa1d810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 324975b1-254d-4cb7-a1da-3872636f081b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e31506d-9650-4797-80c9-aa9b447b95d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32c2ae45-9c3d-44d2-a86f-384a15c4beae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2cf9074-3caf-4b39-bebc-dcb7fc2ead87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c04d5dc-6da4-4270-a52f-65e7054a5e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c36d1f2b-977d-4fd4-8201-83c5c04a1736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23b0641c-9bf5-4186-9959-b506c11c65e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a56a122f-bde4-4912-94cc-9710f9c310e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f440b1dc-d9bd-4291-841d-3c816fba60eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9002e5a7-3348-49bd-b91b-24d201071eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fff9ce6-7c88-42bb-acc0-a56a2e216220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba136ae-b5d2-4944-a76e-4aafc27e642d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 319a4a6a-fe8f-42b0-9163-4932da7f035b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acc3d3e0-8de6-4088-8278-bf6be992ce90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c7b9170-d926-4f9b-8506-9ff96f733592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 969f76b8-9025-4bc0-9020-79dae2ff5293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70c558b9-9389-48b5-8d7d-63ed061c528b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c05ceb12-bf27-4c08-ba0a-82b0cc7e9de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc9258e0-3673-409a-93f9-38d0b1ef786c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c40c35-a190-4d05-b912-8b1bcf52b172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3124a0f4-a355-44cf-98aa-ab55c3d5ba3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31afe0c4-cfaa-411d-967c-9fd1057a9215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84081fd0-4c98-4065-8a01-cb2fff054115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be60575-23e0-4c6d-bd55-b322efd4b3e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe877698-1777-45e5-8d16-c02b7ae0a6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76977a12-a940-4d6c-bcd3-bfd301dc8ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd611efb-e089-4097-bde8-4cb988363ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96326eea-3479-4a4f-ae6e-1c02427c0ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eebd90c-4e9b-41fd-8579-d395a3f7f99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 837e8d83-e912-4ba1-9cca-b5832dac54b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 871b695b-b88a-4dba-8a7a-51c01abb9dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a097345-b752-412a-92f3-b901e463132f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2974fe36-b433-43a4-b7e1-f991a36d4c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea1c73ed-71b0-47ec-8648-f67579326914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b10094-2514-411b-b83b-792a68c83cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655924be-fcc3-4543-bc3c-1a2be7be488d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef4e27b1-9fd5-4e5d-9188-a6a6c7f7d941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 155cbbf8-2c52-43e8-9557-3786e9df2fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c26bb157-9fb0-4cec-aada-48b271e6199c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87ef52e5-80fd-4111-b45f-310d02b712b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 310c4a92-bceb-4ea8-9c31-fe2a06f89867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d01dd987-76c9-46a4-ba60-118777c4792a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 281adcfe-7387-44fd-a535-42a4d47d2e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35283f56-a558-4d27-8137-3d8011a25f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2513bfff-5231-40bc-84d9-c560007be66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf2c300-ae77-4dc1-9c72-f7afab5c45d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a5868b1-8083-4476-a304-aa6dc449207e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6e3e65f-1c14-4148-a728-ac2ae8c5f728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e102784-51ff-461a-8c6d-760de37888d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17607ae3-85b5-47b3-82ba-a31c474cf2b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d44543-478c-45fd-a57e-7ebc0346ac7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b10261b3-b0e1-4ac6-bf45-0a8461348646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fe86a6d-80fe-4af1-9ad2-bfa809059447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80463db1-4f8a-45ee-a0c1-f0de857db1c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c88ed8d0-4f38-431f-8f0c-62d68a77d40c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92eb647f-6110-471f-bf0f-4057c778b9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a025757-9519-433a-a4e3-bafde5ceaaef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9334ba20-3eea-4649-90f1-cce6feef9bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbff7a28-89e2-41f9-b205-883ceceb9cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 302377a1-6cea-467d-b203-b3df2d527856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce8d1652-fb89-4580-8589-69d7c3662f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2066ed28-0461-4b67-9c8b-c3c147937888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd13e95c-8daa-4a0b-86d4-91f04ce5f265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edafae68-99c2-4d3d-8070-c7787796aca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 312a89b8-bafe-4088-a629-90f77712809e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a7e6b5-af1e-4e3a-9dfa-45a54c938742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 202d3d29-5516-479a-97a4-ba8642dfe468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccace9cd-3c1a-4024-a163-330f4e58a8ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f687e89-7883-420f-86ea-584fe4ffbc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea5d6d5d-192e-4b0f-ac03-5ded4c6f585e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ff46893-1d2b-4dbd-865b-44242e6f8e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b314e1dd-c842-4216-9376-3e6798d321f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be7b5d32-4aac-4c37-be8e-f312269ecbf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc6876bb-794a-4ca9-a2c9-f45f38682d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efe54726-048e-4f9c-accf-47e7aebe2778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5857d43f-4634-4070-9f29-0f29c607f4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f65f20f8-665d-462d-8c1b-b2170b4324e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 432abc30-4d30-4603-ace8-0b18139886ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fdd8cfb-2b5b-4e0c-80ab-e73bd504f5c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 695ba203-115e-4814-ad8f-52382f001df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ae8a4a-430f-468a-8911-38b61a7e5814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d949ced-2a84-480d-bed8-ac5fc600f531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58ff3917-276c-4104-a58a-b2a563c1333b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c2600f-bdec-41f4-ad81-62615618cf52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 452b7679-dcf9-458c-95ec-901311d6da25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f6f491-7a9d-4f4e-b8b2-06ab869f76bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa4d072-23e5-401c-b29e-737312263807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ef3aef4-3a8c-435e-a67f-5b94bd04b56c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c4b48a5-252b-49ce-ab4e-5fc956a3424e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4b5866-aa30-4429-8b48-c22a5b6c5421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92d1d97e-830e-4657-8c1e-e05fabc261dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47ba0240-296b-4667-b095-415817619f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b5fb37-d74e-4230-911e-07359b861657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfccc33f-1449-4f06-b576-d4ec9fc99bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b078ded6-c1c6-4f74-9c80-38c5c745967b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec5708c5-8299-4207-a891-04d1b75dc541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee191b3-f8f6-4d4b-a243-585ea58c3b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d2e801e-9015-43c3-980f-f2e96498a278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9f0a019-80e1-438f-9bbb-13adbf39e854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4df9934-b622-4c6d-a1bc-e605fc238766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b859cf0-6aef-41f7-ba07-f8fc70de92f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18ba5d73-e7fa-4c3d-88a1-cd42b1f67914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 727e6be4-2098-4a8c-8679-ab8b4570ddd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f5aad0c-5d15-47e6-b2ff-80595223f80e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f9812d6-8fdf-4675-b03f-a0a2d1f24f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49af120c-e5bc-48f3-9ea1-226252e5371b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e41b47c5-0e14-4d57-a10a-5549ee8929b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0afea51a-86b1-4733-846f-e5fb6cf1061c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e97d9d5-b64e-4a78-819e-2684ca32b73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c77984fc-c9dc-4e49-b65b-7f14a17e8578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be3be790-b75c-41ba-ba31-3833e80b057f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bf489b4-9889-406d-a9b2-d2ba0ee5a860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65d3cbd-ac12-469c-b1c6-86295641f4a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e417341a-fc01-4283-a0ca-7ae48c113194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19151dd6-9d42-4301-a933-147afa6d0587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 065734fa-6eb8-4d9b-83c4-18e860c685a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7c7d62f-5a84-4995-9547-4eacf1b6fd77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 566b9f06-211e-4c91-98f0-abeb394bce84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ec4b37-dd6d-470e-a733-4d490f679b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e4d5120-1f08-4577-9fd3-758cac370d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c12608-6c96-405a-93d4-c8e725b41bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc2fcd17-ff02-4a10-9500-7bb1f9e87ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c3675f0-cdb1-4714-baaa-cb43bcc001cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18397d2-f68d-4336-9b77-40be2b78a04f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bf97038-65e8-480d-878d-4c9c71a59ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f8d97e5-cb8d-4b25-9f6f-baabde1dd3af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f17afe6-df3d-4c71-a667-1ecaada45c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50f5e38-4bb8-43dd-8d83-ac4b123c8fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090c2771-9d97-4ee8-af48-59d6fa316aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b4343a7-cb51-4c80-901a-74e5e2a8c11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff64927e-38b0-49ac-b040-c5f5754ef81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5edeb560-afcf-4269-845e-b721caeab381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecf15576-c11f-4950-b54b-d666522255ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08112316-c361-486c-bc65-f8e771b5167a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60566687-0dc3-4e6d-9c95-126fef796a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9daff80f-ed58-4a6d-838e-292c6417e444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fafe83c8-dd65-4eaf-8bb9-088e939d10cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52f8e823-e7ca-4c23-85c6-9408d19a0934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 386ece7a-d2da-4843-b3da-03b87e3e9f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd7beec6-fac0-440e-9929-7d4d5858f74e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16143978-0b03-48aa-83fa-69499b57e783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 356e2355-c5af-4ac4-9b83-76aecfc3c448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93076cd3-2b85-4f99-8875-a6375c2f87fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05c8f85a-3ded-4cd2-960f-68f35ba8b1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c9a8325-0d2d-4ca0-8eb7-1cdbabf59a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 492f5916-ed4d-4061-8d40-e6e8a15a9bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 932bd801-c766-4d00-87b7-343a5c81887d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f77cfb7b-ed1a-4fea-8d7e-177081309f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c41aae7a-753e-4dd1-b71d-ccc72c7e6601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92bedd2a-00f4-4892-af96-84f21811565b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a612afb5-f70f-493a-8284-8d0d8216cc78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98e1ab83-af60-4f17-8055-75c9e328f71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a757eddc-dc59-48b8-a69e-e610f3d010bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba7d8002-5106-40f6-8c35-dcb2123fbcba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81b4720c-b021-4045-916a-5a2a2e7f8184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a9c18de-0d2f-49b9-b7c3-bc610a474f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 393f49eb-3c33-4943-9599-14ad1790d566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 890e974d-0ed8-4972-96cd-5dad7ce323b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 663d5dbc-7ff4-4a1e-9864-d87dcb9a06c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3681c782-97e8-44e5-83db-252998654039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dee52512-008a-4155-80bc-2552f9ce9acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ab58acc-9a7d-4281-a03c-1314a68e9b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71d7fa10-8f61-4a03-bf65-fd05cffd0011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c5045d-b3f0-47f0-9721-90ba17cf5f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5924285-2552-49f7-a73d-cb30b41b84c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5619ca4-f655-426a-ad1e-47a47182da81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b9c6fbb-8c60-4cda-9b2d-7d43a92882bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78acb700-d12d-4db4-a307-f44df850926b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d03617b7-88f7-4042-964c-f03215a68525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692eef29-9ce8-4746-8267-630e3ac63aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c16995-db4c-4d02-a687-c847c0fb8a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7efa332-aaa3-483d-8d33-ae16f6e7bcc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bede5e0-2b4a-4c30-95fc-9be8a1b09986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed72df8-faca-46f2-a134-26996bcb11e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5388d530-116c-4e9f-9e16-5eda60cfbe78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3a8028a-ff20-4a6d-b7be-c89da0f4fccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14717b09-bc73-4a63-9655-dd7aaa7a8d96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fecae696-13c0-4e65-84d1-eb1352246a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8521a383-110b-4983-9d06-cc81f34dffd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f5761a7-7959-40d9-a0cc-508403fed400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e71a78fe-4b74-4f99-8057-51ef3ab1b315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 306fdd13-55d4-497a-888c-b277e9414181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f85c47-528c-40ce-8f78-ca5507d2f6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 008cddbd-512e-473b-b004-6c7e4ba67e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2372af52-29a5-47c4-a26f-3f0d55c9a0b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdea15ef-4a7e-4883-98be-2ec03bbdc31c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8833b37c-66e0-45a3-85de-8b13d89d8d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f0b3a3-033a-4489-940f-d2546828ee4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a755d2e9-ca51-4de5-a029-c330b60648f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 416e5b9a-3090-418d-8dea-8ac517deaf7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8795a5e-d970-4e47-ac2f-162dd04e8631
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_16
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_16/test_labels.txt

📊 Raw data loaded:
   Train: X=(3836, 24), y=(3836,)
   Test:  X=(959, 24), y=(959,)

⚠️  Limiting training data: 3836 → 800 samples
⚠️  Limiting test data: 959 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_16 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2528, val=0.0881 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0902, val=0.0849 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0813, val=0.0810 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0797, val=0.0803 (↓), lr=0.001000
   • Epoch   5/100: train=0.0793, val=0.0803, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0787, val=0.0800, patience=7/15, lr=0.001000

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 1 Summary - Client client_16
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.001000 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0068
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0150
============================================================


============================================================
🔄 Round 2 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0705 (↓), lr=0.001000
   • Epoch   2/100: train=0.0825, val=0.0706, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0823, val=0.0706, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0820, val=0.0706, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0817, val=0.0707, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0794, val=0.0725, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 2 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0178
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0029
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2382, R²: 0.0009

📊 Round 2 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0035

📊 Round 2 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2383, R²: -0.0004

============================================================
🔄 Round 8 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0833 (↓), lr=0.000250
   • Epoch   2/100: train=0.0780, val=0.0838, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0778, val=0.0842, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0776, val=0.0844, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0775, val=0.0846, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0770, val=0.0849, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 8 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0052
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0028
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 12 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0704 (↓), lr=0.000063
   • Epoch   2/100: train=0.0815, val=0.0700, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0815, val=0.0699 (↓), lr=0.000063
   • Epoch   4/100: train=0.0815, val=0.0699, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0815, val=0.0699, patience=2/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0813, val=0.0700, patience=8/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 12 Summary - Client client_16
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0063
   Val:   Loss=0.0699, RMSE=0.2643, R²=-0.0100
============================================================


============================================================
🔄 Round 16 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0837 (↓), lr=0.000016
   • Epoch   2/100: train=0.0782, val=0.0835, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0782, val=0.0833, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0782, val=0.0831 (↓), lr=0.000016
   • Epoch   5/100: train=0.0781, val=0.0830, patience=1/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0781, val=0.0828, patience=7/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 16 Summary - Client client_16
   Epochs: 19/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0039
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0313
============================================================


============================================================
🔄 Round 17 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0795 (↓), lr=0.000004
   • Epoch   2/100: train=0.0797, val=0.0794, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0797, val=0.0794, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0796, val=0.0793, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0796, val=0.0793, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0795, val=0.0792, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 17 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0029
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0005
============================================================


============================================================
🔄 Round 18 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 18 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0074
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0017
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 22 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 22 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0015
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0358
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 22 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 22 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 26 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 26 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0014
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0112
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 27 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 27 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0016
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0114
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 30 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 30 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0000
   Val:   Loss=0.0676, RMSE=0.2600, R²=-0.0274
============================================================


============================================================
🔄 Round 31 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 31 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0024
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0034
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 31 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 35 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 35 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=-0.0024
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0098
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 36 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 36 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0077
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0047
============================================================


============================================================
🔄 Round 38 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 38 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0069
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0100
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 42 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 42 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0008
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0169
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 46 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 46 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=-0.0033
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0008
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 49 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 49 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0029
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0029
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 49 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 53 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 53 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0000
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0169
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 53 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 57 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 57 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0004
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0390
============================================================


============================================================
🔄 Round 58 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 58 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0005
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0243
============================================================


============================================================
🔄 Round 60 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 60 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0051
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0049
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 60 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 62 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 62 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0013
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0091
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 62 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 65 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 65 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0034
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0006
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 75 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 75 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0001
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0155
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 79 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 79 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0021
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0142
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 82 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 82 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0077
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0089
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 86 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 86 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0017
   Val:   Loss=0.0728, RMSE=0.2697, R²=-0.0088
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 87 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 87 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0017
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0294
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 90 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 90 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0070
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0010
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 92 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 92 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0065
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0002
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 94 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 94 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0018
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0080
============================================================


============================================================
🔄 Round 95 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 95 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0058
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0016
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 95 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 99 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 99 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0059
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0026
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 100 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 100 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0000
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0184
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 100 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 100 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 100 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 108 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 108 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0018
   Val:   Loss=0.0688, RMSE=0.2623, R²=-0.0080
============================================================


============================================================
🔄 Round 111 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 111 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0010
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0380
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 111 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 116 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 116 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0094
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0014
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 116 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 118 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 118 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0072
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0004
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 118 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 120 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 120 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0052
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0009
============================================================


============================================================
🔄 Round 122 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 122 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0042
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0004
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 123 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 123 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0032
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0034
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 123 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 123 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 123 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 130 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 130 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0049
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0022
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 130 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 135 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 135 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0021
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0140
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 135 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 135 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 135 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 135 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 135 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

📊 Round 135 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 146 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 146 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0038
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0018
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0031

============================================================
🔄 Round 147 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 147 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0038
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0034
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 148 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 148 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0086
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0000
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0032

📊 Round 148 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0032

📊 Round 148 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2382, R²: 0.0032

📊 Round 148 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 155 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 155 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0013
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0170
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 156 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0628 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0628, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0628, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0628, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0628, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0629, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0628)

============================================================
📊 Round 156 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0068
   Val:   Loss=0.0628, RMSE=0.2506, R²=0.0017
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 157 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 157 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0018
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0073
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 159 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 159 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0067
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0024
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

📊 Round 159 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 163 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 163 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0033
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0011
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 165 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 165 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0005
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0264
============================================================


============================================================
🔄 Round 166 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 166 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0052
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0009
============================================================


============================================================
🔄 Round 167 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 167 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=-0.0005
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0118
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

📊 Round 167 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 173 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 173 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0036
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0004
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 177 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 177 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0015
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0084
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

📊 Round 177 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

📊 Round 177 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 180 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 180 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0003
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0258
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 184 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 184 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0010
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0146
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0032

============================================================
🔄 Round 188 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 188 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0018
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0067
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

============================================================
🔄 Round 190 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 190 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0012
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0267
============================================================


============================================================
🔄 Round 191 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 191 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0064
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0032
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

============================================================
🔄 Round 192 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 192 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0037
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0104
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

============================================================
🔄 Round 195 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 195 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0063
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0087
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

============================================================
🔄 Round 196 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 196 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0010
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0117
============================================================


============================================================
🔄 Round 197 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 197 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0057
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0006
============================================================


============================================================
🔄 Round 198 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 198 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0034
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0077
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

============================================================
🔄 Round 201 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 201 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0031
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0035
============================================================


============================================================
🔄 Round 202 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 202 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0046
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0019
============================================================


============================================================
🔄 Round 203 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 203 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0082
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0079
============================================================


============================================================
🔄 Round 204 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 204 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0001
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0333
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

============================================================
🔄 Round 205 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 205 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0023
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0052
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

============================================================
🔄 Round 206 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 206 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0039
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0015
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

📊 Round 206 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

============================================================
🔄 Round 208 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 208 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0021
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0051
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

📊 Round 208 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

📊 Round 208 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

📊 Round 208 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0033

📊 Round 208 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

📊 Round 208 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

📊 Round 208 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

============================================================
🔄 Round 226 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 226 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0042
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0032
============================================================


============================================================
🔄 Round 227 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 227 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0085
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0115
============================================================


============================================================
🔄 Round 229 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 229 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0027
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0018
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

============================================================
🔄 Round 231 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 231 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0004
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0182
============================================================


============================================================
🔄 Round 233 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 233 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0032
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0479
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

============================================================
🔄 Round 235 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 235 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0011
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0190
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 235 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 238 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 238 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0029
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0805
============================================================


============================================================
🔄 Round 239 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 239 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0000
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0118
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 239 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 242 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 242 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0055
   Val:   Loss=0.0752, RMSE=0.2741, R²=0.0097
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

📊 Round 242 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

============================================================
🔄 Round 246 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 246 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0015
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0056
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 246 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 249 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 249 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0025
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0021
============================================================


============================================================
🔄 Round 250 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 250 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0030
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0095
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 253 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 253 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0008
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0321
============================================================


============================================================
🔄 Round 254 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 254 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0013
   Val:   Loss=0.0755, RMSE=0.2749, R²=-0.0088
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

============================================================
🔄 Round 256 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 256 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0067
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0065
============================================================


============================================================
🔄 Round 257 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 257 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0020
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0048
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

============================================================
🔄 Round 258 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 258 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0021
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0071
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

============================================================
🔄 Round 259 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 259 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0052
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0052
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 259 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 259 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 265 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 265 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0091
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0038
============================================================


============================================================
🔄 Round 266 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 266 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0036
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0021
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

============================================================
🔄 Round 270 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 270 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0052
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0002
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

📊 Round 270 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

============================================================
🔄 Round 273 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 273 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0036
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0011
============================================================


============================================================
🔄 Round 275 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 275 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0057
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0098
============================================================


============================================================
🔄 Round 276 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 276 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0071
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0015
============================================================


============================================================
🔄 Round 277 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 277 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0013
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0116
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0034

============================================================
🔄 Round 279 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 279 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0050
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0001
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 281 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 281 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0034
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0001
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 281 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 281 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 287 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 287 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0024
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0031
============================================================


============================================================
🔄 Round 288 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 288 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0001
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0168
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 289 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 289 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0012
   Val:   Loss=0.0708, RMSE=0.2660, R²=-0.0074
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 289 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 289 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 289 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 296 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 296 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0030
   Val:   Loss=0.0755, RMSE=0.2749, R²=-0.0014
============================================================


============================================================
🔄 Round 297 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 297 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0012
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0367
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 297 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 300 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 300 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0035
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0018
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 300 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 304 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 304 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0004
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0259
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

📊 Round 304 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

============================================================
🔄 Round 307 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 307 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0043
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0058
============================================================


============================================================
🔄 Round 309 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 309 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0020
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0330
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 309 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 309 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

📊 Round 309 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 316 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 316 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0005
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0136
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 318 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 318 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0013
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0252
============================================================


============================================================
🔄 Round 321 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 321 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0008
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0175
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0035

============================================================
🔄 Round 325 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 325 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=-0.0003
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0250
============================================================


============================================================
🔄 Round 327 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 327 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0012
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0179
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

============================================================
🔄 Round 328 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 328 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0076
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0021
============================================================


============================================================
🔄 Round 329 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 329 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0037
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0015
============================================================


============================================================
🔄 Round 330 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 330 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0015
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0082
============================================================


============================================================
🔄 Round 332 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 332 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0057
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0049
============================================================


============================================================
🔄 Round 334 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 334 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0026
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0010
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

📊 Round 334 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

============================================================
🔄 Round 339 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 339 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0002
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0166
============================================================


============================================================
🔄 Round 341 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 341 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0023
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0036
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0037

============================================================
🔄 Round 344 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 344 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0021
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0260
============================================================


============================================================
🔄 Round 345 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 345 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0000
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0229
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0037

============================================================
🔄 Round 347 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 347 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0065
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0023
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0037

============================================================
🔄 Round 348 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 348 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0082
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0086
============================================================


============================================================
🔄 Round 350 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 350 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0036
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0009
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

📊 Round 350 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

============================================================
🔄 Round 353 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 353 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0001
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0151
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

📊 Round 353 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

📊 Round 353 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

============================================================
🔄 Round 358 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 358 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0028
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0011
============================================================


============================================================
🔄 Round 359 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 359 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0029
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0132
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

============================================================
🔄 Round 363 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 363 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0065
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0098
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 366 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 366 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0052
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0027
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 367 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 367 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0037
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0012
============================================================


============================================================
🔄 Round 368 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 368 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0044
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0060
============================================================


============================================================
🔄 Round 369 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 369 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0029
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0007
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0036

============================================================
🔄 Round 370 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 370 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0028
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0004
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0037

============================================================
🔄 Round 373 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 373 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0034
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0005
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 374 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 374 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0034
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0001
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

📊 Round 374 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 376 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 376 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0088
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0089
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

📊 Round 376 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 378 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 378 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0029
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0010
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 379 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 379 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0000
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0136
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 383 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 383 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0001
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0155
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

============================================================
🔄 Round 385 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 385 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0030
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0008
============================================================


============================================================
🔄 Round 386 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 386 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0021
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0037
============================================================


============================================================
🔄 Round 387 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 387 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0003
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0150
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

============================================================
🔄 Round 389 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 389 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=-0.0006
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0103
============================================================


============================================================
🔄 Round 390 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 390 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0002
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0143
============================================================


============================================================
🔄 Round 392 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 392 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0037
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0015
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

📊 Round 392 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

📊 Round 392 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

📊 Round 392 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

============================================================
🔄 Round 399 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 399 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0029
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0000
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

============================================================
🔄 Round 402 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 402 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0013
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0068
============================================================


============================================================
🔄 Round 404 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 404 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0060
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0028
============================================================


============================================================
🔄 Round 406 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 406 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0046
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0047
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

📊 Round 406 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 414 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 414 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0036
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0014
============================================================


============================================================
🔄 Round 416 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 416 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0033
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0015
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

📊 Round 416 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 421 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 421 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0019
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0051
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

📊 Round 421 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 423 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 423 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0033
   Val:   Loss=0.0694, RMSE=0.2634, R²=-0.0002
============================================================


============================================================
🔄 Round 424 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 424 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0072
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0086
============================================================


============================================================
🔄 Round 426 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 426 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0036
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0014
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

📊 Round 426 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

📊 Round 426 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

============================================================
🔄 Round 432 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 432 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0004
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0145
============================================================


============================================================
🔄 Round 434 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 434 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0008
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0339
============================================================


============================================================
🔄 Round 436 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 436 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0036
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0001
============================================================


============================================================
🔄 Round 439 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 439 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0053
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0055
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

============================================================
🔄 Round 441 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 441 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0002
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0187
============================================================


============================================================
🔄 Round 445 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 445 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0063
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0084
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

📊 Round 445 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

📊 Round 445 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 450 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 450 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0032
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0015
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 453 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 453 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0001
   Val:   Loss=0.0697, RMSE=0.2641, R²=-0.0228
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 455 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 455 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0021
   Val:   Loss=0.0953, RMSE=0.3088, R²=-0.0665
============================================================


============================================================
🔄 Round 458 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 458 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0042
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0013
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

📊 Round 458 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 462 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 462 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0000
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0157
============================================================


============================================================
🔄 Round 463 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 463 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0087
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.0046
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 469 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 469 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0046
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0047
============================================================


============================================================
🔄 Round 470 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 470 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0062
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0061
============================================================


============================================================
🔄 Round 472 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 472 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0012
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0086
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

📊 Round 472 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 475 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 475 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0034
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0004
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0036

============================================================
🔄 Round 476 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 476 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0046
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0001
============================================================


============================================================
🔄 Round 479 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 479 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0002
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0220
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

============================================================
🔄 Round 480 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 480 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0011
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0276
============================================================


============================================================
🔄 Round 481 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 481 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0053
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0037
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

============================================================
🔄 Round 483 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 483 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=-0.0022
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0071
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

============================================================
🔄 Round 484 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 484 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0008
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0169
============================================================


============================================================
🔄 Round 486 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 486 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0045
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0032
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

📊 Round 486 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

📊 Round 486 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

📊 Round 486 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

📊 Round 486 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0037

============================================================
🔄 Round 493 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 493 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0060
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0099
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 494 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 494 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0032
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0014
============================================================


============================================================
🔄 Round 495 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 495 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0031
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0009
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

📊 Round 495 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 498 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 498 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0002
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0191
============================================================


============================================================
🔄 Round 499 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 499 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0019
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0072
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 501 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 501 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0009
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0232
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

📊 Round 501 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 504 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 504 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0027
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0025
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

📊 Round 504 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

📊 Round 504 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 507 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 507 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0010
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0358
============================================================


============================================================
🔄 Round 508 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 508 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0000
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0165
============================================================


============================================================
🔄 Round 509 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 509 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0029
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0049
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 510 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 510 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0004
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0180
============================================================


============================================================
🔄 Round 511 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 511 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0038
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0022
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

📊 Round 511 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 516 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 516 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0001
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0200
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 519 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 519 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0046
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0070
============================================================


============================================================
🔄 Round 520 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 520 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0002
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0272
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 523 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 523 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0016
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0074
============================================================


============================================================
🔄 Round 524 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 524 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0022
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0051
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

📊 Round 524 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 528 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 528 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0051
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0063
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

📊 Round 528 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 532 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 532 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0033
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0004
============================================================


============================================================
🔄 Round 535 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 535 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0015
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0526
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 537 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 537 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0015
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0235
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0038

============================================================
🔄 Round 538 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 538 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0028
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0003
============================================================


============================================================
🔄 Round 539 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 539 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0003
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0167
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 541 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 541 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0008
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0094
============================================================


============================================================
🔄 Round 543 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 543 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0085
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0041
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 543 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 543 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 546 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 546 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0029
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0013
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 547 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 547 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0068
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0033
============================================================


============================================================
🔄 Round 550 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 550 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0018
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0415
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 550 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 550 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 554 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 554 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0003
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0169
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 554 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 556 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 556 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0094
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0142
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 557 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 557 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=-0.0012
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0059
============================================================


============================================================
🔄 Round 558 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 558 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0042
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0032
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 561 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 561 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0006
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0139
============================================================


============================================================
🔄 Round 563 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 563 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0016
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0046
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 570 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 570 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0106
   Val:   Loss=0.0659, RMSE=0.2567, R²=0.0011
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 570 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 572 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 572 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0043
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0044
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 573 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 573 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0019
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0235
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 573 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 577 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 577 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0007
   Val:   Loss=0.0736, RMSE=0.2714, R²=-0.0087
============================================================


============================================================
🔄 Round 578 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 578 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0037
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0010
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 581 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 581 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0022
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0021
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 583 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 583 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0056
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0094
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 586 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 586 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0013
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0050
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 587 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 587 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0010
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0061
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 587 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 587 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 590 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 590 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0002
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0116
============================================================


============================================================
🔄 Round 592 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 592 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0033
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0001
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 593 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 593 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=-0.0022
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0020
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 596 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 596 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0034
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0029
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 596 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 599 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 599 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0085
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0121
============================================================


============================================================
🔄 Round 600 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 600 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0013
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0177
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 603 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 603 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0005
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0088
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 605 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 605 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0023
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0267
============================================================


============================================================
🔄 Round 606 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 606 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0042
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0469
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 606 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 608 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 608 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0003
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0277
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 614 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 614 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0019
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0417
============================================================


============================================================
🔄 Round 616 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 616 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0012
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0240
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 616 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 619 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 619 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0003
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0135
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 619 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 619 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 622 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 622 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0022
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0388
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 625 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 625 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0019
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0224
============================================================


============================================================
🔄 Round 626 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 626 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0051
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0023
============================================================


============================================================
🔄 Round 628 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 628 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0004
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0081
============================================================


============================================================
🔄 Round 629 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 629 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0021
   Val:   Loss=0.0692, RMSE=0.2630, R²=-0.0018
============================================================


============================================================
🔄 Round 630 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 630 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0037
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0045
============================================================


============================================================
🔄 Round 631 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 631 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0013
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0047
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 633 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 633 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0011
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0161
============================================================


============================================================
🔄 Round 635 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 635 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0029
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0380
============================================================


============================================================
🔄 Round 637 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 637 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0006
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0218
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 637 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 640 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 640 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0051
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0040
============================================================


============================================================
🔄 Round 641 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 641 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0138
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0035
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 642 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 642 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0021
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0410
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 642 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 651 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 651 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=-0.0091
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0050
============================================================


============================================================
🔄 Round 652 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 652 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0003
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0192
============================================================


============================================================
🔄 Round 653 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 653 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0030
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0018
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 655 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 655 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0037
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0027
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 655 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 655 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 655 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

📊 Round 655 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 661 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 661 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0006
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0224
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 663 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 663 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0018
   Val:   Loss=0.0681, RMSE=0.2609, R²=-0.0421
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 663 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 666 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 666 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0026
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0026
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 667 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 667 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0017
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0567
============================================================


============================================================
🔄 Round 669 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 669 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0031
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0008
============================================================


📊 Round 669 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 670 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 670 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0058
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0012
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 671 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 671 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0044
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0026
============================================================


📊 Round 671 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 673 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 673 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0024
   Val:   Loss=0.0706, RMSE=0.2656, R²=-0.0519
============================================================


📊 Round 673 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 674 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 674 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0062
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0108
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 674 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 674 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 674 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 674 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 682 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 682 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0027
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0023
============================================================


============================================================
🔄 Round 684 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 684 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0013
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0318
============================================================


📊 Round 684 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 685 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 685 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0040
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0004
============================================================


============================================================
🔄 Round 686 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 686 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0023
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0020
============================================================


============================================================
🔄 Round 687 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 687 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0027
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0501
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 690 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 690 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0000
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0164
============================================================


============================================================
🔄 Round 691 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 691 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0064
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0028
============================================================


============================================================
🔄 Round 692 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 692 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0010
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0092
============================================================


============================================================
🔄 Round 693 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 693 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0011
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0076
============================================================


============================================================
🔄 Round 694 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 694 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0013
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0307
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 697 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 697 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0066
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0117
============================================================


============================================================
🔄 Round 698 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 698 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0051
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0091
============================================================


📊 Round 698 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 698 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 700 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 700 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0019
   Val:   Loss=0.0673, RMSE=0.2593, R²=-0.0058
============================================================


📊 Round 700 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 701 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 701 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0013
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0068
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 702 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 702 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0016
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0058
============================================================


📊 Round 702 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 704 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 704 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0003
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0183
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 706 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 706 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0007
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0335
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 706 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 710 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 710 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0018
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0097
============================================================


============================================================
🔄 Round 711 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 711 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0017
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0068
============================================================


📊 Round 711 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 711 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 711 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 714 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 714 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0043
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0046
============================================================


============================================================
🔄 Round 717 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 717 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0010
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0092
============================================================


============================================================
🔄 Round 718 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 718 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0061
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0012
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 719 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 719 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0030
   Val:   Loss=0.0768, RMSE=0.2770, R²=-0.0005
============================================================


📊 Round 719 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 720 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 720 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0051
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0025
============================================================


============================================================
🔄 Round 722 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 722 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0091
   Val:   Loss=0.0712, RMSE=0.2669, R²=-0.0023
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 723 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 723 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0075
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0082
============================================================


============================================================
🔄 Round 724 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 724 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0034
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0015
============================================================


============================================================
🔄 Round 725 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 725 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0046
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0020
============================================================


📊 Round 725 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

📊 Round 725 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

📊 Round 725 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

📊 Round 725 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

============================================================
🔄 Round 730 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 730 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0029
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0002
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

============================================================
🔄 Round 733 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 733 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0008
   Val:   Loss=0.0721, RMSE=0.2686, R²=-0.0249
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

============================================================
🔄 Round 734 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 734 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0046
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0058
============================================================


============================================================
🔄 Round 735 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 735 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0069
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0016
============================================================


📊 Round 735 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

============================================================
🔄 Round 736 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 736 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0025
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0010
============================================================


============================================================
🔄 Round 737 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 737 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0065
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0073
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

📊 Round 737 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

📊 Round 737 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 744 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 744 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0049
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0053
============================================================


📊 Round 744 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

📊 Round 744 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 748 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 748 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0020
   Val:   Loss=0.0676, RMSE=0.2600, R²=-0.0041
============================================================


============================================================
🔄 Round 749 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 749 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0023
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0029
============================================================


============================================================
🔄 Round 751 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 751 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0125
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0094
============================================================


📊 Round 751 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

============================================================
🔄 Round 753 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 753 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0019
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0069
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

============================================================
🔄 Round 755 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 755 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0006
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0134
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

============================================================
🔄 Round 756 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 756 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0005
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0204
============================================================


============================================================
🔄 Round 757 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 757 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0103
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0030
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

============================================================
🔄 Round 764 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 764 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0012
   Val:   Loss=0.0716, RMSE=0.2675, R²=-0.0075
============================================================


📊 Round 764 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0041

============================================================
🔄 Round 766 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 766 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0004
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0141
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 768 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 768 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0007
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0105
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 768 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 768 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 768 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 773 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 773 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0050
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0021
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 773 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 773 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 777 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 777 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0025
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0394
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 777 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 780 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 780 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0071
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0057
============================================================


📊 Round 780 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 780 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 780 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 784 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 784 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0078
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0049
============================================================


📊 Round 784 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 784 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 786 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 786 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0060
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0036
============================================================


📊 Round 786 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 786 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 790 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 790 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0003
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0183
============================================================


============================================================
🔄 Round 792 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 792 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0002
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0158
============================================================


📊 Round 792 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 792 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 792 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 792 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0039

============================================================
🔄 Round 799 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 799 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0063
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0066
============================================================


📊 Round 799 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 802 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 802 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0002
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0154
============================================================


📊 Round 802 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 802 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

📊 Round 802 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

============================================================
🔄 Round 805 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 805 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0005
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0176
============================================================


📊 Round 805 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0040

❌ Client client_16 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
