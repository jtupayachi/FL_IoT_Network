[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca1c1cf8-8677-4914-9213-5e1025720dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41c679a-e5b7-4b6d-a959-babcbb31fc77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa89a3d-d878-4f57-8d73-1e6338800f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba6779f-415a-4b33-9167-071e05b5976f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d6cce2c-03ae-43b0-9b7c-ecaee9d1b195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1868613-d277-4f63-ab02-fb36d554a4f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 721f83e1-4986-4ba7-a9fb-c26c1bf57b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d0f9f47-94b9-4519-9a16-ff230162fdb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28c5e06c-5ada-4635-872b-f09b991d113f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a36cec1-ec5e-43df-91ed-fd3ac34159af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88c0f6f0-f0ed-4957-b4f0-ba8a5b925dbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ef88e0-f683-4a48-b273-cb9901e81fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd2a1d58-8c46-4ce4-a101-df2d575aa664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e599756-6162-4a29-8060-4611185ad7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4d2611-4976-46e1-b099-d190a69c0f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 565a2653-a6e0-43d7-b120-26d8fff6c17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message facb0238-7fa2-44eb-bef1-434ef0ee5be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a445d5cc-6b1d-4a2f-81e7-3956422f293d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71d35077-8aa9-4cfe-bba5-3348a9602482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54c76376-3d72-4dad-bf70-bdce4bace091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 728fe3f7-2629-4e2b-9945-21c826ee608e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 470baf54-5f7a-4013-bc66-5a8f8cfc2e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0bb021e-9b76-4c2c-a21f-6c3d273ec6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8804296-bcaa-499f-aa77-e767ebe60e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 096117d7-f5b3-4f3e-9c88-c469bde1a3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b117172d-3b97-4917-a481-65ecefde5443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d2322f-1cd0-44d6-b8b6-5dc28a089dac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c7376e3-4d19-4801-bfe6-7a5871601190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7edb41b8-2431-4d89-b5d5-3c6657bd56c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de67eef5-2b4e-426d-a38b-f745fbb2afd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 643a430a-7148-438d-abdb-f4ec81e8b9fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af7c6f9-4998-482e-a120-5041ae44f924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 956cd1ba-8152-41a2-bdba-88fea4701350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e966663-75b7-49b5-9519-2c29974021db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eccbf6b-640f-4818-b669-ee8fee7d2c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dacf017b-1717-4fe5-9982-4b3587c02926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e431756c-60ec-4ae8-849c-7ff86556e59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7bafcfe-7225-476a-82c3-0fa7d60817e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff9f5356-81b3-4e61-a9d3-157e12ab9816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 826e440d-feef-4980-b619-8edec3d44376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddec9a01-1b8f-4335-8e91-efa3557950a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf9ff170-3d7b-446f-951f-38aa17dcf269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afcb10f7-b679-4198-bb0c-dc54fce7acb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86082f3f-52bf-4b2d-a37d-bcd3ea898366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 103639f0-9fc8-40de-8784-ae53012f8e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd972a8-2bfd-43c3-9521-a7e8c32c890c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d021754-5b1b-4d3f-a545-63c18fcec0b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1071c74a-0225-45e9-97b2-da466387003a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfb62fbc-e19d-45f7-b617-26e1e57b6e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8adf3d35-a527-4d35-80be-ef0275414ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a89f8911-ed56-44b8-aa9e-06a7109a2abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c51b01e-73e6-40ab-99c1-9d7a5945a50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3120b01a-7708-4a1e-b473-289e329c1e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cd2c5be-dae2-4c75-ab7b-574600e8826f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ee81d08-7d9f-4734-820d-c1db84bd2ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5acfa003-909d-47cf-b978-da771b7f2d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 184b1c53-c634-4199-a0a7-78aad75bdd95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0989447-ab26-4d84-8133-db281e252a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae12e562-a5b2-40f1-9f5e-f6724170dc47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b345a36-adf2-4fef-a97e-4efda7723bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e9dbc3b-2103-475c-92ea-0e3a64eea774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a34fc69-a193-47f6-a6cb-b18400b74300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac5886a1-c58d-4371-9410-71d85f549b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e80675df-92d6-4849-924a-409c9e5b838c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcce67f7-1001-4bc0-bbb6-1b499d1ea4ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94aad69b-7742-4252-bc46-07e6fe25894a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d426b903-4918-4dad-a12d-36741d570db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9149140e-69af-4f55-bd22-7fdedc97226a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c44da1e-5034-45e5-8d0a-8b26fa1d6b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9d9f579-06af-448f-8f03-ed948b790f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ca74c0a-9ffa-44ed-94f9-7e034cde4218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d04818c4-6911-40ba-ab84-3de9673adbec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4522bae9-f2af-4809-a6d6-bb06ac5897f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaa769d0-b9b7-4ee6-b266-66dc5a43967c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa77a111-31b0-461d-b54c-5921d0ecb6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b774098-524c-4726-920f-ae8301fdf891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91875652-f513-47aa-ba9b-ea4a41d07313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be405916-07a0-4b7b-b110-6c0e944f50e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a277a439-f795-487f-90db-4017305568b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e1bbd57-d93d-418f-80bf-d840b1900dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f0b373f-7238-4f29-9979-0a6908e11f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce25b06-ee27-41c5-bc16-e46c91b42505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2877f53b-3dd4-488b-a732-436eb88931a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9970c04-aaa7-422e-a9f1-0e9c63a2278f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41fef2e8-dbf5-4b16-9c6b-cdb1ce7038f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 330932a6-3388-41f8-ba93-f36133317e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8c208cb-7ceb-4bf2-8ec3-d9a7c45e3477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c2087d-21bd-4006-abfb-eb2659087af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1702398-d1bd-4fd4-9089-396484c5ea80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df350e85-501f-4312-b85f-e067f360e7e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c630b237-dd2a-4a37-9153-ac1a0b13303c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 830e6190-81c4-451f-b816-778377373e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b2409c9-e953-4dcb-9cf0-0705f4d81b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b0376d8-7449-4d99-9376-bdd172143ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81a9f265-6712-4d7b-9ee6-511d8e9b7ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9dc7555-9056-4359-a308-de6d507f1694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c03b49c-21df-4ce7-ac09-f5e3163b0615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bfcad0e-4759-46a2-95a9-2cc294dd832a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0c99f8e-137f-444c-9d45-f2aab88ac979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0c37b54-6c42-4403-9502-c2feeba32fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b26866-67f5-4ac4-8535-1488df107e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f90dce2-dac4-49e4-9126-a661b8546e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 841f9e0e-c5c1-48fd-9327-14c99ff79e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca1574a-5f6a-423b-86d4-492f6ba1c29b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b766bb88-ada7-4dc2-90dc-cd016592978c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faaf098c-c243-49b7-af62-c83f589d76b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64dfed46-527a-4aed-858e-2f766132466e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ab74b76-52aa-40c6-a9e1-136a3a176f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0da0226b-7631-4152-973a-7d536ab8bf52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09548288-8d5c-4002-a844-3af4aeef541f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aad94a7d-4d2e-4010-a256-f464f5e7bd88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44deb47-8ffc-494f-ab44-bdad2ff2a6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f24f9d27-a9e7-42a7-8635-9eb0dbe54cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de018393-f7fd-4c55-98b4-77939973f0c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 543945e7-419c-4bbd-8ac6-c44dcdd1e9cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fa5e586-3925-491d-8258-c8831744612e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e42c8db-2b1e-4b1b-bcf8-f4953d0874fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 842a0344-9940-4831-a562-8286a4287f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b2b2d1b-2c32-4ae8-b0ab-45c9ff089a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4d394b8-75aa-4267-8ae9-57352a6b2117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae06f087-9091-4c97-b8de-ba54be417142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b2df9bb-45f0-4e73-820a-dc141c46183f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed57e4f-3ff7-447b-85f2-12e0c41d014c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07c9f0fd-732a-467c-98fc-bc00dc01590b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 128c3e7a-c074-4671-8c32-53c09a10f81a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 343cfaef-91eb-471b-a320-4b6064acc79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf26430-3e50-4921-99d6-9d1f00640770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e8bb910-5d6d-440b-bb11-e6934ae51ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f5ab0b1-85c1-4245-9a60-664e1b99a9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78b3cbe8-3e5a-4a91-afc5-50093be4a6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f111191-981e-433c-b108-1646b3ca45eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d78663f-ca85-49e8-b63b-af4eb2209cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5caf62a0-8118-4ec8-86fd-891d9ca381c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41e1a3de-b57f-486e-88f8-48a291d99f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd40be7c-2f77-46e0-b4be-b5f440f0234c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5024305-f14b-40d7-bb36-56f6e57f15b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a10dcbe9-a8d9-4745-8576-009bf6698013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15668567-af6c-4e8f-afdb-7839fa37d909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c2ddab8-2c74-46db-b0d3-d5ed471c014f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff539da-b321-49bf-981c-d2af1cae0f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f38491e9-b517-49a5-b87e-2c7e79db7a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c37275-ae21-44dc-b6dc-4849f13384c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 199e94f9-c3d5-4527-9ed8-8d136e6b1e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c669836-7364-4f5f-9458-a01f5703a2f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b70298b-ac91-4add-a307-49a1c2633409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a17daf0-bd6b-4a2c-96ea-fe188d9bd56c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 227a3333-1032-4d50-a5a0-c2abd42f1cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbd92115-7aab-43cd-942e-846bc091156f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9637f336-e1c8-4adb-b313-29781f96abbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc25597-24f0-4264-b663-5e140fc4ea6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02bf4bfb-3329-41e5-960b-af2d41b3e6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e1d38c-6e9a-46b5-b676-3b88696e923e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dc6f3ce-34af-44e2-8253-0749058b44fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ed3e55-5f95-4952-8349-186fb20847a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064b18f0-a897-4ef3-80e7-a8aca945c4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885b8707-4191-4922-8178-f778f64aaa24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a90b72e-d9b0-4656-a5d3-fe2d7a6384f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6e2c079-02fd-46dc-b3a9-357d9015bef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a69d228f-ffdb-457e-b0ca-d843f5723986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f10b87e-6d00-4cc6-a13b-2eb9b885936e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f71f8fd-103b-4df9-9777-fb671e654310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a37109c1-d4d3-4896-836b-9e4cca586c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a09ef448-26b5-477d-ac37-b95e453d14e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e9148a8-d584-462f-9b8c-7b58d869643c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502a143a-f3c2-4f30-9070-34071a88d533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 605f87da-11b9-4997-b970-734f80275743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0f6bc90-80c1-4189-bf5b-f1d8c8129889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adb93245-9128-448b-a517-75f365925db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1879914-55ae-45c0-88d7-331301fbac56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf733038-f50c-40d6-b194-2d86a48ed9e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59ea071c-a9b4-4cc5-885a-48223dd0c62b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb9c29be-44b1-4189-b75a-2fc11a179e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c88b9fc5-031a-4c84-a7fb-5f200eedf0e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8605176-29e6-4279-a429-111f7e6d5071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a1eed6-2b62-4ce5-aa25-3ab16439b39f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d4aa4f-6a4f-44b4-90db-00339c8e7896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc2027f-345a-4d9a-bcf0-3c59bbf1242c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5cb998f-2cc0-4e94-ac52-6e9bf674f6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16ad618b-9e7f-4c2a-95ab-e2491ccd1a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 021e970b-a9d8-4268-adb2-533caf41ce77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54ae966-2003-4b7b-a470-15deaca9e8bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bc13937-631a-4f64-a236-30fa8ee57c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a914e7a5-639c-4f34-9eb5-f9f66fda9f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4c61bd6-9fb6-4f16-882b-1696702791a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fb45d1c-e89d-4cea-98eb-5128f53b6921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9624ad4-7248-4486-b3e0-fe184f77a7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60cf91c-9580-4adb-9db1-afcf7f05ef00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5f6f819-658f-4193-8768-43ae76cb6d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d8a5530-e3f3-45d3-8b3c-6edadb701648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be4e4e1-8bd0-4235-940e-dcc65a8ddb05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab31655a-ebda-41f8-96e3-f248c5cc2bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb4a4d0d-e6bd-486f-af6d-a9d9bc0b3a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 509c87a7-c855-4498-bb42-6c3e30607fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee324b1a-fc49-4646-92c5-894e72aea9e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c46a6b59-1d3e-438a-b0d5-29122d4d5225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 618ce681-8398-4327-af51-34c8552ee764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee14e2c7-aabf-433e-8c4d-1f4c1b35558e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8068e320-b826-4073-b9ad-09c91376ce49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c88049ce-733e-4632-a965-f586a8441c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c81d109-f4b0-42a5-b67f-3869ae821fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 714d7cca-1cd6-402b-9ee4-b39c6ef63977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 009ff065-f6f7-4b92-b8f9-fe660edf3039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d707dd-2566-4bcd-9b76-e283b559712d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6b89925-6a30-446a-93fe-1e54c7b3004b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e847e3-58d2-49ce-b158-4994d43bf923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95e7c800-b668-48db-bf4d-47b36ac6cdbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bedc0303-32d8-4f05-8fe6-b2ea4d810c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a57ef19-d088-4aa4-9dad-22a4e8eb5a86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e66f205e-928d-4416-88ed-9b19524dbe90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3d0fb06-2777-4225-a54e-8cd0046df4fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af429f6e-343c-47d4-8124-45cba504c55d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab46e0d7-a3fe-40a5-b1f7-3c977ebfe791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85acde7b-7916-467b-8dd5-64213a7d6b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6dd605-d830-4dc3-89c2-dc790c6adc2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32422ef8-8d77-45d5-a323-ee07900c01dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a5bb3cb-87ae-4172-a6e4-a3cb66517818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec34e441-35cd-4340-8633-194eaf4c4766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7593c992-5769-4a7d-b60e-91b9f585c1ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13851614-df82-42b4-9c4c-1f268473b6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b38684d6-2672-4c8f-b928-5f21d6961d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08898f3d-c72e-4c30-a7c9-7c7ef5afd9b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 424dd78b-1d86-4b59-be74-d8fb39aaab63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e3baa5d-0c43-4c48-802a-b684feb672ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18f57607-5d6e-4c2a-be65-21c8b46e03b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af54399-8774-47ed-b4b9-8585ee070509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 739e38ee-075d-4690-a2a6-841ffd2b3cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd5040e-1937-40b1-90b9-7afbd199d823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d4cf34a-700b-49b0-97f7-9a78fff3e4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2d418fd-a50e-4740-a53b-9dd2b3374758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2debf22-2af7-477d-ba91-0696968331ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceb681ee-5127-4e59-8f0c-2e5ccf670376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea153ab-b4df-4edb-b6e8-2db15a5cb21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf2b20de-cf34-438b-8e3e-d4c7caa0d78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a05b067-14d8-4efc-abf5-63366cccb7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72826b6f-39cc-4dec-8d19-528a9b9d7de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef59e6c1-20f3-4d9b-ab96-905df8dba2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da048add-7938-43b3-a7a4-2d9d0413b235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2904dc90-7ea2-4639-a4ee-53f0749b5835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4c66451-e9f3-4557-9c15-abe5c00d11fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb0c3bb-2de2-4d03-915b-dd9db05cab68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f164134-0805-4f0f-a79f-930d715f674d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa4585ab-570b-46a1-9889-043fa1284109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d455d58-faeb-4176-a65b-7dae5cf7e069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5091c731-5e97-49cd-9dab-99112a452cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef39417-1f2c-48c8-995e-007077393782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07c8868e-1413-40dd-804e-e29718f28349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9fa25ec-7d36-49a9-a762-c93fd4d48a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3427c9e2-f3eb-415a-978e-776de990b639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 995d9d91-198f-404a-83ce-a654cadcd9d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 633a94e9-e4dc-4e41-bd10-d61d84232684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c276071c-f746-475f-9a0d-10376c0802e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af2accbb-aa0e-4ade-a728-226f9c3170e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e815f35c-5980-4ab9-9002-c6ffe3a7d070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c624a13-8139-450c-bb00-77c8cbc03609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f160c3-1ccf-4d1b-8a78-6970eb7456f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ada2d7-ce6f-4c3c-80f8-7e49faf28879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95878ec6-a82b-42ff-9b63-98d129178b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e63d565a-bb6a-447a-9178-c896b1afdfba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18c08554-8e8d-4ecc-b07c-ac0a3c583cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 402297a7-4f86-48d3-ba41-42c3cb8df5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92a257c5-f7d3-42ee-8e6b-d852ee92f65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52147463-af0a-4bff-b711-a99d2297f6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a62eef0d-f99c-4b36-85db-eb203b7129ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33544962-edf6-4344-ba10-b01f78cba4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30fedb2d-d173-4f07-b420-51798f679c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818def45-d2de-4d7f-a296-6cdecee2ba0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc29738d-0096-4809-a6d9-e1135e70946b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 687a56a0-98b5-4836-88e0-a1e6645bffc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d135fdd8-0544-4562-88b5-caeb8be9ba39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38098387-4bcb-4568-9321-183c6adca3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67eac07b-ec1d-4529-bd3a-988bb53beaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5534c361-779a-44c4-9dae-462b0d0f52a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e426d51e-2004-4828-8e1e-a50f537c7ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 466d2ee1-f5fe-4096-96a7-88d2da9b7485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd978a4-7147-4019-8027-7fcf93585fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57c001ea-fce0-43f1-bf50-5a3652b46648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7b5b52-0911-4853-8fc7-f0ad95e14354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b1fda8-ed47-40aa-9e86-4848d88f98a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5e49a70-cf1d-4494-af79-4373e0616278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 751d02c8-4069-4366-9bc6-699f5521d23b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b16e9ef7-944a-4f2a-ab8b-fc19710c4df3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 539d89a8-1340-4c62-9830-8e995c27c35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28c0d58b-b647-4ff8-acc0-cefe45519729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1382a2c-5db4-471e-a90b-47bc25744ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 299abb0d-9d08-4a12-a2eb-86cce82e0df3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4621497-f522-40d3-8d8e-c6f7db67636b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17a4212a-e990-4206-9918-361b7dda20f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be93b898-9265-4827-bb1e-795b2d1c060b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8af0c0a-6f07-4d3a-b1b6-920a20a44bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10505e2d-c59b-4340-a713-d2c5d14b645e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3c6a908-464c-4f6e-8467-d4c06930447c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d12155f-f1ac-498a-92e6-1adc0d7b8870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffdd8b46-9373-4328-8204-b67a6740b072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f13a61eb-957a-48af-b8a1-4f8d079805fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 829b97fd-1119-4757-8f2a-9e057e3a07c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c808aeca-6cbf-4e18-bb12-67034a992021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be78c4c9-17fd-49c5-93ed-610f915df6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e28793-cf85-49fb-8967-dea6c0c87a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f2a17c1-adad-4270-b657-dcb2f384d331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f99cbc2-9f35-4fe3-b4b0-73e0be6e2d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b01d9996-80b9-4f2f-9a3e-49534c42dc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e55c6a-66f9-4c36-bf80-c2da48c0509b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0966387c-e1ba-41f7-ac36-dc06e5f64c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 874b095e-d900-4ad8-9042-8508d8286f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0dbf9b5-207f-4b67-9f79-50bbc8a80473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa552cf-eade-4652-8f83-8333a00f5057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b85833f8-6aeb-4d43-b88f-908fe1984d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f99cbbd-b8a4-4ee4-9cc7-b7c27ffb96d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b29a9f-e7f8-4e97-8563-4ac0903f776a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3927d0c4-49bf-4cb5-8aeb-79ba9c6c2033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c3cda0-3571-477c-87c5-1035d94debfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d893ba26-48d5-416a-980d-8252bd17bfe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26819ed2-6e09-4b37-bf4b-c4bcf5d65525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f802c438-4317-478a-b28c-aa61e80ab96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed687f40-a2cd-42e6-ba05-a208242ea6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac956b25-3529-4fd4-97aa-c0d9a9897d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e11b8f23-f156-4d8f-924b-aeefc6c6acad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 301628a5-eacf-45c7-8969-1969bd1686f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39dfd263-4252-4d68-bd28-262be8b5430d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436ba235-f585-481c-9819-9ec2886e7276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef710af2-0403-40b6-8352-91e96ecebc90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da90152-dc52-4cab-af35-6e098417da74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89fd9ff1-4ef2-4b60-b270-198f9f00c749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b3e2a7-cc9c-485d-a21e-01ea167613f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e7f3c65-f058-4545-bafd-043af8c628d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc777584-52a4-4d19-9408-3a5621dfa4e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502419a5-5385-4041-a3ab-d6935ecad350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a9be1e0-9717-4a87-a0f4-8572f6e0ce14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9034a3c-8219-40db-af89-63ac2c31d07c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f682946-13ba-4746-ba41-57a62e922100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bbe80b4-b212-4023-9f77-7d9d9c70e59d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01fd27bd-979d-469b-88c4-e28948ad2705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9971063-d123-40b2-8baf-3fd0ada1a81a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 986a7f49-c1be-4c1a-81cb-4b99d5db1297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc69f690-5936-43e5-b04b-9dda06d629cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97c1cfe3-fe79-40d3-8ae7-1d298398e74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f69a06b2-5b6e-441f-b89c-e41ea64e3b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47d45c1b-42d4-411c-a97a-2cc94fa02ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee5868c4-64e3-4d4c-b05c-f9d9e7764c0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcdc28b6-f065-425d-b6f8-4ad53495bc66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 368f5cae-a868-4378-8390-c2eda3be2d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42afaf3c-5742-44cf-be79-5c1a86cf7bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81bbbe1f-fcb5-4882-802d-0688f9222acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14d41e57-784a-45b9-8071-8959c7ef45b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1d13843-ee53-4d8a-af67-396398c7a196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 767de79f-8275-419f-820a-4d39443f6d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ef2fa52-3c37-4c8e-a0da-ee5ffa34137d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca8ef0d-6f3b-4da2-a1c2-de591e59c5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c10dc9a4-ef35-4029-ac34-3eef1ee08776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b281664-578c-4741-9a8e-7e9c47f07a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed16dee1-8708-4b68-8015-c1c677f57fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db061364-e503-49d1-80d1-cf9d97dedc14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aa17744-fdcc-4de2-be51-65003aba8891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6fc742a-e81a-4893-83e1-a59bb0abcfac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb87867f-cd0e-4ec6-8c6b-2d0a3c1f8d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6ff4953-d1e7-48c6-9c29-30f40239b891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a72ec53-8f1b-4641-9bf6-5ad85640467f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0961c93-82bc-4211-adf4-acbddbcecd7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20420c37-25a2-403d-b8c6-87f3b80977c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93041ce9-1d88-4a43-bf15-2bc97edc1b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a00441-db18-4bc2-a5f2-407b39cbeed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bed725e-a57e-4c47-bdc8-c4ca84d1c58a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8948e16-cb65-4549-8816-f95d78c3a0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11cf7656-82f4-4ca3-baee-cf8bdf46b4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ac8f245-720b-447d-b595-91089ffa6c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65755f49-bb87-4981-9e76-b62fb4d7807c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf2a6116-bd97-43b6-aac6-79cadd7d6341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b96bd27-0ecb-4d6a-a652-5ca6655709ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 174d9014-0754-4686-b1ad-66e0cd7d53ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c078b3-9c7a-453d-8729-ae025b078b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e47edf-9a12-486d-8e94-b0d7ba5591b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5239cea7-0ed2-4854-9409-3607e9ad25b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7243d339-a51f-47b5-b0e2-23230144aeac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 885c1374-4cb4-4622-9d02-37854afffff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef80e6a-b362-4863-a335-857d5f27d1d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ecf3924-69b0-4f51-9ac3-437e9f4b9151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb2e8ff9-d807-480a-9cf3-d280026eac72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3e05761-2dde-4e3b-937e-aeffa0f73efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f690f3d4-140a-43e4-91bb-7abed2c28097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33281e3a-b910-4920-83cb-514c17bb8d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a671efa-0d27-48fe-9b43-f492b10f4ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7729e255-ccc0-4bf8-96d8-e3bf59bab61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71743b70-f710-4ec3-a5c3-f6ab0709748f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 803cfd81-6b81-4abd-bf22-d425e199b8c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b40d6e0-fe20-4489-ada1-c047bd399fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67e118de-5453-4eea-a4f5-16de50480efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b3ccf8b-2dc4-472d-bac7-954e40b35f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66e44ca5-a5a9-40c0-b3d1-beaa0a2a7beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aa4b88f-f392-4390-a777-b0797ee10924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a4fc852-53a9-4f09-87e7-192f85450208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 520e5846-383d-414a-aef3-22fd18f01e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 752c2bae-ab7d-41db-8dd8-16dac3bc9da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ef2afe-4a30-473a-afba-9108219e0286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa034abc-e42c-4dd4-9173-36c7b6323079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba0e3af6-c213-45e2-a5f1-a77e08dfb343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a948a4c5-494c-4735-9c03-b7def8812455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9890aaa7-de06-47f4-bdf0-897202154250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35628477-b962-4d62-a6bc-8e33703a5e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2756dc-5f8d-42d0-95e9-9cc357dd1a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8004df9b-c900-4942-b8cc-ae3b20ee6eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 860a0fe6-fd9c-41b4-b164-7522a5537713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30e62ad6-f7e7-4125-8b07-366791dd3420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94c4542-0370-426d-a265-53b9bf1b4ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70a22ffd-cbff-4c2d-9cc7-89ccbe34985e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 425df3fa-80d3-456d-973c-84e15d572bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da89112-682d-4628-b124-562df4a3d7f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c1cff5e-6f1c-4474-9458-d2f63547c0c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc352ce8-7e4e-4505-bde9-70ba52a2a4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33c6ba3-d715-46ae-af41-7df8265cd9ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6c436c2-62e8-49ed-ad7a-78cbcf65f23d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8347f8c-2461-41cc-9a33-a96118e47ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3290da7-f274-406c-9bf6-46ae6c5cf735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9bcdb9a-3208-45e1-bb29-57d8f8dcc286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecebd1d6-449f-4736-9dd7-cf76804fdde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37414e62-bb24-4456-b3f0-571b0a50b83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 376762d2-e5be-4ed1-8437-f0d68eb1d13d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cbf25e0-0852-4fe5-82b3-d35e0e37c136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3f67bd9-e541-4b7c-a99d-19d56db0b6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c20edb3-e049-42d7-b889-66ce823b12a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84bdb81f-767d-4fb4-bbea-1d8525bace8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a0e0d77-10ff-4645-9031-9cd5643b2910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0575715-9b34-4b52-9565-750c73c39cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f3456d5-4000-4349-9b32-e93d88fb14ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c397ac3-ca4a-49f0-b13b-79629b0d9380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 388c1e6a-1fb8-494c-8b25-f065c0b0e3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f20f8587-e371-4d48-af52-f5073ef8cdf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3a5d6ae-4a1a-4501-994d-f3c5c05d038d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4fd6ca5-891d-492c-9f5c-b2da308ecba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b847026c-c3f3-4440-a027-a1ce6d2517b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cbffa98-10d0-45fd-92ab-89daac3b2e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b86595d-2d9d-4163-8e7e-1393b59462dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 276287cb-7a46-4006-8695-ba2e97a67233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17bccf10-3685-445d-8e1f-13f77722d6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60b7b47a-d97c-4a07-987a-8a81afad8853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4086ff0-845c-45d0-b0b1-da9973095872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f78b77d1-f854-42f1-8058-0b0787e305c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dac25ddf-829d-44c8-a64e-af087cd49b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf3df15-fbea-42f1-a3e4-cd2cea0c9144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7abbbd7c-2217-4c59-8ddd-02948ccb34be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d7d8dc6-deb8-43af-9abb-a83e61b8a678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f44b71e-6c43-46ea-b087-30bbe120b96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4459d51a-9dfe-42ba-858a-1d11224e326f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c1bad7d-b8f5-4797-888a-7822c0882513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 251b689e-ce5d-4e20-b2e3-ff6a694b273d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b31502cb-085e-4c1c-b47a-2b320fae598c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5951c8e8-0635-42a3-8d4e-f2435e0f3f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34325694-0e58-43ca-8e70-18a0d0557eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d669583b-05b0-4c8d-b8e6-2a0c762de107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b82dc85-0a37-43d2-abff-b0a95241dc9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30182d5a-be0e-4af4-838f-44fe05ff0775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d84b5bd2-c5b9-4013-98c3-ee98d9c21cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6769aff6-f338-4433-af19-8b8284cd8db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd8cc78-46ca-4b25-8832-f96d008129e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9203f2e7-fe3d-4756-a98f-fd10e01b68cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2ac9de6-7e2a-4201-b521-979c3c29b754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbd2f53c-8c96-4f3d-95a7-8f5dd5d2558c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 972aefdc-67fe-4d6a-a37c-b5f3ef08b964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb28e9f-0eb0-4dfd-9007-e33a0b548318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 690c7f68-767c-4bc9-a363-357fed713185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d86a60-6d47-42fb-8a79-e1b4700043be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ae50958-d9c7-4d69-abcb-04d3209eb384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b6d299c-05c6-43c1-a8ab-e987c57014d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 491c8758-6f36-46b1-99bf-f161eb9435d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c584bbe9-3b5d-43f0-8528-5e34170a5484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd56b149-b081-4303-beed-6642bac98abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fda9a924-f24a-418c-b619-963f3da92e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b369695a-b5a3-4cf3-a021-393325f478a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb05e38c-d739-49f0-b9ce-5f28261d7642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fa6ad9a-e5eb-4827-ab8a-f4cb54177f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d258f47-72a4-492b-8a8b-803fd984babf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb890ae8-fbc1-46d5-949b-47ff93e9494d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e9fdd3e-6090-4eac-9e9a-6544fde21dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce50471-f01c-456a-bc21-c851e37c4e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c45591f-d6d5-46e6-8f63-4d4f8737e1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd7e1a13-50e1-4742-ad2a-b6c2b0e6b3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 221bf6b9-c00d-45fd-a6f7-29ad8229c19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ae6dcb6-684d-41a4-8f17-9f108e3460c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed8002c-a929-4476-8592-2b2edda6bf50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a986d88a-99b0-49cc-9395-dc90392242d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0269e8-5b5a-4b65-8033-c31b7ab65e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7ecf56-ba6f-46ea-8750-8cf694e19ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0bf6cb4-dc1d-4b40-8404-b5b7c9096e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9da068-1840-49fe-91f9-8facb59d3c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2084ea0-c0ef-4464-a2ae-8c98e6fd67a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e4097e-bcac-455f-81de-c6e5d2d97e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b766acb-06ed-43e0-afc3-75b921a351c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d5f2b12-3de6-4824-a6ca-4e97f41a9ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba435b70-95d3-44b2-97cb-418e27db0907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44771b0c-c8f7-4c14-bee7-5023d8c61a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd2cb2c9-c313-41fa-adc8-b5f3ab15db44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47c9d609-f19a-4d04-9d4a-463d337c3cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 973bdbf7-482d-466a-8bc1-0d0b52324a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c352c466-99ed-48b2-b16c-c992b8f5a814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6968f6b7-168b-4651-8e07-b79611e320a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d91636b-586d-40b1-ba94-158360207161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90eacc6b-a5d3-45c9-af58-a0359f82a436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 615f1a52-4913-4c4f-9d16-dc50abac8c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec0e440-5b4f-4ce0-99f2-3a5417070346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e98a8f32-a1de-428b-aed7-253776db268c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f45927ee-ac39-406b-8e85-6d16005103a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b92fb555-a28f-4ad6-8e3e-08e74666e177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13f690fd-80ad-413a-8352-d9e49a8fee0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cf5dc3d-2147-487f-9ebf-33b5790a4475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11ea9ca9-6401-4800-a01a-3383e0c782eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbb965ab-b09a-4ffc-9281-413c0122e42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a63f84-0741-47db-be2d-52e7dade4353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e910be82-bb56-4c44-8eeb-72898bac75ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 070714df-8199-4d9e-b7c4-ce87ec5dd969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b45c06d7-2ee3-4ace-ba58-f82638c8b5ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65acdeab-8c66-4c2b-82f5-59e287dc5022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b03c302-9c05-40c0-939a-92d62dbd1b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee5fe9e6-2cb7-4986-a45f-640343ace270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a9f37a0-d985-4102-b45d-d8db6f911d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a890ffa9-6f63-48b8-8d53-2e5dd4f165ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4644850-6915-45b0-8fd4-f779898b6382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dae55afc-6250-4743-86fa-bf56becc1cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f0dfb0f-721c-4cfd-850d-662e88223ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d34b998-33c4-4298-8cc8-7d17a966981f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d41f136c-433c-4307-8039-4488addea719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46263898-5af7-4bd1-81c8-bfa72ad99c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ffc8277-0b6b-4b82-9de4-c699c1e80861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793ee363-cdb6-49da-982b-f2e59616aee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b11628-464e-4ecb-ba3d-2861874860fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e0e22ae-29fc-435c-a5d6-07bf613866e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f2a2692-0392-4d6b-8ff0-6f10f8e6b450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eddc49b-86d2-4fc5-a9e9-357b2273a5e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02e99f45-0c49-4cc9-9d37-e932dca11791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75bc335b-ea67-49cf-a229-34a5801b1add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbf37bbc-5f10-4441-9e6a-87f116f21b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf21269b-0eeb-4aae-904d-e82dc9aa2aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22df411f-03aa-4cf9-8f21-604afb8c9f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e9e2e9b-6a04-4e65-bc26-1585b3330bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d78effd6-5e93-4965-b186-62bfe074e9b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 414397cf-a75e-4be1-b865-ae65ab641293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a4755ca-ce81-4c71-bc57-ec3bdc402082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61cc0512-4dca-4223-a9dc-512bcfcbd1fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e7d45a-00e9-4183-ab76-7c10247c7a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ada207aa-25e4-417c-bfc7-59fc14b9ce72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80fb6fac-4025-4f35-8b97-86c7b2f5fe6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d50e140d-ee5e-4285-9022-e86b638a2a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 366c52d7-f277-4a38-9613-b1fb54ebfa1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 620854f5-50f8-4d84-8342-db578ceb7094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87dd7464-f9ef-4433-b456-f6fd39f7ebb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e45fabad-edfb-433a-a63a-2d20a6ef89b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1afd2de-8bf7-42aa-97bc-e2f071caa352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15cbfa22-6b13-404c-9c4c-40d6907a83f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 259046f9-6100-4a84-b6a2-d314af637762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eab2901a-2271-4efc-9ace-296cb87416ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae6ff915-ff8a-4e3d-a4c8-e864f80552e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae7a5469-24e8-42fa-9199-87bbf069d591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b4d05c-8e65-4c13-b268-a2cd08c2f256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3329f0eb-38d9-4e98-836e-242c172bbc74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b931ea97-36f4-4eb6-98da-a2908c545400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad263df-c3cc-47b7-b903-785b0d658827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e13c3219-696f-480f-9ceb-f4fb0ef9e841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be825223-9848-4e9d-aa3a-08951e8536e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c40c1b01-6b9c-4020-a14c-83062d4dd13c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ec2be56-d9ae-450e-b51c-41a83bd24b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1222d0c1-09d0-4d29-af83-fc10b6c22868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 409f939d-66ac-43a9-832b-d948ec385861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5675a7a5-662c-44db-8f6a-0113fc8bafc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64fe359f-428f-4a3a-bac3-54c3d8986ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc16e2b4-1dc6-49ae-a7aa-dc342790c309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 833ec446-9707-43fe-a5db-94d994d2cd81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7e6284a-8323-4039-9082-4f8b418c480e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec62a946-87bb-4a97-805a-1f9115d5b155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b1936e8-c1f6-442c-a092-76efff575e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a675bdc-e91f-4acb-8a80-47b2bafd3e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c119a55e-29d2-4d49-b436-73d9ba018b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92dd20a0-e227-4280-a292-147aa891519a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbdd1f90-5b25-4bc7-95cd-04ce1127e5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5166c8d9-21d1-4449-a5c2-02f200860cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce7f61e4-911e-40ef-ba46-2e3bd9536ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24144603-4171-426a-9ba4-ba1df8ce8694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25c89610-da92-4ea8-b64f-5d01656d1d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bf61a4d-00a2-4971-ab69-2a094259ff4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f455c2db-0f6f-4930-847f-6b0f738e2108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad71720e-6d9b-48f8-a2d5-35922b0bce93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2c5b7fb-c4d2-43fd-9177-74dba7fd0de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b25f860-1b24-4eac-bc3a-17e9988d6379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b6ed0d1-6f00-4319-88c4-4f0aa49321d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d6937c-a241-410f-9cb0-d2d01e0d844d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b2da8a8-9e00-47f3-9cb3-2752d511f686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18bf7cd8-b482-40a3-a3b9-5e553a9f502b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 043a215c-f19c-4cc8-8781-303337fd562d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca4659db-0a74-4053-8cf5-ca953b8cac9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53c2d45b-4c8a-4297-8d0a-b99f49b8b2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 521b6ebb-d72a-48ec-b38b-21f182d9d55a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beccbb42-3551-4a36-b7b9-e9060f5774bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d89d39f4-249c-424d-a19a-8d455bac5d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ff0aa62-3579-488d-a907-03ee8d4762c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d461c8cd-951e-4871-8938-9177c2aa95e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3681645-28e2-4bcb-b13d-1af3f27c99cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd74c820-7792-4acc-8520-fb12c3a2dc58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eddbd6ab-46dc-4f59-b514-2bd4825b375b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16cb888a-0890-4dad-8f96-073bfec90752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea5f9632-0f59-461b-a269-c84fe7fe5322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01bb94e4-b688-43ba-b082-8ed40f2a5800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbb867f-f568-45cc-9247-14f78fc4814e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a46e778-6e8f-4d0b-a334-44b839dbb484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f6e124d-a78a-49bc-91fb-3e96c1c001f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5948a529-c74f-46db-8813-2e093822bdbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b02d146-f313-48c1-8571-ea93ad9e5d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50166b6e-2845-43ec-963a-0be436aac360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 825d04a3-025d-4b5c-bc63-021c41111737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff22c92-39ed-49e9-aaeb-77afa2a3f162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae24759b-99e7-4193-97ec-f45a5be17d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ec43f6f-cf57-49dc-b6b9-0222ecfde0a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba555da8-e1a3-4206-a18a-68f7b7c0624b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 248a35da-b217-4ec5-9c54-ce38ec15bfc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e9056b6-057e-449d-9c77-7050e45ae690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b948fd8-adab-482a-b6af-a0f73c258420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bc602ad-6a9d-4932-a04f-f2d8fe2dddff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c657651-4f40-4dc3-b820-94366a306cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb8a1a67-c590-4eb1-a453-ef7287b19ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3034dd8-c335-4806-b1c0-cdaf29e1fc43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49e7f827-7a31-4ce3-b616-ec2600b1e944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 938966da-ef19-4a07-bf67-65572ffe69dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 643cc691-c0d0-4e08-9cea-9d188c5727ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5563b573-f926-41c1-9022-4d312990da51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86766542-d771-4dec-9d89-2cc7313125d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e849ce-1b80-4ab1-ae7a-223185d77ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ea63ace-7dc8-4672-ad64-9224bbe67b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 741ecd98-bcbd-4eeb-a10f-719f0ee8af70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52ab58bf-b522-4e64-ade0-b357688dc095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d2d9a5e-2d6d-42d5-813e-35e22b4f4551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a214954-7413-4e0e-963d-4adef642d030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2a8ada3-504b-4119-ae3d-53c87139180f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37ab382b-0ae1-4cca-a800-1f6c3930d276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26afb16-c258-4499-8ba8-f5379281338f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcce31b1-e51b-40e3-a675-455a5a61a21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cecedac1-c551-458e-9140-2e6866bc524c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9df6a5-df26-49a4-9ad4-b6a42233a695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b43892a0-4ac2-4b2d-9d79-993f705119c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cb96137-00ae-4513-a18f-b1fba3c1bc3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c48782c2-1bab-4669-85d3-2218cb7a8b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e15e3eea-d5d2-40e2-af7e-b9b2b851afff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5d68cb3-120f-455d-a15c-7bec168831d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1abb9f76-0d27-4b69-a5c8-36d7cb04593c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c44373ef-12f2-4d81-8ee9-e4c96ef2399a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a1c560d-53ee-4e00-98c3-fd12b9277ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b15d0dfe-04fd-4391-baa5-552795975d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bbf1026-b3af-411c-8013-2dfe37870555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 947189b8-45c0-4074-8f83-a20cd8650744
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_17
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/test_labels.txt

📊 Raw data loaded:
   Train: X=(4164, 24), y=(4164,)
   Test:  X=(1042, 24), y=(1042,)

⚠️  Limiting training data: 4164 → 800 samples
⚠️  Limiting test data: 1042 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_17 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0730 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0868, val=0.0720 (↓), lr=0.001000
   • Epoch   3/100: train=0.0866, val=0.0720, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0863, val=0.0719, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0859, val=0.0717, patience=3/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0803, val=0.0690 (↓), lr=0.001000
   • Epoch  21/100: train=0.0690, val=0.0662, patience=3/15, lr=0.001000
   📉 Epoch 26: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0645, val=0.0684, patience=13/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0663)

============================================================
📊 Round 2 Summary - Client client_17
   Epochs: 33/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0690, RMSE=0.2628, R²=0.2109
   Val:   Loss=0.0663, RMSE=0.2575, R²=0.0797
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2449, R²: 0.0099

📊 Round 2 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2453, R²: 0.0057

📊 Round 2 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0119

📊 Round 2 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2451, R²: 0.0084

============================================================
🔄 Round 8 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0850, val=0.0775 (↓), lr=0.000250
   • Epoch   2/100: train=0.0845, val=0.0772, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0842, val=0.0772, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0841, val=0.0772, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0839, val=0.0771, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0832, val=0.0768, patience=3/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0827, val=0.0763, patience=4/15, lr=0.000063
   📉 Epoch 25: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0824, val=0.0761, patience=14/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 8 Summary - Client client_17
   Epochs: 32/100 (early stopped)
   LR: 0.000500 → 0.000031 (4 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0347
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0374
============================================================


============================================================
🔄 Round 9 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0826, val=0.0845 (↓), lr=0.000016
   • Epoch   2/100: train=0.0825, val=0.0844, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0825, val=0.0844, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0825, val=0.0844, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0825, val=0.0844, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0824, val=0.0843, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 9 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0187
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0127
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2449, R²: 0.0104

============================================================
🔄 Round 11 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0827, val=0.0839 (↓), lr=0.000004
   • Epoch   2/100: train=0.0827, val=0.0839, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0827, val=0.0840, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0826, val=0.0840, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0826, val=0.0840, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0825, val=0.0841, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 11 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0163
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0172
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 11 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2448, R²: 0.0105

📊 Round 11 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 11 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0109

============================================================
🔄 Round 21 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0841, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 21 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0147
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0041
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 24 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 24 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0164
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0199
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 26 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 26 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0180
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0124
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 27 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 27 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0147
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0203
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 28 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 28 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0143
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0273
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 29 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 29 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0172
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0167
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 32 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 32 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0141
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0265
============================================================


============================================================
🔄 Round 33 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 33 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0164
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0097
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 36 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 36 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0157
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0088
============================================================


============================================================
🔄 Round 37 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 37 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0154
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0065
============================================================


============================================================
🔄 Round 39 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 39 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0183
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0024
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 39 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 47 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 47 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0155
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0241
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 49 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 49 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0188
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0047
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 51 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 51 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0194
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0013
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 55 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 55 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0200
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0038
============================================================


============================================================
🔄 Round 56 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 56 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0151
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0256
============================================================


============================================================
🔄 Round 58 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 58 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0185
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0289
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 59 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 59 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0154
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0254
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 59 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 63 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 63 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0184
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0093
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 63 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 63 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 63 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 70 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 70 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0183
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0136
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 72 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 72 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0165
   Val:   Loss=0.0821, RMSE=0.2864, R²=0.0216
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 72 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 76 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 76 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0179
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0127
============================================================


============================================================
🔄 Round 77 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 77 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0185
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0136
============================================================


============================================================
🔄 Round 78 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 78 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0186
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0124
============================================================


============================================================
🔄 Round 80 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 80 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0164
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0171
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 80 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 82 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 82 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0196
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0054
============================================================


============================================================
🔄 Round 83 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 83 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0179
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0161
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 85 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 85 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0188
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0080
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 86 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 86 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0167
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0197
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 88 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 88 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0164
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0214
============================================================


============================================================
🔄 Round 89 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 89 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0171
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0177
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 91 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 91 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0185
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0028
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 93 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 93 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0197
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0049
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 93 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 93 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 98 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 98 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0172
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0166
============================================================


============================================================
🔄 Round 99 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 99 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0157
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0190
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 99 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 99 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 99 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 105 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 105 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0144
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0278
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 108 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 108 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0192
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0098
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0109

============================================================
🔄 Round 111 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 111 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0160
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0114
============================================================


============================================================
🔄 Round 113 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 113 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0149
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0087
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 118 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 118 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0161
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0225
============================================================


============================================================
🔄 Round 120 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 120 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0178
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0127
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 120 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 123 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 123 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0169
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0023
============================================================


============================================================
🔄 Round 124 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 124 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0173
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0238
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 126 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 126 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0201
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0056
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 128 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 128 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0172
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0181
============================================================


============================================================
🔄 Round 129 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 129 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0164
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0215
============================================================


============================================================
🔄 Round 131 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 131 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0192
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0204
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 133 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 133 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0180
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0093
============================================================


============================================================
🔄 Round 134 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 134 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0170
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0164
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 134 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 134 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 134 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

📊 Round 134 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0108

============================================================
🔄 Round 147 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 147 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0153
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0232
============================================================


============================================================
🔄 Round 148 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 148 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0179
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0080
============================================================


============================================================
🔄 Round 149 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 149 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0178
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0255
============================================================


============================================================
🔄 Round 152 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 152 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0183
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0053
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0109

============================================================
🔄 Round 154 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 154 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0175
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0129
============================================================


============================================================
🔄 Round 158 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 158 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0146
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0178
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0109

============================================================
🔄 Round 160 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 160 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0163
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0222
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

📊 Round 160 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0109

============================================================
🔄 Round 165 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 165 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0179
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0104
============================================================


============================================================
🔄 Round 168 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 168 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0152
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0186
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

============================================================
🔄 Round 169 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 169 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0129
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0126
============================================================


============================================================
🔄 Round 170 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 170 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0177
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0063
============================================================


============================================================
🔄 Round 171 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 171 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0171
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0195
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

============================================================
🔄 Round 173 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 173 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0193
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0099
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

============================================================
🔄 Round 176 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 176 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0162
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0231
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

============================================================
🔄 Round 177 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 177 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0142
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0020
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

============================================================
🔄 Round 181 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 181 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0155
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0155
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

============================================================
🔄 Round 182 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 182 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0198
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0330
============================================================


============================================================
🔄 Round 186 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 186 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0186
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0080
============================================================


============================================================
🔄 Round 187 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 187 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0179
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0163
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

============================================================
🔄 Round 192 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 192 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0166
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0188
============================================================


============================================================
🔄 Round 193 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 193 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0175
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0125
============================================================


============================================================
🔄 Round 195 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 195 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0169
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0180
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

============================================================
🔄 Round 197 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 197 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0182
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0149
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

📊 Round 197 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

============================================================
🔄 Round 199 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 199 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0159
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0238
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

============================================================
🔄 Round 200 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 200 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0157
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0205
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0110

============================================================
🔄 Round 204 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 204 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0154
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0249
============================================================


============================================================
🔄 Round 205 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 205 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0162
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0205
============================================================


============================================================
🔄 Round 206 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 206 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0187
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0104
============================================================


============================================================
🔄 Round 210 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 210 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0179
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0151
============================================================


============================================================
🔄 Round 211 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 211 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0189
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0124
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0111

============================================================
🔄 Round 212 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 212 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0174
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0090
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0112

📊 Round 212 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0112

============================================================
🔄 Round 216 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 216 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0158
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0248
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0112

📊 Round 216 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0112

============================================================
🔄 Round 219 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 219 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0179
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0156
============================================================


============================================================
🔄 Round 222 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 222 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0127
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0106
============================================================


============================================================
🔄 Round 223 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 223 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0141
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0335
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0112

📊 Round 223 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0112

📊 Round 223 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0112

📊 Round 223 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0112

============================================================
🔄 Round 228 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 228 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0151
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0074
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 228 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 232 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 232 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0172
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0186
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

📊 Round 232 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 235 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 235 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0146
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0037
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 238 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 238 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0178
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0177
============================================================


============================================================
🔄 Round 239 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 239 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0170
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0195
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 240 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 240 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0173
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0117
============================================================


============================================================
🔄 Round 241 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 241 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0172
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0162
============================================================


============================================================
🔄 Round 245 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 245 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0159
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0220
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

📊 Round 245 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 247 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 247 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0160
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0261
============================================================


============================================================
🔄 Round 248 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 248 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0190
   Val:   Loss=0.0929, RMSE=0.3049, R²=0.0134
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 250 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 250 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0167
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0204
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 251 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 251 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0186
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0173
============================================================


============================================================
🔄 Round 252 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 252 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0172
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0112
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 253 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 253 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0189
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0099
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 255 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 255 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0153
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0263
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 257 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 257 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0182
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0108
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 258 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 258 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0172
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0165
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

📊 Round 258 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 262 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 262 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0161
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0274
============================================================


============================================================
🔄 Round 263 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 263 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0184
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0150
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

📊 Round 263 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 265 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 265 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0158
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0184
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 268 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 268 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0144
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0193
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 268 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 275 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 275 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0188
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0128
============================================================


============================================================
🔄 Round 276 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 276 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0155
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0261
============================================================


============================================================
🔄 Round 278 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 278 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0180
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0149
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 279 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 279 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0146
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0178
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 281 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 281 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0151
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0210
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

📊 Round 281 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 283 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 283 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0174
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0092
============================================================


============================================================
🔄 Round 284 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 284 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0174
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0023
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

============================================================
🔄 Round 285 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 285 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0172
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0189
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

============================================================
🔄 Round 286 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 286 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0161
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0182
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

📊 Round 286 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

📊 Round 286 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

============================================================
🔄 Round 293 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 293 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0157
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0230
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

📊 Round 293 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

📊 Round 293 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

📊 Round 293 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

============================================================
🔄 Round 298 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 298 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0178
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0168
============================================================


============================================================
🔄 Round 300 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 300 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0168
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0196
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

============================================================
🔄 Round 303 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 303 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0189
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0072
============================================================


============================================================
🔄 Round 304 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 304 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0189
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0130
============================================================


============================================================
🔄 Round 305 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 305 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0165
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0221
============================================================


============================================================
🔄 Round 306 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 306 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0179
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0155
============================================================


============================================================
🔄 Round 307 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 307 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0191
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0016
============================================================


============================================================
🔄 Round 308 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 308 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0180
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0134
============================================================


============================================================
🔄 Round 309 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 309 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0180
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0028
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

📊 Round 309 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 315 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 315 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0167
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0165
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 317 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 317 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0160
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0157
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 319 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 319 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0188
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0134
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0113

============================================================
🔄 Round 321 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 321 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0164
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0240
============================================================


============================================================
🔄 Round 322 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 322 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0159
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0260
============================================================


============================================================
🔄 Round 323 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 323 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0186
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0097
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

============================================================
🔄 Round 325 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 325 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0180
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0170
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

📊 Round 325 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2447, R²: 0.0114

📊 Round 325 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

📊 Round 325 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 329 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 329 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0158
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0256
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 330 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 330 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0192
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0159
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 333 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 333 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0169
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0165
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 337 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 337 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0178
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0134
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 338 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 338 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0192
   Val:   Loss=0.0959, RMSE=0.3097, R²=0.0117
============================================================


============================================================
🔄 Round 339 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 339 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0171
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0200
============================================================


============================================================
🔄 Round 340 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 340 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0196
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0065
============================================================


============================================================
🔄 Round 342 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 342 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0145
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0283
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 343 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 343 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0179
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0177
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 343 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 350 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 350 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0173
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0145
============================================================


============================================================
🔄 Round 351 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 351 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0201
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0051
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

📊 Round 351 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 354 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 354 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0163
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0245
============================================================


============================================================
🔄 Round 356 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 356 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0171
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0080
============================================================


============================================================
🔄 Round 360 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 360 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0163
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0140
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

📊 Round 360 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

📊 Round 360 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

📊 Round 360 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

📊 Round 360 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 360 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 360 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 376 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 376 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0187
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0147
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 379 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 379 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0159
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0046
============================================================


============================================================
🔄 Round 380 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 380 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0221
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0041
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 380 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 383 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 383 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0173
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0206
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 383 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 388 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 388 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0173
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.0023
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 389 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 389 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0148
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0168
============================================================


============================================================
🔄 Round 391 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 391 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0161
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0257
============================================================


============================================================
🔄 Round 394 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 394 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0180
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0180
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 394 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 397 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 397 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0177
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0183
============================================================


============================================================
🔄 Round 398 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 398 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0192
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0133
============================================================


============================================================
🔄 Round 399 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 399 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0180
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0178
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 399 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 399 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 399 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

============================================================
🔄 Round 406 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 406 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0157
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0229
============================================================


============================================================
🔄 Round 407 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 407 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0195
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0115
============================================================


============================================================
🔄 Round 408 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 408 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0188
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0146
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

📊 Round 408 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

📊 Round 408 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 412 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 412 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0205
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0081
============================================================


============================================================
🔄 Round 413 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 413 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0168
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0155
============================================================


============================================================
🔄 Round 415 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 415 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0204
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0073
============================================================


============================================================
🔄 Round 417 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 417 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0154
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0155
============================================================


============================================================
🔄 Round 418 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 418 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0178
   Val:   Loss=0.0921, RMSE=0.3034, R²=0.0181
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 420 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 420 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0185
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0154
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

📊 Round 420 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 425 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 425 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0161
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0182
============================================================


============================================================
🔄 Round 427 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 427 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0176
   Val:   Loss=0.0838, RMSE=0.2896, R²=0.0138
============================================================


============================================================
🔄 Round 428 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 428 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0157
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0230
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 431 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 431 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0155
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0103
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 431 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 431 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 431 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 436 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 436 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0180
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0168
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 438 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 438 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0160
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0169
============================================================


============================================================
🔄 Round 439 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 439 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0185
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0122
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 441 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 441 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0197
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0111
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 443 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 443 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0176
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0157
============================================================


============================================================
🔄 Round 444 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 444 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0183
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0047
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 446 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 446 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0175
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0197
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 449 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 449 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0177
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0181
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

📊 Round 449 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

📊 Round 449 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

📊 Round 449 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 455 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 455 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0177
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0125
============================================================


============================================================
🔄 Round 456 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 456 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0177
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0144
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 457 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 457 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0192
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0088
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 459 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 459 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0147
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0183
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 460 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 460 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0196
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0103
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

📊 Round 460 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 463 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 463 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0173
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.0127
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 465 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 465 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0180
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0165
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 466 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 466 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0190
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0113
============================================================


============================================================
🔄 Round 469 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 469 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0182
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0144
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 472 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 472 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0147
   Val:   Loss=0.0912, RMSE=0.3019, R²=0.0196
============================================================


============================================================
🔄 Round 473 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 473 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0188
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0118
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 473 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 475 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 475 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0179
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0081
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 477 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 477 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0181
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0132
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0115

============================================================
🔄 Round 478 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 478 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0136
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0018
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

📊 Round 478 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 481 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 481 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0195
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0083
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 483 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 483 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0149
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0190
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 485 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 485 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0171
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0214
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0116

============================================================
🔄 Round 487 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 487 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0165
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0219
============================================================


============================================================
🔄 Round 488 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 488 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0191
   Val:   Loss=0.0943, RMSE=0.3070, R²=0.0097
============================================================


============================================================
🔄 Round 489 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 489 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0165
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0194
============================================================


============================================================
🔄 Round 490 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 490 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0195
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0129
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

============================================================
🔄 Round 492 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 492 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0185
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0050
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

============================================================
🔄 Round 493 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 493 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0159
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0129
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

============================================================
🔄 Round 495 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 495 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0169
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0182
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0118

============================================================
🔄 Round 497 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 497 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0184
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0083
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

📊 Round 497 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

📊 Round 497 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

============================================================
🔄 Round 500 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 500 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0182
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0157
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

============================================================
🔄 Round 501 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 501 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0160
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0256
============================================================


============================================================
🔄 Round 503 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 503 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0181
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0071
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

============================================================
🔄 Round 506 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 506 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0169
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0121
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

============================================================
🔄 Round 507 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 507 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0200
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0105
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

============================================================
🔄 Round 511 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 511 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0170
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0112
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0118

============================================================
🔄 Round 512 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 512 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0179
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0001
============================================================


============================================================
🔄 Round 513 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 513 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0179
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0082
============================================================


============================================================
🔄 Round 515 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 515 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0191
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0123
============================================================


============================================================
🔄 Round 517 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 517 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0198
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0063
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0117

============================================================
🔄 Round 519 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 519 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0169
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0187
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0118

📊 Round 519 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0118

============================================================
🔄 Round 522 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 522 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0184
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0156
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0118

📊 Round 522 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0118

📊 Round 522 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0118

============================================================
🔄 Round 529 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 529 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0173
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0052
============================================================


============================================================
🔄 Round 530 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 530 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0196
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0008
============================================================


============================================================
🔄 Round 531 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 531 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0189
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0009
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0119

📊 Round 531 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0119

============================================================
🔄 Round 538 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 538 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0206
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0048
============================================================


============================================================
🔄 Round 540 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 540 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0192
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0141
============================================================


============================================================
🔄 Round 541 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 541 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0157
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0044
============================================================


============================================================
🔄 Round 542 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 542 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0188
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0118
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0119

============================================================
🔄 Round 546 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 546 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0183
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0176
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0119

============================================================
🔄 Round 547 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 547 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0192
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0075
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0119

============================================================
🔄 Round 549 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 549 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0172
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0204
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0119

============================================================
🔄 Round 551 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 551 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0196
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0122
============================================================


============================================================
🔄 Round 552 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 552 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0169
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0201
============================================================


============================================================
🔄 Round 554 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 554 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0166
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0172
============================================================


============================================================
🔄 Round 555 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 555 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0191
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0149
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

📊 Round 555 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 559 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 559 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0174
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0158
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0119

📊 Round 559 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 562 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 562 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0170
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0215
============================================================


============================================================
🔄 Round 564 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 564 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0157
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0018
============================================================


============================================================
🔄 Round 565 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 565 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0198
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0013
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

📊 Round 565 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

📊 Round 565 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

📊 Round 565 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 571 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 571 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0174
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0206
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 573 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 573 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0153
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0235
============================================================


============================================================
🔄 Round 575 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 575 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0137
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0119
============================================================


============================================================
🔄 Round 578 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 578 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0182
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0055
============================================================


============================================================
🔄 Round 580 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 580 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0190
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0004
============================================================


============================================================
🔄 Round 582 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 582 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0152
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0268
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 584 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 584 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0167
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0224
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 587 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 587 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0192
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0143
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 588 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 588 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0153
   Val:   Loss=0.0912, RMSE=0.3019, R²=0.0055
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 589 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 589 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0197
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0001
============================================================


============================================================
🔄 Round 590 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 590 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0164
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0137
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 594 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 594 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0186
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0161
============================================================


============================================================
🔄 Round 595 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 595 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0182
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0152
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 597 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 597 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0166
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0204
============================================================


============================================================
🔄 Round 598 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 598 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0183
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0123
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 600 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 600 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0182
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0141
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 600 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 603 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 603 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0172
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0149
============================================================


============================================================
🔄 Round 604 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 604 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0154
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0075
============================================================


============================================================
🔄 Round 611 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 611 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0228
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0012
============================================================


============================================================
🔄 Round 612 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 612 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0170
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0235
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 612 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 612 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 615 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 615 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0177
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0202
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 617 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 617 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0192
   Val:   Loss=0.0790, RMSE=0.2812, R²=0.0144
============================================================


============================================================
🔄 Round 618 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 618 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0178
   Val:   Loss=0.0956, RMSE=0.3092, R²=0.0169
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 618 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 618 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 618 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 624 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 624 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0182
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0187
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 627 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 627 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0201
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0121
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 627 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 632 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 632 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0164
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0128
============================================================


============================================================
🔄 Round 634 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 634 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0191
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0135
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 634 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 634 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 640 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 640 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0179
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0164
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

📊 Round 640 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

📊 Round 640 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 643 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 643 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0167
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0241
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 646 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 646 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0191
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0144
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0119

📊 Round 646 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0119

📊 Round 646 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0119

📊 Round 646 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

📊 Round 646 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 656 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 656 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0181
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0151
============================================================


============================================================
🔄 Round 657 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 657 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0209
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0009
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

📊 Round 657 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 659 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 659 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0182
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0150
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 660 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 660 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0186
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0062
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

📊 Round 660 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

📊 Round 660 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 669 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 669 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0168
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0225
============================================================


============================================================
🔄 Round 670 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 670 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0192
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0145
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

📊 Round 670 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 670 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 674 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 674 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0196
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0040
============================================================


📊 Round 674 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 676 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 676 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0187
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0166
============================================================


============================================================
🔄 Round 677 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 677 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0171
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0219
============================================================


📊 Round 677 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 677 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 682 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 682 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0198
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0025
============================================================


============================================================
🔄 Round 684 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 684 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0190
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0095
============================================================


============================================================
🔄 Round 685 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 685 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0181
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0190
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 685 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 690 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 690 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0185
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0165
============================================================


============================================================
🔄 Round 691 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 691 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0189
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0140
============================================================


============================================================
🔄 Round 692 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 692 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0205
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0070
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 692 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 692 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 699 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 699 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0176
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0215
============================================================


📊 Round 699 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 701 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 701 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0163
   Val:   Loss=0.0894, RMSE=0.2991, R²=0.0122
============================================================


📊 Round 701 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 704 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 704 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0207
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0087
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 704 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 706 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 706 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0187
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0160
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 707 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 707 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0158
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0195
============================================================


📊 Round 707 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 709 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 709 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0157
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0195
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 709 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 709 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 714 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 714 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0170
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0118
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 716 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 716 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0190
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0134
============================================================


📊 Round 716 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 717 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 717 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0158
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0269
============================================================


============================================================
🔄 Round 720 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 720 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0159
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0276
============================================================


📊 Round 720 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

📊 Round 720 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 725 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 725 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0172
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0223
============================================================


============================================================
🔄 Round 726 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 726 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0195
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0069
============================================================


📊 Round 726 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 728 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 728 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0176
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0158
============================================================


📊 Round 728 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 730 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 730 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0167
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0105
============================================================


📊 Round 730 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

📊 Round 730 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 732 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 732 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0164
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0219
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 735 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 735 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0162
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0035
============================================================


============================================================
🔄 Round 736 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 736 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0172
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0143
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 737 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 737 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0163
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0111
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 738 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 738 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0191
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0135
============================================================


📊 Round 738 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

📊 Round 738 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 740 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 740 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0186
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0175
============================================================


============================================================
🔄 Round 741 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 741 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0157
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0203
============================================================


============================================================
🔄 Round 742 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 742 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0196
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0012
============================================================


============================================================
🔄 Round 744 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 744 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0217
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0038
============================================================


============================================================
🔄 Round 745 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 745 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0182
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0188
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 748 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 748 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0179
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0205
============================================================


============================================================
🔄 Round 750 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 750 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0196
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0133
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

📊 Round 750 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

📊 Round 750 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 755 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 755 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0171
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0182
============================================================


📊 Round 755 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 761 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 761 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0184
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0162
============================================================


📊 Round 761 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

📊 Round 761 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

📊 Round 761 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

📊 Round 761 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

📊 Round 761 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0122

============================================================
🔄 Round 769 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 769 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0173
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0198
============================================================


📊 Round 769 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 769 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 769 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 769 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 769 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 769 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 781 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 781 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0177
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0209
============================================================


📊 Round 781 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 781 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

📊 Round 781 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 781 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 781 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 792 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 792 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0166
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0231
============================================================


============================================================
🔄 Round 793 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 793 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0185
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0115
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 793 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 798 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 798 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0194
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0070
============================================================


📊 Round 798 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 799 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 799 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0166
   Val:   Loss=0.0838, RMSE=0.2896, R²=0.0199
============================================================


============================================================
🔄 Round 800 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 800 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0185
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0160
============================================================


============================================================
🔄 Round 801 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 801 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0182
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0004
============================================================


============================================================
🔄 Round 803 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 803 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0184
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0065
============================================================


📊 Round 803 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

============================================================
🔄 Round 806 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 806 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0169
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0242
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0121

📊 Round 806 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2447, R²: 0.0120

============================================================
🔄 Round 808 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 808 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0163
   Val:   Loss=0.0949, RMSE=0.3080, R²=0.0249
============================================================


❌ Client client_17 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
