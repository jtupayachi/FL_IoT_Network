[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1756efdf-a7aa-4499-9257-b5c330554dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d80e8444-182b-4284-b853-58e07fc65493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abac7276-b010-4d4b-9227-eab684f5598c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10349917-e326-4d96-8de8-60a78c671d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6020254b-7309-4f0a-be7d-c98175f96f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa35b28c-eb6e-4278-94c9-bdeb332ee763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e5205d0-dea8-4a31-baa2-2e1f575b7833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fa0d452-72e5-4288-b84e-c56cbcf6fabf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80daeb27-38f3-4db0-979d-e1a5dc071463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a58ea9f-ce96-4e16-8452-2f18720570b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04055453-0e79-45c6-b740-4ad2e8fcbe45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fa455b8-6a06-4c9c-bf60-21d97d033236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b55eb91e-c4f8-4178-8bfc-25f4d988cc3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0902220e-8d3b-419d-b641-2dc22490a7df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e74e4b0-0def-4241-97b4-485268c471cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcb3430b-5d0f-477e-be23-d6ac13bc5be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1de86d4-ad91-4b47-87d6-d224319a1e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b38ed6b2-ebaf-4a2f-a8a7-1ccd646be811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82bf0c68-19b9-4b7e-8b5c-fbe57a42b95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5823e197-f826-443b-940e-e7fcd0321080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0628f7d9-9566-417f-997a-31f004ecee9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185e135c-3a09-4001-a537-2791c551e0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09afa458-7522-49a2-9df5-150c6a3ba1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d46c66f6-5ec0-4863-876b-e8922224a0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b6b4cd8-0555-46e1-be3a-c699fff4f93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7b6fe4-6de2-47a5-8fb7-d6d286dae662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fff54942-16e6-4130-8363-7f8270649ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7805563d-7cc7-4b31-a2ff-9093d785275b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cc10769-6aef-4e3a-b244-88c11f554bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c6b2c63-54f5-48af-b35f-8fa1236ba9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beaabe21-79b7-4423-afc1-de1654ec2171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c076b135-d8c9-4f7b-969e-295480f6f437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85452113-97a3-48f1-8023-177aa8de7844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71b2b3b4-4c53-47aa-be9e-b78d104ee5df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea780ca2-9a20-4ce7-835f-a0562f923f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b908f833-5446-4d72-9cef-491f5cf52e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e96e3b78-a314-4af2-92c8-a6d0d140f36b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d9db6cc-df75-4c42-9f31-a1c8651f73ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c153c5f-2084-4107-9e1d-80dc5c24246f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5527c380-dc37-4e6f-8069-f665cce532f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69fe4227-9909-4521-bcbf-f9d77159f71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 245c905d-399b-434f-bed7-dbe89076eec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1564df-f5d5-4418-a25e-b8a30b10a05d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cce5e15a-5825-44ac-a6e5-f7e22335bc61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbd33248-1ee4-4e45-84ae-96f63e7d5e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f378bdd-8890-4a70-b408-b66ecf2bf192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ddb4b79-5d27-4bc1-b14f-b2efda8935d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c69843c-81ca-4a2a-b455-fcdabf360345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3b3ed1b-9b26-4e3b-a251-0eab0e0d57f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc70b1e-84cb-4151-8f25-ec3aeb2b33db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e887835a-03c3-4b44-a8dd-e4c5e5d6203a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26decb35-a306-47b8-8282-4e790e08d122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 450f0870-685e-4592-8c32-82b5da212e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc5f73a7-11d8-442f-97da-54d8d920104e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a7ef3d7-3630-40cb-a594-f3e5caccd8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0f4f7c0-f5d7-4687-899e-8e4f6b630f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a850ef2-2927-4993-8abf-98967a7a52e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca5808e6-5564-4d71-99d3-8a3ec094320c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40700aa3-bb8a-4122-bbd2-fdae264ff2ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a28ec933-d360-4355-aa53-ccbaec783bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab26d99-2f36-4a12-9eb8-30dbb997781e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 227da836-de80-443a-b9a1-a795c7e12532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef9fba60-41ca-4baf-93aa-8c4dc414b7b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad6203c-8eb1-4959-a524-d60f112d7702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 180eb881-83df-41e0-9ff0-f99ed8a51069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df1a3043-804f-4b6a-a0c6-e567c739726e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cca12fb-a253-4f34-8c4a-69a1d35f4e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7031a4f3-e52f-4e20-9250-f6256392008e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 663431e9-d932-4d00-bdd3-393a7be7e570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89e15505-58b6-4b5b-a9f5-1f0238d66b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb29231-d25f-4e1c-9b88-cb721be967e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 018456fe-ed2e-4042-b0f6-d5d5fcf61b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c6c49de-5287-4add-948d-c540ac4056d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 123b5306-a0b2-4a4b-a819-5b4a036140c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d042cfc1-fadb-443a-b8ff-d22ac7d58c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a259b67e-606a-40ae-8fcc-6fd7f11c8744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd7c5f4a-7467-4436-88d1-ae49926c9f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ae9d04-a852-4f68-b775-0443ab7fbd49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc3bacdd-c344-4d62-8bb6-6d150c847e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a37913c5-4c67-4651-81bb-efbf1c4e63aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a58b2b5e-150f-4395-acd9-8d35f00bd956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81916b4f-7366-403c-a860-2b40dba72257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7241b60c-2db7-483c-bf94-f0209af4dc07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6102d7b8-5dc3-47d7-b977-a0575cc0df9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddecd31d-a0d4-4702-9c37-d5f5125a620c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 372477c0-0c75-47fb-92c3-22101ee96db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b1f89d-b43d-45ab-9b97-64d69c6086af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08217f02-566e-4d1b-9e11-bc900a7247fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f1de740-1b26-41e1-bd45-6400107f2312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a19b38-1ea5-478d-ac09-b2d2e8587e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb2cf049-326c-4146-b0df-3d96a8220fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 912286a4-91d6-4f84-ac6a-c7f64b7a63f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ac2d7b-dafa-4532-84be-7d7545eafe6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f278a05b-e871-42e5-9a43-5c4fce371df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90814824-0b4c-4c57-aa5d-31f92e915551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3834bf8-7bab-4dc4-83bb-7676e3306b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bddba32-53d8-4241-b18f-4cca484d9b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63928d4e-2b97-4467-b411-3b59e4a5b55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dee7b34d-29f6-4ccc-998f-717b0a1cb40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac88daf-8c3f-4e68-9cc0-7a8a172749ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ebb5ab9-4937-4900-8cc1-e551a512e6ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1612d3cf-3459-4fb9-9c6f-71cf8d2fbee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce4757f2-58dd-474c-ac6d-274d6be38680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 951249ad-ee1e-4336-a651-921c0ef3160e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d5acfe8-2bc8-4189-b04c-cc6501efdd4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68d5f3f0-796a-41b3-9e94-8072deae7b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48bfb438-8ddd-4333-b416-a933a9cabf9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 113ac5ef-ee7b-4338-9a96-f2909b8a23ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56be5879-a261-4b15-bd25-50450777ee21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23f57baf-a4cd-46ac-9ff0-a1f991eb0b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6830662e-b69b-4f3e-b465-f04fb3c0e2f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b25cfb2-d0f6-42cd-a666-15f37d258cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b0df232-60af-4b86-b8e6-5313b088841a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5860204e-2309-4e0b-a6da-b6025a73d895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00cecb2e-d045-4d02-a252-5636d08e95e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c11b283-1f3e-4ce6-9fcb-17ab704e97b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1719a72d-8b4a-4698-92a0-7757c5ce14dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d22a1715-54a6-4075-9bfc-247d1e6ff3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b6fe530-7c41-45a3-b70d-d4a02551a1cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4c9485-05e3-44e9-b4ea-efaaa6821371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee1c020a-40f4-4fe2-8962-576f0bf830e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 373acf58-a8df-4d03-9377-0e2c57fd7b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e048ec0-b8dd-43c8-be7f-7a0b5b68e328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65aaeb31-d2ff-437f-8da5-5b808e8a9e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 767404b1-d368-4bdc-a21d-445e6c1bb906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61137f10-c32e-4093-9819-0d67545a6348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 245310fa-565f-42f8-9b66-d4e4b006b80c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818b3ed2-29f8-4ff6-8fd0-d7edecdffe0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6445c50b-c395-4ce8-951c-27914562b6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61fbacfd-7138-4447-8ac7-5322e220a1f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53ee712f-284a-4ffa-b0f2-b5cb7c681080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 392dafb7-2b55-4c80-8dca-da62346bfae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ab62b64-e5e9-4fe8-9073-acae3e557e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977d92ee-b721-4aa1-be3b-5379058d714a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3443cf8d-0a52-40e5-87fa-49d67eb4572f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90ada784-a880-4e09-9b7b-af8fd3d72566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 102ba0bc-fe5c-4546-ac12-84004df9399b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7c543d5-2dcf-47ef-b7b0-8d36eb3178f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20d72ece-651f-4b87-8e44-52e182b6fd2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 963b3189-0c51-4f2d-a434-b990fc1bc0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dd2c1e8-09fe-4271-b794-5c7d7590f54c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe4d26c-4c7e-4f75-a998-bfb3e706b62b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04942dc6-60c0-4a75-a067-2d47d7594420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 797723e6-f2e1-444a-85e8-a3329eb30c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a40b1e79-c85f-4d36-9821-67b1f55e899a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f403c20-82f1-4f3e-b1ae-bacf0450f265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0436cee-9a1b-4695-96d9-91028ad884a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0105c33e-99f8-4c7a-9992-8014326662a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d46b1663-c081-41a3-b5ae-0ba406510555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcf5fd72-f4c7-43cb-92f4-c19c9f55463b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510e9598-d9fc-4edd-a7f1-fa5198fb1725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc3c445-0233-462a-9325-9eb58a3bb64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0007e7a-709d-4545-9ec2-7b0fe5517e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b2551f2-0b45-4333-b6df-dd33d44d73ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a32222-52f7-4e5a-b260-6a238edbeab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c2234f8-d47c-42cd-97ec-0e033805f52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f79cbef-cc4c-4833-92fc-f14681b3eb2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf98f6d9-07fa-4d20-89fd-a05f0a2685ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98f4c193-1574-40d9-9941-3a325281defd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4534ad94-89bc-4cf4-9757-7428b269a6cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0186dfc-459c-4f10-ae99-f7ea5d38044c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d5bf0b-a429-4be2-a5d6-4ffdbceaf6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9317022-0b09-4fb0-8f83-32574008889f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 293857bf-03f6-434c-9dcb-0a3f88d543fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3ec1ff1-01f0-4501-9332-2c5605706a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70fff586-85cc-4b75-8178-c0b580d0f4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7a4aa02-6bd2-46ba-b96c-f964de07166b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a671cb8-fd76-43c3-aa28-d760605990df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74153820-297e-4dc0-84b2-9eebf2690ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ad82c3-da45-4e90-8b06-3a9309cface2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00286039-c232-4da4-a679-abf4801184d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0d3a2aa-abac-4a36-a755-43d50cb49e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 987c7a84-f021-4e1f-bf40-a9f96f40e70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9968140-a712-471b-8cdf-ee06dabfc3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8313ec20-f6d4-4800-b4fb-2a64688f51e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a06101a-a14b-44d1-b980-6423d3e7179a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7d7de8d-dc3b-40d9-a3ee-df10e0ec2747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf46963c-c0dc-4b0c-a34d-515a1fb7e6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2ebbbc-de9f-4161-b67a-16f584e39169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdbc4c33-4bbe-42ff-a88a-ded6c1916116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a9e7b7a-8755-434d-81ed-1b9a1ec9c89d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4a91dbd-8156-4fcd-b450-1505ea76af17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 614ad854-6a0b-47c5-b904-fa08a4e679af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637e432a-cfa1-4b7a-b298-7d84bb432b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd8a895-1385-4313-b8d0-dfba85ceba7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19300de8-318d-4384-a3f8-28c959a4bdeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4bbbc0f-9bc3-49c9-bfb7-b21f0df9ee59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c79d8548-2036-49a8-ae52-6529208b0316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3352a71-9d33-465c-b830-6c50c3c45f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd6be0dc-95b3-40e9-9a88-861508589725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5670c5e-6c41-457a-af26-ccef80027eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59025115-bdad-4f6e-ab85-d35a5bc2114c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e4fe51-1dae-4926-8838-c854daba4f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c49b6a2-8cd5-4339-a6ba-4d468297a265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b557f44e-24b9-4f63-81c4-91892766f8cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f39882d-61fa-448f-a019-972aae667e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8567bb69-a308-4156-9520-8ffd6c235925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10ef6be7-6047-406c-8189-adcb050404ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2af3d0-314f-4c3c-abba-97bcff64e367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4515ed2a-a517-461a-9baf-0396fa253698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac28ff12-0449-4c93-b512-3bc5192db87d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 422af112-d3d9-45c0-ac37-4e10be61b5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6793c546-2a7e-42c7-97b7-ccbe5df699f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4acbc69-aefc-4eab-b83b-6953899d6b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d299daba-ad74-4f18-b72a-fb6e42ad5c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 442cec06-02b5-4ce9-a425-2088c15dbb27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25ca01f8-5f7c-49d3-8d2c-4f698df345a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67b195ae-43a4-425c-b6a0-bbd59c2c8b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89aa07f1-02fe-4d03-8f46-ad2b79ff6592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e67d9d-5929-4ceb-9888-f88bf984ff17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dbfb27f-a6aa-4e1a-ac4c-6e1902a6f364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d366c0b-15b6-4966-be02-313469bd5980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 307a05f7-d5dd-4fb7-938c-0dc1d1f7d774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e1d45a-1c3f-46c9-ba84-8594638513db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 199bdf37-25bf-4aec-88af-09f02958eaaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce0e60f-f430-4279-b930-31f6f174316f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab4e256b-fe7c-4d5f-aa71-0b7989a9c643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9268c47a-563e-431c-ab1c-b2714ee6e1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bdc2e4c-7328-41f0-9571-dcc927bb893a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f6d1aa-cb38-48eb-acc9-c15bd852c9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acd04655-e43f-48ae-97a2-ff0b03a00b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a0a16d2-2282-4a4d-8fb7-00456c3c40ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af0f816c-5453-4c6a-9994-e0989218ed46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1adad496-99de-4867-8b16-ce2ce8976bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56711d92-0cba-4170-98c5-e0e29ce6f404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1a0c54a-631a-499f-9028-d158788539b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33705e06-a9f1-49a8-a78b-3e8f08154f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0e36802-7d7c-41a8-af9e-6efd6970ff57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7e522c9-020f-43e9-8f15-21821c36f378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c202e162-2362-4d6c-adfd-aa7b0db091e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b19b4468-e22a-4941-9362-9b16b0be9db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34eec772-f3d3-4b2a-8578-228b698ce21b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2e8b7a1-3c6a-456f-88a3-f249dc680502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d74fd875-e54c-4fcd-95f1-84277ac7de4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 018bad0c-bbc2-40df-b195-be7f53ab2d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e64ee85c-925f-4388-a1f9-701f655ce017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10b53109-4bf3-4faa-aec1-f167e9662c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 974dde96-d770-46e6-ae84-5d216f8c811f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 900abd6a-88e6-4c29-b07b-674514e8bdb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453ea6d0-3f2f-405b-bc87-65b65f8fb227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e3e2624-9929-4406-be9d-5eb3a3b1a005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 121a58fe-4b84-4c3e-886c-ffa0c8dd459e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bba9a56-3661-453e-98dd-638626759061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84b3b9da-dd0e-4a8c-aeb4-2b48e102030d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c3d98b2-7d9a-414d-bee5-65adf99fdcf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a98e6d1-b4ab-4a27-b35f-9dcc7c02a989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13408b43-91f1-4a72-a840-0c9870dd00d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1260e59c-f969-49a2-a05b-7b86814692cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51c2502b-3290-4dca-8fa4-a49033ef87ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b0dcc4-9cd4-489a-ac3e-b15fc50ab41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7933df18-9ec2-40da-ad08-885d80e3efbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a01f31-5fc1-4f8a-ae0f-91a481488202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1349b870-f485-47cc-9dd1-2ca0a389c6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28416185-f7be-41b4-b13d-6d33a8686ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d5435ad-5592-43d4-abf9-07ff79b61952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5877cc9-7ded-487b-91c0-e3d705f605cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8124b2ce-c072-4e63-b9e5-6666f3570032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee65be4e-0a0b-4d70-9176-10ff21779bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 713bb08f-19cd-4011-acd3-249fb37a1a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c569c6-f074-4c31-9ebb-9a27de89fffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ed42092-de64-4ca0-9201-6d7c1459242e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c941e81-b7e4-48a9-9541-2526f3440931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1e888c-0b88-44cb-87f6-1d7cca84a516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dfc163e-ccde-4ff8-9c5c-c3d2a0bdd5c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84e1dd9-50e7-4ac0-816c-630149cb0108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3c82765-ae29-4475-bb13-0e0a69c7172d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b16dc6-a9d2-4221-8c79-4e69120fe240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e92681f-bd14-492e-bc9a-009e0a808ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37fc2fb9-d1d9-4536-9da1-e13724886a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e01fce-4ffd-4a68-9d33-ec3124bcc6b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 446dd8c8-3201-4df4-8620-66428fa423fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6c62649-3c72-4d4a-843a-1fcd59a5d427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e064413f-ead2-461e-9b25-0f3e541206b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b7b5ede-45f1-4e41-9970-ee0e25cca0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dac2f12-8c5a-4bb1-a9eb-d5a0afca3e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a069311-bda5-444b-b686-8f6d1cae7dc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da25d48a-e619-44ee-b7a3-b04d64945e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03b9019c-6b97-486a-89e0-1d7397d501c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f51cf1-81a0-463b-b3a1-b643337cda2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7472bb49-9399-431f-9f30-341dd8ca009a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45137068-9811-40f4-9ebf-a71ddda767c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3cc8e3-f7e4-4965-86b5-09291b8e1134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59c59b8c-347a-4cf1-8e98-5226c730c2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e85af6fe-772e-4bcc-956b-9dfbb13808f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43aa250f-638f-4db4-958f-aedc4535596e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 461668f4-13b9-4c0e-9442-680e9962c72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca79833b-d73b-4f4e-9788-0d1db5916e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd038064-c041-484c-a570-a96dda7f5596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f66c01b-9e8d-4525-b57d-f370a232d7d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 898be891-7a36-4777-a1d2-eb9f2d51cf04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7327c8d-804f-4c16-b2b5-57648a610130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feeac1fb-61cb-4ba5-900d-35fdc26f853e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37150d84-2a56-4fcf-b1a9-2ceb57f3588e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f6f68ae-669d-4f57-858e-7a1813859912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 048d9436-ed3b-42ae-807d-ce9dc851c647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b33f9b0f-3cee-4531-8cfe-b8127b32b00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad1e9ef-903b-4ed4-be83-c2106c3bf760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a2ed1fd-572b-41d8-a8bf-e40b7e317492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 902c5a6e-1d34-493c-972d-983110349edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f1e7fdb-0079-46e3-8c34-891499513bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d9bdbe-703a-4e6b-a608-a0467d4a033d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12245ba3-8d8f-4b62-999b-711b78067c6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2433728-a83c-44e8-bb75-364ba1a563c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e8db974-8eda-41bf-8439-9cee42055ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79bcdd7e-e674-4f12-95cc-131b8b8b9a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56404765-dd79-4a98-a668-130f01a6c258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82939aca-9e18-4dd2-ad6a-54a1e0be5ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e570bcc2-81e0-4306-bc1f-b712308dfae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 185d6b70-6e23-41c5-91bb-b07075630371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea8d361a-3f04-405b-b3e8-a606cfe50cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a37d43b-25a3-404a-9acf-d85e1e2ffb63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23417a5f-de0f-4f29-9885-6b3003743dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bfa0ce9-7cbf-4606-b77f-2521f1886277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a116e308-e6b8-4e6e-88c6-c966dba6e308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0bc5984-23b7-4be9-b2cc-3650f8701746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1632d046-e82b-4ad2-8b12-d6d3074da1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2c621e8-ed43-4e7d-9098-9cb18e9c7dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 083b72ec-cfad-4129-8d98-7d3004da10c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e94f7083-461f-4e16-ba3e-ca8b4e2b812b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bf74e89-b429-425f-bc38-52502d6bfe7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f11c0f8-511d-444f-9c93-72b738ca4263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7360b5ed-ad24-4032-b4aa-085621c4dcae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a04cf948-5a9c-4b1a-9050-17af27e9ac49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa991451-fe1f-4a83-862c-7f8b7d8f4c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91862703-9cd9-42bd-ab81-b7de034ee955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 065c791c-a4e0-4e03-ad13-c7553660134a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d4f77ff-7b5d-427f-b825-f9d22141de42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8854ae58-5136-4f8a-8357-e3a3d1222af1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 595753b7-4ab3-45f5-98aa-b78ce1a05891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 273b0f29-dbe4-48c2-b677-3e381df949b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1179bee7-e491-4bc6-b52c-fc6dd74082fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ccca646-2e9c-4650-a17c-18c208ecf2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c88f09b7-0a45-4d8c-b1eb-1b81b78b82ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a0887a-5d81-430c-9f86-203178fa1b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50db143f-72cb-474a-96d8-0aea4c5dbee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc4f47e6-af42-4daa-8ed5-a6f0cac0ec6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a689de1-8f73-48a8-b14f-1ea541395daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0266d490-7923-4ca7-82fe-413ed11f9df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba995949-bf45-4016-be7f-d3ab462c9ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ea72a99-5c91-455b-b977-57b0a281bb0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd6cfb1-3b97-48b8-b4e2-a05581d75b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec502edb-8e12-4d73-b7cd-ab600f6c73ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdcd5f2b-3a78-41a7-936d-b5e366d4559f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e721c2a-94db-4923-9947-9178afbb7a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c03666ed-6625-4d17-b20f-e46e12c25051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a52a2b6e-03cf-4a28-aaf6-26a86130a1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eaab7ce-3f01-4536-9be6-05f8725bfa18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeabe3a1-a29d-4afa-83a0-c5d2a9124291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be9ae0d5-9bd7-4b8c-a58c-1ffae0448d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6890f4ad-dac2-4f3a-8821-829d1fc7bd49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93aee3f7-54a1-4308-a2a9-9e2e331ebeb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4054487c-23a5-47c1-a1ce-4fb06796cbbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a0f4fd2-cef5-4336-9ce4-22c8610dc79c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c0853bf-8515-448a-abb3-7d14c93714fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2976c28-2f96-4734-973e-a3ef2e0955c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e69b61fd-c780-4a05-8a1b-b987fdbf262e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d84b0f8-0b30-4642-ac4a-9557ccef44e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f1d5364-bcfd-4436-915c-0ffd36664c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c184c196-8545-4e99-93b6-0d7bd7df39f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 665ae5af-6b62-40c9-8770-5572ed16e508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 211f58ab-eb77-45ab-a9c9-70d7b664ebf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2df384c1-2684-45d5-a23b-208b073aca1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e774e356-572d-4935-a66c-9ce357997533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08c317ef-f3cd-4c83-9130-2121d8631237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f599ab69-c5e9-482d-9d46-9ab7a6849fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d5a423e-aca2-4258-b52d-6e31415e6ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02c947cc-7f70-4779-8c57-340790fc541e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f63ff7-dee4-46a6-b7b0-e81925afdfb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 638e82db-7094-4f5b-bbf7-5dfbb424bbf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faca90b8-f2be-4017-87c3-59f814755dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47460152-0511-4c13-a58d-c20daf5f34d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fafc1cb7-e143-4cba-8faa-5185dc60de8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fbe1561-62ee-4653-9195-b18509c63151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45033783-9311-4ebf-8399-e8ead9513855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03a2a0cc-3f8f-4983-9537-7e6aeae3b967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5114820-6bb2-426e-9e7b-66905172302b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 956b0fe8-6986-400a-be28-ba1b6e0c5933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb6a6e67-7481-4028-8514-052c71b2157c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eaf67da-c112-44b4-aa37-58c8a854dfc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df220b31-8c6b-461a-9bf8-b3be5003b1f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 140d0f9c-9953-41f2-8e94-0be39044e310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3faf343d-0404-4993-8651-cece7d7de674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd820b9f-ae7f-492f-8451-a393ad9807a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e591badf-e16f-4967-bf93-6187bd18b887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09865992-dd30-4cf7-a466-3a708d402739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d0efbce-0cb0-49ce-9b39-564b5e80a2fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14c07399-1504-4f63-b002-2e7980242113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25a6a8a3-57a5-4879-bc25-cccc803916a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bcebd37-e553-414d-8146-7ec131744152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1adcc037-2dbe-4daf-ad21-a1762535a0f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58a3659a-8fed-47c0-9a6a-84b0945468db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28c463f1-234f-44be-aaa4-f063a0ff931e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc8dae16-c598-48c6-bf67-6488755268e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2b381a-b851-478e-9ee8-3db4082db64d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eac22e8d-a4ba-4a0d-b1ca-d6cf775576cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df5a41e8-aeb0-43f4-a5ad-6932d1df5745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 069b2f81-7bec-4ccd-81ca-5f939a0c4078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4638e100-f669-4a67-85b2-6ecd6a81f6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45a5102b-af88-4788-b2f2-d2c117bf7ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea054ac7-5c04-41e8-9d8e-86c3fb4b57ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f605352-6f30-4558-83da-09020793af1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e401551-ebff-48df-b2b7-933826efd8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8d7b2a5-edc9-4034-ab17-6dbd32d4a37a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78fbf694-95cf-4c60-807d-90a8da87861b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd88ced7-8f24-4388-970a-a9a27558f4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db23ede2-0791-4f7e-ae13-ea0b94395e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc626a16-8371-431e-8405-730d5808fab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6233ae47-f1a5-4e54-85ec-29b1d4c60db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 080e53f3-02a6-4911-be9e-17ef18f860e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06047adf-fa68-4402-8d58-844a24f76942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3536848e-8649-4d12-91b1-d2d0cbf6340e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23cb731-a870-491a-a42d-8ded1dd7f259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 752d66ed-06ad-4b7d-8534-3f01931e6d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b018eac-0240-48b4-9464-87c1c7d34b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c6eedc3-5987-4b5a-a0de-4b7c59b63d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bdcb615-cc83-47f1-8c3c-ddc8c92ea81b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3a9d585-bb4d-4b79-ae26-1625bf10013f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0075a83-9861-4d6d-bd40-cfd9cf288932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d5ebbd3-29b9-4df4-9417-37dd8b0582a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d1c57f-ac01-463e-b461-baa5f0043930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b605d2-5c24-447d-8790-8d14d15e9853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db45b422-02a6-43f0-9c2a-7ab071c470bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3a991dd-c38f-4537-ab9a-43f2800b7f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93129093-b4ae-4ccb-b514-b40e9e63cabd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f930fc09-fe3e-4129-b413-ecdf79141013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5173e1f-f6e8-4fee-88fa-82ecf3e9902c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bdabd6d-d305-4232-b7b6-f12902463e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2148c5b9-98ac-4f42-90ba-c863e1784b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 120a3d71-b829-4e50-9b27-54b1035154d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b954f00-e1df-4d48-906b-81082fa42d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 565d7033-7aa8-412b-82a2-1d0be21859b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af5c6e46-78f0-4345-a55e-69f6ac6dee89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b2aae19-d981-409b-833e-8557b9eaae91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be1454f-351e-43f4-a6bb-a2fb666f39c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f397419-fa98-4921-8326-39523c90098e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4f24bae-8730-442e-8cd5-f6f58e38775f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8521677d-875f-4460-9ba8-dd4d83c1ea24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a836418-9088-499f-8a41-7c551d143569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 164e9902-5a1f-40b3-ab66-adf865fc175c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e248d79b-7fa7-451a-9c30-d38c5183451d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 386113b5-c5f0-4ea4-b1e5-eab6682fee0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a9427d3-25fd-4c74-b472-088b5440721b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b94547c-e0ac-40f2-8733-9a61cd65de06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 607d40b9-6279-44cf-943f-d7a36255757f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 831af0e0-1798-4e25-8306-7ca888611114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ebfc30e-30fe-41f0-92f8-989474d8d587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc03529-a331-450a-b172-473a2d5234e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3d0c51-3ab2-4e8c-be66-ecfd1bf69cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 655a34ee-cd62-4116-83de-af1de3763994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5805e8cd-9527-4a07-bee5-b6cd30cbaf5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 123f958d-dee6-4559-ae6b-9cf0f6e38e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca2c5f07-d690-4743-9e40-2d3b01ab2057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 877f0a18-aea3-4ce1-814b-cab98fe6daf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6b3c15-a009-4d69-978d-4e7e7e333e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff445269-4299-4903-bd27-b1a8504d6124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 648133f4-7518-44f3-a72e-6c49eb154d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff24a294-b617-474a-adae-6306f40742bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b71e04f7-3ac2-41c3-952e-e03c33dea24f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c691a837-dd0d-48cf-98cc-adffff0f87af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd13a25a-964d-4666-8bb2-5ed4a513713e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d0aeb9-459d-416b-b35d-82b83c75c198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 608034ac-d3d4-4af8-ac7f-be2530973875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac404166-b19d-41e5-b9a7-d653247f1e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 908b0c09-f99f-4e64-9775-925c02c1a581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee9b56b-1b20-4f71-9256-955360330f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0e31a4d-ed6b-4e32-987c-ae1b671b709d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b01c778-186c-4a9e-84e7-07afabbf9a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c221348d-a7b0-4bc1-86e5-1c8900a841bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37c41f78-d2e3-498e-830d-3468c067eee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9614f43-ae04-487e-aff5-33d890e6152d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9e53d53-df63-42f6-9814-b6603d62e574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c768a575-c8a4-465c-a311-1eb845b74bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa424b16-4ade-4abf-8247-7e4b6d4b819d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cddee9e3-341a-4c99-b1b1-4032b9fdab18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2861930a-ce2b-46f3-aecc-858fd6fef07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c665b5a-0292-4093-b233-e8ab6c99e3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d785549d-b391-4bda-9621-26e1e28ce8f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 150ad724-ec4b-49fc-b970-b400a62d3feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6e9956c-4a70-4fd4-b5a3-3f5eafe37261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bccc123-3965-4059-9a87-4d138b713bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d44defed-7d5f-46bc-9750-4244a4b6a614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88f2f66-b880-4e9f-adbf-7243816f5e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94b16519-a3a6-4f23-a65b-e6dbc4a06e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8888069a-dd9a-4c7a-80ce-b8763825ef3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf0e9934-fb8a-4799-8d8d-4dae9eefe8c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6349a80f-77f1-433f-91d5-f6831abdb011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31d7873-4e04-4f62-a987-6c0bb5e18538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69fb24e0-32ac-438a-920e-9f884a5d77fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54abe88b-fda4-4748-bc02-1d1be8c6fb7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eea7c97d-26bc-439d-b1e1-ee441c4e5467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc0b85c-7972-4e2a-8bc2-c90818e95651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fadccd3-ce6a-4f21-94c3-79c96ef63861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa6ea053-3158-4f01-a8c8-d3217216093b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fef2731e-0fda-4730-b61d-b4d1cab890e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cef66042-39ac-4a5d-9387-6b7a94d2f768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d829dfa0-4245-44de-8abb-9bf821b9d5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f12621ec-0396-40f1-a6ef-909047d80386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ec71342-f52c-4eb1-bdcc-f6ca94eaa9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9ae2f6c-2013-4384-8c2d-d3026e35e5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6704f6a-fd39-4ec6-95bc-8a85575b7b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5743509f-8b8a-428a-8f62-c5dd6e192729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fdb57ff-b5fb-4545-acc6-e08f14d89eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cea3759-f0c3-4b56-9b1f-b24f4e3bf904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a830b18-2647-48a1-ae5f-810b54bed0d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c1d4043-4640-4bf6-91d1-f12a01c21578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3e81016-2a2b-4688-999f-d2a36ba485c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b3f716-b081-4040-888f-53613e27a38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50407fd-8d83-490a-8438-9e08ab8d99c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b3e17aa-5d81-4256-98f9-337123eb4093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fa15022-e243-46c3-a484-c49037088775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02d545da-7041-4fa1-9c02-f2355355b98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7b4c493-6a7d-43a2-b156-6aeabef5d1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e35d4b55-0235-4ed5-a90c-d2bbea86dc9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adeb6610-8a5f-410e-b52b-2aa9276145da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 181bce46-7637-493f-a891-c8e7609c4a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b054df82-a2b0-4b02-b6d2-856a2bff25f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb987a2-bf65-46c6-8512-b5621aab37ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6de72a37-4c68-4677-9e3e-7c0b694a86ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a6a08f-2cb2-47b3-a7b8-a5f9a6cfd537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 223743b1-a318-4533-aa9d-17eb5230ff24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 107eb355-37c4-4ca2-8827-6cc472979672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ed14ee-0193-433a-890e-1cd5cc66399f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cc43df6-0d8b-4cf2-8eaf-247e55b5b3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2de90352-f614-4dac-ad02-f1bc7fdb2a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5602f991-d6a4-4ab7-9496-f99db037b6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f625bc2-27df-4e7f-8c56-8aa260e7a8e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a961244a-3268-4201-b05b-dfc0f964c9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76672cd4-b5b4-43e0-b182-98efce4f42b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ddf1347-2e0a-49fc-a1a9-54693003a9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d5d904-f4b0-449b-87d2-56e0d847d7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b323559-ccbc-4cc7-a236-d742b5673575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d6a8d99-6467-4ac7-bed8-bab5efc1c1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77295602-89f3-4c54-bb27-130bbd0b99c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c18a7a4-0f7d-4290-b1ec-28c4656b983e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 193a0018-57d4-48ea-acb1-87dde368f9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a9cb38-649d-4a4e-87f0-1c1cf3914dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24dca8ce-98d6-455b-9592-cf6c42d953cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0715a44f-4fdd-4071-b7df-d3b9a79f07ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb07575c-631f-48b4-b533-1ee243d40057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2469490-0fc4-4cac-8285-7295bccbcdf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e82ba7e7-0965-4b91-ba28-f97f76a7d688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a47b4990-53bf-4f69-a435-a3a61303a361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7027f29d-3b1e-4c8b-8f94-b0dcbdd01ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 195a1f99-cd72-425a-b23d-a9803561cb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bf65b06-5a20-4b13-89c4-2282c8387b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceda49f8-0f39-4c75-ac39-5567a1bc7710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 265ac6db-dd2e-45d2-b410-9e52b513df89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79b7def0-f48a-477f-b872-8768a120049f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f74b4ec-f651-4685-83a4-93f21c76da85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c435f7bf-fc8e-4733-8345-304acaaabe55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b3c12b8-135b-466d-86c6-c67bacfba852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cab2115f-c851-4542-bbd0-4809f772a181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9830a3a-14ca-43f3-b6f8-68b4677f1731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd89249f-e76c-4996-b20c-20813303c2d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19d134c2-910b-4576-abb3-93aa6a69bbcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b0cf48f-1f45-41d3-b9bc-ec41027033a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 128000c7-407b-4ccd-b0fc-68df76addde0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06cd7105-ed7f-4824-844f-b603d8b5bbd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30ba19a6-8811-4a91-81a7-6dcfffe1051f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec295580-0d67-4ed7-b2c1-30c9fcc89da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d541c22-20e0-426a-bdeb-5f532d46b639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 781a4200-1d62-4d24-95ea-d7f141be0a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96552b99-3691-42d5-881d-e27e30b63985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9721607e-6468-4a79-aaf1-11cd80a44799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d5b9fd9-fb8d-4322-8221-13edeef4f740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c19539b1-2097-45c3-bd0f-ec0ce878736e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa65c98b-a638-4050-84bf-3582bd574eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac5b2bb-e198-494f-be61-fdc50932dbbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f7cb5a-a609-459a-8dba-c650a10b828b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7363f3e-77e2-4ba3-9639-b3d4a63334b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 842ab71f-7343-4d81-9db4-88d27e6cd8d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b7e8c86-d512-4c66-91e8-2b131708ee82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed24f5a-5302-436e-a1b3-756a6b397bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a38ab96a-d811-4c69-9f5e-211b276696c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa987cbf-8a9e-4dd7-9209-37152e24d938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50b1b78c-7f37-479a-8971-1a2165fba47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e80e5ad-bccb-48f9-9e08-ec57b438d327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1109c838-09ac-4182-8674-d51f6fcba179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da68d0b4-1d98-4226-bad6-8bb3ce2c6930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b89dcf3c-a844-4d18-94f9-427ea2ebeb01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e14006-0d07-469b-bc8f-81bfc493e128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfe95a2e-eeb5-44ac-8efb-142b9f5d9bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2c53a0f-3c3d-4061-bf39-869ad1232268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eec5c71d-a36f-4a53-a3cc-234538eb902c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c960929-b737-4178-8849-ef1e71070a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92d59193-a2aa-4ec1-b542-eafc8f874c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0ffc737-200c-4155-b43b-9d39ff1a1ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f01ea631-e1be-4813-8f4d-63f8b339c974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74be48ed-0167-43a7-9cec-b468fb73776a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50730370-1767-406d-9eac-fcd5418867d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5178511-d5bc-4368-bff2-94149ea30e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71c2a326-e42d-4e54-84b1-af7851ba11af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16710cc3-a7d1-4c7f-a275-8672f7570c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0594a255-2ae2-4d96-aaa4-8fb4b2be8dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5ba7326-b975-4236-9c9d-c50000c7c216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b153ced0-2f2f-4c05-8583-96a0ee866f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8c0ac0e-d54b-4b46-a448-4d265b435c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2310a52f-e452-4548-8b87-4b223fd11cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a421e1d3-ecfb-4537-a0b3-453206bbf571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 578f9fd5-bcd5-43ce-b831-d76b899a3121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adae0658-56e9-427e-ba0f-bbec8a56dfce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15114540-b789-4ee8-8338-5911c1b02bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d515e01a-36a5-497a-b59a-a83c61c88dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d14a5ed-f1f1-4274-b018-2015d0551238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 036f6e7a-fc39-44db-bda3-e8a52abeacdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79605b45-b043-4e6c-9103-f3db746c8c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f9e3a8-80ef-4473-bdac-83451895fa5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f363c6-5599-4cdc-9dd9-ca289e9fa6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da059986-dd91-4730-8c9b-31746a51a943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa907197-956c-42bb-96b3-42d29661780c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc868a14-3ac8-42e6-87c5-525b52d683c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e2bd4ee-f0a5-416a-8ab4-64fd0abd5dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2756002-8c22-42b7-b82d-8b01d33fbec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb7a913-6616-468a-b099-3a895f7a46f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 884454bc-0aaa-424b-a52d-02b32eafc60a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 288db6a1-5820-4fc2-9230-79d310963109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d943224e-11ec-4a2e-8106-eba0126b6648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c187299e-1e82-42ce-aa57-e654e37439a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 245a167f-3785-4719-b039-52cf5d8ede59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad11236e-d2a4-4c33-8b7a-fe3f4d4811b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10fe9068-4bfd-4312-a14a-46c6c00ec23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f32bdd78-1a8a-4012-bc69-289a53e39460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 322d2840-8153-4378-8b74-98fcae5ededf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b03a3de5-ebe5-4ecf-be2d-d4dcc1e7eff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b58c8fe2-e688-4fea-b176-a5b421fcf7d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56a4d173-a64e-4913-b3ee-2a19e2fc38ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b35f05e-fded-4e1d-b3bc-07d0eb13b553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d65eb8-fb02-4429-bd6e-51be95bb1a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dcbed2f-3b1d-4231-9c94-8b3d2074d45c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d8155e7-b266-4594-b08f-cf2af73fd4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde49c3d-a9b3-4cff-80d5-4d63338a5143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d8b9752-d840-4f0c-a988-bff1bb7917d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36440ef7-98ff-4de1-9333-b3814bd63641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f48b078f-d911-4920-910c-1a2acdb93fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac10dbf9-8af6-4443-bb9b-362a6ae27736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ea34a37-4328-4465-9fdf-7658990e3e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8e85edb-a9cf-4994-8485-20b95f60d56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fda3ddb3-c5e8-44bf-a91a-a07268ca2b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a60cac-4fdb-4c38-a7e2-064bc878e456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ee1198b-6b4b-4daf-aea0-8a4564e5a5b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c5a4018-a06a-4f5f-8e47-317d8c2bdaf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1faaf286-d9b5-422c-ac37-69218be84f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2ca772-5876-4d5a-a2ae-41261221e543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bd71d23-abec-4b4c-9805-9a5785c9c613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeb2915f-a08c-4e4c-aa51-1e37ee3f2fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f04078be-32b9-4020-9ecf-3d50570c44d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb5ef96a-d951-43cf-8e7c-a189709c7d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9236ebb-84b8-4b4d-ace5-c3b9804e777f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 614bdf33-099d-4fac-b222-4e6fd3c94f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a99b20a-760b-4811-8777-b869e26d9ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fbc1d35-0fbd-49ef-9c26-bd13b27b6016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e4fab90-6bce-44dd-99d1-0fdeadeba283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9ede654-7f21-41b7-b5dd-2139f4822eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55549ed4-12cc-4f1e-9455-bd7335ed85a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd18462-f59e-4c91-b20a-22629a32be33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ca12cb5-b6a6-4b40-8328-856c8ea329de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b4d705-09db-4b0a-b232-c39fde9b3a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89fb7114-d9d3-4336-b067-0f650ca9ee9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75cd0403-4d05-4383-80aa-98493d3c9e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c994bbb-fb10-415e-b7ec-c3a41edb9afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24a7c756-ebcd-4f26-a23f-332622aaf167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1973b7d3-f447-4eab-8253-06b66d101ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a83e132a-f946-487b-aa26-477e670843d4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_18
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/test_labels.txt

📊 Raw data loaded:
   Train: X=(3505, 24), y=(3505,)
   Test:  X=(877, 24), y=(877,)

⚠️  Limiting training data: 3505 → 800 samples
⚠️  Limiting test data: 877 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_18 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2266, val=0.0902 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0893, val=0.0834 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0811, val=0.0826 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0805, val=0.0808 (↓), lr=0.001000
   • Epoch   5/100: train=0.0801, val=0.0809, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0789, val=0.0818, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 1 Summary - Client client_18
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0169
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0139
============================================================


============================================================
🔄 Round 3 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000250
   • Epoch   2/100: train=0.0810, val=0.0790, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0808, val=0.0788, patience=2/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0807, val=0.0787 (↓), lr=0.000250
   • Epoch   5/100: train=0.0806, val=0.0787, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0803, val=0.0785, patience=7/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 3 Summary - Client client_18
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0073
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0167
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2400, R²: -0.0047

📊 Round 3 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2396, R²: -0.0029

📊 Round 3 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2388, R²: 0.0022

📊 Round 3 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2384, R²: 0.0045

============================================================
🔄 Round 9 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0927 (↓), lr=0.000250
   • Epoch   2/100: train=0.0776, val=0.0928, patience=1/15, lr=0.000250
   📉 Epoch 3: LR reduced 0.000250 → 0.000125
   • Epoch   3/100: train=0.0773, val=0.0930, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0770, val=0.0930, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0769, val=0.0931, patience=4/15, lr=0.000125
   📉 Epoch 11: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0766, val=0.0933, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 9 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0049
   Val:   Loss=0.0927, RMSE=0.3044, R²=0.0047
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0018

============================================================
🔄 Round 12 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000063
   • Epoch   2/100: train=0.0813, val=0.0789, patience=1/15, lr=0.000063
   📉 Epoch 3: LR reduced 0.000063 → 0.000031
   • Epoch   3/100: train=0.0811, val=0.0789, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0810, val=0.0789, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0810, val=0.0789, patience=4/15, lr=0.000031
   📉 Epoch 11: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0808, val=0.0789, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 12 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0048
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0068
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 14 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0802 (↓), lr=0.000016
   • Epoch   2/100: train=0.0809, val=0.0801, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0809, val=0.0801, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0809, val=0.0801, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0809, val=0.0801, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0808, val=0.0800, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 14 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0001
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0043
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

📊 Round 14 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 17 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0795 (↓), lr=0.000004
   • Epoch   2/100: train=0.0813, val=0.0795, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0813, val=0.0795, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0813, val=0.0795, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0813, val=0.0795, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0813, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 17 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0020
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0003
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0008

📊 Round 17 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0008

============================================================
🔄 Round 22 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 22 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0007
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0030
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 22 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 22 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 25 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 25 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0001
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0058
============================================================


============================================================
🔄 Round 27 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 27 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0013
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0114
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 29 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 29 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0007
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0043
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 33 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 33 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0019
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0038
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 33 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 38 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 38 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0020
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0011
============================================================


============================================================
🔄 Round 39 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 39 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0012
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0030
============================================================


============================================================
🔄 Round 40 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 40 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0024
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0023
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 42 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 42 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0020
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0006
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 43 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 43 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0003
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0020
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 45 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 45 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0019
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0006
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 49 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 49 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0013
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0017
============================================================


============================================================
🔄 Round 54 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 54 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0015
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0129
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 54 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 54 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 60 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 60 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0020
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0031
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 60 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 60 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 63 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 63 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0005
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0043
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 65 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 65 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0006
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0016
============================================================


============================================================
🔄 Round 66 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 66 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0019
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0227
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 68 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 68 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0026
   Val:   Loss=0.0700, RMSE=0.2645, R²=-0.0117
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 68 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 68 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 72 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 72 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0012
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0109
============================================================


============================================================
🔄 Round 73 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 73 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0015
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0215
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 75 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 75 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0022
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0015
============================================================


============================================================
🔄 Round 76 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 76 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0000
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0064
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 76 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 84 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 84 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0006
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0011
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 92 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 92 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0022
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0004
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 94 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 94 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0003
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0078
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 95 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 95 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0033
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0069
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 97 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0629 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0629, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0629, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0629, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0629, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0629, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0629)

============================================================
📊 Round 97 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0013
   Val:   Loss=0.0629, RMSE=0.2509, R²=0.0010
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

📊 Round 97 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

============================================================
🔄 Round 101 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 101 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0024
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0065
============================================================


============================================================
🔄 Round 102 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 102 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0021
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0011
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

============================================================
🔄 Round 104 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 104 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0021
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0009
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 105 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 105 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0010
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0009
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

📊 Round 105 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

📊 Round 105 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

📊 Round 105 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 113 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 113 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0003
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0086
============================================================


============================================================
🔄 Round 114 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 114 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0016
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0008
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 115 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 115 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0007
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0043
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0014

============================================================
🔄 Round 116 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 116 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0006
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0077
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

============================================================
🔄 Round 119 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 119 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0003
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0067
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

📊 Round 119 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

============================================================
🔄 Round 122 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 122 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0032
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0052
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

📊 Round 122 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

============================================================
🔄 Round 124 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 124 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0027
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0040
============================================================


============================================================
🔄 Round 125 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 125 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0014
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0018
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

📊 Round 125 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0014

📊 Round 125 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

📊 Round 125 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

============================================================
🔄 Round 131 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 131 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0018
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0001
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

============================================================
🔄 Round 134 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 134 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0011
   Val:   Loss=0.0690, RMSE=0.2627, R²=-0.0123
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

📊 Round 134 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

============================================================
🔄 Round 139 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 139 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0003
   Val:   Loss=0.0712, RMSE=0.2669, R²=-0.0058
============================================================


============================================================
🔄 Round 140 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 140 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0001
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0062
============================================================


============================================================
🔄 Round 143 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 143 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0006
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0051
============================================================


============================================================
🔄 Round 144 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 144 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0030
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0045
============================================================


============================================================
🔄 Round 145 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 145 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0014
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0529
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0014

============================================================
🔄 Round 147 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 147 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0002
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0071
============================================================


============================================================
🔄 Round 148 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 148 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0020
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0021
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0014

============================================================
🔄 Round 151 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 151 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0020
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0043
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0014

📊 Round 151 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

============================================================
🔄 Round 154 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 154 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0012
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0006
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

📊 Round 154 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

📊 Round 154 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

📊 Round 154 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 159 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 159 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0006
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0025
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 161 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 161 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0015
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0010
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0014

============================================================
🔄 Round 165 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 165 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0004
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0083
============================================================


============================================================
🔄 Round 166 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 166 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0018
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0013
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 169 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 169 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0036
   Val:   Loss=0.0681, RMSE=0.2610, R²=-0.0099
============================================================


============================================================
🔄 Round 172 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 172 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0007
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0025
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 173 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 173 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0001
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0063
============================================================


============================================================
🔄 Round 175 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 175 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0033
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0381
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 178 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 178 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0016
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0011
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

============================================================
🔄 Round 182 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 182 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0011
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0020
============================================================


============================================================
🔄 Round 183 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 183 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0027
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0085
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 185 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 185 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0033
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0127
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 186 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 186 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0027
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0139
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

============================================================
🔄 Round 187 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 187 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0004
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0048
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

============================================================
🔄 Round 189 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 189 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0019
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0058
============================================================


============================================================
🔄 Round 190 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 190 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0000
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0072
============================================================


============================================================
🔄 Round 192 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 192 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0003
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0044
============================================================


============================================================
🔄 Round 195 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 195 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0018
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0075
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

📊 Round 195 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 199 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 199 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0042
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0118
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 200 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 200 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0000
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0032
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 201 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 201 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0021
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0056
============================================================


============================================================
🔄 Round 202 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 202 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0003
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0005
============================================================


============================================================
🔄 Round 204 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 204 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0021
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0023
============================================================


============================================================
🔄 Round 205 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 205 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0008
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0028
============================================================


============================================================
🔄 Round 209 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 209 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0006
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0061
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 215 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 215 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0008
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0031
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 217 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 217 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0006
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0036
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 217 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 222 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 222 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0013
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0012
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 223 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 223 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0016
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0026
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 223 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 223 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 223 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 233 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 233 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0010
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0013
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 239 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 239 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0025
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0053
============================================================


============================================================
🔄 Round 243 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 243 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0002
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0045
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 243 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 247 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 247 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0022
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0023
============================================================


============================================================
🔄 Round 249 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 249 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0023
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0049
============================================================


============================================================
🔄 Round 250 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 250 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0017
   Val:   Loss=0.0728, RMSE=0.2697, R²=-0.0019
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 253 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 253 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0001
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0059
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 254 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 254 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0023
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0075
============================================================


============================================================
🔄 Round 255 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 255 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0007
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0084
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 255 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 255 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 260 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 260 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0011
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0050
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 262 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 262 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0011
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0036
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 263 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 263 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0013
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0051
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 264 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 264 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0011
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0013
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 264 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 264 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 268 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 268 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0006
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0004
============================================================


============================================================
🔄 Round 271 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 271 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0019
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0049
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 271 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 271 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 277 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 277 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0009
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0004
============================================================


============================================================
🔄 Round 278 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 278 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0001
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0256
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 278 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 281 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 281 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0014
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0008
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 286 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 286 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0025
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0231
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 289 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 289 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0028
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0299
============================================================


============================================================
🔄 Round 290 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 290 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0006
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0068
============================================================


============================================================
🔄 Round 291 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 291 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0015
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0008
============================================================


============================================================
🔄 Round 292 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 292 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0005
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0039
============================================================


============================================================
🔄 Round 294 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 294 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0023
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0034
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 295 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 295 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0011
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0061
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 297 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 297 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0005
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0068
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 302 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 302 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0003
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0056
============================================================


============================================================
🔄 Round 304 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 304 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0000
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0028
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 304 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 304 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 311 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 311 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0022
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0030
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 312 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 312 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0026
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0216
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 314 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 314 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0013
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0092
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

📊 Round 314 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 316 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 316 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0014
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0129
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 317 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 317 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0008
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0083
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 318 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 318 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0024
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0033
============================================================


============================================================
🔄 Round 319 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 319 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0024
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0073
============================================================


============================================================
🔄 Round 320 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 320 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0003
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0050
============================================================


============================================================
🔄 Round 322 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 322 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0023
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0047
============================================================


============================================================
🔄 Round 325 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 325 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0048
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0295
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0011

📊 Round 325 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 328 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 328 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0013
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0018
============================================================


============================================================
🔄 Round 329 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 329 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0006
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0248
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 329 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 332 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 332 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0001
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0055
============================================================


============================================================
🔄 Round 333 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 333 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0029
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0120
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 335 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 335 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0012
   Val:   Loss=0.0675, RMSE=0.2598, R²=-0.0013
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 337 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 337 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0025
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0006
============================================================


============================================================
🔄 Round 339 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 339 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0014
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0163
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 340 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 340 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0007
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0020
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 341 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 341 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0025
   Val:   Loss=0.0716, RMSE=0.2677, R²=-0.0069
============================================================


============================================================
🔄 Round 343 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 343 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0024
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0057
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 347 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 347 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0016
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0023
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 349 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 349 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0004
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.0015
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 349 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 353 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 353 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0005
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0076
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 354 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 354 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0015
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0024
============================================================


============================================================
🔄 Round 355 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 355 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0010
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0003
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 356 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 356 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0005
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0081
============================================================


============================================================
🔄 Round 357 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 357 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0012
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0011
============================================================


============================================================
🔄 Round 358 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 358 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0012
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0017
============================================================


============================================================
🔄 Round 359 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 359 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0009
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0062
============================================================


============================================================
🔄 Round 361 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 361 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0014
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0068
============================================================


============================================================
🔄 Round 362 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 362 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0017
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0097
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 363 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 363 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0003
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0004
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 365 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 365 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0002
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0000
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 366 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 366 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0007
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0063
============================================================


============================================================
🔄 Round 369 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 369 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0025
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0091
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 371 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 371 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0014
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0097
============================================================


============================================================
🔄 Round 374 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 374 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0001
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0051
============================================================


============================================================
🔄 Round 378 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 378 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0015
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0094
============================================================


============================================================
🔄 Round 379 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 379 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0009
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0079
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 381 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 381 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0010
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0101
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 383 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 383 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0022
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0062
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 385 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 385 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0003
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0063
============================================================


============================================================
🔄 Round 386 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 386 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0016
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0028
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 386 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 389 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 389 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0003
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0026
============================================================


============================================================
🔄 Round 390 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 390 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0011
   Val:   Loss=0.0679, RMSE=0.2606, R²=0.0006
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 390 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 390 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 390 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 395 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 395 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0002
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0107
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 396 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 396 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0026
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0228
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 396 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 401 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 401 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0014
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0152
============================================================


============================================================
🔄 Round 405 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 405 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0020
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0032
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 408 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 408 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0034
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0104
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 411 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 411 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0007
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0012
============================================================


============================================================
🔄 Round 414 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 414 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0011
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0032
============================================================


============================================================
🔄 Round 415 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 415 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0006
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0188
============================================================


============================================================
🔄 Round 416 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 416 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0025
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0276
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

📊 Round 416 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 420 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 420 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0016
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0028
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 422 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 422 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0015
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0029
============================================================


============================================================
🔄 Round 424 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 424 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0021
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0058
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 426 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 426 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0005
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0034
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 428 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 428 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0025
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0051
============================================================


============================================================
🔄 Round 429 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 429 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0007
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0206
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 429 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 432 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 432 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0013
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0124
============================================================


============================================================
🔄 Round 435 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 435 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0002
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0024
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 435 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 440 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 440 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0023
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0095
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 441 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 441 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0021
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0081
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 444 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 444 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0029
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0083
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 446 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 446 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0002
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0030
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 448 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 448 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0014
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0001
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 450 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 450 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0001
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0049
============================================================


============================================================
🔄 Round 453 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 453 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0003
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0068
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

📊 Round 453 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

============================================================
🔄 Round 460 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 460 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0008
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0030
============================================================


============================================================
🔄 Round 461 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 461 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0000
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0033
============================================================


============================================================
🔄 Round 462 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 462 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0002
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0064
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

============================================================
🔄 Round 464 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 464 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0009
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0083
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0014

============================================================
🔄 Round 465 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 465 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0010
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0014
============================================================


============================================================
🔄 Round 466 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 466 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0018
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0123
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

============================================================
🔄 Round 467 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 467 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0017
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0029
============================================================


============================================================
🔄 Round 468 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 468 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0014
   Val:   Loss=0.0702, RMSE=0.2650, R²=-0.0062
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0014

============================================================
🔄 Round 469 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 469 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0017
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0010
============================================================


============================================================
🔄 Round 471 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 471 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0002
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0037
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0014

============================================================
🔄 Round 473 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 473 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0008
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0071
============================================================


============================================================
🔄 Round 475 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 475 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0005
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0307
============================================================


============================================================
🔄 Round 476 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 476 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0008
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0066
============================================================


============================================================
🔄 Round 477 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 477 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0016
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0072
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

============================================================
🔄 Round 479 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 479 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0006
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0035
============================================================


============================================================
🔄 Round 482 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 482 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0043
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0144
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 485 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 485 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0014
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0048
============================================================


============================================================
🔄 Round 486 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 486 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0022
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0074
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

📊 Round 486 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 488 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 488 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0023
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0146
============================================================


============================================================
🔄 Round 489 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 489 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0012
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0005
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 489 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 489 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 489 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0011

📊 Round 489 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 496 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 496 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0023
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0139
============================================================


============================================================
🔄 Round 498 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 498 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0044
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0178
============================================================


============================================================
🔄 Round 499 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 499 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0009
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0123
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 500 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 500 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0022
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0111
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 502 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 502 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0028
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0073
============================================================


============================================================
🔄 Round 504 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 504 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0022
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0005
============================================================


============================================================
🔄 Round 505 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 505 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0005
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0073
============================================================


============================================================
🔄 Round 506 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 506 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0003
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0046
============================================================


============================================================
🔄 Round 507 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 507 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0018
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0050
============================================================


============================================================
🔄 Round 508 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 508 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0014
   Val:   Loss=0.0866, RMSE=0.2944, R²=-0.0004
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 512 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 512 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0035
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0097
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 512 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 512 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 512 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 519 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 519 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0008
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0112
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 521 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 521 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0010
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0017
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 524 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 524 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0017
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0049
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 524 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 528 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 528 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0015
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0029
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 528 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 528 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 532 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 532 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0010
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0006
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 533 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 533 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0021
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0051
============================================================


============================================================
🔄 Round 534 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 534 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0013
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0001
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 534 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 536 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 536 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0011
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0005
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 538 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 538 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0052
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0261
============================================================


============================================================
🔄 Round 539 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 539 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0018
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0052
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 539 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 544 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 544 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0025
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0125
============================================================


============================================================
🔄 Round 546 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 546 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0016
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0081
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 546 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 548 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 548 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0018
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0002
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 548 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 548 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 558 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 558 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0005
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0022
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 558 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 560 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 560 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0005
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0066
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 563 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 563 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0024
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0057
============================================================


============================================================
🔄 Round 565 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 565 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0014
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0010
============================================================


============================================================
🔄 Round 566 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 566 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0025
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0066
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 567 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 567 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0014
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0008
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 568 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 568 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0016
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0023
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 568 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 568 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 568 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 576 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 576 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0010
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0023
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0008

============================================================
🔄 Round 579 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 579 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0009
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0011
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 581 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 581 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0019
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0145
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0008

📊 Round 581 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

📊 Round 581 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

============================================================
🔄 Round 585 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 585 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0021
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0080
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 585 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

============================================================
🔄 Round 588 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 588 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0016
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0110
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

📊 Round 588 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

============================================================
🔄 Round 590 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 590 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0012
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0030
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

📊 Round 590 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0007

📊 Round 590 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0007

📊 Round 590 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

============================================================
🔄 Round 594 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 594 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0003
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0021
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

📊 Round 594 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

============================================================
🔄 Round 596 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 596 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0003
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0037
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0007

============================================================
🔄 Round 599 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 599 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0009
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0008
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0007

📊 Round 599 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0007

📊 Round 599 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0007

============================================================
🔄 Round 604 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 604 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0007
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0004
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0007

📊 Round 604 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0007

============================================================
🔄 Round 609 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 609 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0004
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0026
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

============================================================
🔄 Round 611 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 611 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0013
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0022
============================================================


============================================================
🔄 Round 614 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 614 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0015
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0086
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0008

============================================================
🔄 Round 616 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 616 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0009
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0031
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0008

📊 Round 616 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 616 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 616 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0008

============================================================
🔄 Round 621 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 621 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0035
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0052
============================================================


============================================================
🔄 Round 622 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 622 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0046
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0173
============================================================


============================================================
🔄 Round 623 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 623 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0021
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0102
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 623 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 626 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 626 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0023
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0052
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0008

📊 Round 626 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0008

============================================================
🔄 Round 629 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 629 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0020
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0034
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

📊 Round 629 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

📊 Round 629 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2391, R²: 0.0008

============================================================
🔄 Round 634 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 634 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0006
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0015
============================================================


============================================================
🔄 Round 635 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 635 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0025
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0062
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0008

============================================================
🔄 Round 636 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 636 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0013
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0036
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

📊 Round 636 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0009

============================================================
🔄 Round 639 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 639 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0014
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0024
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 639 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 639 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 645 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 645 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0035
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0288
============================================================


============================================================
🔄 Round 648 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 648 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0028
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0079
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 649 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 649 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0010
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0346
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 651 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 651 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0014
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0013
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 652 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 652 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0010
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0005
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 653 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 653 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0015
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0119
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 653 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 656 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 656 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0041
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0000
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 656 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 660 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 660 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0010
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0214
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 662 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 662 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0002
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0027
============================================================


============================================================
🔄 Round 663 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 663 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0012
   Val:   Loss=0.0690, RMSE=0.2627, R²=0.0114
============================================================


📊 Round 663 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 665 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 665 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0010
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0009
============================================================


📊 Round 665 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 665 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 665 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 668 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 668 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0084
============================================================


============================================================
🔄 Round 670 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 670 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0021
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0034
============================================================


📊 Round 670 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 671 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 671 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0011
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0008
============================================================


============================================================
🔄 Round 672 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 672 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0003
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0036
============================================================


📊 Round 672 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 675 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 675 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0002
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0028
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 676 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 676 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0002
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0029
============================================================


📊 Round 676 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 681 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 681 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=-0.0043
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0085
============================================================


============================================================
🔄 Round 685 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 685 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0024
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0225
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 686 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 686 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0034
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0113
============================================================


📊 Round 686 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 686 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 688 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 688 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0026
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0007
============================================================


============================================================
🔄 Round 689 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 689 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0010
   Val:   Loss=0.0737, RMSE=0.2716, R²=0.0010
============================================================


📊 Round 689 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 690 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 690 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0010
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0062
============================================================


============================================================
🔄 Round 691 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 691 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0031
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0097
============================================================


============================================================
🔄 Round 692 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 692 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0016
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0015
============================================================


📊 Round 692 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 692 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 695 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 695 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0004
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0002
============================================================


============================================================
🔄 Round 696 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 696 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0007
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0044
============================================================


============================================================
🔄 Round 697 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 697 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0031
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0304
============================================================


============================================================
🔄 Round 700 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 700 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0001
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0078
============================================================


============================================================
🔄 Round 701 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 701 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0013
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0012
============================================================


============================================================
🔄 Round 704 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 704 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0002
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0050
============================================================


📊 Round 704 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 706 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 706 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0014
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0009
============================================================


📊 Round 706 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 708 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 708 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0039
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0216
============================================================


📊 Round 708 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 709 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 709 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0021
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0241
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 709 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 711 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 711 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0003
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0016
============================================================


============================================================
🔄 Round 712 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 712 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0019
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0022
============================================================


============================================================
🔄 Round 713 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 713 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0014
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0028
============================================================


📊 Round 713 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 713 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 713 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0011

📊 Round 713 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 719 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 719 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0035
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0149
============================================================


============================================================
🔄 Round 720 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 720 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0019
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0028
============================================================


============================================================
🔄 Round 722 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 722 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0028
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0078
============================================================


📊 Round 722 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 722 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

📊 Round 722 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 728 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 728 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0018
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0032
============================================================


============================================================
🔄 Round 732 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 732 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0019
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0030
============================================================


📊 Round 732 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 734 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 734 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0004
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0143
============================================================


📊 Round 734 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 736 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 736 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0000
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0046
============================================================


📊 Round 736 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 739 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 739 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0005
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0026
============================================================


📊 Round 739 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 739 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

📊 Round 739 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 743 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 743 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0007
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0046
============================================================


📊 Round 743 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 745 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 745 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0011
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0049
============================================================


📊 Round 745 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 748 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 748 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0012
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0039
============================================================


============================================================
🔄 Round 749 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 749 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0007
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0078
============================================================


============================================================
🔄 Round 752 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 752 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0024
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0093
============================================================


📊 Round 752 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 752 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 756 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 756 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0007
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0033
============================================================


============================================================
🔄 Round 757 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 757 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0011
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0004
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0010

============================================================
🔄 Round 758 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 758 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=0.0027
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0055
============================================================


📊 Round 758 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 759 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 759 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0030
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0088
============================================================


📊 Round 759 Test Metrics:
   Loss: 0.0770, RMSE: 0.2776, MAE: 0.2390, R²: 0.0011

============================================================
🔄 Round 760 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 760 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0004
   Val:   Loss=0.0731, RMSE=0.2705, R²=0.0016
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

📊 Round 760 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 764 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 764 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0013
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0028
============================================================


============================================================
🔄 Round 766 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 766 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0001
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0001
============================================================


============================================================
🔄 Round 767 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 767 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0012
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0134
============================================================


📊 Round 767 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 768 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 768 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0022
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0026
============================================================


📊 Round 768 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0012

============================================================
🔄 Round 771 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 771 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0006
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0145
============================================================


📊 Round 771 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 773 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 773 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0034
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0026
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 774 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 774 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0014
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0008
============================================================


📊 Round 774 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 775 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 775 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0007
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0027
============================================================


📊 Round 775 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0013

============================================================
🔄 Round 776 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 776 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0020
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0397
============================================================


============================================================
🔄 Round 777 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 777 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0005
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0011
============================================================


📊 Round 777 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

============================================================
🔄 Round 780 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 780 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0019
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0016
============================================================


============================================================
🔄 Round 781 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 781 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0015
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0088
============================================================


============================================================
🔄 Round 782 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 782 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0002
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0048
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

============================================================
🔄 Round 783 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 783 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0020
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0024
============================================================


============================================================
🔄 Round 786 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 786 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0030
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0325
============================================================


============================================================
🔄 Round 787 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 787 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0004
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0036
============================================================


📊 Round 787 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2390, R²: 0.0014

============================================================
🔄 Round 791 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 791 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0002
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0366
============================================================


📊 Round 791 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0014

📊 Round 791 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

============================================================
🔄 Round 793 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 793 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0031
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0066
============================================================


============================================================
🔄 Round 794 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 794 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0009
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0020
============================================================


============================================================
🔄 Round 795 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 795 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0022
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0044
============================================================


============================================================
🔄 Round 796 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 796 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0010
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0001
============================================================


📊 Round 796 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

============================================================
🔄 Round 801 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 801 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0018
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0156
============================================================


============================================================
🔄 Round 802 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 802 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0027
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0035
============================================================


============================================================
🔄 Round 803 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 803 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0010
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0083
============================================================


============================================================
🔄 Round 804 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 804 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0019
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0035
============================================================


📊 Round 804 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

📊 Round 804 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

📊 Round 804 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2389, R²: 0.0015

============================================================
🔄 Round 808 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 808 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0002
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0038
============================================================


❌ Client client_18 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
