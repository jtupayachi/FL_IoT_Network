[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab5ac7f2-0456-46e4-9bc3-ed0caeeac580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc795d03-0e04-470c-8ba3-ac1f0f79794d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b87729-2c35-488d-9813-b080057415a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aebef6d8-9360-4882-9d29-55d8f12ea3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5ad93ec-5446-44bd-94d7-3b2e4a94a8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10b63836-2700-476e-a1d2-36a631b769e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e93af5-a835-424c-838c-f54df1982955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5da579f-2df0-4c1a-ac9c-279cfc627a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bbfb44b-1d92-420c-bdfc-6379794732ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40df5a21-230a-4b5c-ba74-cd2c0bbabef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63566e55-28c5-4391-98d4-341a5b1aed50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c264b0f1-0a1c-4b7e-963b-a4f45bc71371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49f9776d-a83b-48cb-aca7-0314501e324f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 990e4266-5f49-4ee3-a29b-0e61b052354f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f3affd6-b8d8-42b8-b815-6a2d2889607d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 092205d0-3a33-45fe-8817-94e354cb0c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d10a4ee0-84df-4a92-ac4e-827e5ed255e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4504ba08-66fc-4a7f-88c3-ce5029f62eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc43e9c6-f84b-46cf-9e01-a68d7b4b7b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e09386a-6963-4996-909b-b41714e0a117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0741eeb5-a2d8-4da0-bd2d-90bef068adea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a862a6-56f2-4d9a-9208-8e2e791ad227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba3b608-5505-4d07-bed2-3b567de60377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cabed7da-cbc2-408a-a007-61e7ba33df78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a8d6ada-f216-4d22-aa18-8f738af04b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7256fdcf-adca-4d12-a9f8-55fb47b91302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 581976d2-8ba3-4df1-acad-2982740bf8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5752f8d7-08c1-4351-8831-7328cde4f3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56237853-0de1-49e9-ad6d-47897f02762d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b14a325-4fc4-46e9-8cee-c4278d63020d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a54348-6e8f-4cbb-aac7-90d49b96779c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b641e5-f54b-4212-b46f-39d7b63010e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df5a9dc-7c96-4d07-ba85-70c499ada991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db38b053-0728-4b4e-87f3-6ff08adea556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8ad241a-fff0-4e6c-b3b2-55e50f151519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ba20fd-574b-41ef-a39f-7923a108971e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 629e1e0e-fcea-4b71-b362-98ebecaa18a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7af6dacf-8695-4f64-98de-10e729bfc9ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d21bbcf-f55c-455d-9150-a87205f491e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 119afb95-03a6-4aa6-a2e8-39029738cdc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708f614f-cd64-48de-9e40-7125c8a1d9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e48576fb-0da9-4c8a-ba84-d2a009b10fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce63a8b8-6e22-4db3-b461-ce12d1ac46cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b400149b-dced-4b5d-a8a2-eb8c65a21fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87d013bb-48b5-4731-8f81-ed60a1b55e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cab4cce0-d88b-4dbb-8089-2af046e1a9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc803ac3-f845-45b0-96fa-34a21172107e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34b0f117-921f-4d75-887d-6c8d48934a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e5cdc3e-8efe-43e5-b065-46aa29674b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ce6cc5f-c9b3-44a6-958d-0cb938952d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d4f4f5e-245d-49a7-b511-e861031f0d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0827c32d-0042-4320-abfe-4c442ac2e9fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8c2d76c-59a4-421c-a534-f7684e5a0146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40f4f2a6-39b0-4b09-8595-f73e4017dd54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37334959-d17a-493e-af2e-136210d9c874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c81e2f76-6542-4f63-83a7-e81b92d1b516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b46e11df-968f-4ff0-a24a-24d06ffd0295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5ffca3c-fffa-4967-8e43-467a4285d4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 625cbcd3-8d40-4955-a953-c7f467c76bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 097e8e87-f2b8-488d-b50a-24718b229dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e610517-208c-4cd4-a6ba-fb0cf2e41818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b852461d-c83d-4a30-9dda-dc51d5ae26af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ebd07e6-60b2-44f4-ba5c-ab4204cf181a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2718d23f-4ed1-4458-be9b-daee0e120b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd01274-8f0f-46e8-a00a-e8e05bf49e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 013ca3e2-831e-43a3-a19d-d9ebcbb15fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2959f60c-43ba-4976-b166-aec4b01b0d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d61ba01e-024b-41d2-8721-b49bc413a290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd48f862-c9c0-4bea-94b3-acdce0d9bc63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee4b7841-1fa3-4db2-85d0-4ee3fca1924a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59503f63-7d9f-42aa-a0cb-6ceac689b11d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e68d63c9-4223-4c4d-9381-b4f0dc419d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe1d136-23d1-4521-808f-6cdbdc0639e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67d9c0e8-ddac-429d-be47-9218bd47f655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e57184db-b50c-4a9c-a093-a45adc2435fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd07a426-8c2c-47cb-873e-cb17f3fd504a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 817125b4-31bc-42d1-b6a7-c1207454a259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bdda68d-c7ec-48c1-bc00-52e7d59e19fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1754af9a-8b8c-4bac-8dca-c398276e54a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa28559-0fa0-4b5d-bc09-d6e50346f2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33148c0-46c7-4e61-bbc2-947537e8b0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e706a50-fa69-4ba5-8249-98120e414c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c92a6b0-ecc5-49b7-9793-2966ea754fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d803a900-306a-47b9-b278-b774ebb94c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75365eea-c803-4bf2-ab92-bd0a6e1393b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e8d8d87-dbcb-4ed9-939d-1513333e1474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506ba841-bb53-4a2f-a850-79f2d51e51e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded38688-1d1f-4f6a-932d-9faaa382fac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73dd5b22-b6b8-49f9-b17f-312598d03cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3c12078-9676-4606-b68e-93606f8482f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f59be7a-0f93-4d49-884d-ca5297eb095e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba5a7a2d-9070-40d7-b86f-7e0983bbaf27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ca550e1-2431-4086-ac04-a39eaddb31bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dae1462-cf8b-41dd-8b80-477d01651d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caaa5eab-4d2a-47a9-b582-06ec3e8913b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d9a3b3b-0330-44dd-a7ee-0fb59a5ad6a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ca0865-634c-4fdf-8c4d-50d1335c7dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58072ff0-7374-485e-8ec7-a338f01893db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99d5f941-ae1e-496e-a3e4-f4f769fa067a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4cc54ed-6caa-4b8a-afa4-0889da9d83ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a8c1427-d79b-4453-910d-b5e2c26fd060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23f5624d-150f-44cd-913e-5f169de27b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e82bf411-3c3f-45e9-a1c7-9827bb7eccce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d0754fb-8b61-45f4-a53f-e24cbb234adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7376573-35e7-4937-a097-f79789bcc2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaaecd9e-46eb-4057-bc9d-d527deac211a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ab205aa-71db-4376-afa1-5c637cf2ec45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc9d6d3e-a3ce-4ece-aa71-1fd3a51553a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d14a20e-b6ac-46b2-ae58-44dd2e65353e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45be3ae8-db73-4c81-8bc1-e24084e5f641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de5be805-7fd5-4d19-8bb3-b4ff22600fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83c0ea95-77cf-4d9d-8032-87944f27324f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09269e96-e2fa-4dd6-8059-7f30a6bcc764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3eb472-b167-48ab-a04c-e3f7454197f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4027786a-4eef-4921-804a-8ac81b8ffcc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d77b07de-4405-4dc5-9527-0477a2f22b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27169c37-f771-4f6d-b89f-6a9d43116778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e35b06a-8989-4fc3-a7bc-ba9adc1dd11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fcd35ca-bcfa-4c45-a484-4a36cc3000bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eed5bf6-9112-44f0-a235-c970bfc1ccc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f54f5cd9-2578-4f78-8ccb-1a16b590dc44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f417fc03-b54d-4eff-ae6a-23b736b69513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf6f782-811d-457c-880c-494133001969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae5ab1e-ac0f-462f-945d-7bcac5feaefe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f3c4497-6232-48d1-a052-f1b72528beaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ec0fe9-d8f0-48a9-9a94-dd0784d2ded8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eba8a368-8433-4e46-a3cb-0b9c573c02d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aebdec55-4bf3-4639-bfd6-6ae7bd86af3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a5fc8ab-b87a-427d-9598-fb6c6b206cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c5ddac7-0741-48c2-8d01-bb06c3f07367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21dc5ed4-7d73-432b-ac14-60cfc45051e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567fef0e-42d7-4896-b420-d1bb63d1afa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23dea10a-7e1f-40c4-ba83-470baa6885c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 655ecb13-c0c6-4463-b249-8e567346a186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ca5b66-aca8-4e72-aaca-1933ab1c884e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2050a422-9dd0-4ee0-8e04-1e0f24270667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f87900b0-c2e6-4fd3-a725-9de129a2b210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8931fa1d-05c5-45fd-ab63-a37163902e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cb2c63c-5060-4134-a6dd-c21b955203ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cbe097b-7c34-4b4d-9ed3-e7e6713e17de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24ae1c29-6acb-4d14-996e-04a1a5542182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f387661d-fc7a-4330-9af5-818a4c9415cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2231d0e6-fb54-41a8-a72b-d8ac03366a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ff0fb1f-0498-4e1f-8f4f-cfc97a4abfab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 451142d8-8b4e-401d-a65d-2a0835e5f672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf07e1d1-54fc-4370-b7c0-2e509622302d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0925e6e-9362-4535-bbbb-8aa60229f0ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b372ba84-f46d-45b9-8999-d631fe19a699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cb7000d-fde9-4ffe-b37c-a9f857e399a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26276c26-2bd8-4499-b10f-6eda5b07dce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f187d7d-95d8-44eb-b49c-2ba9c9f446d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f1810d4-5190-48ab-8988-925d38896687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8e8d8fb-5fe5-49f2-96e8-a37ef455a145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe038d4e-1033-4fa8-9175-5bb64898ee4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 462b45db-d87a-4d52-9f43-b499f595a08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c154234-37fe-4248-99ad-34e0afedc0e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 058d2356-419a-4412-bf4f-278040f39463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7c1f863-762c-4188-a68f-d202d8482b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bdf3a4a-a317-4d32-871c-41e5c7eaebb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fb98197-a918-45fe-96cf-1198599cfbc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ac925b-f156-4f4c-8218-aaa8448acea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e273480-c1fe-43f4-8574-0a1b364f89b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f90972b-a6e4-404c-94a9-21e3d4a0a753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 867338ac-54dc-4ac4-bdce-7a640012e2da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7651af-6faf-4a19-ad02-03c430da1c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92000238-2a58-4b61-adf0-f14e8e61eee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62d165f2-0b79-44c3-ae7e-a5bbb594769c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a122b5a0-447a-48fa-a055-de49b332f817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a70546c5-983d-4169-ae77-a8f9a6a6d9b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e92eda-6162-4310-b723-2775df688022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02dc4f99-d7c3-4de9-83f1-37813abdb031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 525a781e-01a6-4e9c-baab-38fb3c31f101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71e671dc-df34-4f3f-ba5c-d6e78afe6b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8f75b64-6c90-4296-9899-89373e3bab61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 857c34ce-db26-44e7-aab8-cafd1ebd479c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd575145-3573-4f83-b132-e13203e358b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db93a498-6094-45d2-b899-84216fa02cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d75022f-1196-4049-8f9d-c5bbe2071257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc4e31f1-9b8c-4c6c-be43-91ccdf615de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02856999-84af-4a2e-837b-066837aa3d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce230d9f-1ad7-438e-b1db-307b18623426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 592d7bbd-edb9-41b6-9592-65307c51fdf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c7d98a-76a9-49c1-89e6-885e1290e3fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 505cfde9-5719-4d2f-8af1-bd48468527eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dcec2b5-1812-4d58-a782-ee1dc4e26266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73b5661f-19fe-49ea-99c3-4d1ebb24f70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72a5670b-a8a7-4684-8ee7-f7003bcc581d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8050fa39-0bf7-4b56-a0e9-d1d190f5735a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af6724c9-f0bf-4681-b359-f7d22239de30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74f00e69-333e-4af1-9fd6-e9842d125fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d91b8552-5f6a-4654-b738-e2f02ff984f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8599de4c-b92d-4581-a2cb-11b62d421fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f5851e-a769-481a-bae8-7038ed4f6f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b621aa2-b722-4863-9517-f67ef751d139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f2884a-9a3a-46c7-91fb-cf7e449134a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b35140c-173b-4717-b2b6-d6a4ae109e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce0172bd-5f6c-4a5d-8564-06598f52f5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 542bf232-62c6-4005-81d9-ed1e8895dec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fef91e9-a2d4-42d6-b85f-cd50bf6b9d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2ecca09-e8a1-4ba2-b287-fb784157a62b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0824fd8a-9943-4e17-875c-75da8322bfe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f8a823b-afef-44d6-812d-1768c23308e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 070359e4-e706-4a20-a7ce-476153c8bafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cd6a79c-430d-4f75-8319-216df9c51cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9461a875-5c1b-4719-a612-dd2dccd4e75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b0c08df-95ff-4118-93a8-ec0505f82ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfe1d380-48f8-465a-a394-9f3e2a6fd350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80fc2db4-2c56-4974-b396-fd348fa3bd90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66b67af2-c6e7-4fd5-8645-90c0e6c6c96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38bf56e9-ea8d-490b-a562-e34f5aae1c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a3732e2-e549-40a2-9ac7-bdb81f4048ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd7ab6a8-b2f7-4d6c-b736-6550556c72d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf141a0c-8168-431e-ae3f-2f0ebdd88595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60091a47-c56d-4cce-890a-026b96b61fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda0eee0-ff12-41fb-bd50-85a154b46c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d763f5f-a0fd-4a77-859f-c020b674ff5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 379362d6-b0bf-4221-98ec-4cf947536816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c61b04-4b22-4a5c-ac0e-b860c442e3c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ff2edf6-e209-4548-a1c8-a09617ca7b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31741285-9d15-4a4e-aabc-cdf28e4e81e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dd5843e-af71-4f61-9c97-6c16369894af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e24b0927-dc30-4a32-b281-ba067cfa7443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6da2aa8-8f2a-4ad5-9af7-a099e43a9b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 314d7c8e-05ef-4e79-829b-24acc0c212dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab5e729-89d8-4d7d-b28e-1100a9c39d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b133c755-27d4-4c10-b88f-fc360ff115dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e68cc8a-144d-4df5-abc3-d110ee085039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8b89f7-a6d7-44f2-9562-534c16f2e3ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d1e4e5f-9a43-4f88-af83-7c755d40e9f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bd2da1b-7904-47be-8982-7f8364e0c3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 816d1320-0ece-4830-83cc-2c3d5ebbbb9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e005071c-e894-466b-99f6-287f5e49b5e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dad9e72-5da2-45c3-81eb-c5faf23da60b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 179603a0-4814-4079-b04a-39eb312a4ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 968c0dc8-2c06-4eb3-9695-98cdd40e53d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e0d59d3-fbd3-46c6-a207-9e8bf0aaf53b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 133005eb-110a-41f1-8da5-e77d0c5aebb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8099f9c-4a98-47af-8e67-a3716bffd817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80fe3f7f-6486-4bca-b5a5-4fcbbac6a7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3773830-da52-4a4b-ae9c-c2cb987cf5f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6a2ece-8822-431a-a288-9515767f985f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c221ea6-cb8c-4527-bf11-8a52a945ae4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4e36c5-2067-47ad-993e-534222a15feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5df681f5-6106-423c-a1fe-b7d9dfbdadcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 175be7f3-e6c8-4f32-9783-7240823cec37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cda8dbc6-b4c2-42e0-902e-14719f74623f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40aab73d-4e68-40dc-91c8-33113c3f5572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4fa0897-3b62-4ccf-b2ae-084353fe16c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4178f553-5e77-4e43-8343-069d5b65a4a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cad21e6-568a-471b-8ce5-f3291883575e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 774acaa4-7d4b-4117-9bc3-d4dd3cf9b064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc1b48f-a35f-44bd-bc3b-4f7d0ce99f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02349105-f709-44d4-861d-0e4e07adfed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ed7da12-0952-4ed3-b430-f4d34089c371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36764748-19b3-456a-b292-e853588478ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bdc2b9c-5e7e-47d2-bffc-07c1b22c612c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 019e6a7b-84a4-458a-b3a1-64429e7ff0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 683ddd02-c66a-480c-9cfa-ebcba5ddd223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5efe40d4-2997-4923-a1a3-801af8312f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed31878-5243-4dcc-8cc5-ba7698fcfa4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cd5c590-2ddb-4108-b79c-d0f1640c4750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d1bac4-76e7-45d3-b632-6703ed0a9308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee4a5945-3faf-4d00-b66b-638ad496b81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b35f756-3334-45c1-a072-c60f92d44890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de0a60fd-2aba-4e8d-a9ea-8a1ed2baf2dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f3370a7-32c5-4a6f-994f-404b04179ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0496f745-619c-44c7-9acf-4bf235b634f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 024bd202-2ef9-4101-8871-8a48f8a4893d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c4863e-ed33-4e46-89ad-987c03abbf0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b193e06-ff58-482d-bfba-a179ead89413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c752d28-b288-471a-97d8-c20d9f1cf49f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83e8092e-e087-48c1-a7c8-c8874d9720b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97779647-3e3d-4b29-ac09-ff8a5208640b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c43ebc92-ce00-4095-bbb2-53b0fdad5016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5160cc6-d581-46da-9762-a33ef1811931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a35558-00de-4252-8105-a31b719d2b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d3c696f-5c43-4ffa-b591-bf3e17cbb810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d3d180-3cea-4032-9b01-0e9e553ce9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39cba1cc-796c-4866-a7e8-03273382ed26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a040b79-6d19-4436-b7a4-098dd1bfb1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca9758d-dad1-43eb-b6b3-5dc6c1df9e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee356c5-c7fb-4fdd-8f2e-c14d00dcaca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc41c64-abe0-4f94-a933-5aa3c992b985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2964fea-efc3-47a2-9d4a-023794825f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09ec6394-926b-4765-b115-24c9e36caab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd4b82e6-7b19-41e5-ad2b-b1db042c9318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a8ec5b-be61-49de-9bd2-5429fa30d256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 183ad596-45e3-4ad5-b58f-a55ea296f571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeec9071-919b-4c66-9049-2fd2d81a2efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d35d0fc-28d6-4b51-9232-dc9607cf62f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c3cbd00-2f48-456e-a871-c1ce53f082bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd28627c-6cf2-461d-8433-bc4016dae627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 865bca6f-b4f9-4160-9f83-e1bfe425a8da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da5d9682-bb89-4151-a9c6-55712d7f83f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee1a96f-46aa-4195-b710-7bd1cfd02da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fb201ac-cc69-44b8-8ffd-ef95b90c214c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8edbd6c-ffa8-4cd4-ac78-21c96c996a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d43f515-ea8e-46f5-88fa-fca10135e349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d861f02-fb63-4082-a1c0-2dfeef2967c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1536f66-b01c-4652-871f-e7c66cefc5f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 085447a8-5a2f-484d-881e-e9a9a74aca75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d64a55a-765c-422c-93a9-c7b7ff04140c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f4c517c-d257-4ecf-920e-c43c36427d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abcfb0f5-f38b-4399-8a31-62966ff5bd7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 728d56e7-68e7-43c3-97d7-2fa7b5be1247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a456dabf-847e-4d2c-8a1e-c87b9e067d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb437bc-6b0d-4dda-8bb7-06f7ca57b1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 096d040c-d1cf-4b05-a319-0ae43d871282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d12f473-a234-462c-9459-eafce940a1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4efadf4-3e07-40e0-9bb2-20409985b9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d6ca0b-c04a-43da-b07e-660044870c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b31e2daf-314d-4d6d-8208-13b5dc4880ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aac2e46-7b72-4991-9bd2-1bd5708ad042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 320a4fc4-ea86-4913-b660-2ed9b6b88c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 633e95d0-6586-48f3-85ce-30ec0ef07727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6965122c-87b5-4513-9cd2-d3f54a06ad8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02f47db0-5fa1-4429-9405-504e7dec2830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 891f6c64-1e6d-4961-8f32-ba2983a234cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c559103-d463-4b90-95a5-46f124d970a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38bfb936-c9c0-4566-8c62-c86244ad2e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 047c5587-cd19-4f6f-894e-9dfcf272e1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 703daf57-ec48-4459-99b4-2e6f67e354b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 266a087f-8427-4185-8b91-48c857008545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58c82ac2-27c3-4eb7-83c2-f9509d6ef00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f68f803-60c2-4dcc-a4cb-8e32fe5ad6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aef205b3-e6b9-49b4-8283-70ee574ef52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240c95db-552d-4497-b504-49e3aacdd542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e3655ab-0a98-4587-918c-b40d2a0cfe5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ca0756a-8872-403a-a785-c15bac4f8bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07841a6d-da7e-47c4-831e-a39fb8f9c301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9f1ffde-4b6b-4e58-b520-5e7af8b1cc04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 097fa99d-f211-4ae3-9ebb-685a874adfe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a32c76-d47c-4440-946f-add2d2fc2f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c517e21-359c-4c68-a22e-a4b028fe37c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5743c59-38de-4f9e-95e2-32255ce12529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b2307f9-1044-429f-9147-eca31bff5372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa93986-2d97-4d84-83fc-83fc34d79740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06387fb6-4dc6-479c-ad92-5e87b6a93c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0197c48-3ecb-41cc-a424-dcb62d40f1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb89fcca-9c2f-474f-b011-fc76e3aec481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ce251db-6ef2-4a41-8295-7c7742393f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74108e20-abae-49bc-a6cf-704ffdf5d3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50208933-40d8-4cc7-94e5-149526a3e70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bebae38-7cfe-46f7-b857-e59c2d45ecd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aa779ac-d356-40b5-bfc7-132e22a8f848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f7caf3a-fe3a-4639-aa3a-94619fb7e926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e527a04a-df63-40e4-9fa4-6315eec255ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c8fcbb-9bdf-42ba-9851-fb00d0fd10b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b45b314-ac03-4429-aa34-6dc39c481927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad6489dd-5e22-4100-871d-0bcabe40f151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fecff16-1748-4ef8-ad21-99319feefd72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf64412-a6ed-44da-9735-a4d24a746406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62957c9d-1b65-47fd-9b4e-f65bc375c41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e42bd5a-c9db-45f2-a4ab-5719c4756cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe0c8755-81ff-4618-8d4d-5deba4b868eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f26ee4-61a1-4b29-ace8-a585999a67d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b328e7-be6d-4caf-a29c-777891ebaec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec2e6c3-ab41-463e-888b-b57eea76ca67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d9ed19-5a7b-417f-96cb-d796bbd1f0d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc9c67e2-c217-4a93-bf76-5a23abf6297b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bacd995-83e1-4b49-9b54-1cb740c41dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf291303-5923-4bf8-9e69-87183b8f9f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16d0084b-8441-44a5-81c8-d9ae45a2ed7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71bb629d-9dc1-4004-918a-5b26ad5ca509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a070fed-6dfe-4f5d-bef1-9d62e306c166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 582cd620-99ef-4d37-85b3-27579a787f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd956bf-a226-4615-bc0f-913535e05997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18f70570-6f33-4ceb-8be4-cebe563001fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92732b0e-26ba-4c68-b881-118221389f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4d415c4-f11e-48e9-9dc3-4a9340f712f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0474469b-5d7d-46a7-bd46-b1c281c0c095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 095d61e7-74ec-4d5d-8453-c55e53dcbe32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f7e86e7-dad5-4414-aacf-d8a15554776f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1be304d-eabb-42bc-a646-e79a1f3a1aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 094c8fd1-fa97-4cbd-804b-2534c1b43177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 902dcf8e-a5bd-4f7c-98b8-8cc6bdc4fd36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6325a11c-2359-4dc8-833e-9cc78a8c6699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b0e479-bc2c-4df1-8367-4a0474405f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc856536-23c2-4936-9ec1-923f54b8de53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f91e410-e793-4a0d-840b-c6efd3c5bff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d81e1f-f1a9-42f8-b819-c5c9189aa499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1436acbe-ebba-42f2-80e5-ded8fb719f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a909b3c2-13ef-4e83-a8d8-49bac672806e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0146eab-cd69-452c-91f6-1686deb9c18d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d6f5ddf-4e69-4661-8d0f-2d912ab84370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca815d87-27d4-4883-8f2d-51a4532d6e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf42bdce-aa71-4bb8-bc3f-1568a8337e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f7aacc9-a049-48ca-971b-5fdb3bda70c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59cf48b-6024-4631-a91b-73bc919737ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13040d65-c510-4ed3-83d2-8296e07a5925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 176e287c-c984-4817-baf4-65a9c3bc9ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89db39e0-4b4f-4ac9-8c2b-4d4953b81dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1822ab67-30f6-400c-b393-71a2a62b71f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb1e47c5-ee94-4226-86c5-5572d899da0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e64861f-a1ea-4d12-945a-c61cab6585da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a41aa1-4a8c-4ee9-8f1d-0d21dbd15b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1efe1d8f-0fb4-4d50-9f86-6e21f1c5691b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86813c99-5af7-4434-a58d-20bb5168b77a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58ac6282-82f0-47db-923e-f0d5fdc28ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3247717-141e-4c6b-bb51-fdf3331a0b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12cce1e6-3d00-4ceb-9f2a-0d7b98e2014d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edbf6c81-ac53-4d3e-9766-e76cc81013b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7935ce0-c25d-41bb-bcaf-08e61052e209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 430c6bd6-405b-4481-bf8f-4dcf4ab7c5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf8c67b7-5524-4518-88b3-88d06118acbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf463dd6-f481-421d-9c25-b0c2eb365c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13887721-1ffb-4d95-95c6-45c905e4cecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c974fbd1-5da6-426f-9ebd-4d739a76ed04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cdd6d29-90d3-4e29-ae8a-35e98d7bc55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbdded41-f59a-4047-bf9c-2835a1892efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f6d4cd-d151-4011-9b22-3f14d1a3f783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e5f7935-257f-4195-ad53-d887f12940c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14818e1-5162-4161-8753-e8e432646ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e9895d3-6af6-437e-85f4-b3157af14d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6446f144-f6e7-4186-bb09-53b64384d2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c05c309d-9c57-4e27-a7f8-10c307e0d1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d95594e-1ee4-489d-a6f4-603429e52738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34ff7d10-f5a8-4a17-8cb1-42aa5da3bdf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5977e231-fdae-483e-81a0-2c160de79a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2ab0f08-2ca2-46d3-85ca-959f9cb75211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 498f8034-c440-4a2a-b93a-81c65a5e1e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbafd061-3fbb-41eb-aa70-2b4fb3242375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 552a2291-f0bc-41af-bb58-8aec32bb082a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a02a8bfc-6719-498d-8f6a-282270035a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6273552-2d51-40bb-b191-e8c2caa30a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 164c3cce-d045-4b35-a904-13e6c3a51f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8727889-b0c3-40dd-84fe-2545acc21b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 123dc4d8-2c7d-493d-a27e-fa047e901f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74c84e16-c8ac-43e5-bbe1-bb56a7f74645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73eda7d7-2e39-4a67-84f2-ff75023e43fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41a3e434-0dbb-477b-89e0-21dd2de0aff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e27bb7b-26bd-4117-a711-13b4d5ef63fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d21a7b88-f6df-4465-aeb6-0afbc17cb609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8d5b86f-3e76-4837-abc8-58ab844d5933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d154dea-6d52-49eb-b719-0ca45ceb64df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac5f128e-4f42-4380-ba22-f387e8ce77ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a59c751-e57e-4331-97c3-70b980669ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6224590b-d035-4752-b497-fbd453a5dba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c1e62f-eb93-492b-8a55-cfc99dbecb3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d173613d-a974-44b0-9a35-f7b1b7803b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f13b3909-043d-402e-9936-6f1f8f592229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8b0dac-893d-4639-a291-b97e16b0044b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6557ebb-634e-4b68-b741-c969959df026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e57ba25-aaff-4293-9873-8b9925acdd93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca9a2aee-215e-44b2-8b7c-d777da99ec54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b29825f5-702f-4243-b654-a047555cc191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 043fb033-1526-4b4f-869b-20741fc9f956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b843edb-1ab8-4edb-ad98-6f43e0c9aeb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7166f5d-df5d-451f-92de-afa004549403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d0d2407-e8da-44f2-b723-4b789adfcacb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc54983-b6a8-4723-b5bf-7ee0d04e9778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c18d7753-95c2-47f9-9539-2f819d090ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bbf8258-06bd-4214-860a-03e62ef0356a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9ed0373-4a28-472e-ade1-82930d0db293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcd3a18f-ff1f-4236-97c9-08d4446dd5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdf126f2-6a3b-4984-8764-c335a20c5bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 952f0605-049f-4703-9e07-60e6ba1cc004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 635966b4-a545-4a91-bc90-5c5fc3bdf65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ed7fa09-a169-425f-bf99-18f3da757901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 409117ac-c9a4-4c83-8a2b-82674fb958d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0efef3b8-d5c7-4097-8875-9886af7c48e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d1281d-be5c-4b6c-a24b-9c4fade0508f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 538cb1f3-fc62-47ac-901c-d52d1ee66dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c525c563-5aec-4158-80b9-6bf84bb5802f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f4e0039-2681-4548-aa2b-83cce36a6002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1a9a9fd-44e6-4e55-9d94-44c12d859106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58a496ca-0a6f-45d9-af17-18a72bf94d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 750c5759-b3e3-420f-89ec-d6c956b99335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a309d19-b51d-4cf5-8811-46d55cb97587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3e14c91-0b27-4969-8d33-b507108845c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29f83510-424e-49a5-a15d-a18405488bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4574b5-a358-45db-9414-e55e0dc5dd60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ef0cb51-e922-4ac3-a3fc-d87189b0fb9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 612f8e80-2680-4a6b-a60b-daaa7f22f212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3cba5ce-7f5e-40b9-b5a6-721ba0ebe372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e778c487-40be-4446-96c4-f65e390c62f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5679d32d-5b44-4154-9cac-270941d96069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17f23e6c-a4ad-4c67-bb4a-f6c517368a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d06fcd-3965-41bf-ba55-768eeec1f18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca5b6f6-59e9-4c95-a0f3-d97816dc39d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 792eca03-ad7e-437f-92ff-34d95b95b11c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d083083-1b05-4ec1-8937-45d2f3cd0740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2afa1f1d-ee87-444a-9fcc-e41b4a3a92e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58274216-9319-4002-b3c3-adda8196be8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f7a61ca-6eeb-4e33-a1a6-7ae7840996f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1912e454-f47e-41cb-9ad4-aac9990a7a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6910632f-34b6-4857-83d2-3f2c46155ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c684130a-c620-4153-b39c-fcf1b3bfac88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbdf499-23ba-4510-aae2-d0daf6caa03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2f42142-ef2b-469d-9894-df547710bd13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7623755-720e-4694-81ba-bef6a69a7c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message becc5972-7a87-44bf-8127-ea22a3eb53e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4161db8d-6af0-451a-8563-fb20afde2737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 976ddf6a-2904-47d0-8b6d-a7a2b070c201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7609fa1b-8927-4f37-9315-08cac0daca6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 898477eb-4375-46a5-befb-dee9df945047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9468864a-6d3f-43b1-83b3-b959b07a7755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab148ad6-b947-4267-90c1-7fa25d38c55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 240b25d6-bfba-4265-9d53-32dc6dab2e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ae9154d-05cf-4a65-8111-154814e3639e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10436402-1243-4490-b068-4c5714e7b2e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5418df8a-078a-4e35-b65f-eeef5fe1f6f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f90409b8-a19d-46b8-8724-f38465a408cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 349e1a68-a96b-4bb7-8d54-abed18dee611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8943d8cf-a96f-4c66-82ee-f00c98c02145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42120043-310d-40e7-8867-ce11b7368d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31ca4459-62e6-4287-aad8-345ff296afea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fb5fae9-1689-47ec-a9e1-996b09c8cf8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e43fdc1f-7dad-4857-8b34-8edb641d4a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a4607d-a5db-4a33-a094-d8337f23d6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe957a9d-7eb7-4645-a7ba-16ad58caa36b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5895dc4e-a867-43ab-b041-02e68ac34a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76c01685-9c41-4eaa-a846-01f94510a4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8b1decf-e203-4718-94f4-e24bbe54c8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0df30a-fbdf-4f2f-9c86-4a5e316c93e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba5c547-84a8-4a37-af36-3b6a535276c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a76abc18-50d8-4976-bea6-82fb6e52076a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc020c7-cdd6-40c1-bf75-18a57178b110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18821f6-5d7f-466a-907a-e1d9b78b285c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92f75f0c-f4f0-4441-910d-f259512e504a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5d328e8-d8f6-4bdb-ad9e-da2ca3136543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c3d4a0e-ac99-49a9-b5f9-b8231c8743d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbc7867d-b505-405c-89a6-b9cb62176f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03605678-9b13-4b1d-9baa-a37ea7a886b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bab9fdf-3191-436e-b214-1fcb054a8407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27b469cf-6401-422a-a211-8d3c684fe8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23774edb-2cdb-489e-8716-4f36120b3f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c7b3f26-a91a-45ff-a3e9-2b1dd1e955eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 258a00aa-db2e-4708-9f35-baed8485462e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 983052ff-0544-40cf-a4b6-b0faaeb2bf4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45dd9f3f-af8c-4412-abc2-259f5ed3baa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d914d77-0542-4080-8745-adba97a159cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8fef20c-3153-4fc5-95ec-187373eb369b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 713145df-330c-41b8-8f22-e04f72a366b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0680c2e-73ba-42e4-bc76-dc52dadefb57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e7d701-eb31-4afc-9f42-b21d913ae466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d47d2e47-65de-47c4-a353-c9ba0070731f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea17e9ab-ca53-48c4-a570-cd5c9b62a9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a87f2529-b183-4aa6-8b1f-3809efd0eb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d3d94a-2671-491d-be09-0836ed1a8a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0b60c68-9c22-471d-95b5-c905119072de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e6de78-a95a-408d-aefe-c0fa4827b67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 099fe515-0dff-4e2e-b1d8-5aa4f71c1ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25b04fbb-e230-46de-8760-69dc7862de01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 202570a2-01c1-4fe5-8580-b997ba01205c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 340aac30-7b9a-4eb7-bae4-1d62207267f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b55743-b232-4ecd-b56c-a155fdb50e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25974a70-1c0f-41e9-ad47-abd2a0622117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 484d5aed-13d5-4379-9f8a-900a8b5a79b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d59782b-66b8-4de5-bfc5-234319542de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0031c09b-1d4e-4f92-9bca-745dd913c458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e37ed11d-1ea2-483c-a6a3-c671c81ab13d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 322d5a18-57a1-4d31-86c8-bfd49b94c011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 254ed778-8dad-4a78-92bb-4beba0df26f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 948920e0-e485-4575-8d39-159f323615ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 433801ce-a7f6-4f57-8dee-dd6bf868c10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f1c9e24-b2da-4ee7-a35f-1de7c0281428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6f43cc-b792-489e-9b11-346513ecc237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89b0b621-2740-41be-8948-affd13da98a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec7f679b-120f-428b-8aa4-52899f2958e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 629a05c6-a4c7-4129-89b1-267e7809d044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c407f51-9cd0-4b5d-ad20-e426af992536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af975ad7-ac78-41ef-b690-8358961680bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf887f80-d194-4530-9730-7dcccf9622c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a08a1f75-c41d-4f47-ab9f-6c95d46ed2cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7337324-7d94-42b0-a127-4ba24f0b3a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da329644-5b89-4614-b450-588ccdbcd0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c1f60fc-cca1-430f-8d10-b0dd29ceb4e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c82f472-622f-480e-a4eb-fe73776aa4ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980b8daf-a717-453f-8ac8-de723c23f4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c9faa5d-2191-469d-beff-0f19785e65de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f43dd103-60cd-425d-a48b-06ea2b89a647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22555a42-f50b-40fb-81f7-d4449c97f070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d8103d9-56d7-46e8-a4c9-0d89c53ca402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 128b3313-d4da-4652-85ca-f7b7d2f33e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ca55cc4-1f00-4189-9c82-1e5ea5c59c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11048992-7fd9-4b75-8d5c-ee06648f72b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a5fb43b-89a9-44ec-9244-986b1dd38791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f0aefff-12d5-4fe0-96c9-a338a0cddc2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47310b1e-d9d5-42ad-b7e0-a486e60e003f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38db1647-6c69-4b33-8b1e-1d1f61f5e01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38cb1a94-b3d4-4fab-aeba-43ac9ba09478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4392a22c-a47a-4da2-b146-7a75d90e2c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ab922df-03dc-42e3-afe7-a8ad457a8a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db837da6-df53-4712-9db3-364c13968be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54a0a8bf-1cac-4f79-849d-0c0d6613d25f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71138ac8-c78b-474e-be42-8c416171cbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb0365e-98b4-4b80-a1b8-9958c7a0077b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bc2f974-043c-4ade-82fd-0ffede596e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d7fd71-c46a-4124-80ac-e110049308e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68b4adb6-2fd1-434a-8ccb-9ba0089f22f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22074a40-cd6c-44ae-9363-715c79661c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0b406c4-bd2d-4fc6-a6cf-38e879388b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5057d45f-def6-490e-a969-02319b839a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 574dd48d-d954-4ae5-b922-ee1e96a7c1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eb793e6-b974-4df7-b1a4-d0bda4e4e42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77455a56-6fa8-4630-a496-574ec7d57b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaef429d-1e6f-4ca7-bcf1-dae7f40c789e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c72b0a89-335e-49bb-8be7-b8b2251782c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84c549b-70ac-4147-a6f7-1cfb74e746c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5787d053-557c-43a3-b399-280edc8375bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ffe31f-3c2d-4563-b78d-f7b83f530f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9841f9ba-8d90-4466-9706-73189ca0c9d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9397cd1-8d1f-4937-a9d9-9b98b4c395bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46346388-46a0-47e3-9990-8ff6009d4843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14ec8081-eb22-4b5a-9668-57cd2da71280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dbdca37-eb29-402c-afa7-a9bcf2a980bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 640a6a14-7f56-4267-9786-eda29456749c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24f8d4fd-32ef-4d83-b540-0eb2547821ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65b173c1-8643-4c2d-99f4-64400213ccf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b79977ec-678e-42ba-bd95-ce68fff9a200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 868810f6-6958-4788-bc10-c34bb0d5f8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 463d4214-0425-4898-b9d4-eca96531ed29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 552df4c7-7012-42ec-9b44-66549064ee3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1a58223-5987-441b-b141-d3fe81dc302a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab46ed25-84ba-4360-ae5c-f4740753ec54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee9fe47-0a43-49a7-a796-f4b10a7a5141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd46da1c-1e81-481d-8985-b1a9e634374c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1c98fd9-8ea9-4fa0-a97f-2e445b57a837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10ad9e09-b0cf-4a61-9735-f106be61aad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5250ad6-4388-49ea-bced-247ce4e1ad9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 308f1087-302d-4ed8-88a1-0d0219ffce26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d4c7599-ff56-4368-a3e4-3924169ba5ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822c8493-a782-493b-9da6-32887450ae28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d94abc1-6bc5-44d8-bca8-134303ca2bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f56bc96-cb94-401f-aa72-06574799c6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 936e5ce8-cf14-434b-be33-d5dc2b765711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d1867f7-223e-46ca-96c1-915a284a1fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16d65926-a3b6-4b7a-ac14-1d37daff60cb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_1
Server: localhost:8686
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/test_labels.txt

📊 Raw data loaded:
   Train: X=(6065, 24), y=(6065,)
   Test:  X=(1517, 24), y=(1517,)

⚠️  Limiting training data: 6065 → 800 samples
⚠️  Limiting test data: 1517 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_1 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2310, val=0.0928 (↓), lr=0.001000
   • Epoch   2/100: train=0.0915, val=0.0961, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0828, val=0.0930, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0829, val=0.0911 (↓), lr=0.001000
   • Epoch   5/100: train=0.0831, val=0.0908, patience=1/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0830, val=0.0899 (↓), lr=0.001000
   • Epoch  21/100: train=0.0821, val=0.0890, patience=5/15, lr=0.001000
   📉 Epoch 29: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0788, val=0.0911, patience=15/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 1 Summary - Client client_1
   Epochs: 31/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0067
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0210
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2443, R²: -0.0069

============================================================
🔄 Round 2 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0743 (↓), lr=0.000500
   • Epoch   2/100: train=0.0890, val=0.0749, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0881, val=0.0747, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0878, val=0.0745, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0877, val=0.0745, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0864, val=0.0742, patience=10/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 2 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=0.0041
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0025
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2431, R²: 0.0028

============================================================
🔄 Round 4 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0857 (↓), lr=0.000250
   • Epoch   2/100: train=0.0845, val=0.0855, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0844, val=0.0852, patience=2/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0842, val=0.0851 (↓), lr=0.000250
   • Epoch   5/100: train=0.0841, val=0.0851, patience=1/15, lr=0.000250
   📉 Epoch 6: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0835, val=0.0849, patience=7/15, lr=0.000125
   📉 Epoch 14: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 4 Summary - Client client_1
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0089
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0061
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2435, R²: 0.0035

📊 Round 4 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2434, R²: 0.0034

============================================================
🔄 Round 6 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0794 (↓), lr=0.000063
   • Epoch   2/100: train=0.0852, val=0.0793, patience=1/15, lr=0.000063
   📉 Epoch 3: LR reduced 0.000063 → 0.000031
   • Epoch   3/100: train=0.0852, val=0.0792, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0851, val=0.0792, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0851, val=0.0791, patience=4/15, lr=0.000031
   📉 Epoch 11: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0850, val=0.0790, patience=10/15, lr=0.000016
   📉 Epoch 19: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0849, val=0.0788, patience=5/15, lr=0.000008
   📉 Epoch 27: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0849, val=0.0788, patience=15/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 6 Summary - Client client_1
   Epochs: 31/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0086
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0080
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2437, R²: -0.0012

============================================================
🔄 Round 8 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0856 (↓), lr=0.000004
   • Epoch   2/100: train=0.0835, val=0.0855, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0835, val=0.0855, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0835, val=0.0855, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0834, val=0.0855, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0834, val=0.0855, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 8 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0067
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0013
============================================================


============================================================
🔄 Round 9 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 9 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0063
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0025
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2434, R²: 0.0021

📊 Round 9 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0028

============================================================
🔄 Round 13 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 13 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0081
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0002
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2434, R²: 0.0023

📊 Round 13 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 18 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 18 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0074
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0021
============================================================


============================================================
🔄 Round 19 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 19 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0068
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0055
============================================================


============================================================
🔄 Round 21 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 21 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0073
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0037
============================================================


============================================================
🔄 Round 23 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 23 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0071
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0045
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 27 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 27 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0068
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0043
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 28 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 28 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0084
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0069
============================================================


============================================================
🔄 Round 30 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 30 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0058
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0091
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 39 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 39 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0075
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0006
============================================================


============================================================
🔄 Round 40 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 40 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0074
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0027
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 41 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 41 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0073
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0003
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 42 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 42 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0052
   Val:   Loss=0.0891, RMSE=0.2986, R²=0.0053
============================================================


============================================================
🔄 Round 45 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 45 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0057
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0266
============================================================


============================================================
🔄 Round 46 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 46 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0078
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0003
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

📊 Round 46 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

📊 Round 46 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 50 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 50 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0056
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0088
============================================================


============================================================
🔄 Round 51 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 51 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0061
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0029
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 52 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 52 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0059
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0090
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 53 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 53 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0067
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0090
============================================================


============================================================
🔄 Round 55 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 55 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0068
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0031
============================================================


============================================================
🔄 Round 56 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 56 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0076
   Val:   Loss=0.0947, RMSE=0.3077, R²=0.0031
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 57 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 57 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0089
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0048
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

📊 Round 57 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 62 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 62 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0063
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0139
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

📊 Round 62 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

📊 Round 62 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 67 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 67 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0064
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0031
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 68 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 68 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0085
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0014
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 69 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 69 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0045
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0074
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

📊 Round 69 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 72 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 72 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0062
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0072
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 75 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 75 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0070
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0028
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

📊 Round 75 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 78 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 78 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0061
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0031
============================================================


============================================================
🔄 Round 79 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 79 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0052
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0126
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 81 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 81 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0063
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0073
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 82 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 82 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0052
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0057
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 85 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 85 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0042
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0093
============================================================


============================================================
🔄 Round 88 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 88 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0048
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0149
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 91 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 91 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0073
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0030
============================================================


============================================================
🔄 Round 94 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 94 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0086
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0041
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 97 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 97 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0079
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0016
============================================================


============================================================
🔄 Round 98 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 98 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0060
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0093
============================================================


============================================================
🔄 Round 101 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 101 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0055
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0094
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0025

📊 Round 101 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2434, R²: 0.0025

============================================================
🔄 Round 103 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 103 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0087
   Val:   Loss=0.0920, RMSE=0.3032, R²=-0.0011
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 105 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 105 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0064
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0002
============================================================


============================================================
🔄 Round 106 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 106 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0055
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0063
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 109 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 109 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0080
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0255
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

📊 Round 109 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 116 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 116 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0068
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0039
============================================================


============================================================
🔄 Round 118 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 118 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0055
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0079
============================================================


============================================================
🔄 Round 119 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 119 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0082
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0012
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2434, R²: 0.0025

📊 Round 119 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2434, R²: 0.0025

📊 Round 119 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2434, R²: 0.0025

============================================================
🔄 Round 123 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 123 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0070
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0047
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2434, R²: 0.0025

============================================================
🔄 Round 127 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 127 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0047
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0032
============================================================


============================================================
🔄 Round 130 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 130 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0066
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0018
============================================================


============================================================
🔄 Round 131 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 131 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0075
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0006
============================================================


============================================================
🔄 Round 132 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 132 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0048
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0106
============================================================


============================================================
🔄 Round 139 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 139 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0064
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0044
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2434, R²: 0.0025

============================================================
🔄 Round 140 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 140 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0069
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0048
============================================================


============================================================
🔄 Round 143 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 143 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0059
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0086
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2434, R²: 0.0025

📊 Round 143 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2434, R²: 0.0025

📊 Round 143 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2434, R²: 0.0025

============================================================
🔄 Round 146 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 146 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0065
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0062
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 149 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 149 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0078
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0016
============================================================


============================================================
🔄 Round 150 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 150 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0084
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0010
============================================================


============================================================
🔄 Round 151 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 151 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0071
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0038
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

📊 Round 151 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 158 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 158 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0083
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0054
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

📊 Round 158 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 162 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 162 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0058
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0086
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

📊 Round 162 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

============================================================
🔄 Round 164 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 164 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0081
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0011
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0026

📊 Round 164 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

📊 Round 164 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 169 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 169 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0058
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0065
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0027

============================================================
🔄 Round 170 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 170 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0055
   Val:   Loss=0.0933, RMSE=0.3055, R²=0.0039
============================================================


============================================================
🔄 Round 171 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 171 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0060
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0089
============================================================


============================================================
🔄 Round 173 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 173 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0064
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0045
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

📊 Round 173 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 176 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 176 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0075
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0017
============================================================


============================================================
🔄 Round 177 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 177 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0061
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0084
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 181 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 181 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0054
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0043
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 185 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 185 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0056
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0050
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0027

============================================================
🔄 Round 187 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 187 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0055
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0087
============================================================


============================================================
🔄 Round 188 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 188 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0081
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0011
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 190 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 190 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0064
   Val:   Loss=0.0950, RMSE=0.3082, R²=0.0023
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

📊 Round 190 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 192 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 192 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0072
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0042
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

============================================================
🔄 Round 193 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 193 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0061
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0084
============================================================


============================================================
🔄 Round 195 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 195 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0072
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0039
============================================================


============================================================
🔄 Round 198 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 198 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0072
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0040
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0027

============================================================
🔄 Round 199 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 199 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0046
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0142
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2434, R²: 0.0027

📊 Round 199 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0027

============================================================
🔄 Round 207 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 207 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0062
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0061
============================================================


============================================================
🔄 Round 208 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 208 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0054
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0100
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0028

============================================================
🔄 Round 211 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 211 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0066
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0058
============================================================


============================================================
🔄 Round 212 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 212 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0073
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0032
============================================================


============================================================
🔄 Round 218 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 218 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0073
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0036
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 220 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 220 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0047
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0037
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 221 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 221 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0052
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0121
============================================================


============================================================
🔄 Round 223 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 223 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0063
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0056
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 227 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 227 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0061
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0081
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

📊 Round 227 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 230 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 230 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0069
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0203
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 230 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 233 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 233 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0065
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0237
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 234 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 234 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0097
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0093
============================================================


============================================================
🔄 Round 236 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 236 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0063
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0061
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 237 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 237 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0067
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0012
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 237 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 239 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 239 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0053
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0014
============================================================


============================================================
🔄 Round 241 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 241 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0071
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0025
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 245 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 245 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0073
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0039
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 245 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 245 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 245 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 251 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 251 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0059
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0018
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 252 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 252 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0064
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0072
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 253 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 253 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0061
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0043
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 254 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 254 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0073
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0013
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 255 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 255 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0044
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0120
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

📊 Round 255 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 262 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 262 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0067
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0032
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 263 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 263 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0056
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0066
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

📊 Round 263 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

📊 Round 263 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

📊 Round 263 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 269 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 269 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0057
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0073
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 273 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 273 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0082
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0170
============================================================


============================================================
🔄 Round 275 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 275 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0057
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0078
============================================================


============================================================
🔄 Round 278 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 278 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0076
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0017
============================================================


============================================================
🔄 Round 280 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 280 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0080
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0007
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 280 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 280 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 285 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 285 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0057
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0030
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 288 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 288 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0082
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0000
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 289 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 289 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0051
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0099
============================================================


============================================================
🔄 Round 291 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 291 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0050
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0113
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 295 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 295 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0060
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0010
============================================================


============================================================
🔄 Round 296 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 296 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0071
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0034
============================================================


============================================================
🔄 Round 297 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 297 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0085
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0020
============================================================


============================================================
🔄 Round 298 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 298 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0048
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0141
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 299 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 299 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0068
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0025
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 299 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 299 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 307 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 307 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0067
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0062
============================================================


============================================================
🔄 Round 309 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 309 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0068
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0048
============================================================


============================================================
🔄 Round 312 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 312 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0078
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0043
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 317 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 317 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0062
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0046
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 318 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 318 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0062
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0039
============================================================


============================================================
🔄 Round 321 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 321 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0077
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0020
============================================================


============================================================
🔄 Round 322 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 322 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0048
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0148
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

📊 Round 322 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 324 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 324 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0062
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0083
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 327 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 327 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0064
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0076
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 328 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 328 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0090
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0037
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 328 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 330 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 330 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0033
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0188
============================================================


============================================================
🔄 Round 332 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 332 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0072
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0072
============================================================


============================================================
🔄 Round 333 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 333 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0081
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0030
============================================================


============================================================
🔄 Round 334 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 334 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0066
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0068
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 336 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 336 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0051
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0010
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 338 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 338 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0046
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0032
============================================================


============================================================
🔄 Round 339 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 339 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0063
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0055
============================================================


============================================================
🔄 Round 340 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 340 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0082
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0003
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 343 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 343 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0061
   Val:   Loss=0.0968, RMSE=0.3111, R²=0.0049
============================================================


============================================================
🔄 Round 345 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 345 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0074
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0031
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0032

📊 Round 345 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 349 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 349 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0047
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0085
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 349 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 349 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 355 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 355 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0061
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0046
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 359 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 359 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0079
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0014
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 361 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 361 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0062
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0165
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 362 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 362 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0051
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0366
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 363 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 363 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0062
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0010
============================================================


============================================================
🔄 Round 364 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 364 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0089
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0024
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 364 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 364 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 368 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 368 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0049
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0096
============================================================


============================================================
🔄 Round 369 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 369 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0066
   Val:   Loss=0.0768, RMSE=0.2770, R²=-0.0047
============================================================


============================================================
🔄 Round 370 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 370 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0087
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0057
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 373 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 373 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0067
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0063
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 374 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 374 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0056
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0036
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 374 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 377 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 377 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0058
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0003
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 377 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 377 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 382 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 382 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0054
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0073
============================================================


============================================================
🔄 Round 385 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 385 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0064
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0014
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 387 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 387 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0070
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0015
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 388 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 388 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0069
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0027
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 390 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 390 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0060
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0063
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 390 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 394 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 394 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0049
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0051
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 394 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 399 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 399 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0082
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0142
============================================================


============================================================
🔄 Round 400 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 400 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0070
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0052
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 400 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 400 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 400 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 407 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 407 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0072
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0039
============================================================


============================================================
🔄 Round 409 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 409 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0086
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0033
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 409 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 412 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 412 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0047
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0077
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 414 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 414 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0083
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0005
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 415 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 415 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0068
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0105
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 415 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 415 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 415 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 427 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 427 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0068
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0054
============================================================


============================================================
🔄 Round 428 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 428 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0069
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0049
============================================================


============================================================
🔄 Round 429 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 429 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0062
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0025
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 430 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 430 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0066
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0050
============================================================


============================================================
🔄 Round 431 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 431 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0048
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0109
============================================================


============================================================
🔄 Round 433 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 433 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0050
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0118
============================================================


============================================================
🔄 Round 434 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 434 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0058
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0100
============================================================


============================================================
🔄 Round 435 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 435 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0066
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0127
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 436 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 436 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0053
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0043
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 438 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 438 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0069
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0028
============================================================


============================================================
🔄 Round 439 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 439 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0059
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0091
============================================================


============================================================
🔄 Round 440 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 440 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0058
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0053
============================================================


============================================================
🔄 Round 443 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 443 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0073
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0038
============================================================


============================================================
🔄 Round 444 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 444 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0069
   Val:   Loss=0.0972, RMSE=0.3117, R²=0.0039
============================================================


============================================================
🔄 Round 445 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 445 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0074
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0020
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 445 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 448 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 448 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0062
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0043
============================================================


============================================================
🔄 Round 450 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 450 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0051
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0127
============================================================


============================================================
🔄 Round 451 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 451 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0080
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0003
============================================================


============================================================
🔄 Round 454 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 454 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0073
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0009
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 454 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 456 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 456 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0049
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0125
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 457 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 457 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0065
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0073
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

📊 Round 457 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 460 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 460 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0043
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0088
============================================================


============================================================
🔄 Round 463 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 463 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0080
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0029
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

📊 Round 463 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

📊 Round 463 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 469 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 469 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0053
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0115
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

📊 Round 469 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 473 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 473 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0079
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0026
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 478 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 478 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0037
   Val:   Loss=0.0891, RMSE=0.2986, R²=0.0093
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0029

============================================================
🔄 Round 479 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 479 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0064
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0075
============================================================


============================================================
🔄 Round 481 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 481 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0071
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0016
============================================================


============================================================
🔄 Round 482 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 482 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0062
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0054
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 483 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 483 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0084
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0001
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 484 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 484 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0066
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0022
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 486 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 486 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0056
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0138
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 487 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 487 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0063
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0044
============================================================


============================================================
🔄 Round 489 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 489 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0066
   Val:   Loss=0.0842, RMSE=0.2903, R²=-0.0127
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 494 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 494 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0065
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0057
============================================================


============================================================
🔄 Round 495 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 495 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0073
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0009
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 495 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 495 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 503 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 503 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0062
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0080
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 504 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 504 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0085
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0023
============================================================


============================================================
🔄 Round 505 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 505 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0060
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0080
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 506 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 506 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0055
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0087
============================================================


============================================================
🔄 Round 507 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 507 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0042
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0143
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 512 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 512 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0051
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0118
============================================================


============================================================
🔄 Round 513 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 513 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0069
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0041
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 516 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 516 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0061
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0022
============================================================


============================================================
🔄 Round 517 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 517 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0058
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0084
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 518 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 518 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0055
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0103
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 518 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 523 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 523 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0068
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0030
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 524 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 524 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0068
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0051
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 524 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 526 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 526 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0069
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0054
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 527 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 527 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0066
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0067
============================================================


============================================================
🔄 Round 530 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 530 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0043
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0031
============================================================


============================================================
🔄 Round 532 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 532 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0071
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0045
============================================================


============================================================
🔄 Round 533 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 533 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0049
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0095
============================================================


============================================================
🔄 Round 535 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 535 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0071
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0048
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 536 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 536 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0091
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0048
============================================================


============================================================
🔄 Round 539 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 539 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0057
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0104
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 539 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 541 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 541 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0053
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0009
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 541 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 543 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 543 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0074
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0033
============================================================


============================================================
🔄 Round 544 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 544 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0047
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0091
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 545 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 545 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0052
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0065
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

📊 Round 545 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

📊 Round 545 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 549 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 549 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0091
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0143
============================================================


============================================================
🔄 Round 550 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 550 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0073
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0020
============================================================


============================================================
🔄 Round 551 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 551 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0069
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0047
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 554 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 554 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0067
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0060
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 558 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 558 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0077
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0038
============================================================


============================================================
🔄 Round 559 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 559 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0029
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0155
============================================================


============================================================
🔄 Round 560 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 560 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0057
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0094
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 562 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 562 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0061
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0081
============================================================


============================================================
🔄 Round 563 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 563 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0045
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0023
============================================================


============================================================
🔄 Round 567 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 567 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0075
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0003
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

📊 Round 567 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

📊 Round 567 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 572 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 572 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0071
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0022
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 576 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 576 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0068
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0056
============================================================


============================================================
🔄 Round 580 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 580 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0056
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0034
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

📊 Round 580 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 583 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 583 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0063
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0038
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 586 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 586 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0056
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0095
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 588 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 588 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0046
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0136
============================================================


============================================================
🔄 Round 590 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 590 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0075
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0019
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0035

📊 Round 590 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0035

============================================================
🔄 Round 593 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 593 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0071
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0020
============================================================


============================================================
🔄 Round 594 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 594 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0089
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0025
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0035

============================================================
🔄 Round 595 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 595 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0058
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0050
============================================================


============================================================
🔄 Round 596 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 596 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0048
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0039
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0035

📊 Round 596 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0035

📊 Round 596 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0035

============================================================
🔄 Round 599 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 599 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0084
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0074
============================================================


============================================================
🔄 Round 601 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 601 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0052
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0075
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2432, R²: 0.0035

============================================================
🔄 Round 607 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 607 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0063
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0046
============================================================


============================================================
🔄 Round 608 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 608 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0061
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0019
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0035

============================================================
🔄 Round 610 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 610 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0075
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0048
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 612 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 612 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0062
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0072
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 615 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 615 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0025
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0471
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 616 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 616 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0079
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0012
============================================================


============================================================
🔄 Round 618 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 618 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0045
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0087
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 622 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 622 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0077
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0023
============================================================


============================================================
🔄 Round 623 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 623 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0067
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0043
============================================================


============================================================
🔄 Round 627 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 627 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0058
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0101
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 628 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 628 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0076
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0005
============================================================


============================================================
🔄 Round 629 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 629 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0086
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0104
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 630 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 630 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0058
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0043
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0035

📊 Round 630 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0035

============================================================
🔄 Round 634 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 634 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0050
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0129
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 635 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 635 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0042
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0162
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 636 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 636 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0067
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0030
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 637 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 637 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0068
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0043
============================================================


============================================================
🔄 Round 638 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 638 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0054
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0003
============================================================


============================================================
🔄 Round 639 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 639 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0073
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0136
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 639 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 639 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 639 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 639 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 639 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 650 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 650 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0071
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0046
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 652 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 652 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0073
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0039
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 652 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 652 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 656 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 656 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0079
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0009
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 658 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 658 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0070
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0039
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 661 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 661 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0057
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0088
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 661 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 666 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 666 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0072
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0009
============================================================


📊 Round 666 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 666 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 668 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 668 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0058
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0021
============================================================


📊 Round 668 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 668 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 668 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 668 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 675 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 675 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0072
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0068
============================================================


📊 Round 675 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 675 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 677 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 677 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0069
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0054
============================================================


============================================================
🔄 Round 680 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 680 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0073
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0027
============================================================


📊 Round 680 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 681 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 681 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0049
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0002
============================================================


============================================================
🔄 Round 682 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 682 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0085
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0273
============================================================


📊 Round 682 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 684 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 684 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0081
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0010
============================================================


============================================================
🔄 Round 685 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 685 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0049
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0245
============================================================


📊 Round 685 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 687 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 687 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0077
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0018
============================================================


📊 Round 687 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 687 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 687 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 687 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 693 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 693 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0069
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0047
============================================================


============================================================
🔄 Round 694 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 694 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0062
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0037
============================================================


📊 Round 694 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 696 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 696 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0070
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0006
============================================================


📊 Round 696 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 696 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 702 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 702 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0077
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0001
============================================================


============================================================
🔄 Round 706 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 706 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0055
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0090
============================================================


============================================================
🔄 Round 707 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 707 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0055
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0003
============================================================


============================================================
🔄 Round 709 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 709 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0054
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0099
============================================================


📊 Round 709 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 713 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 713 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0065
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0062
============================================================


============================================================
🔄 Round 714 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 714 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0073
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0031
============================================================


📊 Round 714 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 715 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 715 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0064
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0069
============================================================


📊 Round 715 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 715 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 715 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 718 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 718 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0073
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0033
============================================================


📊 Round 718 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 721 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 721 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0079
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0041
============================================================


📊 Round 721 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 723 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 723 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0038
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0094
============================================================


============================================================
🔄 Round 724 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 724 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0072
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0036
============================================================


============================================================
🔄 Round 725 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 725 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0065
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0067
============================================================


============================================================
🔄 Round 726 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 726 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0066
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0009
============================================================


============================================================
🔄 Round 727 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 727 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0024
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0198
============================================================


📊 Round 727 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 733 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 733 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0047
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0044
============================================================


📊 Round 733 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

📊 Round 733 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

============================================================
🔄 Round 737 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 737 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0070
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0045
============================================================


📊 Round 737 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0034

📊 Round 737 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 741 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 741 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0047
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0102
============================================================


📊 Round 741 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 743 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 743 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0040
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0166
============================================================


============================================================
🔄 Round 746 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 746 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0077
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0005
============================================================


📊 Round 746 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 750 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 750 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0043
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0154
============================================================


📊 Round 750 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 753 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 753 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0045
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0407
============================================================


📊 Round 753 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

📊 Round 753 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 757 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 757 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0051
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0022
============================================================


📊 Round 757 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 760 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 760 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0069
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0027
============================================================


📊 Round 760 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 763 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 763 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0085
   Val:   Loss=0.0953, RMSE=0.3088, R²=-0.0008
============================================================


📊 Round 763 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 765 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 765 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0055
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0057
============================================================


📊 Round 765 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0033

============================================================
🔄 Round 766 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 766 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0078
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0006
============================================================


📊 Round 766 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 769 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 769 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0061
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0073
============================================================


============================================================
🔄 Round 771 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 771 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0063
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0033
============================================================


============================================================
🔄 Round 772 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 772 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0074
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0008
============================================================


============================================================
🔄 Round 773 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 773 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0040
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0061
============================================================


📊 Round 773 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 773 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

📊 Round 773 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 778 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 778 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0075
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0014
============================================================


📊 Round 778 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0032

============================================================
🔄 Round 782 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 782 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0062
   Val:   Loss=0.0951, RMSE=0.3083, R²=-0.0062
============================================================


📊 Round 782 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 782 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 782 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 788 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 788 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0063
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0071
============================================================


📊 Round 788 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 788 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

============================================================
🔄 Round 792 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 792 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0071
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0018
============================================================


============================================================
🔄 Round 793 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 793 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0079
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0002
============================================================


📊 Round 793 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 793 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0031

📊 Round 793 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

============================================================
🔄 Round 801 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 801 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0071
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0040
============================================================


============================================================
🔄 Round 803 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 803 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0053
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0077
============================================================


============================================================
🔄 Round 804 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 804 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0061
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0084
============================================================


============================================================
🔄 Round 806 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 806 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0077
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0011
============================================================


📊 Round 806 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: 0.0030

❌ Client client_1 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8686 {grpc_status:14, grpc_message:"Socket closed"}"
>
